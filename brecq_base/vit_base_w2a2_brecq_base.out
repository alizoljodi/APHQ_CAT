Starting ViT-Base W2A2 BRECQ experiment at Mon Sep  8 03:57:32 PM CEST 2025
2025-09-08 15:57:32,620 - INFO - Starting multi-seed experiment
2025-09-08 15:57:32,620 - INFO - Architecture: vit_base
2025-09-08 15:57:32,620 - INFO - Weight bits: 2
2025-09-08 15:57:32,620 - INFO - Activation bits: 2
2025-09-08 15:57:32,620 - INFO - Seeds: [1001, 1002, 1003]
2025-09-08 15:57:32,620 - INFO - Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
2025-09-08 15:57:32,620 - INFO - Cluster numbers: [8, 16, 32, 64, 128, 256]
2025-09-08 15:57:32,620 - INFO - PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]
2025-09-08 15:57:32,620 - INFO - Output directory: ./experiment_results/vit_base_w2_a2_20250908_155732
2025-09-08 15:57:32,620 - INFO - Checking basic requirements...
2025-09-08 15:57:32,620 - INFO - Basic checks passed
2025-09-08 15:57:32,620 - INFO - 
Starting experiments for 3 seeds...
2025-09-08 15:57:32,620 - INFO - Total parameter combinations: 600
2025-09-08 15:57:32,620 - INFO - Total experiments: 1800
2025-09-08 15:57:32,620 - INFO - 
============================================================
2025-09-08 15:57:32,620 - INFO - Running experiment 1/3 for seed 1001
2025-09-08 15:57:32,620 - INFO - ============================================================
2025-09-08 15:57:32,620 - INFO - Running experiment for seed 1001
2025-09-08 15:57:32,621 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model vit_base --w_bit 2 --a_bit 2 --seed 1001 --config ../configs/4bit/brecq_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-08 15:57:32,621 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/brecq_base
2025-09-08 15:59:05 - start the process.
Namespace(model='vit_base', config='../configs/4bit/brecq_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1001, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=2, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 2
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: rinp
drop_prob: 1.0
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/vit_base_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
[timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 10.790 (10.790)	Loss 0.4459 (0.4459)	Prec@1 91.400 (91.400)	Prec@5 98.600 (98.600)
Test: [10/100]	Time 0.766 (1.747)	Loss 0.4659 (0.5379)	Prec@1 90.800 (88.455)	Prec@5 98.600 (98.345)
Test: [20/100]	Time 0.779 (1.598)	Loss 0.6057 (0.5588)	Prec@1 85.800 (88.124)	Prec@5 98.600 (98.095)
Test: [30/100]	Time 0.780 (1.344)	Loss 0.5066 (0.5820)	Prec@1 89.800 (87.471)	Prec@5 99.600 (98.045)
Test: [40/100]	Time 3.643 (1.317)	Loss 0.7571 (0.5772)	Prec@1 81.400 (87.532)	Prec@5 97.000 (98.088)
Test: [50/100]	Time 0.785 (1.221)	Loss 1.0069 (0.6165)	Prec@1 77.000 (86.384)	Prec@5 95.200 (97.827)
Test: [60/100]	Time 1.055 (1.211)	Loss 0.5700 (0.6205)	Prec@1 89.200 (86.285)	Prec@5 97.200 (97.751)
Test: [70/100]	Time 0.792 (1.240)	Loss 0.7296 (0.6361)	Prec@1 83.800 (85.673)	Prec@5 97.400 (97.654)
Test: [80/100]	Time 4.711 (1.289)	Loss 0.5101 (0.6392)	Prec@1 88.400 (85.605)	Prec@5 98.000 (97.580)
Test: [90/100]	Time 0.792 (1.262)	Loss 0.9420 (0.6541)	Prec@1 75.000 (85.062)	Prec@5 95.800 (97.495)
 * Prec@1 85.102 Prec@5 97.526 Loss 0.652 Time 122.191
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-08 16:01:43 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:11<14:18, 11.77s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:11<14:18, 11.77s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [01:25<58:11, 48.49s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [01:25<58:11, 48.49s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [01:51<44:51, 37.90s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [01:51<44:51, 37.90s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [03:02<59:43, 51.19s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [03:02<59:43, 51.19s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [04:03<1:02:48, 54.62s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [04:03<1:02:48, 54.62s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [05:56<1:24:25, 74.49s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [05:56<1:24:25, 74.49s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [07:52<1:38:13, 87.97s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [07:52<1:38:13, 87.97s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [09:08<1:32:41, 84.26s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [09:08<1:32:41, 84.26s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [09:35<1:11:42, 66.20s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [09:35<1:11:42, 66.20s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [10:46<1:12:23, 67.87s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [10:46<1:12:23, 67.87s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [11:47<1:08:56, 65.66s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [11:47<1:08:56, 65.66s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [13:40<1:22:39, 79.98s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [13:40<1:22:39, 79.98s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [15:35<1:32:12, 90.70s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [15:35<1:32:12, 90.70s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [16:51<1:26:07, 86.13s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [16:51<1:26:07, 86.13s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [17:17<1:06:57, 68.10s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [17:17<1:06:57, 68.10s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [18:29<1:06:56, 69.25s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [18:29<1:06:56, 69.25s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [19:30<1:03:21, 66.70s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [19:30<1:03:21, 66.70s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [21:23<1:15:18, 80.69s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [21:23<1:15:18, 80.69s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [23:19<1:23:44, 91.35s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [23:19<1:23:44, 91.35s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [24:35<1:18:02, 86.70s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [24:35<1:18:02, 86.70s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [25:01<1:00:35, 68.60s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [25:01<1:00:35, 68.60s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [26:13<1:00:23, 69.68s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [26:13<1:00:23, 69.68s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [27:15<57:01, 67.09s/it]  calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [27:15<57:01, 67.09s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [29:08<1:07:30, 81.01s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [29:08<1:07:30, 81.01s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [31:04<1:14:49, 91.62s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [31:04<1:14:49, 91.62s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [32:21<1:09:43, 87.15s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [32:21<1:09:43, 87.15s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [32:48<54:00, 68.94s/it]  calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [32:48<54:00, 68.94s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [33:59<53:29, 69.78s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [33:59<53:29, 69.78s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [35:00<50:18, 67.07s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [35:00<50:18, 67.07s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [36:53<59:20, 80.91s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [36:53<59:20, 80.91s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [38:49<1:05:28, 91.37s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [38:49<1:05:28, 91.37s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [40:05<1:00:42, 86.72s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [40:05<1:00:42, 86.72s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [40:31<46:54, 68.64s/it]  calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [40:31<46:54, 68.64s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [41:44<46:31, 69.78s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [41:44<46:31, 69.78s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [42:45<43:41, 67.23s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [42:45<43:41, 67.23s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [44:39<51:23, 81.16s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [44:39<51:23, 81.16s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [46:35<56:36, 91.79s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [46:35<56:36, 91.79s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [47:52<52:21, 87.27s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [47:52<52:21, 87.27s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [48:18<40:09, 68.85s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [48:18<40:09, 68.85s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [49:29<39:27, 69.65s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [49:29<39:27, 69.65s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [50:30<36:48, 66.91s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [50:30<36:48, 66.91s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [52:23<43:03, 80.75s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [52:23<43:03, 80.75s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [54:19<47:09, 91.27s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [54:19<47:09, 91.27s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [55:34<43:18, 86.60s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [55:35<43:18, 86.60s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [56:01<33:06, 68.50s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [56:01<33:06, 68.50s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [57:13<32:25, 69.50s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [57:13<32:25, 69.50s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [58:13<30:03, 66.81s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [58:13<30:03, 66.81s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [1:00:07<35:03, 80.91s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [1:00:07<35:03, 80.91s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [1:02:04<38:11, 91.68s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [1:02:04<38:11, 91.68s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [1:03:21<34:52, 87.21s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [1:03:21<34:52, 87.21s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [1:03:47<26:26, 68.97s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [1:03:47<26:26, 68.97s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [1:04:59<25:41, 70.05s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [1:04:59<25:41, 70.05s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [1:06:00<23:28, 67.08s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [1:06:00<23:28, 67.08s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [1:07:52<26:51, 80.56s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [1:07:52<26:51, 80.56s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [1:09:47<28:46, 90.86s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [1:09:47<28:46, 90.86s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [1:11:02<25:49, 86.09s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [1:11:02<25:49, 86.09s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [1:11:27<19:16, 68.02s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [1:11:27<19:16, 68.02s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [1:12:39<18:25, 69.09s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [1:12:39<18:25, 69.09s/it]calibrating blocks.9.attn.matmul2:  80%|███████▉  | 59/74 [1:13:40<16:38, 66.53s/it]calibrating blocks.9.mlp.fc1:  80%|███████▉  | 59/74 [1:13:40<16:38, 66.53s/it]     calibrating blocks.9.mlp.fc1:  81%|████████  | 60/74 [1:15:32<18:46, 80.44s/it]calibrating blocks.9.mlp.fc2:  81%|████████  | 60/74 [1:15:32<18:46, 80.44s/it]calibrating blocks.9.mlp.fc2:  82%|████████▏ | 61/74 [1:17:29<19:44, 91.15s/it]calibrating blocks.10.attn.qkv:  82%|████████▏ | 61/74 [1:17:29<19:44, 91.15s/it]calibrating blocks.10.attn.qkv:  84%|████████▍ | 62/74 [1:18:45<17:20, 86.73s/it]calibrating blocks.10.attn.proj:  84%|████████▍ | 62/74 [1:18:45<17:20, 86.73s/it]calibrating blocks.10.attn.proj:  85%|████████▌ | 63/74 [1:19:11<12:34, 68.63s/it]calibrating blocks.10.attn.matmul1:  85%|████████▌ | 63/74 [1:19:11<12:34, 68.63s/it]calibrating blocks.10.attn.matmul1:  86%|████████▋ | 64/74 [1:20:24<11:37, 69.75s/it]calibrating blocks.10.attn.matmul2:  86%|████████▋ | 64/74 [1:20:24<11:37, 69.75s/it]calibrating blocks.10.attn.matmul2:  88%|████████▊ | 65/74 [1:21:25<10:04, 67.15s/it]calibrating blocks.10.mlp.fc1:  88%|████████▊ | 65/74 [1:21:25<10:04, 67.15s/it]     calibrating blocks.10.mlp.fc1:  89%|████████▉ | 66/74 [1:23:18<10:47, 80.96s/it]calibrating blocks.10.mlp.fc2:  89%|████████▉ | 66/74 [1:23:18<10:47, 80.96s/it]calibrating blocks.10.mlp.fc2:  91%|█████████ | 67/74 [1:25:15<10:41, 91.71s/it]calibrating blocks.11.attn.qkv:  91%|█████████ | 67/74 [1:25:15<10:41, 91.71s/it]calibrating blocks.11.attn.qkv:  92%|█████████▏| 68/74 [1:26:31<08:42, 87.08s/it]calibrating blocks.11.attn.proj:  92%|█████████▏| 68/74 [1:26:31<08:42, 87.08s/it]calibrating blocks.11.attn.proj:  93%|█████████▎| 69/74 [1:26:58<05:44, 68.90s/it]calibrating blocks.11.attn.matmul1:  93%|█████████▎| 69/74 [1:26:58<05:44, 68.90s/it]calibrating blocks.11.attn.matmul1:  95%|█████████▍| 70/74 [1:28:10<04:39, 69.84s/it]calibrating blocks.11.attn.matmul2:  95%|█████████▍| 70/74 [1:28:10<04:39, 69.84s/it]calibrating blocks.11.attn.matmul2:  96%|█████████▌| 71/74 [1:29:11<03:21, 67.23s/it]calibrating blocks.11.mlp.fc1:  96%|█████████▌| 71/74 [1:29:11<03:21, 67.23s/it]     calibrating blocks.11.mlp.fc1:  97%|█████████▋| 72/74 [1:31:04<02:42, 81.15s/it]calibrating blocks.11.mlp.fc2:  97%|█████████▋| 72/74 [1:31:04<02:42, 81.15s/it]calibrating blocks.11.mlp.fc2:  99%|█████████▊| 73/74 [1:33:01<01:31, 91.91s/it]calibrating head:  99%|█████████▊| 73/74 [1:33:01<01:31, 91.91s/it]             calibrating head: 100%|██████████| 74/74 [1:33:05<00:00, 65.39s/it]calibrating head: 100%|██████████| 74/74 [1:33:05<00:00, 75.48s/it]
2025-09-08 17:35:16 - mse guided calibration finished.
Saving checkpoint to ./checkpoint/quant_result/20250908_1559/vit_base_w2_a2_calibsize_1000_mse.pth
Validating after calibration ...
Test: [0/100]	Time 4.796 (4.796)	Loss 7.2188 (7.2188)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [10/100]	Time 1.661 (1.950)	Loss 7.9073 (7.5052)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.073)
Test: [20/100]	Time 1.668 (1.813)	Loss 7.1765 (7.4677)	Prec@1 0.000 (0.000)	Prec@5 0.800 (0.124)
Test: [30/100]	Time 1.662 (1.764)	Loss 7.1385 (7.3709)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.510)
Test: [40/100]	Time 1.658 (1.739)	Loss 7.2513 (7.3349)	Prec@1 0.000 (0.234)	Prec@5 1.200 (0.790)
Test: [50/100]	Time 1.659 (1.724)	Loss 7.9617 (7.3204)	Prec@1 0.000 (0.192)	Prec@5 0.000 (0.698)
Test: [60/100]	Time 1.659 (1.714)	Loss 7.6363 (7.3240)	Prec@1 0.000 (0.161)	Prec@5 0.000 (0.620)
Test: [70/100]	Time 1.663 (1.706)	Loss 6.8905 (7.3122)	Prec@1 0.000 (0.138)	Prec@5 0.000 (0.555)
Test: [80/100]	Time 1.665 (1.701)	Loss 7.3137 (7.3182)	Prec@1 0.000 (0.121)	Prec@5 0.000 (0.491)
Test: [90/100]	Time 1.663 (1.697)	Loss 7.3144 (7.3193)	Prec@1 0.000 (0.108)	Prec@5 0.000 (0.448)
 * Prec@1 0.098 Prec@5 0.482 Loss 7.322 Time 169.597
Building calibrator ...
2025-09-08 17:38:10 - start mse guided block reconstruction
reconstructing patch_embed ...
initializing raw input and raw output ...
adaround training for patch_embed ...
wraping quantizers in patch_embed ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.055 (rec:0.055, round:0.000)	b=0.00	count=500
Total loss:	0.024 (rec:0.024, round:0.000)	b=0.00	count=1000
Total loss:	0.022 (rec:0.022, round:0.000)	b=0.00	count=1500
Total loss:	0.020 (rec:0.020, round:0.000)	b=0.00	count=2000
Total loss:	0.014 (rec:0.014, round:0.000)	b=0.00	count=2500
Total loss:	0.018 (rec:0.018, round:0.000)	b=0.00	count=3000
Total loss:	0.009 (rec:0.009, round:0.000)	b=0.00	count=3500
Total loss:	5556.044 (rec:0.008, round:5556.036)	b=20.00	count=4000
Total loss:	2797.814 (rec:0.032, round:2797.782)	b=19.44	count=4500
Total loss:	2582.633 (rec:0.030, round:2582.603)	b=18.88	count=5000
Total loss:	2440.220 (rec:0.020, round:2440.200)	b=18.31	count=5500
Total loss:	2317.514 (rec:0.031, round:2317.483)	b=17.75	count=6000
Total loss:	2198.152 (rec:0.027, round:2198.125)	b=17.19	count=6500
Total loss:	2082.104 (rec:0.026, round:2082.078)	b=16.62	count=7000
Total loss:	1962.341 (rec:0.026, round:1962.315)	b=16.06	count=7500
Total loss:	1839.607 (rec:0.013, round:1839.594)	b=15.50	count=8000
Total loss:	1712.788 (rec:0.020, round:1712.768)	b=14.94	count=8500
Total loss:	1584.296 (rec:0.021, round:1584.275)	b=14.38	count=9000
Total loss:	1452.417 (rec:0.020, round:1452.396)	b=13.81	count=9500
Total loss:	1319.228 (rec:0.024, round:1319.205)	b=13.25	count=10000
Total loss:	1181.409 (rec:0.030, round:1181.379)	b=12.69	count=10500
Total loss:	1043.304 (rec:0.028, round:1043.276)	b=12.12	count=11000
Total loss:	903.220 (rec:0.030, round:903.190)	b=11.56	count=11500
Total loss:	763.578 (rec:0.041, round:763.537)	b=11.00	count=12000
Total loss:	629.118 (rec:0.040, round:629.078)	b=10.44	count=12500
Total loss:	499.709 (rec:0.055, round:499.654)	b=9.88	count=13000
Total loss:	376.694 (rec:0.060, round:376.634)	b=9.31	count=13500
Total loss:	266.082 (rec:0.051, round:266.031)	b=8.75	count=14000
Total loss:	175.568 (rec:0.093, round:175.475)	b=8.19	count=14500
Total loss:	104.896 (rec:0.068, round:104.829)	b=7.62	count=15000
Total loss:	57.124 (rec:0.067, round:57.057)	b=7.06	count=15500
Total loss:	26.813 (rec:0.104, round:26.709)	b=6.50	count=16000
Total loss:	11.495 (rec:0.109, round:11.386)	b=5.94	count=16500
Total loss:	4.566 (rec:0.085, round:4.482)	b=5.38	count=17000
Total loss:	2.111 (rec:0.080, round:2.031)	b=4.81	count=17500
Total loss:	1.005 (rec:0.090, round:0.915)	b=4.25	count=18000
Total loss:	0.353 (rec:0.102, round:0.251)	b=3.69	count=18500
Total loss:	0.100 (rec:0.066, round:0.034)	b=3.12	count=19000
Total loss:	0.073 (rec:0.073, round:0.000)	b=2.56	count=19500
Total loss:	0.115 (rec:0.115, round:0.000)	b=2.00	count=20000
finished reconstructing patch_embed.
reconstructing blocks.0 ...
initializing raw input and raw output ...
adaround training for blocks.0 ...
wraping quantizers in blocks.0 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.881 (rec:0.881, round:0.000)	b=0.00	count=500
Total loss:	0.442 (rec:0.442, round:0.000)	b=0.00	count=1000
Total loss:	0.402 (rec:0.402, round:0.000)	b=0.00	count=1500
Total loss:	0.345 (rec:0.345, round:0.000)	b=0.00	count=2000
Total loss:	0.319 (rec:0.319, round:0.000)	b=0.00	count=2500
Total loss:	0.329 (rec:0.329, round:0.000)	b=0.00	count=3000
Total loss:	0.276 (rec:0.276, round:0.000)	b=0.00	count=3500
Total loss:	61866.301 (rec:0.255, round:61866.047)	b=20.00	count=4000
Total loss:	21799.596 (rec:0.260, round:21799.336)	b=19.44	count=4500
Total loss:	19818.504 (rec:0.254, round:19818.250)	b=18.88	count=5000
Total loss:	18513.018 (rec:0.250, round:18512.768)	b=18.31	count=5500
Total loss:	17383.305 (rec:0.234, round:17383.070)	b=17.75	count=6000
Total loss:	16315.696 (rec:0.263, round:16315.434)	b=17.19	count=6500
Total loss:	15306.475 (rec:0.232, round:15306.242)	b=16.62	count=7000
Total loss:	14342.996 (rec:0.227, round:14342.770)	b=16.06	count=7500
Total loss:	13401.105 (rec:0.238, round:13400.867)	b=15.50	count=8000
Total loss:	12496.667 (rec:0.226, round:12496.440)	b=14.94	count=8500
Total loss:	11620.130 (rec:0.231, round:11619.899)	b=14.38	count=9000
Total loss:	10772.614 (rec:0.227, round:10772.388)	b=13.81	count=9500
Total loss:	9951.139 (rec:0.236, round:9950.903)	b=13.25	count=10000
Total loss:	9148.080 (rec:0.223, round:9147.857)	b=12.69	count=10500
Total loss:	8367.273 (rec:0.233, round:8367.040)	b=12.12	count=11000
Total loss:	7602.509 (rec:0.233, round:7602.275)	b=11.56	count=11500
Total loss:	6853.149 (rec:0.217, round:6852.932)	b=11.00	count=12000
Total loss:	6114.731 (rec:0.232, round:6114.500)	b=10.44	count=12500
Total loss:	5396.348 (rec:0.250, round:5396.097)	b=9.88	count=13000
Total loss:	4693.480 (rec:0.234, round:4693.247)	b=9.31	count=13500
Total loss:	4009.734 (rec:0.240, round:4009.495)	b=8.75	count=14000
Total loss:	3352.535 (rec:0.237, round:3352.298)	b=8.19	count=14500
Total loss:	2725.171 (rec:0.247, round:2724.924)	b=7.62	count=15000
Total loss:	2133.101 (rec:0.245, round:2132.856)	b=7.06	count=15500
Total loss:	1587.579 (rec:0.241, round:1587.338)	b=6.50	count=16000
Total loss:	1106.298 (rec:0.248, round:1106.050)	b=5.94	count=16500
Total loss:	708.753 (rec:0.237, round:708.516)	b=5.38	count=17000
Total loss:	398.960 (rec:0.238, round:398.722)	b=4.81	count=17500
Total loss:	183.027 (rec:0.258, round:182.769)	b=4.25	count=18000
Total loss:	60.419 (rec:0.237, round:60.182)	b=3.69	count=18500
Total loss:	11.470 (rec:0.238, round:11.232)	b=3.12	count=19000
Total loss:	1.192 (rec:0.237, round:0.956)	b=2.56	count=19500
Total loss:	0.278 (rec:0.256, round:0.022)	b=2.00	count=20000
finished reconstructing blocks.0.
reconstructing blocks.1 ...
initializing raw input and raw output ...
adaround training for blocks.1 ...
wraping quantizers in blocks.1 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.782 (rec:0.782, round:0.000)	b=0.00	count=500
Total loss:	0.576 (rec:0.576, round:0.000)	b=0.00	count=1000
Total loss:	0.522 (rec:0.522, round:0.000)	b=0.00	count=1500
Total loss:	0.408 (rec:0.408, round:0.000)	b=0.00	count=2000
Total loss:	0.357 (rec:0.357, round:0.000)	b=0.00	count=2500
Total loss:	0.362 (rec:0.362, round:0.000)	b=0.00	count=3000
Total loss:	0.341 (rec:0.341, round:0.000)	b=0.00	count=3500
Total loss:	62113.016 (rec:0.303, round:62112.711)	b=20.00	count=4000
Total loss:	25731.631 (rec:0.302, round:25731.328)	b=19.44	count=4500
Total loss:	23364.279 (rec:0.283, round:23363.996)	b=18.88	count=5000
Total loss:	21671.678 (rec:0.268, round:21671.410)	b=18.31	count=5500
Total loss:	20142.221 (rec:0.270, round:20141.951)	b=17.75	count=6000
Total loss:	18696.506 (rec:0.277, round:18696.229)	b=17.19	count=6500
Total loss:	17307.143 (rec:0.266, round:17306.877)	b=16.62	count=7000
Total loss:	15959.671 (rec:0.258, round:15959.413)	b=16.06	count=7500
Total loss:	14664.840 (rec:0.270, round:14664.570)	b=15.50	count=8000
Total loss:	13423.324 (rec:0.252, round:13423.072)	b=14.94	count=8500
Total loss:	12231.146 (rec:0.263, round:12230.883)	b=14.38	count=9000
Total loss:	11078.291 (rec:0.267, round:11078.024)	b=13.81	count=9500
Total loss:	9997.348 (rec:0.259, round:9997.089)	b=13.25	count=10000
Total loss:	8994.638 (rec:0.278, round:8994.360)	b=12.69	count=10500
Total loss:	8062.387 (rec:0.253, round:8062.134)	b=12.12	count=11000
Total loss:	7180.522 (rec:0.253, round:7180.269)	b=11.56	count=11500
Total loss:	6352.118 (rec:0.254, round:6351.864)	b=11.00	count=12000
Total loss:	5569.729 (rec:0.240, round:5569.489)	b=10.44	count=12500
Total loss:	4824.931 (rec:0.275, round:4824.656)	b=9.88	count=13000
Total loss:	4130.378 (rec:0.264, round:4130.114)	b=9.31	count=13500
Total loss:	3467.696 (rec:0.256, round:3467.440)	b=8.75	count=14000
Total loss:	2844.615 (rec:0.258, round:2844.356)	b=8.19	count=14500
Total loss:	2261.169 (rec:0.264, round:2260.906)	b=7.62	count=15000
Total loss:	1713.973 (rec:0.275, round:1713.698)	b=7.06	count=15500
Total loss:	1202.871 (rec:0.280, round:1202.591)	b=6.50	count=16000
Total loss:	718.905 (rec:0.261, round:718.643)	b=5.94	count=16500
Total loss:	333.605 (rec:0.254, round:333.351)	b=5.38	count=17000
Total loss:	141.509 (rec:0.273, round:141.236)	b=4.81	count=17500
Total loss:	56.795 (rec:0.282, round:56.512)	b=4.25	count=18000
Total loss:	17.428 (rec:0.272, round:17.156)	b=3.69	count=18500
Total loss:	3.408 (rec:0.270, round:3.138)	b=3.12	count=19000
Total loss:	0.532 (rec:0.273, round:0.259)	b=2.56	count=19500
Total loss:	0.255 (rec:0.249, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.1.
reconstructing blocks.2 ...
initializing raw input and raw output ...
adaround training for blocks.2 ...
wraping quantizers in blocks.2 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.864 (rec:0.864, round:0.000)	b=0.00	count=500
Total loss:	0.748 (rec:0.748, round:0.000)	b=0.00	count=1000
Total loss:	0.659 (rec:0.659, round:0.000)	b=0.00	count=1500
Total loss:	0.613 (rec:0.613, round:0.000)	b=0.00	count=2000
Total loss:	0.579 (rec:0.579, round:0.000)	b=0.00	count=2500
Total loss:	0.577 (rec:0.577, round:0.000)	b=0.00	count=3000
Total loss:	0.534 (rec:0.534, round:0.000)	b=0.00	count=3500
Total loss:	62928.824 (rec:0.544, round:62928.281)	b=20.00	count=4000
Total loss:	28611.697 (rec:0.541, round:28611.156)	b=19.44	count=4500
Total loss:	26149.619 (rec:0.525, round:26149.094)	b=18.88	count=5000
Total loss:	24412.719 (rec:0.520, round:24412.199)	b=18.31	count=5500
Total loss:	22864.617 (rec:0.492, round:22864.125)	b=17.75	count=6000
Total loss:	21425.988 (rec:0.495, round:21425.494)	b=17.19	count=6500
Total loss:	20059.422 (rec:0.504, round:20058.918)	b=16.62	count=7000
Total loss:	18742.299 (rec:0.504, round:18741.795)	b=16.06	count=7500
Total loss:	17471.410 (rec:0.479, round:17470.932)	b=15.50	count=8000
Total loss:	16241.487 (rec:0.493, round:16240.994)	b=14.94	count=8500
Total loss:	15053.190 (rec:0.491, round:15052.699)	b=14.38	count=9000
Total loss:	13902.109 (rec:0.495, round:13901.614)	b=13.81	count=9500
Total loss:	12782.761 (rec:0.484, round:12782.277)	b=13.25	count=10000
Total loss:	11703.312 (rec:0.471, round:11702.841)	b=12.69	count=10500
Total loss:	10657.695 (rec:0.478, round:10657.218)	b=12.12	count=11000
Total loss:	9649.162 (rec:0.480, round:9648.682)	b=11.56	count=11500
Total loss:	8668.704 (rec:0.478, round:8668.227)	b=11.00	count=12000
Total loss:	7714.765 (rec:0.480, round:7714.285)	b=10.44	count=12500
Total loss:	6790.913 (rec:0.488, round:6790.425)	b=9.88	count=13000
Total loss:	5895.268 (rec:0.494, round:5894.773)	b=9.31	count=13500
Total loss:	5029.627 (rec:0.502, round:5029.125)	b=8.75	count=14000
Total loss:	4199.939 (rec:0.487, round:4199.452)	b=8.19	count=14500
Total loss:	3403.353 (rec:0.499, round:3402.854)	b=7.62	count=15000
Total loss:	2654.945 (rec:0.496, round:2654.449)	b=7.06	count=15500
Total loss:	1955.671 (rec:0.499, round:1955.172)	b=6.50	count=16000
Total loss:	1297.962 (rec:0.509, round:1297.453)	b=5.94	count=16500
Total loss:	639.737 (rec:0.510, round:639.227)	b=5.38	count=17000
Total loss:	182.052 (rec:0.496, round:181.556)	b=4.81	count=17500
Total loss:	56.087 (rec:0.501, round:55.586)	b=4.25	count=18000
Total loss:	17.049 (rec:0.523, round:16.526)	b=3.69	count=18500
Total loss:	3.530 (rec:0.521, round:3.009)	b=3.12	count=19000
Total loss:	0.724 (rec:0.500, round:0.224)	b=2.56	count=19500
Total loss:	0.514 (rec:0.511, round:0.003)	b=2.00	count=20000
finished reconstructing blocks.2.
reconstructing blocks.3 ...
initializing raw input and raw output ...
adaround training for blocks.3 ...
wraping quantizers in blocks.3 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.949 (rec:0.949, round:0.000)	b=0.00	count=500
Total loss:	0.807 (rec:0.807, round:0.000)	b=0.00	count=1000
Total loss:	0.724 (rec:0.724, round:0.000)	b=0.00	count=1500
Total loss:	0.664 (rec:0.664, round:0.000)	b=0.00	count=2000
Total loss:	0.635 (rec:0.635, round:0.000)	b=0.00	count=2500
Total loss:	0.601 (rec:0.601, round:0.000)	b=0.00	count=3000
Total loss:	0.581 (rec:0.581, round:0.000)	b=0.00	count=3500
Total loss:	63058.555 (rec:0.562, round:63057.992)	b=20.00	count=4000
Total loss:	29019.891 (rec:0.566, round:29019.324)	b=19.44	count=4500
Total loss:	26600.588 (rec:0.542, round:26600.045)	b=18.88	count=5000
Total loss:	24914.301 (rec:0.554, round:24913.746)	b=18.31	count=5500
Total loss:	23417.625 (rec:0.534, round:23417.092)	b=17.75	count=6000
Total loss:	22012.609 (rec:0.526, round:22012.084)	b=17.19	count=6500
Total loss:	20664.279 (rec:0.527, round:20663.752)	b=16.62	count=7000
Total loss:	19362.137 (rec:0.536, round:19361.602)	b=16.06	count=7500
Total loss:	18102.043 (rec:0.540, round:18101.504)	b=15.50	count=8000
Total loss:	16868.066 (rec:0.527, round:16867.539)	b=14.94	count=8500
Total loss:	15662.379 (rec:0.520, round:15661.859)	b=14.38	count=9000
Total loss:	14492.208 (rec:0.516, round:14491.691)	b=13.81	count=9500
Total loss:	13344.498 (rec:0.519, round:13343.979)	b=13.25	count=10000
Total loss:	12236.350 (rec:0.523, round:12235.826)	b=12.69	count=10500
Total loss:	11154.344 (rec:0.523, round:11153.820)	b=12.12	count=11000
Total loss:	10099.498 (rec:0.524, round:10098.974)	b=11.56	count=11500
Total loss:	9068.229 (rec:0.521, round:9067.708)	b=11.00	count=12000
Total loss:	8069.156 (rec:0.530, round:8068.626)	b=10.44	count=12500
Total loss:	7098.094 (rec:0.519, round:7097.575)	b=9.88	count=13000
Total loss:	6152.764 (rec:0.523, round:6152.241)	b=9.31	count=13500
Total loss:	5238.726 (rec:0.547, round:5238.179)	b=8.75	count=14000
Total loss:	4364.843 (rec:0.540, round:4364.303)	b=8.19	count=14500
Total loss:	3527.556 (rec:0.537, round:3527.019)	b=7.62	count=15000
Total loss:	2742.226 (rec:0.538, round:2741.688)	b=7.06	count=15500
Total loss:	2016.574 (rec:0.534, round:2016.040)	b=6.50	count=16000
Total loss:	1340.772 (rec:0.551, round:1340.221)	b=5.94	count=16500
Total loss:	677.343 (rec:0.548, round:676.795)	b=5.38	count=17000
Total loss:	215.188 (rec:0.547, round:214.641)	b=4.81	count=17500
Total loss:	64.946 (rec:0.551, round:64.395)	b=4.25	count=18000
Total loss:	18.669 (rec:0.554, round:18.115)	b=3.69	count=18500
Total loss:	3.918 (rec:0.554, round:3.364)	b=3.12	count=19000
Total loss:	0.841 (rec:0.555, round:0.286)	b=2.56	count=19500
Total loss:	0.560 (rec:0.555, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.3.
reconstructing blocks.4 ...
initializing raw input and raw output ...
adaround training for blocks.4 ...
wraping quantizers in blocks.4 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.014 (rec:1.014, round:0.000)	b=0.00	count=500
Total loss:	0.860 (rec:0.860, round:0.000)	b=0.00	count=1000
Total loss:	0.789 (rec:0.789, round:0.000)	b=0.00	count=1500
Total loss:	0.714 (rec:0.714, round:0.000)	b=0.00	count=2000
Total loss:	0.677 (rec:0.677, round:0.000)	b=0.00	count=2500
Total loss:	0.648 (rec:0.648, round:0.000)	b=0.00	count=3000
Total loss:	0.626 (rec:0.626, round:0.000)	b=0.00	count=3500
Total loss:	63290.254 (rec:0.591, round:63289.664)	b=20.00	count=4000
Total loss:	29463.109 (rec:0.594, round:29462.516)	b=19.44	count=4500
Total loss:	27053.941 (rec:0.568, round:27053.373)	b=18.88	count=5000
Total loss:	25390.678 (rec:0.571, round:25390.107)	b=18.31	count=5500
Total loss:	23930.248 (rec:0.573, round:23929.676)	b=17.75	count=6000
Total loss:	22561.258 (rec:0.571, round:22560.686)	b=17.19	count=6500
Total loss:	21250.307 (rec:0.558, round:21249.748)	b=16.62	count=7000
Total loss:	19985.742 (rec:0.548, round:19985.193)	b=16.06	count=7500
Total loss:	18753.879 (rec:0.562, round:18753.316)	b=15.50	count=8000
Total loss:	17556.947 (rec:0.546, round:17556.400)	b=14.94	count=8500
Total loss:	16384.254 (rec:0.549, round:16383.705)	b=14.38	count=9000
Total loss:	15243.873 (rec:0.555, round:15243.318)	b=13.81	count=9500
Total loss:	14131.165 (rec:0.555, round:14130.610)	b=13.25	count=10000
Total loss:	13039.786 (rec:0.557, round:13039.229)	b=12.69	count=10500
Total loss:	11973.968 (rec:0.567, round:11973.401)	b=12.12	count=11000
Total loss:	10924.050 (rec:0.555, round:10923.494)	b=11.56	count=11500
Total loss:	9892.639 (rec:0.553, round:9892.086)	b=11.00	count=12000
Total loss:	8876.106 (rec:0.544, round:8875.562)	b=10.44	count=12500
Total loss:	7878.245 (rec:0.544, round:7877.701)	b=9.88	count=13000
Total loss:	6892.257 (rec:0.552, round:6891.705)	b=9.31	count=13500
Total loss:	5938.313 (rec:0.573, round:5937.741)	b=8.75	count=14000
Total loss:	5003.482 (rec:0.567, round:5002.915)	b=8.19	count=14500
Total loss:	4102.232 (rec:0.581, round:4101.651)	b=7.62	count=15000
Total loss:	3235.593 (rec:0.574, round:3235.020)	b=7.06	count=15500
Total loss:	2419.711 (rec:0.576, round:2419.135)	b=6.50	count=16000
Total loss:	1664.722 (rec:0.578, round:1664.144)	b=5.94	count=16500
Total loss:	953.686 (rec:0.590, round:953.097)	b=5.38	count=17000
Total loss:	297.719 (rec:0.590, round:297.129)	b=4.81	count=17500
Total loss:	63.687 (rec:0.607, round:63.080)	b=4.25	count=18000
Total loss:	17.832 (rec:0.602, round:17.231)	b=3.69	count=18500
Total loss:	3.774 (rec:0.597, round:3.176)	b=3.12	count=19000
Total loss:	0.850 (rec:0.599, round:0.252)	b=2.56	count=19500
Total loss:	0.590 (rec:0.584, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.4.
reconstructing blocks.5 ...
initializing raw input and raw output ...
adaround training for blocks.5 ...
wraping quantizers in blocks.5 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.060 (rec:1.060, round:0.000)	b=0.00	count=500
Total loss:	0.868 (rec:0.868, round:0.000)	b=0.00	count=1000
Total loss:	0.809 (rec:0.809, round:0.000)	b=0.00	count=1500
Total loss:	0.737 (rec:0.737, round:0.000)	b=0.00	count=2000
Total loss:	0.685 (rec:0.685, round:0.000)	b=0.00	count=2500
Total loss:	0.635 (rec:0.635, round:0.000)	b=0.00	count=3000
Total loss:	0.613 (rec:0.613, round:0.000)	b=0.00	count=3500
Total loss:	63100.426 (rec:0.590, round:63099.836)	b=20.00	count=4000
Total loss:	29001.301 (rec:0.581, round:29000.719)	b=19.44	count=4500
Total loss:	26568.064 (rec:0.559, round:26567.506)	b=18.88	count=5000
Total loss:	24862.102 (rec:0.555, round:24861.547)	b=18.31	count=5500
Total loss:	23338.955 (rec:0.553, round:23338.402)	b=17.75	count=6000
Total loss:	21909.430 (rec:0.546, round:21908.883)	b=17.19	count=6500
Total loss:	20543.178 (rec:0.541, round:20542.637)	b=16.62	count=7000
Total loss:	19234.920 (rec:0.531, round:19234.389)	b=16.06	count=7500
Total loss:	17969.990 (rec:0.542, round:17969.449)	b=15.50	count=8000
Total loss:	16743.963 (rec:0.544, round:16743.418)	b=14.94	count=8500
Total loss:	15569.708 (rec:0.526, round:15569.183)	b=14.38	count=9000
Total loss:	14432.829 (rec:0.529, round:14432.300)	b=13.81	count=9500
Total loss:	13330.995 (rec:0.529, round:13330.467)	b=13.25	count=10000
Total loss:	12263.068 (rec:0.545, round:12262.523)	b=12.69	count=10500
Total loss:	11224.187 (rec:0.531, round:11223.656)	b=12.12	count=11000
Total loss:	10212.190 (rec:0.528, round:10211.662)	b=11.56	count=11500
Total loss:	9226.146 (rec:0.530, round:9225.616)	b=11.00	count=12000
Total loss:	8263.119 (rec:0.539, round:8262.580)	b=10.44	count=12500
Total loss:	7327.755 (rec:0.531, round:7327.224)	b=9.88	count=13000
Total loss:	6407.088 (rec:0.532, round:6406.557)	b=9.31	count=13500
Total loss:	5512.204 (rec:0.535, round:5511.669)	b=8.75	count=14000
Total loss:	4644.011 (rec:0.544, round:4643.466)	b=8.19	count=14500
Total loss:	3807.271 (rec:0.538, round:3806.733)	b=7.62	count=15000
Total loss:	3004.058 (rec:0.548, round:3003.510)	b=7.06	count=15500
Total loss:	2241.916 (rec:0.550, round:2241.366)	b=6.50	count=16000
Total loss:	1528.380 (rec:0.550, round:1527.830)	b=5.94	count=16500
Total loss:	832.746 (rec:0.558, round:832.189)	b=5.38	count=17000
Total loss:	229.969 (rec:0.563, round:229.406)	b=4.81	count=17500
Total loss:	54.852 (rec:0.561, round:54.291)	b=4.25	count=18000
Total loss:	16.438 (rec:0.573, round:15.864)	b=3.69	count=18500
Total loss:	3.568 (rec:0.581, round:2.986)	b=3.12	count=19000
Total loss:	0.808 (rec:0.558, round:0.250)	b=2.56	count=19500
Total loss:	0.572 (rec:0.568, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.5.
reconstructing blocks.6 ...
initializing raw input and raw output ...
adaround training for blocks.6 ...
wraping quantizers in blocks.6 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.237 (rec:1.237, round:0.000)	b=0.00	count=500
Total loss:	1.040 (rec:1.040, round:0.000)	b=0.00	count=1000
Total loss:	0.963 (rec:0.963, round:0.000)	b=0.00	count=1500
Total loss:	0.916 (rec:0.916, round:0.000)	b=0.00	count=2000
Total loss:	0.833 (rec:0.833, round:0.000)	b=0.00	count=2500
Total loss:	0.810 (rec:0.810, round:0.000)	b=0.00	count=3000
Total loss:	0.779 (rec:0.779, round:0.000)	b=0.00	count=3500
Total loss:	62507.004 (rec:0.742, round:62506.262)	b=20.00	count=4000
Total loss:	28786.566 (rec:0.714, round:28785.852)	b=19.44	count=4500
Total loss:	26331.607 (rec:0.691, round:26330.916)	b=18.88	count=5000
Total loss:	24579.918 (rec:0.697, round:24579.221)	b=18.31	count=5500
Total loss:	23023.543 (rec:0.668, round:23022.875)	b=17.75	count=6000
Total loss:	21565.576 (rec:0.664, round:21564.912)	b=17.19	count=6500
Total loss:	20175.354 (rec:0.669, round:20174.684)	b=16.62	count=7000
Total loss:	18843.859 (rec:0.675, round:18843.184)	b=16.06	count=7500
Total loss:	17570.166 (rec:0.669, round:17569.496)	b=15.50	count=8000
Total loss:	16351.788 (rec:0.657, round:16351.131)	b=14.94	count=8500
Total loss:	15178.578 (rec:0.662, round:15177.916)	b=14.38	count=9000
Total loss:	14047.399 (rec:0.653, round:14046.747)	b=13.81	count=9500
Total loss:	12953.155 (rec:0.648, round:12952.508)	b=13.25	count=10000
Total loss:	11896.204 (rec:0.659, round:11895.545)	b=12.69	count=10500
Total loss:	10862.360 (rec:0.653, round:10861.707)	b=12.12	count=11000
Total loss:	9858.443 (rec:0.663, round:9857.780)	b=11.56	count=11500
Total loss:	8883.506 (rec:0.656, round:8882.850)	b=11.00	count=12000
Total loss:	7935.293 (rec:0.654, round:7934.639)	b=10.44	count=12500
Total loss:	7007.385 (rec:0.676, round:7006.709)	b=9.88	count=13000
Total loss:	6102.417 (rec:0.659, round:6101.758)	b=9.31	count=13500
Total loss:	5218.052 (rec:0.672, round:5217.380)	b=8.75	count=14000
Total loss:	4356.935 (rec:0.665, round:4356.269)	b=8.19	count=14500
Total loss:	3528.006 (rec:0.684, round:3527.322)	b=7.62	count=15000
Total loss:	2738.667 (rec:0.672, round:2737.995)	b=7.06	count=15500
Total loss:	1993.016 (rec:0.681, round:1992.335)	b=6.50	count=16000
Total loss:	1306.233 (rec:0.672, round:1305.560)	b=5.94	count=16500
Total loss:	703.370 (rec:0.691, round:702.679)	b=5.38	count=17000
Total loss:	283.528 (rec:0.696, round:282.832)	b=4.81	count=17500
Total loss:	94.000 (rec:0.709, round:93.291)	b=4.25	count=18000
Total loss:	26.438 (rec:0.687, round:25.751)	b=3.69	count=18500
Total loss:	5.244 (rec:0.697, round:4.547)	b=3.12	count=19000
Total loss:	1.020 (rec:0.693, round:0.327)	b=2.56	count=19500
Total loss:	0.705 (rec:0.700, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.6.
reconstructing blocks.7 ...
initializing raw input and raw output ...
adaround training for blocks.7 ...
wraping quantizers in blocks.7 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.681 (rec:0.681, round:0.000)	b=0.00	count=500
Total loss:	0.601 (rec:0.601, round:0.000)	b=0.00	count=1000
Total loss:	0.539 (rec:0.539, round:0.000)	b=0.00	count=1500
Total loss:	0.523 (rec:0.523, round:0.000)	b=0.00	count=2000
Total loss:	0.480 (rec:0.480, round:0.000)	b=0.00	count=2500
Total loss:	0.455 (rec:0.455, round:0.000)	b=0.00	count=3000
Total loss:	0.442 (rec:0.442, round:0.000)	b=0.00	count=3500
Total loss:	63365.746 (rec:0.433, round:63365.312)	b=20.00	count=4000
Total loss:	29618.510 (rec:0.420, round:29618.090)	b=19.44	count=4500
Total loss:	27196.750 (rec:0.418, round:27196.332)	b=18.88	count=5000
Total loss:	25511.021 (rec:0.404, round:25510.617)	b=18.31	count=5500
Total loss:	24010.658 (rec:0.404, round:24010.254)	b=17.75	count=6000
Total loss:	22586.318 (rec:0.402, round:22585.916)	b=17.19	count=6500
Total loss:	21221.549 (rec:0.389, round:21221.160)	b=16.62	count=7000
Total loss:	19905.871 (rec:0.384, round:19905.488)	b=16.06	count=7500
Total loss:	18622.832 (rec:0.392, round:18622.439)	b=15.50	count=8000
Total loss:	17373.484 (rec:0.390, round:17373.094)	b=14.94	count=8500
Total loss:	16151.579 (rec:0.385, round:16151.193)	b=14.38	count=9000
Total loss:	14963.732 (rec:0.388, round:14963.345)	b=13.81	count=9500
Total loss:	13811.771 (rec:0.395, round:13811.377)	b=13.25	count=10000
Total loss:	12680.731 (rec:0.390, round:12680.342)	b=12.69	count=10500
Total loss:	11582.031 (rec:0.384, round:11581.646)	b=12.12	count=11000
Total loss:	10517.491 (rec:0.380, round:10517.111)	b=11.56	count=11500
Total loss:	9477.241 (rec:0.386, round:9476.855)	b=11.00	count=12000
Total loss:	8461.140 (rec:0.382, round:8460.757)	b=10.44	count=12500
Total loss:	7468.529 (rec:0.388, round:7468.142)	b=9.88	count=13000
Total loss:	6502.852 (rec:0.387, round:6502.465)	b=9.31	count=13500
Total loss:	5563.140 (rec:0.395, round:5562.745)	b=8.75	count=14000
Total loss:	4647.064 (rec:0.389, round:4646.675)	b=8.19	count=14500
Total loss:	3763.214 (rec:0.396, round:3762.818)	b=7.62	count=15000
Total loss:	2916.067 (rec:0.393, round:2915.675)	b=7.06	count=15500
Total loss:	2119.357 (rec:0.405, round:2118.952)	b=6.50	count=16000
Total loss:	1381.583 (rec:0.414, round:1381.169)	b=5.94	count=16500
Total loss:	748.831 (rec:0.405, round:748.426)	b=5.38	count=17000
Total loss:	311.397 (rec:0.414, round:310.983)	b=4.81	count=17500
Total loss:	102.914 (rec:0.409, round:102.504)	b=4.25	count=18000
Total loss:	26.713 (rec:0.414, round:26.298)	b=3.69	count=18500
Total loss:	4.709 (rec:0.414, round:4.295)	b=3.12	count=19000
Total loss:	0.723 (rec:0.411, round:0.312)	b=2.56	count=19500
Total loss:	0.417 (rec:0.410, round:0.007)	b=2.00	count=20000
finished reconstructing blocks.7.
reconstructing blocks.8 ...
initializing raw input and raw output ...
adaround training for blocks.8 ...
wraping quantizers in blocks.8 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.630 (rec:0.630, round:0.000)	b=0.00	count=500
Total loss:	0.557 (rec:0.557, round:0.000)	b=0.00	count=1000
Total loss:	0.510 (rec:0.510, round:0.000)	b=0.00	count=1500
Total loss:	0.478 (rec:0.478, round:0.000)	b=0.00	count=2000
Total loss:	0.451 (rec:0.451, round:0.000)	b=0.00	count=2500
Total loss:	0.431 (rec:0.431, round:0.000)	b=0.00	count=3000
Total loss:	0.413 (rec:0.413, round:0.000)	b=0.00	count=3500
Total loss:	64655.867 (rec:0.406, round:64655.461)	b=20.00	count=4000
Total loss:	30887.074 (rec:0.387, round:30886.688)	b=19.44	count=4500
Total loss:	28443.799 (rec:0.391, round:28443.408)	b=18.88	count=5000
Total loss:	26765.068 (rec:0.377, round:26764.691)	b=18.31	count=5500
Total loss:	25283.600 (rec:0.381, round:25283.219)	b=17.75	count=6000
Total loss:	23887.316 (rec:0.367, round:23886.949)	b=17.19	count=6500
Total loss:	22537.135 (rec:0.372, round:22536.764)	b=16.62	count=7000
Total loss:	21219.781 (rec:0.358, round:21219.424)	b=16.06	count=7500
Total loss:	19924.432 (rec:0.366, round:19924.066)	b=15.50	count=8000
Total loss:	18653.502 (rec:0.359, round:18653.143)	b=14.94	count=8500
Total loss:	17407.008 (rec:0.357, round:17406.650)	b=14.38	count=9000
Total loss:	16174.937 (rec:0.361, round:16174.576)	b=13.81	count=9500
Total loss:	14972.775 (rec:0.367, round:14972.408)	b=13.25	count=10000
Total loss:	13791.729 (rec:0.346, round:13791.383)	b=12.69	count=10500
Total loss:	12637.041 (rec:0.346, round:12636.695)	b=12.12	count=11000
Total loss:	11499.631 (rec:0.361, round:11499.270)	b=11.56	count=11500
Total loss:	10389.077 (rec:0.363, round:10388.715)	b=11.00	count=12000
Total loss:	9302.809 (rec:0.363, round:9302.445)	b=10.44	count=12500
Total loss:	8232.994 (rec:0.381, round:8232.613)	b=9.88	count=13000
Total loss:	7189.280 (rec:0.351, round:7188.929)	b=9.31	count=13500
Total loss:	6164.497 (rec:0.354, round:6164.144)	b=8.75	count=14000
Total loss:	5173.900 (rec:0.367, round:5173.533)	b=8.19	count=14500
Total loss:	4216.771 (rec:0.362, round:4216.408)	b=7.62	count=15000
Total loss:	3305.087 (rec:0.370, round:3304.717)	b=7.06	count=15500
Total loss:	2444.704 (rec:0.388, round:2444.316)	b=6.50	count=16000
Total loss:	1658.102 (rec:0.381, round:1657.720)	b=5.94	count=16500
Total loss:	986.533 (rec:0.377, round:986.156)	b=5.38	count=17000
Total loss:	476.593 (rec:0.387, round:476.206)	b=4.81	count=17500
Total loss:	172.482 (rec:0.383, round:172.099)	b=4.25	count=18000
Total loss:	40.733 (rec:0.395, round:40.338)	b=3.69	count=18500
Total loss:	6.087 (rec:0.395, round:5.692)	b=3.12	count=19000
Total loss:	0.828 (rec:0.403, round:0.425)	b=2.56	count=19500
Total loss:	0.406 (rec:0.383, round:0.023)	b=2.00	count=20000
finished reconstructing blocks.8.
reconstructing blocks.9 ...
initializing raw input and raw output ...
adaround training for blocks.9 ...
wraping quantizers in blocks.9 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.465 (rec:1.465, round:0.000)	b=0.00	count=500
Total loss:	1.282 (rec:1.282, round:0.000)	b=0.00	count=1000
Total loss:	1.101 (rec:1.101, round:0.000)	b=0.00	count=1500
Total loss:	1.092 (rec:1.092, round:0.000)	b=0.00	count=2000
Total loss:	0.988 (rec:0.988, round:0.000)	b=0.00	count=2500
Total loss:	0.967 (rec:0.967, round:0.000)	b=0.00	count=3000
Total loss:	0.923 (rec:0.923, round:0.000)	b=0.00	count=3500
Total loss:	65000.977 (rec:0.906, round:65000.070)	b=20.00	count=4000
Total loss:	32542.594 (rec:0.912, round:32541.682)	b=19.44	count=4500
Total loss:	30084.182 (rec:0.968, round:30083.213)	b=18.88	count=5000
Total loss:	28417.775 (rec:0.856, round:28416.920)	b=18.31	count=5500
Total loss:	26956.936 (rec:0.904, round:26956.031)	b=17.75	count=6000
Total loss:	25580.756 (rec:0.839, round:25579.916)	b=17.19	count=6500
Total loss:	24243.480 (rec:0.796, round:24242.684)	b=16.62	count=7000
Total loss:	22942.648 (rec:0.844, round:22941.805)	b=16.06	count=7500
Total loss:	21656.686 (rec:0.803, round:21655.883)	b=15.50	count=8000
Total loss:	20387.549 (rec:0.819, round:20386.730)	b=14.94	count=8500
Total loss:	19137.346 (rec:0.783, round:19136.562)	b=14.38	count=9000
Total loss:	17902.176 (rec:0.817, round:17901.359)	b=13.81	count=9500
Total loss:	16679.779 (rec:0.810, round:16678.969)	b=13.25	count=10000
Total loss:	15471.510 (rec:0.840, round:15470.670)	b=12.69	count=10500
Total loss:	14276.066 (rec:0.800, round:14275.266)	b=12.12	count=11000
Total loss:	13097.323 (rec:0.778, round:13096.545)	b=11.56	count=11500
Total loss:	11928.272 (rec:0.792, round:11927.480)	b=11.00	count=12000
Total loss:	10777.910 (rec:0.825, round:10777.085)	b=10.44	count=12500
Total loss:	9638.001 (rec:0.817, round:9637.184)	b=9.88	count=13000
Total loss:	8517.841 (rec:0.838, round:8517.003)	b=9.31	count=13500
Total loss:	7412.320 (rec:0.863, round:7411.457)	b=8.75	count=14000
Total loss:	6324.345 (rec:0.819, round:6323.525)	b=8.19	count=14500
Total loss:	5263.495 (rec:0.841, round:5262.654)	b=7.62	count=15000
Total loss:	4229.978 (rec:0.841, round:4229.138)	b=7.06	count=15500
Total loss:	3245.663 (rec:0.918, round:3244.745)	b=6.50	count=16000
Total loss:	2330.618 (rec:0.890, round:2329.729)	b=5.94	count=16500
Total loss:	1506.590 (rec:0.873, round:1505.717)	b=5.38	count=17000
Total loss:	822.873 (rec:0.910, round:821.963)	b=4.81	count=17500
Total loss:	336.850 (rec:0.915, round:335.934)	b=4.25	count=18000
Total loss:	87.092 (rec:0.899, round:86.192)	b=3.69	count=18500
Total loss:	11.887 (rec:0.938, round:10.949)	b=3.12	count=19000
Total loss:	1.499 (rec:0.926, round:0.572)	b=2.56	count=19500
Total loss:	0.960 (rec:0.950, round:0.010)	b=2.00	count=20000
finished reconstructing blocks.9.
reconstructing blocks.10 ...
initializing raw input and raw output ...
adaround training for blocks.10 ...
wraping quantizers in blocks.10 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.266 (rec:1.266, round:0.000)	b=0.00	count=500
Total loss:	1.146 (rec:1.146, round:0.000)	b=0.00	count=1000
Total loss:	1.265 (rec:1.265, round:0.000)	b=0.00	count=1500
Total loss:	0.937 (rec:0.937, round:0.000)	b=0.00	count=2000
Total loss:	0.813 (rec:0.813, round:0.000)	b=0.00	count=2500
Total loss:	0.843 (rec:0.843, round:0.000)	b=0.00	count=3000
Total loss:	0.779 (rec:0.779, round:0.000)	b=0.00	count=3500
Total loss:	65515.262 (rec:0.787, round:65514.477)	b=20.00	count=4000
Total loss:	32695.201 (rec:0.763, round:32694.438)	b=19.44	count=4500
Total loss:	30214.232 (rec:0.761, round:30213.473)	b=18.88	count=5000
Total loss:	28529.107 (rec:0.693, round:28528.414)	b=18.31	count=5500
Total loss:	27041.232 (rec:0.762, round:27040.471)	b=17.75	count=6000
Total loss:	25634.365 (rec:0.683, round:25633.682)	b=17.19	count=6500
Total loss:	24272.516 (rec:0.706, round:24271.811)	b=16.62	count=7000
Total loss:	22940.623 (rec:0.717, round:22939.906)	b=16.06	count=7500
Total loss:	21624.447 (rec:0.766, round:21623.682)	b=15.50	count=8000
Total loss:	20319.734 (rec:0.739, round:20318.996)	b=14.94	count=8500
Total loss:	19035.295 (rec:0.747, round:19034.549)	b=14.38	count=9000
Total loss:	17761.217 (rec:0.705, round:17760.512)	b=13.81	count=9500
Total loss:	16504.266 (rec:0.711, round:16503.555)	b=13.25	count=10000
Total loss:	15270.146 (rec:0.675, round:15269.471)	b=12.69	count=10500
Total loss:	14047.520 (rec:0.691, round:14046.829)	b=12.12	count=11000
Total loss:	12850.092 (rec:0.723, round:12849.369)	b=11.56	count=11500
Total loss:	11671.045 (rec:0.650, round:11670.395)	b=11.00	count=12000
Total loss:	10516.355 (rec:0.740, round:10515.615)	b=10.44	count=12500
Total loss:	9388.160 (rec:0.677, round:9387.482)	b=9.88	count=13000
Total loss:	8275.793 (rec:0.745, round:8275.048)	b=9.31	count=13500
Total loss:	7179.459 (rec:0.705, round:7178.755)	b=8.75	count=14000
Total loss:	6105.859 (rec:0.783, round:6105.077)	b=8.19	count=14500
Total loss:	5053.051 (rec:0.781, round:5052.270)	b=7.62	count=15000
Total loss:	4044.394 (rec:0.835, round:4043.559)	b=7.06	count=15500
Total loss:	3084.354 (rec:0.723, round:3083.631)	b=6.50	count=16000
Total loss:	2194.320 (rec:0.728, round:2193.592)	b=5.94	count=16500
Total loss:	1406.244 (rec:0.779, round:1405.465)	b=5.38	count=17000
Total loss:	762.291 (rec:0.773, round:761.518)	b=4.81	count=17500
Total loss:	311.973 (rec:0.791, round:311.182)	b=4.25	count=18000
Total loss:	81.850 (rec:0.834, round:81.016)	b=3.69	count=18500
Total loss:	11.950 (rec:0.899, round:11.050)	b=3.12	count=19000
Total loss:	1.562 (rec:0.882, round:0.680)	b=2.56	count=19500
Total loss:	0.830 (rec:0.804, round:0.026)	b=2.00	count=20000
finished reconstructing blocks.10.
reconstructing blocks.11 ...
initializing raw input and raw output ...
adaround training for blocks.11 ...
wraping quantizers in blocks.11 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.247 (rec:0.247, round:0.000)	b=0.00	count=500
Total loss:	0.171 (rec:0.171, round:0.000)	b=0.00	count=1000
Total loss:	0.146 (rec:0.146, round:0.000)	b=0.00	count=1500
Total loss:	0.136 (rec:0.136, round:0.000)	b=0.00	count=2000
Total loss:	0.125 (rec:0.125, round:0.000)	b=0.00	count=2500
Total loss:	0.120 (rec:0.120, round:0.000)	b=0.00	count=3000
Total loss:	0.116 (rec:0.116, round:0.000)	b=0.00	count=3500
Total loss:	65534.223 (rec:0.109, round:65534.113)	b=20.00	count=4000
Total loss:	30318.174 (rec:0.107, round:30318.066)	b=19.44	count=4500
Total loss:	27947.568 (rec:0.104, round:27947.465)	b=18.88	count=5000
Total loss:	26352.652 (rec:0.098, round:26352.555)	b=18.31	count=5500
Total loss:	24937.770 (rec:0.094, round:24937.676)	b=17.75	count=6000
Total loss:	23586.955 (rec:0.096, round:23586.859)	b=17.19	count=6500
Total loss:	22275.688 (rec:0.093, round:22275.596)	b=16.62	count=7000
Total loss:	20965.012 (rec:0.093, round:20964.918)	b=16.06	count=7500
Total loss:	19658.057 (rec:0.084, round:19657.973)	b=15.50	count=8000
Total loss:	18362.330 (rec:0.084, round:18362.246)	b=14.94	count=8500
Total loss:	17058.264 (rec:0.083, round:17058.180)	b=14.38	count=9000
Total loss:	15765.130 (rec:0.085, round:15765.045)	b=13.81	count=9500
Total loss:	14490.836 (rec:0.083, round:14490.753)	b=13.25	count=10000
Total loss:	13232.286 (rec:0.081, round:13232.205)	b=12.69	count=10500
Total loss:	11996.495 (rec:0.081, round:11996.414)	b=12.12	count=11000
Total loss:	10791.002 (rec:0.084, round:10790.918)	b=11.56	count=11500
Total loss:	9618.337 (rec:0.083, round:9618.254)	b=11.00	count=12000
Total loss:	8476.213 (rec:0.077, round:8476.136)	b=10.44	count=12500
Total loss:	7374.330 (rec:0.085, round:7374.245)	b=9.88	count=13000
Total loss:	6312.846 (rec:0.078, round:6312.769)	b=9.31	count=13500
Total loss:	5300.473 (rec:0.082, round:5300.391)	b=8.75	count=14000
Total loss:	4341.562 (rec:0.081, round:4341.481)	b=8.19	count=14500
Total loss:	3441.113 (rec:0.081, round:3441.032)	b=7.62	count=15000
Total loss:	2599.675 (rec:0.076, round:2599.599)	b=7.06	count=15500
Total loss:	1829.745 (rec:0.085, round:1829.660)	b=6.50	count=16000
Total loss:	1135.017 (rec:0.084, round:1134.933)	b=5.94	count=16500
Total loss:	573.124 (rec:0.085, round:573.040)	b=5.38	count=17000
Total loss:	232.218 (rec:0.084, round:232.134)	b=4.81	count=17500
Total loss:	79.429 (rec:0.083, round:79.346)	b=4.25	count=18000
Total loss:	21.595 (rec:0.083, round:21.512)	b=3.69	count=18500
Total loss:	3.838 (rec:0.085, round:3.753)	b=3.12	count=19000
Total loss:	0.405 (rec:0.088, round:0.318)	b=2.56	count=19500
Total loss:	0.102 (rec:0.084, round:0.018)	b=2.00	count=20000
finished reconstructing blocks.11.
reconstructing head ...
initializing raw input and raw output ...
adaround training for head ...
wraping quantizers in head ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.375 (rec:1.375, round:0.000)	b=0.00	count=500
Total loss:	0.759 (rec:0.759, round:0.000)	b=0.00	count=1000
Total loss:	0.433 (rec:0.433, round:0.000)	b=0.00	count=1500
Total loss:	0.386 (rec:0.386, round:0.000)	b=0.00	count=2000
Total loss:	0.235 (rec:0.235, round:0.000)	b=0.00	count=2500
Total loss:	0.213 (rec:0.213, round:0.000)	b=0.00	count=3000
Total loss:	0.136 (rec:0.136, round:0.000)	b=0.00	count=3500
Total loss:	7037.877 (rec:0.133, round:7037.744)	b=20.00	count=4000
Total loss:	3943.121 (rec:0.075, round:3943.046)	b=19.44	count=4500
Total loss:	3664.526 (rec:0.085, round:3664.441)	b=18.88	count=5000
Total loss:	3478.807 (rec:0.110, round:3478.696)	b=18.31	count=5500
Total loss:	3321.311 (rec:0.056, round:3321.255)	b=17.75	count=6000
Total loss:	3173.116 (rec:0.051, round:3173.065)	b=17.19	count=6500
Total loss:	3028.027 (rec:0.056, round:3027.970)	b=16.62	count=7000
Total loss:	2883.250 (rec:0.057, round:2883.193)	b=16.06	count=7500
Total loss:	2737.418 (rec:0.039, round:2737.379)	b=15.50	count=8000
Total loss:	2592.977 (rec:0.049, round:2592.928)	b=14.94	count=8500
Total loss:	2450.692 (rec:0.048, round:2450.644)	b=14.38	count=9000
Total loss:	2309.883 (rec:0.045, round:2309.837)	b=13.81	count=9500
Total loss:	2171.383 (rec:0.047, round:2171.336)	b=13.25	count=10000
Total loss:	2033.392 (rec:0.042, round:2033.349)	b=12.69	count=10500
Total loss:	1895.538 (rec:0.047, round:1895.492)	b=12.12	count=11000
Total loss:	1759.808 (rec:0.044, round:1759.764)	b=11.56	count=11500
Total loss:	1624.474 (rec:0.039, round:1624.435)	b=11.00	count=12000
Total loss:	1490.049 (rec:0.043, round:1490.006)	b=10.44	count=12500
Total loss:	1354.577 (rec:0.047, round:1354.530)	b=9.88	count=13000
Total loss:	1218.281 (rec:0.040, round:1218.241)	b=9.31	count=13500
Total loss:	1078.819 (rec:0.046, round:1078.774)	b=8.75	count=14000
Total loss:	942.566 (rec:0.048, round:942.518)	b=8.19	count=14500
Total loss:	808.023 (rec:0.044, round:807.979)	b=7.62	count=15000
Total loss:	674.147 (rec:0.049, round:674.097)	b=7.06	count=15500
Total loss:	541.201 (rec:0.053, round:541.148)	b=6.50	count=16000
Total loss:	414.917 (rec:0.047, round:414.871)	b=5.94	count=16500
Total loss:	295.723 (rec:0.055, round:295.667)	b=5.38	count=17000
Total loss:	186.563 (rec:0.056, round:186.507)	b=4.81	count=17500
Total loss:	93.228 (rec:0.062, round:93.166)	b=4.25	count=18000
Total loss:	31.303 (rec:0.064, round:31.239)	b=3.69	count=18500
Total loss:	5.629 (rec:0.069, round:5.559)	b=3.12	count=19000
Total loss:	0.490 (rec:0.055, round:0.435)	b=2.56	count=19500
Total loss:	0.071 (rec:0.060, round:0.010)	b=2.00	count=20000
finished reconstructing head.
2025-09-08 19:17:26 - mse guided block reconstruction finished.
Saving checkpoint to ./checkpoint/quant_result/20250908_1559/vit_base_w2_a2_optimsize_1024_mse_rinp.pth
Validating on calibration set after block reconstruction ...
Test: [0/32]	Time 0.477 (0.477)	Loss 6.3784 (6.3784)	Prec@1 12.500 (12.500)	Prec@5 21.875 (21.875)
Test: [10/32]	Time 0.076 (0.113)	Loss 6.4901 (6.4797)	Prec@1 6.250 (5.682)	Prec@5 9.375 (11.080)
Test: [20/32]	Time 0.076 (0.095)	Loss 6.4328 (6.4864)	Prec@1 0.000 (5.655)	Prec@5 3.125 (9.970)
Test: [30/32]	Time 0.076 (0.089)	Loss 6.6406 (6.4901)	Prec@1 3.125 (5.444)	Prec@5 6.250 (9.879)
 * Prec@1 5.566 Prec@5 9.863 Loss 6.484 Time 2.956
Validating on test set after block reconstruction ...
Test: [0/100]	Time 4.831 (4.831)	Loss 6.6264 (6.6264)	Prec@1 0.600 (0.600)	Prec@5 4.800 (4.800)
Test: [10/100]	Time 1.660 (1.945)	Loss 6.3477 (6.6647)	Prec@1 3.000 (1.964)	Prec@5 13.800 (5.364)
Test: [20/100]	Time 1.659 (1.809)	Loss 6.1833 (6.6074)	Prec@1 2.200 (2.600)	Prec@5 11.400 (7.343)
Test: [30/100]	Time 1.668 (1.761)	Loss 6.4644 (6.5769)	Prec@1 1.800 (2.735)	Prec@5 6.800 (7.994)
Test: [40/100]	Time 1.658 (1.738)	Loss 6.7223 (6.6083)	Prec@1 4.000 (2.400)	Prec@5 10.400 (7.146)
Test: [50/100]	Time 1.663 (1.723)	Loss 6.7806 (6.6216)	Prec@1 4.600 (2.157)	Prec@5 9.000 (6.557)
Test: [60/100]	Time 1.658 (1.713)	Loss 6.5860 (6.6253)	Prec@1 7.400 (2.170)	Prec@5 8.800 (6.292)
Test: [70/100]	Time 1.660 (1.706)	Loss 6.1710 (6.6330)	Prec@1 6.200 (2.065)	Prec@5 14.400 (5.972)
Test: [80/100]	Time 1.660 (1.700)	Loss 6.3822 (6.6318)	Prec@1 6.400 (1.993)	Prec@5 9.200 (5.743)
Test: [90/100]	Time 1.657 (1.696)	Loss 6.6616 (6.6380)	Prec@1 4.400 (1.892)	Prec@5 7.200 (5.523)
 * Prec@1 2.042 Prec@5 5.856 Loss 6.630 Time 169.499
2025-09-08 19:20:18 - finished the process.
Extracting logits from quantized and full-precision models...
Testing combinations:
  Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  Cluster numbers: [8, 16, 32, 64, 128, 256]
  PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.07%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.07%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.10%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.11%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.09%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.09%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.09%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.09%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.08%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.09%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.01%
Result: Top-1: 2.09%, Top-5: 6.01%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.08%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.09%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.09%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 5.96%
Result: Top-1: 2.08%, Top-5: 5.96%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.08%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 5.97%
Result: Top-1: 2.10%, Top-5: 5.97%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.97%
Result: Top-1: 2.09%, Top-5: 5.97%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.97%
Result: Top-1: 2.09%, Top-5: 5.97%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.09%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.09%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.08%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.11%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.10%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.11%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.12%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.11%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 6.01%
Result: Top-1: 2.11%, Top-5: 6.01%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.07%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.07%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.11%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.12%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.04%
Result: Top-1: 2.08%, Top-5: 6.04%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.10%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.11%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.09%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 6.04%
Result: Top-1: 2.11%, Top-5: 6.04%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.07%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.07%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.12%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 5.97%
Result: Top-1: 2.12%, Top-5: 5.97%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.01%
Result: Top-1: 2.09%, Top-5: 6.01%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.01%
Result: Top-1: 2.10%, Top-5: 6.01%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.08%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.10%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.11%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.11%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.09%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.12%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.01%
Result: Top-1: 2.08%, Top-5: 6.01%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.10%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.09%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.13%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.13%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.09%
[Alpha=0.10] Top-5 Accuracy: 6.01%
Result: Top-1: 2.09%, Top-5: 6.01%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.03%
Result: Top-1: 2.10%, Top-5: 6.03%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.10%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 6.00%
Result: Top-1: 2.08%, Top-5: 6.00%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.10%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 5.99%
Result: Top-1: 2.12%, Top-5: 5.99%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.04%
Result: Top-1: 2.10%, Top-5: 6.04%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.08%
[Alpha=0.10] Top-5 Accuracy: 5.98%
Result: Top-1: 2.08%, Top-5: 5.98%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.05%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.05%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.10%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.10%, Top-5: 6.02%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.12%
[Alpha=0.10] Top-5 Accuracy: 6.02%
Result: Top-1: 2.12%, Top-5: 6.02%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.18%
Result: Top-1: 2.15%, Top-5: 6.18%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.16%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.15%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.17%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.17%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.16%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.19%
[Alpha=0.20] Top-5 Accuracy: 6.21%
Result: Top-1: 2.19%, Top-5: 6.21%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.22%
Result: Top-1: 2.16%, Top-5: 6.22%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.17%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.17%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.19%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.19%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.17%
[Alpha=0.20] Top-5 Accuracy: 6.21%
Result: Top-1: 2.17%, Top-5: 6.21%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.20%
Result: Top-1: 2.16%, Top-5: 6.20%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.13%
Result: Top-1: 2.14%, Top-5: 6.13%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.17%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.17%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.15%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.15%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.12%
Result: Top-1: 2.16%, Top-5: 6.12%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.14%
Result: Top-1: 2.14%, Top-5: 6.14%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.15%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.20%
[Alpha=0.20] Top-5 Accuracy: 6.21%
Result: Top-1: 2.20%, Top-5: 6.21%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.19%
Result: Top-1: 2.16%, Top-5: 6.19%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.13%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.13%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.21%
[Alpha=0.20] Top-5 Accuracy: 6.18%
Result: Top-1: 2.21%, Top-5: 6.18%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.14%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.15%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.18%
[Alpha=0.20] Top-5 Accuracy: 6.14%
Result: Top-1: 2.18%, Top-5: 6.14%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.13%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.13%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.13%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.13%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.12%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.12%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.13%
[Alpha=0.20] Top-5 Accuracy: 6.15%
Result: Top-1: 2.13%, Top-5: 6.15%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.19%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.19%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.12%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.12%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.10%
Result: Top-1: 2.15%, Top-5: 6.10%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.20%
Result: Top-1: 2.15%, Top-5: 6.20%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.08%
Result: Top-1: 2.16%, Top-5: 6.08%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.14%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.12%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.12%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.23%
Result: Top-1: 2.14%, Top-5: 6.23%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.14%
Result: Top-1: 2.15%, Top-5: 6.14%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.11%
Result: Top-1: 2.14%, Top-5: 6.11%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.17%
Result: Top-1: 2.15%, Top-5: 6.17%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.11%
[Alpha=0.20] Top-5 Accuracy: 6.16%
Result: Top-1: 2.11%, Top-5: 6.16%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.10%
Result: Top-1: 2.14%, Top-5: 6.10%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.18%
Result: Top-1: 2.14%, Top-5: 6.18%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.12%
Result: Top-1: 2.14%, Top-5: 6.12%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.16%
[Alpha=0.20] Top-5 Accuracy: 6.12%
Result: Top-1: 2.16%, Top-5: 6.12%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.12%
[Alpha=0.20] Top-5 Accuracy: 6.10%
Result: Top-1: 2.12%, Top-5: 6.10%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.10%
Result: Top-1: 2.15%, Top-5: 6.10%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.13%
[Alpha=0.20] Top-5 Accuracy: 6.19%
Result: Top-1: 2.13%, Top-5: 6.19%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.19%
Result: Top-1: 2.15%, Top-5: 6.19%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.11%
[Alpha=0.20] Top-5 Accuracy: 6.18%
Result: Top-1: 2.11%, Top-5: 6.18%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.12%
Result: Top-1: 2.14%, Top-5: 6.12%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.12%
[Alpha=0.20] Top-5 Accuracy: 6.11%
Result: Top-1: 2.12%, Top-5: 6.11%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.09%
[Alpha=0.20] Top-5 Accuracy: 6.14%
Result: Top-1: 2.09%, Top-5: 6.14%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.15%
[Alpha=0.20] Top-5 Accuracy: 6.14%
Result: Top-1: 2.15%, Top-5: 6.14%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.14%
[Alpha=0.20] Top-5 Accuracy: 6.11%
Result: Top-1: 2.14%, Top-5: 6.11%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.10%
[Alpha=0.20] Top-5 Accuracy: 6.12%
Result: Top-1: 2.10%, Top-5: 6.12%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.05%
[Alpha=0.20] Top-5 Accuracy: 6.06%
Result: Top-1: 2.05%, Top-5: 6.06%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.03%
[Alpha=0.20] Top-5 Accuracy: 6.08%
Result: Top-1: 2.03%, Top-5: 6.08%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.11%
[Alpha=0.20] Top-5 Accuracy: 6.13%
Result: Top-1: 2.11%, Top-5: 6.13%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.13%
[Alpha=0.20] Top-5 Accuracy: 6.20%
Result: Top-1: 2.13%, Top-5: 6.20%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.10%
[Alpha=0.30] Top-5 Accuracy: 6.19%
Result: Top-1: 2.10%, Top-5: 6.19%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 6.02%
Result: Top-1: 1.90%, Top-5: 6.02%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.96%
[Alpha=0.30] Top-5 Accuracy: 6.03%
Result: Top-1: 1.96%, Top-5: 6.03%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.91%
[Alpha=0.30] Top-5 Accuracy: 6.04%
Result: Top-1: 1.91%, Top-5: 6.04%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.93%
[Alpha=0.30] Top-5 Accuracy: 5.98%
Result: Top-1: 1.93%, Top-5: 5.98%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.01%
[Alpha=0.30] Top-5 Accuracy: 6.07%
Result: Top-1: 2.01%, Top-5: 6.07%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.02%
[Alpha=0.30] Top-5 Accuracy: 6.06%
Result: Top-1: 2.02%, Top-5: 6.06%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.00%
[Alpha=0.30] Top-5 Accuracy: 6.04%
Result: Top-1: 2.00%, Top-5: 6.04%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.00%
[Alpha=0.30] Top-5 Accuracy: 6.03%
Result: Top-1: 2.00%, Top-5: 6.03%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.03%
[Alpha=0.30] Top-5 Accuracy: 6.08%
Result: Top-1: 2.03%, Top-5: 6.08%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.10%
[Alpha=0.30] Top-5 Accuracy: 6.21%
Result: Top-1: 2.10%, Top-5: 6.21%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.89%
[Alpha=0.30] Top-5 Accuracy: 6.09%
Result: Top-1: 1.89%, Top-5: 6.09%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 5.99%
Result: Top-1: 1.90%, Top-5: 5.99%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.96%
[Alpha=0.30] Top-5 Accuracy: 6.12%
Result: Top-1: 1.96%, Top-5: 6.12%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.97%
[Alpha=0.30] Top-5 Accuracy: 6.09%
Result: Top-1: 1.97%, Top-5: 6.09%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.92%
[Alpha=0.30] Top-5 Accuracy: 6.02%
Result: Top-1: 1.92%, Top-5: 6.02%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.91%
[Alpha=0.30] Top-5 Accuracy: 6.04%
Result: Top-1: 1.91%, Top-5: 6.04%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.91%
[Alpha=0.30] Top-5 Accuracy: 6.05%
Result: Top-1: 1.91%, Top-5: 6.05%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.91%
[Alpha=0.30] Top-5 Accuracy: 6.03%
Result: Top-1: 1.91%, Top-5: 6.03%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 6.05%
Result: Top-1: 1.90%, Top-5: 6.05%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.11%
[Alpha=0.30] Top-5 Accuracy: 6.17%
Result: Top-1: 2.11%, Top-5: 6.17%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.85%
[Alpha=0.30] Top-5 Accuracy: 5.98%
Result: Top-1: 1.85%, Top-5: 5.98%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.85%
[Alpha=0.30] Top-5 Accuracy: 6.03%
Result: Top-1: 1.85%, Top-5: 6.03%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 6.00%
Result: Top-1: 1.90%, Top-5: 6.00%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 5.99%
Result: Top-1: 1.90%, Top-5: 5.99%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.83%
[Alpha=0.30] Top-5 Accuracy: 6.00%
Result: Top-1: 1.83%, Top-5: 6.00%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.88%
[Alpha=0.30] Top-5 Accuracy: 6.04%
Result: Top-1: 1.88%, Top-5: 6.04%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.83%
[Alpha=0.30] Top-5 Accuracy: 5.99%
Result: Top-1: 1.83%, Top-5: 5.99%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.88%
[Alpha=0.30] Top-5 Accuracy: 6.01%
Result: Top-1: 1.88%, Top-5: 6.01%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.89%
[Alpha=0.30] Top-5 Accuracy: 6.01%
Result: Top-1: 1.89%, Top-5: 6.01%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.09%
[Alpha=0.30] Top-5 Accuracy: 6.15%
Result: Top-1: 2.09%, Top-5: 6.15%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 5.95%
Result: Top-1: 1.73%, Top-5: 5.95%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.78%
[Alpha=0.30] Top-5 Accuracy: 5.95%
Result: Top-1: 1.78%, Top-5: 5.95%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.75%
[Alpha=0.30] Top-5 Accuracy: 5.92%
Result: Top-1: 1.75%, Top-5: 5.92%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 5.89%
Result: Top-1: 1.73%, Top-5: 5.89%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.71%
[Alpha=0.30] Top-5 Accuracy: 5.93%
Result: Top-1: 1.71%, Top-5: 5.93%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.77%
[Alpha=0.30] Top-5 Accuracy: 5.97%
Result: Top-1: 1.77%, Top-5: 5.97%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.74%
[Alpha=0.30] Top-5 Accuracy: 5.97%
Result: Top-1: 1.74%, Top-5: 5.97%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.76%
[Alpha=0.30] Top-5 Accuracy: 5.94%
Result: Top-1: 1.76%, Top-5: 5.94%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.79%
[Alpha=0.30] Top-5 Accuracy: 6.01%
Result: Top-1: 1.79%, Top-5: 6.01%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.07%
[Alpha=0.30] Top-5 Accuracy: 6.12%
Result: Top-1: 2.07%, Top-5: 6.12%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 5.87%
Result: Top-1: 1.73%, Top-5: 5.87%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 5.90%
Result: Top-1: 1.73%, Top-5: 5.90%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.68%
[Alpha=0.30] Top-5 Accuracy: 5.95%
Result: Top-1: 1.68%, Top-5: 5.95%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.66%
[Alpha=0.30] Top-5 Accuracy: 5.89%
Result: Top-1: 1.66%, Top-5: 5.89%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.76%
[Alpha=0.30] Top-5 Accuracy: 6.00%
Result: Top-1: 1.76%, Top-5: 6.00%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 5.86%
Result: Top-1: 1.73%, Top-5: 5.86%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.74%
[Alpha=0.30] Top-5 Accuracy: 5.99%
Result: Top-1: 1.74%, Top-5: 5.99%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.72%
[Alpha=0.30] Top-5 Accuracy: 6.03%
Result: Top-1: 1.72%, Top-5: 6.03%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.67%
[Alpha=0.30] Top-5 Accuracy: 5.95%
Result: Top-1: 1.67%, Top-5: 5.95%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.05%
[Alpha=0.30] Top-5 Accuracy: 6.02%
Result: Top-1: 2.05%, Top-5: 6.02%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.66%
[Alpha=0.30] Top-5 Accuracy: 5.85%
Result: Top-1: 1.66%, Top-5: 5.85%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.53%
[Alpha=0.30] Top-5 Accuracy: 5.82%
Result: Top-1: 1.53%, Top-5: 5.82%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.64%
[Alpha=0.30] Top-5 Accuracy: 5.88%
Result: Top-1: 1.64%, Top-5: 5.88%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.69%
[Alpha=0.30] Top-5 Accuracy: 5.88%
Result: Top-1: 1.69%, Top-5: 5.88%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.60%
[Alpha=0.30] Top-5 Accuracy: 5.84%
Result: Top-1: 1.60%, Top-5: 5.84%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.58%
[Alpha=0.30] Top-5 Accuracy: 5.80%
Result: Top-1: 1.58%, Top-5: 5.80%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.61%
[Alpha=0.30] Top-5 Accuracy: 5.87%
Result: Top-1: 1.61%, Top-5: 5.87%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.63%
[Alpha=0.30] Top-5 Accuracy: 5.95%
Result: Top-1: 1.63%, Top-5: 5.95%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.66%
[Alpha=0.30] Top-5 Accuracy: 5.93%
Result: Top-1: 1.66%, Top-5: 5.93%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.75%
[Alpha=0.40] Top-5 Accuracy: 5.72%
Result: Top-1: 1.75%, Top-5: 5.72%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.38%
[Alpha=0.40] Top-5 Accuracy: 5.60%
Result: Top-1: 1.38%, Top-5: 5.60%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.48%
[Alpha=0.40] Top-5 Accuracy: 5.58%
Result: Top-1: 1.48%, Top-5: 5.58%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.41%
[Alpha=0.40] Top-5 Accuracy: 5.58%
Result: Top-1: 1.41%, Top-5: 5.58%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.38%
[Alpha=0.40] Top-5 Accuracy: 5.59%
Result: Top-1: 1.38%, Top-5: 5.59%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.46%
[Alpha=0.40] Top-5 Accuracy: 5.67%
Result: Top-1: 1.46%, Top-5: 5.67%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.48%
[Alpha=0.40] Top-5 Accuracy: 5.71%
Result: Top-1: 1.48%, Top-5: 5.71%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.54%
[Alpha=0.40] Top-5 Accuracy: 5.67%
Result: Top-1: 1.54%, Top-5: 5.67%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.43%
[Alpha=0.40] Top-5 Accuracy: 5.65%
Result: Top-1: 1.43%, Top-5: 5.65%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.48%
[Alpha=0.40] Top-5 Accuracy: 5.73%
Result: Top-1: 1.48%, Top-5: 5.73%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.73%
[Alpha=0.40] Top-5 Accuracy: 5.73%
Result: Top-1: 1.73%, Top-5: 5.73%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.30%
[Alpha=0.40] Top-5 Accuracy: 5.73%
Result: Top-1: 1.30%, Top-5: 5.73%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.31%
[Alpha=0.40] Top-5 Accuracy: 5.60%
Result: Top-1: 1.31%, Top-5: 5.60%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.30%
[Alpha=0.40] Top-5 Accuracy: 5.67%
Result: Top-1: 1.30%, Top-5: 5.67%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.34%
[Alpha=0.40] Top-5 Accuracy: 5.67%
Result: Top-1: 1.34%, Top-5: 5.67%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.30%
[Alpha=0.40] Top-5 Accuracy: 5.71%
Result: Top-1: 1.30%, Top-5: 5.71%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.35%
[Alpha=0.40] Top-5 Accuracy: 5.73%
Result: Top-1: 1.35%, Top-5: 5.73%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.31%
[Alpha=0.40] Top-5 Accuracy: 5.67%
Result: Top-1: 1.31%, Top-5: 5.67%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.19%
[Alpha=0.40] Top-5 Accuracy: 5.68%
Result: Top-1: 1.19%, Top-5: 5.68%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.27%
[Alpha=0.40] Top-5 Accuracy: 5.67%
Result: Top-1: 1.27%, Top-5: 5.67%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.71%
[Alpha=0.40] Top-5 Accuracy: 5.74%
Result: Top-1: 1.71%, Top-5: 5.74%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.10%
[Alpha=0.40] Top-5 Accuracy: 5.61%
Result: Top-1: 1.10%, Top-5: 5.61%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.23%
[Alpha=0.40] Top-5 Accuracy: 5.61%
Result: Top-1: 1.23%, Top-5: 5.61%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.21%
[Alpha=0.40] Top-5 Accuracy: 5.63%
Result: Top-1: 1.21%, Top-5: 5.63%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.26%
[Alpha=0.40] Top-5 Accuracy: 5.69%
Result: Top-1: 1.26%, Top-5: 5.69%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.21%
[Alpha=0.40] Top-5 Accuracy: 5.70%
Result: Top-1: 1.21%, Top-5: 5.70%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.19%
[Alpha=0.40] Top-5 Accuracy: 5.78%
Result: Top-1: 1.19%, Top-5: 5.78%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.16%
[Alpha=0.40] Top-5 Accuracy: 5.65%
Result: Top-1: 1.16%, Top-5: 5.65%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.19%
[Alpha=0.40] Top-5 Accuracy: 5.64%
Result: Top-1: 1.19%, Top-5: 5.64%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.17%
[Alpha=0.40] Top-5 Accuracy: 5.65%
Result: Top-1: 1.17%, Top-5: 5.65%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.67%
[Alpha=0.40] Top-5 Accuracy: 5.66%
Result: Top-1: 1.67%, Top-5: 5.66%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.01%
[Alpha=0.40] Top-5 Accuracy: 5.55%
Result: Top-1: 1.01%, Top-5: 5.55%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 5.64%
Result: Top-1: 1.08%, Top-5: 5.64%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.02%
[Alpha=0.40] Top-5 Accuracy: 5.50%
Result: Top-1: 1.02%, Top-5: 5.50%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 5.56%
Result: Top-1: 1.08%, Top-5: 5.56%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.03%
[Alpha=0.40] Top-5 Accuracy: 5.58%
Result: Top-1: 1.03%, Top-5: 5.58%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.04%
[Alpha=0.40] Top-5 Accuracy: 5.60%
Result: Top-1: 1.04%, Top-5: 5.60%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.00%
[Alpha=0.40] Top-5 Accuracy: 5.49%
Result: Top-1: 1.00%, Top-5: 5.49%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.99%
[Alpha=0.40] Top-5 Accuracy: 5.55%
Result: Top-1: 0.99%, Top-5: 5.55%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 5.60%
Result: Top-1: 1.08%, Top-5: 5.60%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.67%
[Alpha=0.40] Top-5 Accuracy: 5.64%
Result: Top-1: 1.67%, Top-5: 5.64%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.99%
[Alpha=0.40] Top-5 Accuracy: 5.55%
Result: Top-1: 0.99%, Top-5: 5.55%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.02%
[Alpha=0.40] Top-5 Accuracy: 5.50%
Result: Top-1: 1.02%, Top-5: 5.50%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.02%
[Alpha=0.40] Top-5 Accuracy: 5.56%
Result: Top-1: 1.02%, Top-5: 5.56%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.01%
[Alpha=0.40] Top-5 Accuracy: 5.60%
Result: Top-1: 1.01%, Top-5: 5.60%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.12%
[Alpha=0.40] Top-5 Accuracy: 5.54%
Result: Top-1: 1.12%, Top-5: 5.54%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.07%
[Alpha=0.40] Top-5 Accuracy: 5.51%
Result: Top-1: 1.07%, Top-5: 5.51%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.01%
[Alpha=0.40] Top-5 Accuracy: 5.63%
Result: Top-1: 1.01%, Top-5: 5.63%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.03%
[Alpha=0.40] Top-5 Accuracy: 5.60%
Result: Top-1: 1.03%, Top-5: 5.60%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.03%
[Alpha=0.40] Top-5 Accuracy: 5.59%
Result: Top-1: 1.03%, Top-5: 5.59%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.56%
[Alpha=0.40] Top-5 Accuracy: 5.57%
Result: Top-1: 1.56%, Top-5: 5.57%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.98%
[Alpha=0.40] Top-5 Accuracy: 5.43%
Result: Top-1: 0.98%, Top-5: 5.43%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.89%
[Alpha=0.40] Top-5 Accuracy: 5.32%
Result: Top-1: 0.89%, Top-5: 5.32%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.97%
[Alpha=0.40] Top-5 Accuracy: 5.47%
Result: Top-1: 0.97%, Top-5: 5.47%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.99%
[Alpha=0.40] Top-5 Accuracy: 5.49%
Result: Top-1: 0.99%, Top-5: 5.49%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.93%
[Alpha=0.40] Top-5 Accuracy: 5.46%
Result: Top-1: 0.93%, Top-5: 5.46%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.00%
[Alpha=0.40] Top-5 Accuracy: 5.31%
Result: Top-1: 1.00%, Top-5: 5.31%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.00%
[Alpha=0.40] Top-5 Accuracy: 5.42%
Result: Top-1: 1.00%, Top-5: 5.42%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.98%
[Alpha=0.40] Top-5 Accuracy: 5.53%
Result: Top-1: 0.98%, Top-5: 5.53%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.99%
[Alpha=0.40] Top-5 Accuracy: 5.47%
Result: Top-1: 0.99%, Top-5: 5.47%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.01%
[Alpha=0.50] Top-5 Accuracy: 5.02%
Result: Top-1: 1.01%, Top-5: 5.02%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.78%
[Alpha=0.50] Top-5 Accuracy: 5.00%
Result: Top-1: 0.78%, Top-5: 5.00%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.82%
[Alpha=0.50] Top-5 Accuracy: 4.92%
Result: Top-1: 0.82%, Top-5: 4.92%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.79%
[Alpha=0.50] Top-5 Accuracy: 4.98%
Result: Top-1: 0.79%, Top-5: 4.98%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.70%
[Alpha=0.50] Top-5 Accuracy: 4.98%
Result: Top-1: 0.70%, Top-5: 4.98%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.82%
[Alpha=0.50] Top-5 Accuracy: 5.04%
Result: Top-1: 0.82%, Top-5: 5.04%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.85%
[Alpha=0.50] Top-5 Accuracy: 5.11%
Result: Top-1: 0.85%, Top-5: 5.11%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.85%
[Alpha=0.50] Top-5 Accuracy: 5.05%
Result: Top-1: 0.85%, Top-5: 5.05%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.78%
[Alpha=0.50] Top-5 Accuracy: 5.03%
Result: Top-1: 0.78%, Top-5: 5.03%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.85%
[Alpha=0.50] Top-5 Accuracy: 5.10%
Result: Top-1: 0.85%, Top-5: 5.10%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.02%
[Alpha=0.50] Top-5 Accuracy: 5.09%
Result: Top-1: 1.02%, Top-5: 5.09%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.73%
[Alpha=0.50] Top-5 Accuracy: 5.09%
Result: Top-1: 0.73%, Top-5: 5.09%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.72%
[Alpha=0.50] Top-5 Accuracy: 5.02%
Result: Top-1: 0.72%, Top-5: 5.02%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.74%
[Alpha=0.50] Top-5 Accuracy: 5.04%
Result: Top-1: 0.74%, Top-5: 5.04%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.76%
[Alpha=0.50] Top-5 Accuracy: 5.03%
Result: Top-1: 0.76%, Top-5: 5.03%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.80%
[Alpha=0.50] Top-5 Accuracy: 5.08%
Result: Top-1: 0.80%, Top-5: 5.08%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.77%
[Alpha=0.50] Top-5 Accuracy: 5.14%
Result: Top-1: 0.77%, Top-5: 5.14%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.73%
[Alpha=0.50] Top-5 Accuracy: 5.08%
Result: Top-1: 0.73%, Top-5: 5.08%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.66%
[Alpha=0.50] Top-5 Accuracy: 5.10%
Result: Top-1: 0.66%, Top-5: 5.10%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.70%
[Alpha=0.50] Top-5 Accuracy: 5.00%
Result: Top-1: 0.70%, Top-5: 5.00%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.01%
[Alpha=0.50] Top-5 Accuracy: 5.09%
Result: Top-1: 1.01%, Top-5: 5.09%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.56%
[Alpha=0.50] Top-5 Accuracy: 4.94%
Result: Top-1: 0.56%, Top-5: 4.94%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.69%
[Alpha=0.50] Top-5 Accuracy: 4.94%
Result: Top-1: 0.69%, Top-5: 4.94%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.65%
[Alpha=0.50] Top-5 Accuracy: 5.04%
Result: Top-1: 0.65%, Top-5: 5.04%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.69%
[Alpha=0.50] Top-5 Accuracy: 5.10%
Result: Top-1: 0.69%, Top-5: 5.10%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.71%
[Alpha=0.50] Top-5 Accuracy: 5.03%
Result: Top-1: 0.71%, Top-5: 5.03%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.71%
[Alpha=0.50] Top-5 Accuracy: 5.21%
Result: Top-1: 0.71%, Top-5: 5.21%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.72%
[Alpha=0.50] Top-5 Accuracy: 5.03%
Result: Top-1: 0.72%, Top-5: 5.03%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.67%
[Alpha=0.50] Top-5 Accuracy: 5.00%
Result: Top-1: 0.67%, Top-5: 5.00%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.66%
[Alpha=0.50] Top-5 Accuracy: 5.02%
Result: Top-1: 0.66%, Top-5: 5.02%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.01%
[Alpha=0.50] Top-5 Accuracy: 5.03%
Result: Top-1: 1.01%, Top-5: 5.03%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.58%
[Alpha=0.50] Top-5 Accuracy: 4.95%
Result: Top-1: 0.58%, Top-5: 4.95%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.63%
[Alpha=0.50] Top-5 Accuracy: 5.00%
Result: Top-1: 0.63%, Top-5: 5.00%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.56%
[Alpha=0.50] Top-5 Accuracy: 5.00%
Result: Top-1: 0.56%, Top-5: 5.00%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.66%
[Alpha=0.50] Top-5 Accuracy: 4.94%
Result: Top-1: 0.66%, Top-5: 4.94%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.60%
[Alpha=0.50] Top-5 Accuracy: 4.83%
Result: Top-1: 0.60%, Top-5: 4.83%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.68%
[Alpha=0.50] Top-5 Accuracy: 4.93%
Result: Top-1: 0.68%, Top-5: 4.93%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.54%
[Alpha=0.50] Top-5 Accuracy: 4.81%
Result: Top-1: 0.54%, Top-5: 4.81%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.55%
[Alpha=0.50] Top-5 Accuracy: 4.95%
Result: Top-1: 0.55%, Top-5: 4.95%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.62%
[Alpha=0.50] Top-5 Accuracy: 4.98%
Result: Top-1: 0.62%, Top-5: 4.98%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.01%
[Alpha=0.50] Top-5 Accuracy: 4.97%
Result: Top-1: 1.01%, Top-5: 4.97%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 4.93%
Result: Top-1: 0.59%, Top-5: 4.93%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.60%
[Alpha=0.50] Top-5 Accuracy: 4.90%
Result: Top-1: 0.60%, Top-5: 4.90%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.63%
[Alpha=0.50] Top-5 Accuracy: 4.94%
Result: Top-1: 0.63%, Top-5: 4.94%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.66%
[Alpha=0.50] Top-5 Accuracy: 4.93%
Result: Top-1: 0.66%, Top-5: 4.93%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.69%
[Alpha=0.50] Top-5 Accuracy: 4.90%
Result: Top-1: 0.69%, Top-5: 4.90%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.69%
[Alpha=0.50] Top-5 Accuracy: 4.84%
Result: Top-1: 0.69%, Top-5: 4.84%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.62%
[Alpha=0.50] Top-5 Accuracy: 4.98%
Result: Top-1: 0.62%, Top-5: 4.98%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 4.96%
Result: Top-1: 0.59%, Top-5: 4.96%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.64%
[Alpha=0.50] Top-5 Accuracy: 4.91%
Result: Top-1: 0.64%, Top-5: 4.91%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.97%
[Alpha=0.50] Top-5 Accuracy: 4.93%
Result: Top-1: 0.97%, Top-5: 4.93%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.64%
[Alpha=0.50] Top-5 Accuracy: 4.78%
Result: Top-1: 0.64%, Top-5: 4.78%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.52%
[Alpha=0.50] Top-5 Accuracy: 4.70%
Result: Top-1: 0.52%, Top-5: 4.70%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.60%
[Alpha=0.50] Top-5 Accuracy: 4.79%
Result: Top-1: 0.60%, Top-5: 4.79%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.63%
[Alpha=0.50] Top-5 Accuracy: 4.80%
Result: Top-1: 0.63%, Top-5: 4.80%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 4.80%
Result: Top-1: 0.59%, Top-5: 4.80%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.62%
[Alpha=0.50] Top-5 Accuracy: 4.67%
Result: Top-1: 0.62%, Top-5: 4.67%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.61%
[Alpha=0.50] Top-5 Accuracy: 4.68%
Result: Top-1: 0.61%, Top-5: 4.68%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.64%
[Alpha=0.50] Top-5 Accuracy: 4.89%
Result: Top-1: 0.64%, Top-5: 4.89%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.61%
[Alpha=0.50] Top-5 Accuracy: 4.85%
Result: Top-1: 0.61%, Top-5: 4.85%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.55%
[Alpha=0.60] Top-5 Accuracy: 4.16%
Result: Top-1: 0.55%, Top-5: 4.16%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 4.12%
Result: Top-1: 0.43%, Top-5: 4.12%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.06%
Result: Top-1: 0.44%, Top-5: 4.06%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 4.10%
Result: Top-1: 0.43%, Top-5: 4.10%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.38%
[Alpha=0.60] Top-5 Accuracy: 4.09%
Result: Top-1: 0.38%, Top-5: 4.09%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.45%
[Alpha=0.60] Top-5 Accuracy: 4.15%
Result: Top-1: 0.45%, Top-5: 4.15%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.46%
[Alpha=0.60] Top-5 Accuracy: 4.20%
Result: Top-1: 0.46%, Top-5: 4.20%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.17%
Result: Top-1: 0.44%, Top-5: 4.17%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.10%
Result: Top-1: 0.44%, Top-5: 4.10%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.47%
[Alpha=0.60] Top-5 Accuracy: 4.18%
Result: Top-1: 0.47%, Top-5: 4.18%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.54%
[Alpha=0.60] Top-5 Accuracy: 4.12%
Result: Top-1: 0.54%, Top-5: 4.12%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 4.13%
Result: Top-1: 0.43%, Top-5: 4.13%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.42%
[Alpha=0.60] Top-5 Accuracy: 4.08%
Result: Top-1: 0.42%, Top-5: 4.08%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 4.14%
Result: Top-1: 0.43%, Top-5: 4.14%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.46%
[Alpha=0.60] Top-5 Accuracy: 4.20%
Result: Top-1: 0.46%, Top-5: 4.20%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.50%
[Alpha=0.60] Top-5 Accuracy: 4.08%
Result: Top-1: 0.50%, Top-5: 4.08%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.48%
[Alpha=0.60] Top-5 Accuracy: 4.13%
Result: Top-1: 0.48%, Top-5: 4.13%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.45%
[Alpha=0.60] Top-5 Accuracy: 4.18%
Result: Top-1: 0.45%, Top-5: 4.18%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.42%
[Alpha=0.60] Top-5 Accuracy: 4.15%
Result: Top-1: 0.42%, Top-5: 4.15%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.42%
[Alpha=0.60] Top-5 Accuracy: 4.17%
Result: Top-1: 0.42%, Top-5: 4.17%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.54%
[Alpha=0.60] Top-5 Accuracy: 4.16%
Result: Top-1: 0.54%, Top-5: 4.16%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.37%
[Alpha=0.60] Top-5 Accuracy: 4.09%
Result: Top-1: 0.37%, Top-5: 4.09%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.01%
Result: Top-1: 0.44%, Top-5: 4.01%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 4.12%
Result: Top-1: 0.43%, Top-5: 4.12%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.41%
[Alpha=0.60] Top-5 Accuracy: 4.18%
Result: Top-1: 0.41%, Top-5: 4.18%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.46%
[Alpha=0.60] Top-5 Accuracy: 4.00%
Result: Top-1: 0.46%, Top-5: 4.00%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.47%
[Alpha=0.60] Top-5 Accuracy: 4.22%
Result: Top-1: 0.47%, Top-5: 4.22%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.49%
[Alpha=0.60] Top-5 Accuracy: 4.07%
Result: Top-1: 0.49%, Top-5: 4.07%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 4.03%
Result: Top-1: 0.43%, Top-5: 4.03%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.39%
[Alpha=0.60] Top-5 Accuracy: 4.15%
Result: Top-1: 0.39%, Top-5: 4.15%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.57%
[Alpha=0.60] Top-5 Accuracy: 4.05%
Result: Top-1: 0.57%, Top-5: 4.05%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.42%
[Alpha=0.60] Top-5 Accuracy: 4.13%
Result: Top-1: 0.42%, Top-5: 4.13%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.40%
[Alpha=0.60] Top-5 Accuracy: 4.12%
Result: Top-1: 0.40%, Top-5: 4.12%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.38%
[Alpha=0.60] Top-5 Accuracy: 4.05%
Result: Top-1: 0.38%, Top-5: 4.05%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.46%
[Alpha=0.60] Top-5 Accuracy: 4.03%
Result: Top-1: 0.46%, Top-5: 4.03%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 3.90%
Result: Top-1: 0.43%, Top-5: 3.90%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.46%
[Alpha=0.60] Top-5 Accuracy: 4.02%
Result: Top-1: 0.46%, Top-5: 4.02%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.35%
[Alpha=0.60] Top-5 Accuracy: 3.98%
Result: Top-1: 0.35%, Top-5: 3.98%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.39%
[Alpha=0.60] Top-5 Accuracy: 4.09%
Result: Top-1: 0.39%, Top-5: 4.09%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.42%
[Alpha=0.60] Top-5 Accuracy: 4.02%
Result: Top-1: 0.42%, Top-5: 4.02%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.61%
[Alpha=0.60] Top-5 Accuracy: 4.04%
Result: Top-1: 0.61%, Top-5: 4.04%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.07%
Result: Top-1: 0.44%, Top-5: 4.07%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.46%
[Alpha=0.60] Top-5 Accuracy: 4.02%
Result: Top-1: 0.46%, Top-5: 4.02%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.45%
[Alpha=0.60] Top-5 Accuracy: 4.14%
Result: Top-1: 0.45%, Top-5: 4.14%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.48%
[Alpha=0.60] Top-5 Accuracy: 4.12%
Result: Top-1: 0.48%, Top-5: 4.12%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.48%
[Alpha=0.60] Top-5 Accuracy: 4.03%
Result: Top-1: 0.48%, Top-5: 4.03%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.45%
[Alpha=0.60] Top-5 Accuracy: 3.98%
Result: Top-1: 0.45%, Top-5: 3.98%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.00%
Result: Top-1: 0.44%, Top-5: 4.00%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.41%
[Alpha=0.60] Top-5 Accuracy: 4.18%
Result: Top-1: 0.41%, Top-5: 4.18%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.49%
[Alpha=0.60] Top-5 Accuracy: 4.10%
Result: Top-1: 0.49%, Top-5: 4.10%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.59%
[Alpha=0.60] Top-5 Accuracy: 4.08%
Result: Top-1: 0.59%, Top-5: 4.08%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.47%
[Alpha=0.60] Top-5 Accuracy: 3.94%
Result: Top-1: 0.47%, Top-5: 3.94%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.39%
[Alpha=0.60] Top-5 Accuracy: 3.87%
Result: Top-1: 0.39%, Top-5: 3.87%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.43%
[Alpha=0.60] Top-5 Accuracy: 3.97%
Result: Top-1: 0.43%, Top-5: 3.97%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.48%
[Alpha=0.60] Top-5 Accuracy: 3.92%
Result: Top-1: 0.48%, Top-5: 3.92%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.45%
[Alpha=0.60] Top-5 Accuracy: 3.96%
Result: Top-1: 0.45%, Top-5: 3.96%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.48%
[Alpha=0.60] Top-5 Accuracy: 3.83%
Result: Top-1: 0.48%, Top-5: 3.83%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 3.93%
Result: Top-1: 0.44%, Top-5: 3.93%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.47%
[Alpha=0.60] Top-5 Accuracy: 3.99%
Result: Top-1: 0.47%, Top-5: 3.99%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 0.44%
[Alpha=0.60] Top-5 Accuracy: 4.03%
Result: Top-1: 0.44%, Top-5: 4.03%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.35%
[Alpha=0.70] Top-5 Accuracy: 2.93%
Result: Top-1: 0.35%, Top-5: 2.93%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.31%
[Alpha=0.70] Top-5 Accuracy: 2.86%
Result: Top-1: 0.31%, Top-5: 2.86%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.34%
[Alpha=0.70] Top-5 Accuracy: 2.96%
Result: Top-1: 0.34%, Top-5: 2.96%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.30%
[Alpha=0.70] Top-5 Accuracy: 2.84%
Result: Top-1: 0.30%, Top-5: 2.84%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.28%
[Alpha=0.70] Top-5 Accuracy: 2.92%
Result: Top-1: 0.28%, Top-5: 2.92%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 2.99%
Result: Top-1: 0.32%, Top-5: 2.99%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 2.95%
Result: Top-1: 0.32%, Top-5: 2.95%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 2.97%
Result: Top-1: 0.32%, Top-5: 2.97%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 2.96%
Result: Top-1: 0.32%, Top-5: 2.96%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 2.95%
Result: Top-1: 0.32%, Top-5: 2.95%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.36%
[Alpha=0.70] Top-5 Accuracy: 2.92%
Result: Top-1: 0.36%, Top-5: 2.92%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.31%
[Alpha=0.70] Top-5 Accuracy: 3.10%
Result: Top-1: 0.31%, Top-5: 3.10%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.28%
[Alpha=0.70] Top-5 Accuracy: 2.92%
Result: Top-1: 0.28%, Top-5: 2.92%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.02%
Result: Top-1: 0.33%, Top-5: 3.02%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.36%
[Alpha=0.70] Top-5 Accuracy: 3.05%
Result: Top-1: 0.36%, Top-5: 3.05%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.35%
[Alpha=0.70] Top-5 Accuracy: 2.92%
Result: Top-1: 0.35%, Top-5: 2.92%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.00%
Result: Top-1: 0.33%, Top-5: 3.00%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.34%
[Alpha=0.70] Top-5 Accuracy: 3.07%
Result: Top-1: 0.34%, Top-5: 3.07%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 3.13%
Result: Top-1: 0.32%, Top-5: 3.13%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.30%
[Alpha=0.70] Top-5 Accuracy: 3.06%
Result: Top-1: 0.30%, Top-5: 3.06%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 2.88%
Result: Top-1: 0.37%, Top-5: 2.88%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.30%
[Alpha=0.70] Top-5 Accuracy: 3.08%
Result: Top-1: 0.30%, Top-5: 3.08%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 2.89%
Result: Top-1: 0.33%, Top-5: 2.89%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.00%
Result: Top-1: 0.33%, Top-5: 3.00%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.31%
[Alpha=0.70] Top-5 Accuracy: 3.13%
Result: Top-1: 0.31%, Top-5: 3.13%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 2.97%
Result: Top-1: 0.33%, Top-5: 2.97%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.34%
[Alpha=0.70] Top-5 Accuracy: 3.09%
Result: Top-1: 0.34%, Top-5: 3.09%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.00%
Result: Top-1: 0.37%, Top-5: 3.00%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.34%
[Alpha=0.70] Top-5 Accuracy: 3.00%
Result: Top-1: 0.34%, Top-5: 3.00%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.03%
Result: Top-1: 0.33%, Top-5: 3.03%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.40%
[Alpha=0.70] Top-5 Accuracy: 2.90%
Result: Top-1: 0.40%, Top-5: 2.90%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 2.97%
Result: Top-1: 0.32%, Top-5: 2.97%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.13%
Result: Top-1: 0.33%, Top-5: 3.13%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.31%
[Alpha=0.70] Top-5 Accuracy: 3.07%
Result: Top-1: 0.31%, Top-5: 3.07%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.01%
Result: Top-1: 0.37%, Top-5: 3.01%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.00%
Result: Top-1: 0.33%, Top-5: 3.00%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.35%
[Alpha=0.70] Top-5 Accuracy: 3.02%
Result: Top-1: 0.35%, Top-5: 3.02%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.30%
[Alpha=0.70] Top-5 Accuracy: 3.00%
Result: Top-1: 0.30%, Top-5: 3.00%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 3.13%
Result: Top-1: 0.32%, Top-5: 3.13%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.34%
[Alpha=0.70] Top-5 Accuracy: 3.03%
Result: Top-1: 0.34%, Top-5: 3.03%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.41%
[Alpha=0.70] Top-5 Accuracy: 3.03%
Result: Top-1: 0.41%, Top-5: 3.03%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.04%
Result: Top-1: 0.37%, Top-5: 3.04%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.38%
[Alpha=0.70] Top-5 Accuracy: 3.13%
Result: Top-1: 0.38%, Top-5: 3.13%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.36%
[Alpha=0.70] Top-5 Accuracy: 3.21%
Result: Top-1: 0.36%, Top-5: 3.21%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.41%
[Alpha=0.70] Top-5 Accuracy: 3.24%
Result: Top-1: 0.41%, Top-5: 3.24%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.15%
Result: Top-1: 0.37%, Top-5: 3.15%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.35%
[Alpha=0.70] Top-5 Accuracy: 3.07%
Result: Top-1: 0.35%, Top-5: 3.07%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.36%
[Alpha=0.70] Top-5 Accuracy: 3.18%
Result: Top-1: 0.36%, Top-5: 3.18%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.33%
[Alpha=0.70] Top-5 Accuracy: 3.19%
Result: Top-1: 0.33%, Top-5: 3.19%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.39%
[Alpha=0.70] Top-5 Accuracy: 3.11%
Result: Top-1: 0.39%, Top-5: 3.11%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.40%
[Alpha=0.70] Top-5 Accuracy: 3.12%
Result: Top-1: 0.40%, Top-5: 3.12%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.40%
[Alpha=0.70] Top-5 Accuracy: 3.12%
Result: Top-1: 0.40%, Top-5: 3.12%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.32%
[Alpha=0.70] Top-5 Accuracy: 3.12%
Result: Top-1: 0.32%, Top-5: 3.12%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.17%
Result: Top-1: 0.37%, Top-5: 3.17%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.39%
[Alpha=0.70] Top-5 Accuracy: 3.14%
Result: Top-1: 0.39%, Top-5: 3.14%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.20%
Result: Top-1: 0.37%, Top-5: 3.20%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.40%
[Alpha=0.70] Top-5 Accuracy: 3.02%
Result: Top-1: 0.40%, Top-5: 3.02%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.38%
[Alpha=0.70] Top-5 Accuracy: 3.10%
Result: Top-1: 0.38%, Top-5: 3.10%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.38%
[Alpha=0.70] Top-5 Accuracy: 3.17%
Result: Top-1: 0.38%, Top-5: 3.17%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.37%
[Alpha=0.70] Top-5 Accuracy: 3.11%
Result: Top-1: 0.37%, Top-5: 3.11%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.78%
Result: Top-1: 0.29%, Top-5: 1.78%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.27%
[Alpha=0.80] Top-5 Accuracy: 1.85%
Result: Top-1: 0.27%, Top-5: 1.85%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.91%
Result: Top-1: 0.29%, Top-5: 1.91%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.27%
[Alpha=0.80] Top-5 Accuracy: 1.86%
Result: Top-1: 0.27%, Top-5: 1.86%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.26%
[Alpha=0.80] Top-5 Accuracy: 1.91%
Result: Top-1: 0.26%, Top-5: 1.91%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.93%
Result: Top-1: 0.29%, Top-5: 1.93%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.96%
Result: Top-1: 0.29%, Top-5: 1.96%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.95%
Result: Top-1: 0.29%, Top-5: 1.95%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.28%
[Alpha=0.80] Top-5 Accuracy: 1.96%
Result: Top-1: 0.28%, Top-5: 1.96%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.92%
Result: Top-1: 0.29%, Top-5: 1.92%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.28%
[Alpha=0.80] Top-5 Accuracy: 1.83%
Result: Top-1: 0.28%, Top-5: 1.83%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.26%
[Alpha=0.80] Top-5 Accuracy: 2.04%
Result: Top-1: 0.26%, Top-5: 2.04%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.26%
[Alpha=0.80] Top-5 Accuracy: 1.94%
Result: Top-1: 0.26%, Top-5: 1.94%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.99%
Result: Top-1: 0.29%, Top-5: 1.99%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 1.99%
Result: Top-1: 0.30%, Top-5: 1.99%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 1.97%
Result: Top-1: 0.30%, Top-5: 1.97%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.27%
[Alpha=0.80] Top-5 Accuracy: 1.96%
Result: Top-1: 0.27%, Top-5: 1.96%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 2.03%
Result: Top-1: 0.30%, Top-5: 2.03%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 2.00%
Result: Top-1: 0.29%, Top-5: 2.00%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.27%
[Alpha=0.80] Top-5 Accuracy: 2.08%
Result: Top-1: 0.27%, Top-5: 2.08%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 1.87%
Result: Top-1: 0.29%, Top-5: 1.87%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.27%
[Alpha=0.80] Top-5 Accuracy: 2.11%
Result: Top-1: 0.27%, Top-5: 2.11%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 1.96%
Result: Top-1: 0.30%, Top-5: 1.96%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 2.02%
Result: Top-1: 0.30%, Top-5: 2.02%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.27%
[Alpha=0.80] Top-5 Accuracy: 2.13%
Result: Top-1: 0.27%, Top-5: 2.13%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 2.08%
Result: Top-1: 0.31%, Top-5: 2.08%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 2.13%
Result: Top-1: 0.29%, Top-5: 2.13%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.33%
[Alpha=0.80] Top-5 Accuracy: 2.09%
Result: Top-1: 0.33%, Top-5: 2.09%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 2.08%
Result: Top-1: 0.30%, Top-5: 2.08%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 2.06%
Result: Top-1: 0.30%, Top-5: 2.06%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 1.91%
Result: Top-1: 0.31%, Top-5: 1.91%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 2.16%
Result: Top-1: 0.30%, Top-5: 2.16%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.30%
[Alpha=0.80] Top-5 Accuracy: 2.22%
Result: Top-1: 0.30%, Top-5: 2.22%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.28%
[Alpha=0.80] Top-5 Accuracy: 2.19%
Result: Top-1: 0.28%, Top-5: 2.19%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.32%
[Alpha=0.80] Top-5 Accuracy: 2.15%
Result: Top-1: 0.32%, Top-5: 2.15%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 2.11%
Result: Top-1: 0.31%, Top-5: 2.11%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.32%
[Alpha=0.80] Top-5 Accuracy: 2.15%
Result: Top-1: 0.32%, Top-5: 2.15%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.28%
[Alpha=0.80] Top-5 Accuracy: 2.12%
Result: Top-1: 0.28%, Top-5: 2.12%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.29%
[Alpha=0.80] Top-5 Accuracy: 2.25%
Result: Top-1: 0.29%, Top-5: 2.25%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 2.18%
Result: Top-1: 0.31%, Top-5: 2.18%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.33%
[Alpha=0.80] Top-5 Accuracy: 2.07%
Result: Top-1: 0.33%, Top-5: 2.07%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.29%
Result: Top-1: 0.34%, Top-5: 2.29%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.37%
Result: Top-1: 0.34%, Top-5: 2.37%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.33%
[Alpha=0.80] Top-5 Accuracy: 2.37%
Result: Top-1: 0.33%, Top-5: 2.37%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.37%
[Alpha=0.80] Top-5 Accuracy: 2.40%
Result: Top-1: 0.37%, Top-5: 2.40%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.32%
[Alpha=0.80] Top-5 Accuracy: 2.33%
Result: Top-1: 0.32%, Top-5: 2.33%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 2.35%
Result: Top-1: 0.31%, Top-5: 2.35%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.32%
Result: Top-1: 0.34%, Top-5: 2.32%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 2.40%
Result: Top-1: 0.31%, Top-5: 2.40%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.35%
[Alpha=0.80] Top-5 Accuracy: 2.28%
Result: Top-1: 0.35%, Top-5: 2.28%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.32%
[Alpha=0.80] Top-5 Accuracy: 2.32%
Result: Top-1: 0.32%, Top-5: 2.32%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.36%
[Alpha=0.80] Top-5 Accuracy: 2.51%
Result: Top-1: 0.36%, Top-5: 2.51%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.31%
[Alpha=0.80] Top-5 Accuracy: 2.45%
Result: Top-1: 0.31%, Top-5: 2.45%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.48%
Result: Top-1: 0.34%, Top-5: 2.48%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.45%
Result: Top-1: 0.34%, Top-5: 2.45%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.57%
Result: Top-1: 0.34%, Top-5: 2.57%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.35%
[Alpha=0.80] Top-5 Accuracy: 2.41%
Result: Top-1: 0.35%, Top-5: 2.41%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.35%
[Alpha=0.80] Top-5 Accuracy: 2.38%
Result: Top-1: 0.35%, Top-5: 2.38%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.36%
[Alpha=0.80] Top-5 Accuracy: 2.39%
Result: Top-1: 0.36%, Top-5: 2.39%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.34%
[Alpha=0.80] Top-5 Accuracy: 2.41%
Result: Top-1: 0.34%, Top-5: 2.41%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.19%
Result: Top-1: 0.26%, Top-5: 1.19%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.34%
Result: Top-1: 0.27%, Top-5: 1.34%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.37%
Result: Top-1: 0.27%, Top-5: 1.37%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.35%
Result: Top-1: 0.26%, Top-5: 1.35%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.39%
Result: Top-1: 0.26%, Top-5: 1.39%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.37%
Result: Top-1: 0.27%, Top-5: 1.37%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.37%
Result: Top-1: 0.27%, Top-5: 1.37%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.34%
Result: Top-1: 0.27%, Top-5: 1.34%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.39%
Result: Top-1: 0.27%, Top-5: 1.39%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.38%
Result: Top-1: 0.27%, Top-5: 1.38%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.23%
Result: Top-1: 0.26%, Top-5: 1.23%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.25%
[Alpha=0.90] Top-5 Accuracy: 1.45%
Result: Top-1: 0.25%, Top-5: 1.45%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.25%
[Alpha=0.90] Top-5 Accuracy: 1.45%
Result: Top-1: 0.25%, Top-5: 1.45%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.47%
Result: Top-1: 0.26%, Top-5: 1.47%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.44%
Result: Top-1: 0.28%, Top-5: 1.44%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.46%
Result: Top-1: 0.27%, Top-5: 1.46%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.50%
Result: Top-1: 0.26%, Top-5: 1.50%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.51%
Result: Top-1: 0.28%, Top-5: 1.51%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.46%
Result: Top-1: 0.27%, Top-5: 1.46%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.50%
Result: Top-1: 0.26%, Top-5: 1.50%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.27%
Result: Top-1: 0.27%, Top-5: 1.27%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.62%
Result: Top-1: 0.27%, Top-5: 1.62%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.49%
Result: Top-1: 0.29%, Top-5: 1.49%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.54%
Result: Top-1: 0.28%, Top-5: 1.54%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.26%
[Alpha=0.90] Top-5 Accuracy: 1.53%
Result: Top-1: 0.26%, Top-5: 1.53%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.59%
Result: Top-1: 0.28%, Top-5: 1.59%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.62%
Result: Top-1: 0.28%, Top-5: 1.62%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.31%
[Alpha=0.90] Top-5 Accuracy: 1.58%
Result: Top-1: 0.31%, Top-5: 1.58%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.55%
Result: Top-1: 0.29%, Top-5: 1.55%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.30%
[Alpha=0.90] Top-5 Accuracy: 1.52%
Result: Top-1: 0.30%, Top-5: 1.52%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.30%
Result: Top-1: 0.28%, Top-5: 1.30%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.64%
Result: Top-1: 0.29%, Top-5: 1.64%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.76%
Result: Top-1: 0.29%, Top-5: 1.76%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.65%
Result: Top-1: 0.28%, Top-5: 1.65%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.66%
Result: Top-1: 0.29%, Top-5: 1.66%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.63%
Result: Top-1: 0.28%, Top-5: 1.63%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.31%
[Alpha=0.90] Top-5 Accuracy: 1.67%
Result: Top-1: 0.31%, Top-5: 1.67%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.27%
[Alpha=0.90] Top-5 Accuracy: 1.66%
Result: Top-1: 0.27%, Top-5: 1.66%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.28%
[Alpha=0.90] Top-5 Accuracy: 1.67%
Result: Top-1: 0.28%, Top-5: 1.67%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.30%
[Alpha=0.90] Top-5 Accuracy: 1.66%
Result: Top-1: 0.30%, Top-5: 1.66%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.47%
Result: Top-1: 0.29%, Top-5: 1.47%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.32%
[Alpha=0.90] Top-5 Accuracy: 1.84%
Result: Top-1: 0.32%, Top-5: 1.84%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.32%
[Alpha=0.90] Top-5 Accuracy: 1.84%
Result: Top-1: 0.32%, Top-5: 1.84%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 1.89%
Result: Top-1: 0.33%, Top-5: 1.89%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.35%
[Alpha=0.90] Top-5 Accuracy: 1.88%
Result: Top-1: 0.35%, Top-5: 1.88%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.30%
[Alpha=0.90] Top-5 Accuracy: 1.82%
Result: Top-1: 0.30%, Top-5: 1.82%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.30%
[Alpha=0.90] Top-5 Accuracy: 1.86%
Result: Top-1: 0.30%, Top-5: 1.86%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.32%
[Alpha=0.90] Top-5 Accuracy: 1.87%
Result: Top-1: 0.32%, Top-5: 1.87%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.86%
Result: Top-1: 0.29%, Top-5: 1.86%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.34%
[Alpha=0.90] Top-5 Accuracy: 1.74%
Result: Top-1: 0.34%, Top-5: 1.74%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.81%
Result: Top-1: 0.29%, Top-5: 1.81%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.34%
[Alpha=0.90] Top-5 Accuracy: 2.05%
Result: Top-1: 0.34%, Top-5: 2.05%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.29%
[Alpha=0.90] Top-5 Accuracy: 1.97%
Result: Top-1: 0.29%, Top-5: 1.97%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 2.06%
Result: Top-1: 0.33%, Top-5: 2.06%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 1.96%
Result: Top-1: 0.33%, Top-5: 1.96%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 2.13%
Result: Top-1: 0.33%, Top-5: 2.13%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 1.97%
Result: Top-1: 0.33%, Top-5: 1.97%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.34%
[Alpha=0.90] Top-5 Accuracy: 1.90%
Result: Top-1: 0.34%, Top-5: 1.90%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.34%
[Alpha=0.90] Top-5 Accuracy: 1.92%
Result: Top-1: 0.34%, Top-5: 1.92%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 2.00%
Result: Top-1: 0.33%, Top-5: 2.00%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 0.95%
Result: Top-1: 0.26%, Top-5: 0.95%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.08%
Result: Top-1: 0.27%, Top-5: 1.08%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.15%
Result: Top-1: 0.27%, Top-5: 1.15%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.08%
Result: Top-1: 0.26%, Top-5: 1.08%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.14%
Result: Top-1: 0.26%, Top-5: 1.14%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.11%
Result: Top-1: 0.27%, Top-5: 1.11%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.13%
Result: Top-1: 0.27%, Top-5: 1.13%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.07%
Result: Top-1: 0.27%, Top-5: 1.07%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.11%
Result: Top-1: 0.27%, Top-5: 1.11%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.11%
Result: Top-1: 0.27%, Top-5: 1.11%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.25%
[Alpha=1.00] Top-5 Accuracy: 0.98%
Result: Top-1: 0.25%, Top-5: 0.98%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.25%
[Alpha=1.00] Top-5 Accuracy: 1.21%
Result: Top-1: 0.25%, Top-5: 1.21%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.24%
[Alpha=1.00] Top-5 Accuracy: 1.26%
Result: Top-1: 0.24%, Top-5: 1.26%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.22%
Result: Top-1: 0.26%, Top-5: 1.22%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.21%
Result: Top-1: 0.27%, Top-5: 1.21%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.24%
Result: Top-1: 0.26%, Top-5: 1.24%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.25%
[Alpha=1.00] Top-5 Accuracy: 1.25%
Result: Top-1: 0.25%, Top-5: 1.25%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.25%
Result: Top-1: 0.26%, Top-5: 1.25%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.22%
Result: Top-1: 0.26%, Top-5: 1.22%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.26%
Result: Top-1: 0.26%, Top-5: 1.26%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 0.98%
Result: Top-1: 0.26%, Top-5: 0.98%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.38%
Result: Top-1: 0.27%, Top-5: 1.38%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.26%
Result: Top-1: 0.28%, Top-5: 1.26%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.31%
Result: Top-1: 0.28%, Top-5: 1.31%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.27%
Result: Top-1: 0.26%, Top-5: 1.27%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.36%
Result: Top-1: 0.27%, Top-5: 1.36%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.34%
Result: Top-1: 0.27%, Top-5: 1.34%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.30%
[Alpha=1.00] Top-5 Accuracy: 1.34%
Result: Top-1: 0.30%, Top-5: 1.34%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.33%
Result: Top-1: 0.28%, Top-5: 1.33%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.29%
[Alpha=1.00] Top-5 Accuracy: 1.28%
Result: Top-1: 0.29%, Top-5: 1.28%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.04%
Result: Top-1: 0.28%, Top-5: 1.04%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.37%
Result: Top-1: 0.28%, Top-5: 1.37%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.44%
Result: Top-1: 0.28%, Top-5: 1.44%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.27%
[Alpha=1.00] Top-5 Accuracy: 1.37%
Result: Top-1: 0.27%, Top-5: 1.37%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.40%
Result: Top-1: 0.28%, Top-5: 1.40%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.38%
Result: Top-1: 0.28%, Top-5: 1.38%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.30%
[Alpha=1.00] Top-5 Accuracy: 1.41%
Result: Top-1: 0.30%, Top-5: 1.41%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.43%
Result: Top-1: 0.26%, Top-5: 1.43%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.38%
Result: Top-1: 0.28%, Top-5: 1.38%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.29%
[Alpha=1.00] Top-5 Accuracy: 1.43%
Result: Top-1: 0.29%, Top-5: 1.43%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.28%
[Alpha=1.00] Top-5 Accuracy: 1.19%
Result: Top-1: 0.28%, Top-5: 1.19%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.57%
Result: Top-1: 0.32%, Top-5: 1.57%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.31%
[Alpha=1.00] Top-5 Accuracy: 1.57%
Result: Top-1: 0.31%, Top-5: 1.57%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.57%
Result: Top-1: 0.32%, Top-5: 1.57%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 1.59%
Result: Top-1: 0.33%, Top-5: 1.59%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.29%
[Alpha=1.00] Top-5 Accuracy: 1.54%
Result: Top-1: 0.29%, Top-5: 1.54%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.29%
[Alpha=1.00] Top-5 Accuracy: 1.55%
Result: Top-1: 0.29%, Top-5: 1.55%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.31%
[Alpha=1.00] Top-5 Accuracy: 1.56%
Result: Top-1: 0.31%, Top-5: 1.56%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.29%
[Alpha=1.00] Top-5 Accuracy: 1.54%
Result: Top-1: 0.29%, Top-5: 1.54%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 1.51%
Result: Top-1: 0.34%, Top-5: 1.51%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.26%
[Alpha=1.00] Top-5 Accuracy: 1.42%
Result: Top-1: 0.26%, Top-5: 1.42%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 1.79%
Result: Top-1: 0.33%, Top-5: 1.79%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.29%
[Alpha=1.00] Top-5 Accuracy: 1.69%
Result: Top-1: 0.29%, Top-5: 1.69%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.75%
Result: Top-1: 0.32%, Top-5: 1.75%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.62%
Result: Top-1: 0.32%, Top-5: 1.62%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.83%
Result: Top-1: 0.32%, Top-5: 1.83%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.67%
Result: Top-1: 0.32%, Top-5: 1.67%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 1.64%
Result: Top-1: 0.33%, Top-5: 1.64%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 1.66%
Result: Top-1: 0.33%, Top-5: 1.66%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 1.75%
Result: Top-1: 0.32%, Top-5: 1.75%

================================================================================
SUMMARY OF ALL RESULTS
================================================================================
Alpha    Clusters   PCA_dim    Top-1      Top-5     
--------------------------------------------------
0.10     8          1          2.07       6.00      
0.10     8          25         2.10       5.99      
0.10     8          50         2.11       5.98      
0.10     8          75         2.09       5.98      
0.10     8          100        2.09       5.99      
0.10     8          125        2.09       6.00      
0.10     8          150        2.09       6.00      
0.10     8          175        2.08       5.98      
0.10     8          200        2.09       5.98      
0.10     8          220        2.09       6.01      
0.10     16         1          2.08       6.02      
0.10     16         25         2.09       5.99      
0.10     16         50         2.09       5.99      
0.10     16         75         2.08       5.96      
0.10     16         100        2.08       6.00      
0.10     16         125        2.10       5.97      
0.10     16         150        2.09       5.97      
0.10     16         175        2.09       5.97      
0.10     16         200        2.09       6.00      
0.10     16         220        2.09       5.99      
0.10     32         1          2.08       6.03      
0.10     32         25         2.11       6.03      
0.10     32         50         2.10       6.00      
0.10     32         75         2.11       5.98      
0.10     32         100        2.12       5.98      
0.10     32         125        2.11       5.99      
0.10     32         150        2.11       6.01      
0.10     32         175        2.07       5.98      
0.10     32         200        2.11       5.99      
0.10     32         220        2.12       5.98      
0.10     64         1          2.08       6.04      
0.10     64         25         2.10       5.99      
0.10     64         50         2.11       6.03      
0.10     64         75         2.09       6.02      
0.10     64         100        2.11       6.04      
0.10     64         125        2.07       6.03      
0.10     64         150        2.12       6.02      
0.10     64         175        2.12       5.97      
0.10     64         200        2.09       6.01      
0.10     64         220        2.10       6.01      
0.10     128        1          2.08       6.03      
0.10     128        25         2.10       6.00      
0.10     128        50         2.11       6.00      
0.10     128        75         2.09       6.00      
0.10     128        100        2.12       6.02      
0.10     128        125        2.08       6.01      
0.10     128        150        2.10       5.99      
0.10     128        175        2.09       6.03      
0.10     128        200        2.13       6.03      
0.10     128        220        2.09       6.01      
0.10     256        1          2.10       6.03      
0.10     256        25         2.10       6.02      
0.10     256        50         2.08       6.00      
0.10     256        75         2.10       5.99      
0.10     256        100        2.12       5.99      
0.10     256        125        2.10       6.04      
0.10     256        150        2.08       5.98      
0.10     256        175        2.05       6.02      
0.10     256        200        2.10       6.02      
0.10     256        220        2.12       6.02      
0.20     8          1          2.15       6.18      
0.20     8          25         2.16       6.16      
0.20     8          50         2.15       6.15      
0.20     8          75         2.17       6.16      
0.20     8          100        2.16       6.15      
0.20     8          125        2.19       6.21      
0.20     8          150        2.16       6.22      
0.20     8          175        2.17       6.17      
0.20     8          200        2.19       6.15      
0.20     8          220        2.17       6.21      
0.20     16         1          2.16       6.20      
0.20     16         25         2.14       6.13      
0.20     16         50         2.17       6.15      
0.20     16         75         2.15       6.16      
0.20     16         100        2.15       6.17      
0.20     16         125        2.16       6.12      
0.20     16         150        2.14       6.14      
0.20     16         175        2.15       6.16      
0.20     16         200        2.20       6.21      
0.20     16         220        2.16       6.19      
0.20     32         1          2.13       6.15      
0.20     32         25         2.21       6.18      
0.20     32         50         2.14       6.15      
0.20     32         75         2.15       6.17      
0.20     32         100        2.18       6.14      
0.20     32         125        2.13       6.17      
0.20     32         150        2.13       6.16      
0.20     32         175        2.12       6.16      
0.20     32         200        2.13       6.15      
0.20     32         220        2.19       6.16      
0.20     64         1          2.12       6.17      
0.20     64         25         2.15       6.10      
0.20     64         50         2.15       6.20      
0.20     64         75         2.16       6.08      
0.20     64         100        2.14       6.16      
0.20     64         125        2.12       6.17      
0.20     64         150        2.14       6.23      
0.20     64         175        2.15       6.14      
0.20     64         200        2.14       6.11      
0.20     64         220        2.15       6.17      
0.20     128        1          2.11       6.16      
0.20     128        25         2.14       6.10      
0.20     128        50         2.14       6.18      
0.20     128        75         2.14       6.12      
0.20     128        100        2.16       6.12      
0.20     128        125        2.12       6.10      
0.20     128        150        2.15       6.10      
0.20     128        175        2.13       6.19      
0.20     128        200        2.15       6.19      
0.20     128        220        2.11       6.18      
0.20     256        1          2.14       6.12      
0.20     256        25         2.12       6.11      
0.20     256        50         2.09       6.14      
0.20     256        75         2.15       6.14      
0.20     256        100        2.14       6.11      
0.20     256        125        2.10       6.12      
0.20     256        150        2.05       6.06      
0.20     256        175        2.03       6.08      
0.20     256        200        2.11       6.13      
0.20     256        220        2.13       6.20      
0.30     8          1          2.10       6.19      
0.30     8          25         1.90       6.02      
0.30     8          50         1.96       6.03      
0.30     8          75         1.91       6.04      
0.30     8          100        1.93       5.98      
0.30     8          125        2.01       6.07      
0.30     8          150        2.02       6.06      
0.30     8          175        2.00       6.04      
0.30     8          200        2.00       6.03      
0.30     8          220        2.03       6.08      
0.30     16         1          2.10       6.21      
0.30     16         25         1.89       6.09      
0.30     16         50         1.90       5.99      
0.30     16         75         1.96       6.12      
0.30     16         100        1.97       6.09      
0.30     16         125        1.92       6.02      
0.30     16         150        1.91       6.04      
0.30     16         175        1.91       6.05      
0.30     16         200        1.91       6.03      
0.30     16         220        1.90       6.05      
0.30     32         1          2.11       6.17      
0.30     32         25         1.85       5.98      
0.30     32         50         1.85       6.03      
0.30     32         75         1.90       6.00      
0.30     32         100        1.90       5.99      
0.30     32         125        1.83       6.00      
0.30     32         150        1.88       6.04      
0.30     32         175        1.83       5.99      
0.30     32         200        1.88       6.01      
0.30     32         220        1.89       6.01      
0.30     64         1          2.09       6.15      
0.30     64         25         1.73       5.95      
0.30     64         50         1.78       5.95      
0.30     64         75         1.75       5.92      
0.30     64         100        1.73       5.89      
0.30     64         125        1.71       5.93      
0.30     64         150        1.77       5.97      
0.30     64         175        1.74       5.97      
0.30     64         200        1.76       5.94      
0.30     64         220        1.79       6.01      
0.30     128        1          2.07       6.12      
0.30     128        25         1.73       5.87      
0.30     128        50         1.73       5.90      
0.30     128        75         1.68       5.95      
0.30     128        100        1.66       5.89      
0.30     128        125        1.76       6.00      
0.30     128        150        1.73       5.86      
0.30     128        175        1.74       5.99      
0.30     128        200        1.72       6.03      
0.30     128        220        1.67       5.95      
0.30     256        1          2.05       6.02      
0.30     256        25         1.66       5.85      
0.30     256        50         1.53       5.82      
0.30     256        75         1.64       5.88      
0.30     256        100        1.69       5.88      
0.30     256        125        1.60       5.84      
0.30     256        150        1.58       5.80      
0.30     256        175        1.61       5.87      
0.30     256        200        1.63       5.95      
0.30     256        220        1.66       5.93      
0.40     8          1          1.75       5.72      
0.40     8          25         1.38       5.60      
0.40     8          50         1.48       5.58      
0.40     8          75         1.41       5.58      
0.40     8          100        1.38       5.59      
0.40     8          125        1.46       5.67      
0.40     8          150        1.48       5.71      
0.40     8          175        1.54       5.67      
0.40     8          200        1.43       5.65      
0.40     8          220        1.48       5.73      
0.40     16         1          1.73       5.73      
0.40     16         25         1.30       5.73      
0.40     16         50         1.31       5.60      
0.40     16         75         1.30       5.67      
0.40     16         100        1.34       5.67      
0.40     16         125        1.30       5.71      
0.40     16         150        1.35       5.73      
0.40     16         175        1.31       5.67      
0.40     16         200        1.19       5.68      
0.40     16         220        1.27       5.67      
0.40     32         1          1.71       5.74      
0.40     32         25         1.10       5.61      
0.40     32         50         1.23       5.61      
0.40     32         75         1.21       5.63      
0.40     32         100        1.26       5.69      
0.40     32         125        1.21       5.70      
0.40     32         150        1.19       5.78      
0.40     32         175        1.16       5.65      
0.40     32         200        1.19       5.64      
0.40     32         220        1.17       5.65      
0.40     64         1          1.67       5.66      
0.40     64         25         1.01       5.55      
0.40     64         50         1.08       5.64      
0.40     64         75         1.02       5.50      
0.40     64         100        1.08       5.56      
0.40     64         125        1.03       5.58      
0.40     64         150        1.04       5.60      
0.40     64         175        1.00       5.49      
0.40     64         200        0.99       5.55      
0.40     64         220        1.08       5.60      
0.40     128        1          1.67       5.64      
0.40     128        25         0.99       5.55      
0.40     128        50         1.02       5.50      
0.40     128        75         1.02       5.56      
0.40     128        100        1.01       5.60      
0.40     128        125        1.12       5.54      
0.40     128        150        1.07       5.51      
0.40     128        175        1.01       5.63      
0.40     128        200        1.03       5.60      
0.40     128        220        1.03       5.59      
0.40     256        1          1.56       5.57      
0.40     256        25         0.98       5.43      
0.40     256        50         0.89       5.32      
0.40     256        75         0.97       5.47      
0.40     256        100        0.99       5.49      
0.40     256        125        0.93       5.46      
0.40     256        150        1.00       5.31      
0.40     256        175        1.00       5.42      
0.40     256        200        0.98       5.53      
0.40     256        220        0.99       5.47      
0.50     8          1          1.01       5.02      
0.50     8          25         0.78       5.00      
0.50     8          50         0.82       4.92      
0.50     8          75         0.79       4.98      
0.50     8          100        0.70       4.98      
0.50     8          125        0.82       5.04      
0.50     8          150        0.85       5.11      
0.50     8          175        0.85       5.05      
0.50     8          200        0.78       5.03      
0.50     8          220        0.85       5.10      
0.50     16         1          1.02       5.09      
0.50     16         25         0.73       5.09      
0.50     16         50         0.72       5.02      
0.50     16         75         0.74       5.04      
0.50     16         100        0.76       5.03      
0.50     16         125        0.80       5.08      
0.50     16         150        0.77       5.14      
0.50     16         175        0.73       5.08      
0.50     16         200        0.66       5.10      
0.50     16         220        0.70       5.00      
0.50     32         1          1.01       5.09      
0.50     32         25         0.56       4.94      
0.50     32         50         0.69       4.94      
0.50     32         75         0.65       5.04      
0.50     32         100        0.69       5.10      
0.50     32         125        0.71       5.03      
0.50     32         150        0.71       5.21      
0.50     32         175        0.72       5.03      
0.50     32         200        0.67       5.00      
0.50     32         220        0.66       5.02      
0.50     64         1          1.01       5.03      
0.50     64         25         0.58       4.95      
0.50     64         50         0.63       5.00      
0.50     64         75         0.56       5.00      
0.50     64         100        0.66       4.94      
0.50     64         125        0.60       4.83      
0.50     64         150        0.68       4.93      
0.50     64         175        0.54       4.81      
0.50     64         200        0.55       4.95      
0.50     64         220        0.62       4.98      
0.50     128        1          1.01       4.97      
0.50     128        25         0.59       4.93      
0.50     128        50         0.60       4.90      
0.50     128        75         0.63       4.94      
0.50     128        100        0.66       4.93      
0.50     128        125        0.69       4.90      
0.50     128        150        0.69       4.84      
0.50     128        175        0.62       4.98      
0.50     128        200        0.59       4.96      
0.50     128        220        0.64       4.91      
0.50     256        1          0.97       4.93      
0.50     256        25         0.64       4.78      
0.50     256        50         0.52       4.70      
0.50     256        75         0.60       4.79      
0.50     256        100        0.63       4.80      
0.50     256        125        0.59       4.80      
0.50     256        150        0.62       4.67      
0.50     256        175        0.61       4.68      
0.50     256        200        0.64       4.89      
0.50     256        220        0.61       4.85      
0.60     8          1          0.55       4.16      
0.60     8          25         0.43       4.12      
0.60     8          50         0.44       4.06      
0.60     8          75         0.43       4.10      
0.60     8          100        0.38       4.09      
0.60     8          125        0.45       4.15      
0.60     8          150        0.46       4.20      
0.60     8          175        0.44       4.17      
0.60     8          200        0.44       4.10      
0.60     8          220        0.47       4.18      
0.60     16         1          0.54       4.12      
0.60     16         25         0.43       4.13      
0.60     16         50         0.42       4.08      
0.60     16         75         0.43       4.14      
0.60     16         100        0.46       4.20      
0.60     16         125        0.50       4.08      
0.60     16         150        0.48       4.13      
0.60     16         175        0.45       4.18      
0.60     16         200        0.42       4.15      
0.60     16         220        0.42       4.17      
0.60     32         1          0.54       4.16      
0.60     32         25         0.37       4.09      
0.60     32         50         0.44       4.01      
0.60     32         75         0.43       4.12      
0.60     32         100        0.41       4.18      
0.60     32         125        0.46       4.00      
0.60     32         150        0.47       4.22      
0.60     32         175        0.49       4.07      
0.60     32         200        0.43       4.03      
0.60     32         220        0.39       4.15      
0.60     64         1          0.57       4.05      
0.60     64         25         0.42       4.13      
0.60     64         50         0.40       4.12      
0.60     64         75         0.38       4.05      
0.60     64         100        0.46       4.03      
0.60     64         125        0.43       3.90      
0.60     64         150        0.46       4.02      
0.60     64         175        0.35       3.98      
0.60     64         200        0.39       4.09      
0.60     64         220        0.42       4.02      
0.60     128        1          0.61       4.04      
0.60     128        25         0.44       4.07      
0.60     128        50         0.46       4.02      
0.60     128        75         0.45       4.14      
0.60     128        100        0.48       4.12      
0.60     128        125        0.48       4.03      
0.60     128        150        0.45       3.98      
0.60     128        175        0.44       4.00      
0.60     128        200        0.41       4.18      
0.60     128        220        0.49       4.10      
0.60     256        1          0.59       4.08      
0.60     256        25         0.47       3.94      
0.60     256        50         0.39       3.87      
0.60     256        75         0.43       3.97      
0.60     256        100        0.48       3.92      
0.60     256        125        0.45       3.96      
0.60     256        150        0.48       3.83      
0.60     256        175        0.44       3.93      
0.60     256        200        0.47       3.99      
0.60     256        220        0.44       4.03      
0.70     8          1          0.35       2.93      
0.70     8          25         0.31       2.86      
0.70     8          50         0.34       2.96      
0.70     8          75         0.30       2.84      
0.70     8          100        0.28       2.92      
0.70     8          125        0.32       2.99      
0.70     8          150        0.32       2.95      
0.70     8          175        0.32       2.97      
0.70     8          200        0.32       2.96      
0.70     8          220        0.32       2.95      
0.70     16         1          0.36       2.92      
0.70     16         25         0.31       3.10      
0.70     16         50         0.28       2.92      
0.70     16         75         0.33       3.02      
0.70     16         100        0.36       3.05      
0.70     16         125        0.35       2.92      
0.70     16         150        0.33       3.00      
0.70     16         175        0.34       3.07      
0.70     16         200        0.32       3.13      
0.70     16         220        0.30       3.06      
0.70     32         1          0.37       2.88      
0.70     32         25         0.30       3.08      
0.70     32         50         0.33       2.89      
0.70     32         75         0.33       3.00      
0.70     32         100        0.31       3.13      
0.70     32         125        0.33       2.97      
0.70     32         150        0.34       3.09      
0.70     32         175        0.37       3.00      
0.70     32         200        0.34       3.00      
0.70     32         220        0.33       3.03      
0.70     64         1          0.40       2.90      
0.70     64         25         0.32       2.97      
0.70     64         50         0.33       3.13      
0.70     64         75         0.31       3.07      
0.70     64         100        0.37       3.01      
0.70     64         125        0.33       3.00      
0.70     64         150        0.35       3.02      
0.70     64         175        0.30       3.00      
0.70     64         200        0.32       3.13      
0.70     64         220        0.34       3.03      
0.70     128        1          0.41       3.03      
0.70     128        25         0.37       3.04      
0.70     128        50         0.38       3.13      
0.70     128        75         0.36       3.21      
0.70     128        100        0.41       3.24      
0.70     128        125        0.37       3.15      
0.70     128        150        0.35       3.07      
0.70     128        175        0.36       3.18      
0.70     128        200        0.33       3.19      
0.70     128        220        0.39       3.11      
0.70     256        1          0.40       3.12      
0.70     256        25         0.40       3.12      
0.70     256        50         0.32       3.12      
0.70     256        75         0.37       3.17      
0.70     256        100        0.39       3.14      
0.70     256        125        0.37       3.20      
0.70     256        150        0.40       3.02      
0.70     256        175        0.38       3.10      
0.70     256        200        0.38       3.17      
0.70     256        220        0.37       3.11      
0.80     8          1          0.29       1.78      
0.80     8          25         0.27       1.85      
0.80     8          50         0.29       1.91      
0.80     8          75         0.27       1.86      
0.80     8          100        0.26       1.91      
0.80     8          125        0.29       1.93      
0.80     8          150        0.29       1.96      
0.80     8          175        0.29       1.95      
0.80     8          200        0.28       1.96      
0.80     8          220        0.29       1.92      
0.80     16         1          0.28       1.83      
0.80     16         25         0.26       2.04      
0.80     16         50         0.26       1.94      
0.80     16         75         0.29       1.99      
0.80     16         100        0.30       1.99      
0.80     16         125        0.30       1.97      
0.80     16         150        0.27       1.96      
0.80     16         175        0.30       2.03      
0.80     16         200        0.29       2.00      
0.80     16         220        0.27       2.08      
0.80     32         1          0.29       1.87      
0.80     32         25         0.27       2.11      
0.80     32         50         0.30       1.96      
0.80     32         75         0.30       2.02      
0.80     32         100        0.27       2.13      
0.80     32         125        0.31       2.08      
0.80     32         150        0.29       2.13      
0.80     32         175        0.33       2.09      
0.80     32         200        0.30       2.08      
0.80     32         220        0.30       2.06      
0.80     64         1          0.31       1.91      
0.80     64         25         0.30       2.16      
0.80     64         50         0.30       2.22      
0.80     64         75         0.28       2.19      
0.80     64         100        0.32       2.15      
0.80     64         125        0.31       2.11      
0.80     64         150        0.32       2.15      
0.80     64         175        0.28       2.12      
0.80     64         200        0.29       2.25      
0.80     64         220        0.31       2.18      
0.80     128        1          0.33       2.07      
0.80     128        25         0.34       2.29      
0.80     128        50         0.34       2.37      
0.80     128        75         0.33       2.37      
0.80     128        100        0.37       2.40      
0.80     128        125        0.32       2.33      
0.80     128        150        0.31       2.35      
0.80     128        175        0.34       2.32      
0.80     128        200        0.31       2.40      
0.80     128        220        0.35       2.28      
0.80     256        1          0.32       2.32      
0.80     256        25         0.36       2.51      
0.80     256        50         0.31       2.45      
0.80     256        75         0.34       2.48      
0.80     256        100        0.34       2.45      
0.80     256        125        0.34       2.57      
0.80     256        150        0.35       2.41      
0.80     256        175        0.35       2.38      
0.80     256        200        0.36       2.39      
0.80     256        220        0.34       2.41      
0.90     8          1          0.26       1.19      
0.90     8          25         0.27       1.34      
0.90     8          50         0.27       1.37      
0.90     8          75         0.26       1.35      
0.90     8          100        0.26       1.39      
0.90     8          125        0.27       1.37      
0.90     8          150        0.27       1.37      
0.90     8          175        0.27       1.34      
0.90     8          200        0.27       1.39      
0.90     8          220        0.27       1.38      
0.90     16         1          0.26       1.23      
0.90     16         25         0.25       1.45      
0.90     16         50         0.25       1.45      
0.90     16         75         0.26       1.47      
0.90     16         100        0.28       1.44      
0.90     16         125        0.27       1.46      
0.90     16         150        0.26       1.50      
0.90     16         175        0.28       1.51      
0.90     16         200        0.27       1.46      
0.90     16         220        0.26       1.50      
0.90     32         1          0.27       1.27      
0.90     32         25         0.27       1.62      
0.90     32         50         0.29       1.49      
0.90     32         75         0.28       1.54      
0.90     32         100        0.26       1.53      
0.90     32         125        0.28       1.59      
0.90     32         150        0.28       1.62      
0.90     32         175        0.31       1.58      
0.90     32         200        0.29       1.55      
0.90     32         220        0.30       1.52      
0.90     64         1          0.28       1.30      
0.90     64         25         0.29       1.64      
0.90     64         50         0.29       1.76      
0.90     64         75         0.28       1.65      
0.90     64         100        0.29       1.66      
0.90     64         125        0.28       1.63      
0.90     64         150        0.31       1.67      
0.90     64         175        0.27       1.66      
0.90     64         200        0.28       1.67      
0.90     64         220        0.30       1.66      
0.90     128        1          0.29       1.47      
0.90     128        25         0.32       1.84      
0.90     128        50         0.32       1.84      
0.90     128        75         0.33       1.89      
0.90     128        100        0.35       1.88      
0.90     128        125        0.30       1.82      
0.90     128        150        0.30       1.86      
0.90     128        175        0.32       1.87      
0.90     128        200        0.29       1.86      
0.90     128        220        0.34       1.74      
0.90     256        1          0.29       1.81      
0.90     256        25         0.34       2.05      
0.90     256        50         0.29       1.97      
0.90     256        75         0.33       2.06      
0.90     256        100        0.33       1.96      
0.90     256        125        0.33       2.13      
0.90     256        150        0.33       1.97      
0.90     256        175        0.34       1.90      
0.90     256        200        0.34       1.92      
0.90     256        220        0.33       2.00      
1.00     8          1          0.26       0.95      
1.00     8          25         0.27       1.08      
1.00     8          50         0.27       1.15      
1.00     8          75         0.26       1.08      
1.00     8          100        0.26       1.14      
1.00     8          125        0.27       1.11      
1.00     8          150        0.27       1.13      
1.00     8          175        0.27       1.07      
1.00     8          200        0.27       1.11      
1.00     8          220        0.27       1.11      
1.00     16         1          0.25       0.98      
1.00     16         25         0.25       1.21      
1.00     16         50         0.24       1.26      
1.00     16         75         0.26       1.22      
1.00     16         100        0.27       1.21      
1.00     16         125        0.26       1.24      
1.00     16         150        0.25       1.25      
1.00     16         175        0.26       1.25      
1.00     16         200        0.26       1.22      
1.00     16         220        0.26       1.26      
1.00     32         1          0.26       0.98      
1.00     32         25         0.27       1.38      
1.00     32         50         0.28       1.26      
1.00     32         75         0.28       1.31      
1.00     32         100        0.26       1.27      
1.00     32         125        0.27       1.36      
1.00     32         150        0.27       1.34      
1.00     32         175        0.30       1.34      
1.00     32         200        0.28       1.33      
1.00     32         220        0.29       1.28      
1.00     64         1          0.28       1.04      
1.00     64         25         0.28       1.37      
1.00     64         50         0.28       1.44      
1.00     64         75         0.27       1.37      
1.00     64         100        0.28       1.40      
1.00     64         125        0.28       1.38      
1.00     64         150        0.30       1.41      
1.00     64         175        0.26       1.43      
1.00     64         200        0.28       1.38      
1.00     64         220        0.29       1.43      
1.00     128        1          0.28       1.19      
1.00     128        25         0.32       1.57      
1.00     128        50         0.31       1.57      
1.00     128        75         0.32       1.57      
1.00     128        100        0.33       1.59      
1.00     128        125        0.29       1.54      
1.00     128        150        0.29       1.55      
1.00     128        175        0.31       1.56      
1.00     128        200        0.29       1.54      
1.00     128        220        0.34       1.51      
1.00     256        1          0.26       1.42      
1.00     256        25         0.33       1.79      
1.00     256        50         0.29       1.69      
1.00     256        75         0.32       1.75      
1.00     256        100        0.32       1.62      
1.00     256        125        0.32       1.83      
1.00     256        150        0.32       1.67      
1.00     256        175        0.33       1.64      
1.00     256        200        0.33       1.66      
1.00     256        220        0.32       1.75      

BEST RESULT:
  Alpha: 0.2
  Clusters: 32
  PCA_dim: 25
  Top-1 Accuracy: 2.21%
  Top-5 Accuracy: 6.18%
2025-09-10 12:59:31,839 - INFO - Experiment for seed 1001 completed in 162119.22 seconds
2025-09-10 12:59:31,841 - INFO - SUCCESS: Experiment for seed 1001 completed successfully
2025-09-10 12:59:31,844 - INFO - Looking for results in: ./checkpoint/quant_result/20250910_1017
2025-09-10 12:59:31,844 - INFO - Parsed 0 reconstructed results from log file for seed 1001
2025-09-10 12:59:31,844 - INFO - Parsed 0 baseline results from log file for seed 1001
2025-09-10 12:59:31,844 - INFO - Seed 1001 completed successfully
2025-09-10 12:59:31,844 - INFO - Sleeping for 0.5 seconds before next seed...
2025-09-10 12:59:32,344 - INFO - 
============================================================
2025-09-10 12:59:32,344 - INFO - Running experiment 2/3 for seed 1002
2025-09-10 12:59:32,345 - INFO - ============================================================
2025-09-10 12:59:32,346 - INFO - Running experiment for seed 1002
2025-09-10 12:59:32,346 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model vit_base --w_bit 2 --a_bit 2 --seed 1002 --config ../configs/4bit/brecq_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-10 12:59:32,346 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/brecq_base
2025-09-10 12:59:49 - start the process.
Namespace(model='vit_base', config='../configs/4bit/brecq_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1002, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=2, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 2
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: rinp
drop_prob: 1.0
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/vit_base_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
[timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 22.064 (22.064)	Loss 0.4459 (0.4459)	Prec@1 91.400 (91.400)	Prec@5 98.600 (98.600)
Test: [10/100]	Time 0.769 (3.206)	Loss 0.4659 (0.5379)	Prec@1 90.800 (88.455)	Prec@5 98.600 (98.345)
Test: [20/100]	Time 0.779 (2.419)	Loss 0.6057 (0.5588)	Prec@1 85.800 (88.124)	Prec@5 98.600 (98.095)
Test: [30/100]	Time 0.774 (2.155)	Loss 0.5066 (0.5820)	Prec@1 89.800 (87.471)	Prec@5 99.600 (98.045)
Test: [40/100]	Time 1.778 (2.026)	Loss 0.7571 (0.5772)	Prec@1 81.400 (87.532)	Prec@5 97.000 (98.088)
Test: [50/100]	Time 0.787 (1.783)	Loss 1.0069 (0.6165)	Prec@1 77.000 (86.384)	Prec@5 95.200 (97.827)
Test: [60/100]	Time 0.780 (1.620)	Loss 0.5700 (0.6205)	Prec@1 89.200 (86.285)	Prec@5 97.200 (97.751)
Test: [70/100]	Time 0.788 (1.503)	Loss 0.7296 (0.6361)	Prec@1 83.800 (85.673)	Prec@5 97.400 (97.654)
Test: [80/100]	Time 0.787 (1.415)	Loss 0.5101 (0.6392)	Prec@1 88.400 (85.605)	Prec@5 98.000 (97.580)
Test: [90/100]	Time 0.792 (1.346)	Loss 0.9420 (0.6541)	Prec@1 75.000 (85.062)	Prec@5 95.800 (97.495)
 * Prec@1 85.102 Prec@5 97.526 Loss 0.652 Time 129.844
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-10 13:02:44 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:11<14:18, 11.76s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:11<14:18, 11.76s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [01:26<58:14, 48.53s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [01:26<58:14, 48.53s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [01:51<44:52, 37.92s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [01:51<44:52, 37.92s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [03:02<59:26, 50.95s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [03:02<59:26, 50.95s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [04:02<1:02:25, 54.28s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [04:02<1:02:25, 54.28s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [05:55<1:24:09, 74.26s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [05:55<1:24:09, 74.26s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [07:51<1:38:09, 87.90s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [07:51<1:38:09, 87.90s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [09:07<1:32:32, 84.13s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [09:07<1:32:32, 84.13s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [09:34<1:11:38, 66.13s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [09:34<1:11:38, 66.13s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [10:46<1:12:26, 67.92s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [10:46<1:12:26, 67.92s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [11:46<1:09:01, 65.74s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [11:46<1:09:01, 65.74s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [13:40<1:22:52, 80.19s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [13:40<1:22:52, 80.19s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [15:36<1:32:43, 91.20s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [15:36<1:32:43, 91.20s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [16:52<1:26:29, 86.49s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [16:52<1:26:29, 86.49s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [17:18<1:07:11, 68.34s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [17:18<1:07:11, 68.34s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [18:30<1:07:01, 69.34s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [18:30<1:07:01, 69.34s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [19:30<1:03:20, 66.68s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [19:30<1:03:20, 66.68s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [21:23<1:15:10, 80.54s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [21:23<1:15:10, 80.54s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [23:18<1:23:23, 90.97s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [23:18<1:23:23, 90.97s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [24:34<1:17:45, 86.40s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [24:34<1:17:45, 86.40s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [25:00<1:00:23, 68.37s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [25:00<1:00:23, 68.37s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [26:13<1:00:19, 69.60s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [26:13<1:00:19, 69.60s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [27:14<57:00, 67.06s/it]  calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [27:14<57:00, 67.06s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [29:07<1:07:29, 80.99s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [29:07<1:07:29, 80.99s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [31:03<1:14:44, 91.53s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [31:03<1:14:44, 91.53s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [32:20<1:09:34, 86.98s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [32:20<1:09:34, 86.98s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [32:46<53:55, 68.84s/it]  calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [32:46<53:55, 68.84s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [33:59<53:42, 70.05s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [33:59<53:42, 70.05s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [35:01<50:37, 67.50s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [35:01<50:37, 67.50s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [36:55<59:41, 81.41s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [36:55<59:41, 81.41s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [38:51<1:05:56, 92.01s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [38:51<1:05:56, 92.01s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [40:08<1:01:11, 87.41s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [40:08<1:01:11, 87.41s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [40:35<47:14, 69.14s/it]  calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [40:35<47:14, 69.14s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [41:47<46:50, 70.27s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [41:47<46:50, 70.27s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [42:49<44:01, 67.73s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [42:49<44:01, 67.73s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [44:43<51:39, 81.58s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [44:43<51:39, 81.58s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [46:39<56:43, 91.99s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [46:39<56:43, 91.99s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [47:56<52:23, 87.31s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [47:56<52:23, 87.31s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [48:22<40:17, 69.06s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [48:22<40:17, 69.06s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [49:34<39:36, 69.89s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [49:34<39:36, 69.89s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [50:35<36:53, 67.07s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [50:35<36:53, 67.07s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [52:27<43:05, 80.78s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [52:27<43:05, 80.78s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [54:23<47:07, 91.21s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [54:23<47:07, 91.21s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [55:38<43:14, 86.50s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [55:39<43:14, 86.50s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [56:05<33:05, 68.46s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [56:05<33:05, 68.46s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [57:17<32:24, 69.46s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [57:17<32:24, 69.46s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [58:17<30:04, 66.85s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [58:17<30:04, 66.85s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [1:00:10<34:58, 80.71s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [1:00:10<34:58, 80.71s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [1:02:06<37:59, 91.20s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [1:02:06<37:59, 91.20s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [1:03:21<34:34, 86.44s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [1:03:21<34:34, 86.44s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [1:03:47<26:10, 68.29s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [1:03:47<26:10, 68.29s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [1:04:59<25:24, 69.32s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [1:04:59<25:24, 69.32s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [1:06:00<23:21, 66.74s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [1:06:00<23:21, 66.74s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [1:07:53<26:54, 80.71s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [1:07:53<26:54, 80.71s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [1:09:50<28:59, 91.56s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [1:09:50<28:59, 91.56s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [1:11:07<26:08, 87.13s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [1:11:07<26:08, 87.13s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [1:11:33<19:32, 68.98s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [1:11:33<19:32, 68.98s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [1:12:46<18:42, 70.13s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [1:12:46<18:42, 70.13s/it]calibrating blocks.9.attn.matmul2:  80%|███████▉  | 59/74 [1:13:48<16:53, 67.55s/it]calibrating blocks.9.mlp.fc1:  80%|███████▉  | 59/74 [1:13:48<16:53, 67.55s/it]     calibrating blocks.9.mlp.fc1:  81%|████████  | 60/74 [1:15:42<18:59, 81.40s/it]calibrating blocks.9.mlp.fc2:  81%|████████  | 60/74 [1:15:42<18:59, 81.40s/it]calibrating blocks.9.mlp.fc2:  82%|████████▏ | 61/74 [1:17:39<19:57, 92.11s/it]calibrating blocks.10.attn.qkv:  82%|████████▏ | 61/74 [1:17:39<19:57, 92.11s/it]calibrating blocks.10.attn.qkv:  84%|████████▍ | 62/74 [1:18:56<17:31, 87.59s/it]calibrating blocks.10.attn.proj:  84%|████████▍ | 62/74 [1:18:56<17:31, 87.59s/it]calibrating blocks.10.attn.proj:  85%|████████▌ | 63/74 [1:19:22<12:42, 69.29s/it]calibrating blocks.10.attn.matmul1:  85%|████████▌ | 63/74 [1:19:22<12:42, 69.29s/it]calibrating blocks.10.attn.matmul1:  86%|████████▋ | 64/74 [1:20:35<11:43, 70.31s/it]calibrating blocks.10.attn.matmul2:  86%|████████▋ | 64/74 [1:20:35<11:43, 70.31s/it]calibrating blocks.10.attn.matmul2:  88%|████████▊ | 65/74 [1:21:36<10:08, 67.60s/it]calibrating blocks.10.mlp.fc1:  88%|████████▊ | 65/74 [1:21:36<10:08, 67.60s/it]     calibrating blocks.10.mlp.fc1:  89%|████████▉ | 66/74 [1:23:30<10:50, 81.37s/it]calibrating blocks.10.mlp.fc2:  89%|████████▉ | 66/74 [1:23:30<10:50, 81.37s/it]calibrating blocks.10.mlp.fc2:  91%|█████████ | 67/74 [1:25:27<10:44, 92.08s/it]calibrating blocks.11.attn.qkv:  91%|█████████ | 67/74 [1:25:27<10:44, 92.08s/it]calibrating blocks.11.attn.qkv:  92%|█████████▏| 68/74 [1:26:44<08:44, 87.48s/it]calibrating blocks.11.attn.proj:  92%|█████████▏| 68/74 [1:26:44<08:44, 87.48s/it]calibrating blocks.11.attn.proj:  93%|█████████▎| 69/74 [1:27:10<05:46, 69.21s/it]calibrating blocks.11.attn.matmul1:  93%|█████████▎| 69/74 [1:27:10<05:46, 69.21s/it]calibrating blocks.11.attn.matmul1:  95%|█████████▍| 70/74 [1:28:23<04:40, 70.17s/it]calibrating blocks.11.attn.matmul2:  95%|█████████▍| 70/74 [1:28:23<04:40, 70.17s/it]calibrating blocks.11.attn.matmul2:  96%|█████████▌| 71/74 [1:29:24<03:22, 67.53s/it]calibrating blocks.11.mlp.fc1:  96%|█████████▌| 71/74 [1:29:24<03:22, 67.53s/it]     calibrating blocks.11.mlp.fc1:  97%|█████████▋| 72/74 [1:31:18<02:42, 81.39s/it]calibrating blocks.11.mlp.fc2:  97%|█████████▋| 72/74 [1:31:18<02:42, 81.39s/it]calibrating blocks.11.mlp.fc2:  99%|█████████▊| 73/74 [1:33:14<01:31, 91.97s/it]calibrating head:  99%|█████████▊| 73/74 [1:33:14<01:31, 91.97s/it]             calibrating head: 100%|██████████| 74/74 [1:33:18<00:00, 65.44s/it]calibrating head: 100%|██████████| 74/74 [1:33:18<00:00, 75.65s/it]
2025-09-10 14:36:30 - mse guided calibration finished.
Saving checkpoint to ./checkpoint/quant_result/20250910_1259/vit_base_w2_a2_calibsize_1000_mse.pth
Validating after calibration ...
Test: [0/100]	Time 5.092 (5.092)	Loss 7.2262 (7.2262)	Prec@1 0.000 (0.000)	Prec@5 0.200 (0.200)
Test: [10/100]	Time 1.661 (1.975)	Loss 7.8698 (7.4549)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.145)
Test: [20/100]	Time 1.667 (1.827)	Loss 7.3905 (7.4693)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.105)
Test: [30/100]	Time 1.664 (1.775)	Loss 7.1790 (7.3905)	Prec@1 0.000 (0.039)	Prec@5 0.000 (0.361)
Test: [40/100]	Time 1.671 (1.748)	Loss 7.3001 (7.3497)	Prec@1 0.000 (0.185)	Prec@5 3.000 (0.751)
Test: [50/100]	Time 1.668 (1.733)	Loss 7.9359 (7.3326)	Prec@1 0.000 (0.157)	Prec@5 0.000 (0.769)
Test: [60/100]	Time 1.664 (1.722)	Loss 7.6898 (7.3476)	Prec@1 0.000 (0.131)	Prec@5 0.000 (0.643)
Test: [70/100]	Time 1.663 (1.714)	Loss 6.8161 (7.3304)	Prec@1 0.000 (0.113)	Prec@5 0.000 (0.572)
Test: [80/100]	Time 1.667 (1.709)	Loss 7.4159 (7.3400)	Prec@1 0.000 (0.099)	Prec@5 0.000 (0.501)
Test: [90/100]	Time 1.666 (1.704)	Loss 7.3929 (7.3405)	Prec@1 0.000 (0.088)	Prec@5 0.000 (0.448)
 * Prec@1 0.112 Prec@5 0.500 Loss 7.339 Time 170.296
Building calibrator ...
2025-09-10 14:39:25 - start mse guided block reconstruction
reconstructing patch_embed ...
initializing raw input and raw output ...
adaround training for patch_embed ...
wraping quantizers in patch_embed ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.059 (rec:0.059, round:0.000)	b=0.00	count=500
Total loss:	0.035 (rec:0.035, round:0.000)	b=0.00	count=1000
Total loss:	0.024 (rec:0.024, round:0.000)	b=0.00	count=1500
Total loss:	0.013 (rec:0.013, round:0.000)	b=0.00	count=2000
Total loss:	0.018 (rec:0.018, round:0.000)	b=0.00	count=2500
Total loss:	0.014 (rec:0.014, round:0.000)	b=0.00	count=3000
Total loss:	0.013 (rec:0.013, round:0.000)	b=0.00	count=3500
Total loss:	5555.646 (rec:0.013, round:5555.634)	b=20.00	count=4000
Total loss:	2804.747 (rec:0.028, round:2804.719)	b=19.44	count=4500
Total loss:	2589.531 (rec:0.021, round:2589.510)	b=18.88	count=5000
Total loss:	2446.385 (rec:0.021, round:2446.364)	b=18.31	count=5500
Total loss:	2324.180 (rec:0.025, round:2324.156)	b=17.75	count=6000
Total loss:	2205.890 (rec:0.024, round:2205.866)	b=17.19	count=6500
Total loss:	2087.526 (rec:0.020, round:2087.506)	b=16.62	count=7000
Total loss:	1968.323 (rec:0.018, round:1968.305)	b=16.06	count=7500
Total loss:	1844.530 (rec:0.022, round:1844.508)	b=15.50	count=8000
Total loss:	1716.888 (rec:0.043, round:1716.845)	b=14.94	count=8500
Total loss:	1587.861 (rec:0.027, round:1587.834)	b=14.38	count=9000
Total loss:	1457.137 (rec:0.020, round:1457.117)	b=13.81	count=9500
Total loss:	1322.570 (rec:0.035, round:1322.535)	b=13.25	count=10000
Total loss:	1185.503 (rec:0.038, round:1185.465)	b=12.69	count=10500
Total loss:	1044.149 (rec:0.030, round:1044.119)	b=12.12	count=11000
Total loss:	905.547 (rec:0.029, round:905.518)	b=11.56	count=11500
Total loss:	764.830 (rec:0.048, round:764.782)	b=11.00	count=12000
Total loss:	630.022 (rec:0.035, round:629.987)	b=10.44	count=12500
Total loss:	498.514 (rec:0.054, round:498.460)	b=9.88	count=13000
Total loss:	375.633 (rec:0.052, round:375.582)	b=9.31	count=13500
Total loss:	267.244 (rec:0.091, round:267.153)	b=8.75	count=14000
Total loss:	177.577 (rec:0.065, round:177.512)	b=8.19	count=14500
Total loss:	107.063 (rec:0.061, round:107.002)	b=7.62	count=15000
Total loss:	57.623 (rec:0.082, round:57.541)	b=7.06	count=15500
Total loss:	27.324 (rec:0.098, round:27.226)	b=6.50	count=16000
Total loss:	10.754 (rec:0.072, round:10.682)	b=5.94	count=16500
Total loss:	4.582 (rec:0.111, round:4.471)	b=5.38	count=17000
Total loss:	2.198 (rec:0.124, round:2.075)	b=4.81	count=17500
Total loss:	1.029 (rec:0.103, round:0.927)	b=4.25	count=18000
Total loss:	0.350 (rec:0.086, round:0.265)	b=3.69	count=18500
Total loss:	0.157 (rec:0.112, round:0.046)	b=3.12	count=19000
Total loss:	0.126 (rec:0.124, round:0.002)	b=2.56	count=19500
Total loss:	0.087 (rec:0.087, round:0.000)	b=2.00	count=20000
finished reconstructing patch_embed.
reconstructing blocks.0 ...
initializing raw input and raw output ...
adaround training for blocks.0 ...
wraping quantizers in blocks.0 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.850 (rec:0.850, round:0.000)	b=0.00	count=500
Total loss:	0.439 (rec:0.439, round:0.000)	b=0.00	count=1000
Total loss:	0.367 (rec:0.367, round:0.000)	b=0.00	count=1500
Total loss:	0.357 (rec:0.357, round:0.000)	b=0.00	count=2000
Total loss:	0.299 (rec:0.299, round:0.000)	b=0.00	count=2500
Total loss:	0.269 (rec:0.269, round:0.000)	b=0.00	count=3000
Total loss:	0.280 (rec:0.280, round:0.000)	b=0.00	count=3500
Total loss:	61819.855 (rec:0.256, round:61819.598)	b=20.00	count=4000
Total loss:	21725.355 (rec:0.266, round:21725.090)	b=19.44	count=4500
Total loss:	19738.148 (rec:0.238, round:19737.910)	b=18.88	count=5000
Total loss:	18423.439 (rec:0.239, round:18423.199)	b=18.31	count=5500
Total loss:	17284.539 (rec:0.226, round:17284.312)	b=17.75	count=6000
Total loss:	16224.079 (rec:0.229, round:16223.851)	b=17.19	count=6500
Total loss:	15212.219 (rec:0.244, round:15211.975)	b=16.62	count=7000
Total loss:	14242.979 (rec:0.226, round:14242.753)	b=16.06	count=7500
Total loss:	13311.506 (rec:0.245, round:13311.261)	b=15.50	count=8000
Total loss:	12413.055 (rec:0.239, round:12412.816)	b=14.94	count=8500
Total loss:	11543.181 (rec:0.229, round:11542.951)	b=14.38	count=9000
Total loss:	10695.762 (rec:0.244, round:10695.518)	b=13.81	count=9500
Total loss:	9878.474 (rec:0.236, round:9878.237)	b=13.25	count=10000
Total loss:	9082.861 (rec:0.239, round:9082.622)	b=12.69	count=10500
Total loss:	8309.800 (rec:0.222, round:8309.578)	b=12.12	count=11000
Total loss:	7549.211 (rec:0.235, round:7548.976)	b=11.56	count=11500
Total loss:	6808.387 (rec:0.238, round:6808.149)	b=11.00	count=12000
Total loss:	6079.319 (rec:0.234, round:6079.086)	b=10.44	count=12500
Total loss:	5365.657 (rec:0.238, round:5365.419)	b=9.88	count=13000
Total loss:	4669.191 (rec:0.229, round:4668.962)	b=9.31	count=13500
Total loss:	3990.022 (rec:0.230, round:3989.792)	b=8.75	count=14000
Total loss:	3330.310 (rec:0.232, round:3330.078)	b=8.19	count=14500
Total loss:	2705.372 (rec:0.248, round:2705.123)	b=7.62	count=15000
Total loss:	2112.563 (rec:0.229, round:2112.333)	b=7.06	count=15500
Total loss:	1570.958 (rec:0.236, round:1570.722)	b=6.50	count=16000
Total loss:	1093.232 (rec:0.235, round:1092.996)	b=5.94	count=16500
Total loss:	698.661 (rec:0.246, round:698.415)	b=5.38	count=17000
Total loss:	391.238 (rec:0.245, round:390.993)	b=4.81	count=17500
Total loss:	179.074 (rec:0.246, round:178.828)	b=4.25	count=18000
Total loss:	59.998 (rec:0.238, round:59.760)	b=3.69	count=18500
Total loss:	11.496 (rec:0.252, round:11.244)	b=3.12	count=19000
Total loss:	1.210 (rec:0.247, round:0.963)	b=2.56	count=19500
Total loss:	0.258 (rec:0.235, round:0.023)	b=2.00	count=20000
finished reconstructing blocks.0.
reconstructing blocks.1 ...
initializing raw input and raw output ...
adaround training for blocks.1 ...
wraping quantizers in blocks.1 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.804 (rec:0.804, round:0.000)	b=0.00	count=500
Total loss:	0.554 (rec:0.554, round:0.000)	b=0.00	count=1000
Total loss:	0.509 (rec:0.509, round:0.000)	b=0.00	count=1500
Total loss:	0.401 (rec:0.401, round:0.000)	b=0.00	count=2000
Total loss:	0.352 (rec:0.352, round:0.000)	b=0.00	count=2500
Total loss:	0.327 (rec:0.327, round:0.000)	b=0.00	count=3000
Total loss:	0.319 (rec:0.319, round:0.000)	b=0.00	count=3500
Total loss:	62082.523 (rec:0.295, round:62082.227)	b=20.00	count=4000
Total loss:	25636.760 (rec:0.297, round:25636.463)	b=19.44	count=4500
Total loss:	23278.109 (rec:0.278, round:23277.832)	b=18.88	count=5000
Total loss:	21596.047 (rec:0.282, round:21595.766)	b=18.31	count=5500
Total loss:	20078.018 (rec:0.267, round:20077.750)	b=17.75	count=6000
Total loss:	18634.570 (rec:0.244, round:18634.326)	b=17.19	count=6500
Total loss:	17250.496 (rec:0.239, round:17250.256)	b=16.62	count=7000
Total loss:	15914.665 (rec:0.247, round:15914.418)	b=16.06	count=7500
Total loss:	14618.526 (rec:0.270, round:14618.256)	b=15.50	count=8000
Total loss:	13382.860 (rec:0.253, round:13382.607)	b=14.94	count=8500
Total loss:	12190.947 (rec:0.269, round:12190.678)	b=14.38	count=9000
Total loss:	11037.096 (rec:0.249, round:11036.847)	b=13.81	count=9500
Total loss:	9939.357 (rec:0.261, round:9939.097)	b=13.25	count=10000
Total loss:	8927.387 (rec:0.248, round:8927.139)	b=12.69	count=10500
Total loss:	7983.272 (rec:0.254, round:7983.018)	b=12.12	count=11000
Total loss:	7098.957 (rec:0.256, round:7098.700)	b=11.56	count=11500
Total loss:	6267.479 (rec:0.252, round:6267.227)	b=11.00	count=12000
Total loss:	5486.417 (rec:0.271, round:5486.146)	b=10.44	count=12500
Total loss:	4744.747 (rec:0.275, round:4744.473)	b=9.88	count=13000
Total loss:	4050.754 (rec:0.259, round:4050.494)	b=9.31	count=13500
Total loss:	3396.292 (rec:0.236, round:3396.056)	b=8.75	count=14000
Total loss:	2786.147 (rec:0.262, round:2785.885)	b=8.19	count=14500
Total loss:	2210.518 (rec:0.255, round:2210.263)	b=7.62	count=15000
Total loss:	1676.019 (rec:0.245, round:1675.774)	b=7.06	count=15500
Total loss:	1172.953 (rec:0.256, round:1172.697)	b=6.50	count=16000
Total loss:	697.777 (rec:0.247, round:697.530)	b=5.94	count=16500
Total loss:	324.159 (rec:0.246, round:323.913)	b=5.38	count=17000
Total loss:	139.318 (rec:0.260, round:139.058)	b=4.81	count=17500
Total loss:	56.092 (rec:0.270, round:55.822)	b=4.25	count=18000
Total loss:	17.396 (rec:0.274, round:17.122)	b=3.69	count=18500
Total loss:	3.390 (rec:0.259, round:3.131)	b=3.12	count=19000
Total loss:	0.502 (rec:0.241, round:0.261)	b=2.56	count=19500
Total loss:	0.271 (rec:0.264, round:0.007)	b=2.00	count=20000
finished reconstructing blocks.1.
reconstructing blocks.2 ...
initializing raw input and raw output ...
adaround training for blocks.2 ...
wraping quantizers in blocks.2 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.870 (rec:0.870, round:0.000)	b=0.00	count=500
Total loss:	0.738 (rec:0.738, round:0.000)	b=0.00	count=1000
Total loss:	0.653 (rec:0.653, round:0.000)	b=0.00	count=1500
Total loss:	0.613 (rec:0.613, round:0.000)	b=0.00	count=2000
Total loss:	0.582 (rec:0.582, round:0.000)	b=0.00	count=2500
Total loss:	0.551 (rec:0.551, round:0.000)	b=0.00	count=3000
Total loss:	0.544 (rec:0.544, round:0.000)	b=0.00	count=3500
Total loss:	62912.676 (rec:0.535, round:62912.141)	b=20.00	count=4000
Total loss:	28606.496 (rec:0.537, round:28605.959)	b=19.44	count=4500
Total loss:	26135.342 (rec:0.529, round:26134.812)	b=18.88	count=5000
Total loss:	24396.311 (rec:0.502, round:24395.809)	b=18.31	count=5500
Total loss:	22856.928 (rec:0.495, round:22856.432)	b=17.75	count=6000
Total loss:	21411.615 (rec:0.504, round:21411.111)	b=17.19	count=6500
Total loss:	20028.574 (rec:0.499, round:20028.076)	b=16.62	count=7000
Total loss:	18708.756 (rec:0.491, round:18708.266)	b=16.06	count=7500
Total loss:	17433.121 (rec:0.484, round:17432.637)	b=15.50	count=8000
Total loss:	16205.927 (rec:0.479, round:16205.447)	b=14.94	count=8500
Total loss:	15015.158 (rec:0.483, round:15014.675)	b=14.38	count=9000
Total loss:	13866.184 (rec:0.488, round:13865.695)	b=13.81	count=9500
Total loss:	12756.225 (rec:0.492, round:12755.732)	b=13.25	count=10000
Total loss:	11681.078 (rec:0.485, round:11680.594)	b=12.69	count=10500
Total loss:	10638.451 (rec:0.494, round:10637.957)	b=12.12	count=11000
Total loss:	9622.823 (rec:0.492, round:9622.331)	b=11.56	count=11500
Total loss:	8641.600 (rec:0.501, round:8641.099)	b=11.00	count=12000
Total loss:	7692.668 (rec:0.488, round:7692.181)	b=10.44	count=12500
Total loss:	6771.310 (rec:0.502, round:6770.808)	b=9.88	count=13000
Total loss:	5879.690 (rec:0.491, round:5879.199)	b=9.31	count=13500
Total loss:	5015.764 (rec:0.492, round:5015.271)	b=8.75	count=14000
Total loss:	4185.912 (rec:0.488, round:4185.424)	b=8.19	count=14500
Total loss:	3394.589 (rec:0.490, round:3394.098)	b=7.62	count=15000
Total loss:	2642.506 (rec:0.501, round:2642.005)	b=7.06	count=15500
Total loss:	1942.891 (rec:0.490, round:1942.401)	b=6.50	count=16000
Total loss:	1280.754 (rec:0.509, round:1280.245)	b=5.94	count=16500
Total loss:	623.125 (rec:0.513, round:622.612)	b=5.38	count=17000
Total loss:	175.969 (rec:0.548, round:175.421)	b=4.81	count=17500
Total loss:	55.474 (rec:0.503, round:54.971)	b=4.25	count=18000
Total loss:	16.839 (rec:0.511, round:16.329)	b=3.69	count=18500
Total loss:	3.428 (rec:0.516, round:2.912)	b=3.12	count=19000
Total loss:	0.717 (rec:0.506, round:0.210)	b=2.56	count=19500
Total loss:	0.528 (rec:0.525, round:0.003)	b=2.00	count=20000
finished reconstructing blocks.2.
reconstructing blocks.3 ...
initializing raw input and raw output ...
adaround training for blocks.3 ...
wraping quantizers in blocks.3 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.943 (rec:0.943, round:0.000)	b=0.00	count=500
Total loss:	0.822 (rec:0.822, round:0.000)	b=0.00	count=1000
Total loss:	0.738 (rec:0.738, round:0.000)	b=0.00	count=1500
Total loss:	0.701 (rec:0.701, round:0.000)	b=0.00	count=2000
Total loss:	0.655 (rec:0.655, round:0.000)	b=0.00	count=2500
Total loss:	0.625 (rec:0.625, round:0.000)	b=0.00	count=3000
Total loss:	0.619 (rec:0.619, round:0.000)	b=0.00	count=3500
Total loss:	63051.098 (rec:0.575, round:63050.523)	b=20.00	count=4000
Total loss:	29059.477 (rec:0.573, round:29058.904)	b=19.44	count=4500
Total loss:	26638.850 (rec:0.572, round:26638.277)	b=18.88	count=5000
Total loss:	24944.502 (rec:0.567, round:24943.936)	b=18.31	count=5500
Total loss:	23451.680 (rec:0.548, round:23451.133)	b=17.75	count=6000
Total loss:	22052.609 (rec:0.543, round:22052.066)	b=17.19	count=6500
Total loss:	20711.000 (rec:0.551, round:20710.449)	b=16.62	count=7000
Total loss:	19404.711 (rec:0.534, round:19404.176)	b=16.06	count=7500
Total loss:	18137.451 (rec:0.550, round:18136.902)	b=15.50	count=8000
Total loss:	16910.111 (rec:0.533, round:16909.578)	b=14.94	count=8500
Total loss:	15712.526 (rec:0.531, round:15711.996)	b=14.38	count=9000
Total loss:	14547.269 (rec:0.536, round:14546.732)	b=13.81	count=9500
Total loss:	13404.260 (rec:0.535, round:13403.725)	b=13.25	count=10000
Total loss:	12291.935 (rec:0.530, round:12291.404)	b=12.69	count=10500
Total loss:	11208.616 (rec:0.532, round:11208.084)	b=12.12	count=11000
Total loss:	10155.771 (rec:0.533, round:10155.238)	b=11.56	count=11500
Total loss:	9123.503 (rec:0.538, round:9122.965)	b=11.00	count=12000
Total loss:	8125.340 (rec:0.531, round:8124.809)	b=10.44	count=12500
Total loss:	7149.448 (rec:0.556, round:7148.893)	b=9.88	count=13000
Total loss:	6197.784 (rec:0.554, round:6197.229)	b=9.31	count=13500
Total loss:	5286.453 (rec:0.551, round:5285.902)	b=8.75	count=14000
Total loss:	4409.606 (rec:0.553, round:4409.054)	b=8.19	count=14500
Total loss:	3573.082 (rec:0.559, round:3572.523)	b=7.62	count=15000
Total loss:	2781.138 (rec:0.550, round:2780.588)	b=7.06	count=15500
Total loss:	2044.511 (rec:0.556, round:2043.955)	b=6.50	count=16000
Total loss:	1359.498 (rec:0.547, round:1358.952)	b=5.94	count=16500
Total loss:	693.146 (rec:0.555, round:692.591)	b=5.38	count=17000
Total loss:	222.510 (rec:0.593, round:221.916)	b=4.81	count=17500
Total loss:	68.478 (rec:0.577, round:67.901)	b=4.25	count=18000
Total loss:	19.666 (rec:0.566, round:19.101)	b=3.69	count=18500
Total loss:	3.964 (rec:0.578, round:3.386)	b=3.12	count=19000
Total loss:	0.834 (rec:0.572, round:0.262)	b=2.56	count=19500
Total loss:	0.574 (rec:0.570, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.3.
reconstructing blocks.4 ...
initializing raw input and raw output ...
adaround training for blocks.4 ...
wraping quantizers in blocks.4 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.005 (rec:1.005, round:0.000)	b=0.00	count=500
Total loss:	0.881 (rec:0.881, round:0.000)	b=0.00	count=1000
Total loss:	0.780 (rec:0.780, round:0.000)	b=0.00	count=1500
Total loss:	0.729 (rec:0.729, round:0.000)	b=0.00	count=2000
Total loss:	0.686 (rec:0.686, round:0.000)	b=0.00	count=2500
Total loss:	0.652 (rec:0.652, round:0.000)	b=0.00	count=3000
Total loss:	0.610 (rec:0.610, round:0.000)	b=0.00	count=3500
Total loss:	63265.211 (rec:0.595, round:63264.617)	b=20.00	count=4000
Total loss:	29448.109 (rec:0.583, round:29447.527)	b=19.44	count=4500
Total loss:	27043.129 (rec:0.567, round:27042.562)	b=18.88	count=5000
Total loss:	25374.783 (rec:0.573, round:25374.211)	b=18.31	count=5500
Total loss:	23911.270 (rec:0.551, round:23910.719)	b=17.75	count=6000
Total loss:	22545.018 (rec:0.564, round:22544.453)	b=17.19	count=6500
Total loss:	21233.777 (rec:0.543, round:21233.234)	b=16.62	count=7000
Total loss:	19961.299 (rec:0.557, round:19960.742)	b=16.06	count=7500
Total loss:	18720.711 (rec:0.549, round:18720.162)	b=15.50	count=8000
Total loss:	17521.951 (rec:0.540, round:17521.412)	b=14.94	count=8500
Total loss:	16345.672 (rec:0.541, round:16345.131)	b=14.38	count=9000
Total loss:	15199.610 (rec:0.542, round:15199.068)	b=13.81	count=9500
Total loss:	14076.688 (rec:0.551, round:14076.137)	b=13.25	count=10000
Total loss:	12988.135 (rec:0.534, round:12987.601)	b=12.69	count=10500
Total loss:	11909.383 (rec:0.531, round:11908.853)	b=12.12	count=11000
Total loss:	10861.006 (rec:0.535, round:10860.471)	b=11.56	count=11500
Total loss:	9826.204 (rec:0.569, round:9825.635)	b=11.00	count=12000
Total loss:	8810.734 (rec:0.549, round:8810.186)	b=10.44	count=12500
Total loss:	7812.300 (rec:0.549, round:7811.751)	b=9.88	count=13000
Total loss:	6838.055 (rec:0.545, round:6837.510)	b=9.31	count=13500
Total loss:	5883.466 (rec:0.567, round:5882.899)	b=8.75	count=14000
Total loss:	4955.468 (rec:0.550, round:4954.918)	b=8.19	count=14500
Total loss:	4058.329 (rec:0.560, round:4057.770)	b=7.62	count=15000
Total loss:	3198.876 (rec:0.556, round:3198.320)	b=7.06	count=15500
Total loss:	2390.306 (rec:0.569, round:2389.736)	b=6.50	count=16000
Total loss:	1636.912 (rec:0.548, round:1636.364)	b=5.94	count=16500
Total loss:	922.880 (rec:0.580, round:922.299)	b=5.38	count=17000
Total loss:	277.149 (rec:0.587, round:276.562)	b=4.81	count=17500
Total loss:	60.374 (rec:0.564, round:59.810)	b=4.25	count=18000
Total loss:	17.138 (rec:0.574, round:16.564)	b=3.69	count=18500
Total loss:	3.670 (rec:0.592, round:3.078)	b=3.12	count=19000
Total loss:	0.827 (rec:0.599, round:0.228)	b=2.56	count=19500
Total loss:	0.586 (rec:0.581, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.4.
reconstructing blocks.5 ...
initializing raw input and raw output ...
adaround training for blocks.5 ...
wraping quantizers in blocks.5 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.062 (rec:1.062, round:0.000)	b=0.00	count=500
Total loss:	0.900 (rec:0.900, round:0.000)	b=0.00	count=1000
Total loss:	0.807 (rec:0.807, round:0.000)	b=0.00	count=1500
Total loss:	0.774 (rec:0.774, round:0.000)	b=0.00	count=2000
Total loss:	0.691 (rec:0.691, round:0.000)	b=0.00	count=2500
Total loss:	0.658 (rec:0.658, round:0.000)	b=0.00	count=3000
Total loss:	0.628 (rec:0.628, round:0.000)	b=0.00	count=3500
Total loss:	63088.156 (rec:0.597, round:63087.559)	b=20.00	count=4000
Total loss:	29010.742 (rec:0.584, round:29010.158)	b=19.44	count=4500
Total loss:	26576.803 (rec:0.577, round:26576.227)	b=18.88	count=5000
Total loss:	24877.287 (rec:0.568, round:24876.719)	b=18.31	count=5500
Total loss:	23362.387 (rec:0.558, round:23361.828)	b=17.75	count=6000
Total loss:	21938.229 (rec:0.565, round:21937.662)	b=17.19	count=6500
Total loss:	20584.727 (rec:0.556, round:20584.170)	b=16.62	count=7000
Total loss:	19273.340 (rec:0.550, round:19272.789)	b=16.06	count=7500
Total loss:	18013.021 (rec:0.549, round:18012.473)	b=15.50	count=8000
Total loss:	16792.936 (rec:0.534, round:16792.402)	b=14.94	count=8500
Total loss:	15611.882 (rec:0.542, round:15611.340)	b=14.38	count=9000
Total loss:	14462.635 (rec:0.541, round:14462.094)	b=13.81	count=9500
Total loss:	13357.565 (rec:0.546, round:13357.020)	b=13.25	count=10000
Total loss:	12288.689 (rec:0.553, round:12288.137)	b=12.69	count=10500
Total loss:	11253.503 (rec:0.548, round:11252.955)	b=12.12	count=11000
Total loss:	10238.697 (rec:0.547, round:10238.150)	b=11.56	count=11500
Total loss:	9246.971 (rec:0.560, round:9246.410)	b=11.00	count=12000
Total loss:	8284.569 (rec:0.548, round:8284.021)	b=10.44	count=12500
Total loss:	7347.095 (rec:0.547, round:7346.547)	b=9.88	count=13000
Total loss:	6427.651 (rec:0.560, round:6427.092)	b=9.31	count=13500
Total loss:	5531.381 (rec:0.564, round:5530.817)	b=8.75	count=14000
Total loss:	4659.191 (rec:0.546, round:4658.646)	b=8.19	count=14500
Total loss:	3813.624 (rec:0.559, round:3813.064)	b=7.62	count=15000
Total loss:	3006.483 (rec:0.559, round:3005.924)	b=7.06	count=15500
Total loss:	2240.743 (rec:0.557, round:2240.187)	b=6.50	count=16000
Total loss:	1525.309 (rec:0.563, round:1524.747)	b=5.94	count=16500
Total loss:	824.236 (rec:0.568, round:823.668)	b=5.38	count=17000
Total loss:	231.112 (rec:0.575, round:230.538)	b=4.81	count=17500
Total loss:	56.102 (rec:0.575, round:55.527)	b=4.25	count=18000
Total loss:	16.633 (rec:0.581, round:16.052)	b=3.69	count=18500
Total loss:	3.653 (rec:0.588, round:3.065)	b=3.12	count=19000
Total loss:	0.853 (rec:0.586, round:0.267)	b=2.56	count=19500
Total loss:	0.584 (rec:0.579, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.5.
reconstructing blocks.6 ...
initializing raw input and raw output ...
adaround training for blocks.6 ...
wraping quantizers in blocks.6 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.201 (rec:1.201, round:0.000)	b=0.00	count=500
Total loss:	1.020 (rec:1.020, round:0.000)	b=0.00	count=1000
Total loss:	0.948 (rec:0.948, round:0.000)	b=0.00	count=1500
Total loss:	0.883 (rec:0.883, round:0.000)	b=0.00	count=2000
Total loss:	0.818 (rec:0.818, round:0.000)	b=0.00	count=2500
Total loss:	0.793 (rec:0.793, round:0.000)	b=0.00	count=3000
Total loss:	0.750 (rec:0.750, round:0.000)	b=0.00	count=3500
Total loss:	62530.270 (rec:0.734, round:62529.535)	b=20.00	count=4000
Total loss:	28791.227 (rec:0.695, round:28790.531)	b=19.44	count=4500
Total loss:	26333.678 (rec:0.677, round:26333.000)	b=18.88	count=5000
Total loss:	24578.836 (rec:0.682, round:24578.154)	b=18.31	count=5500
Total loss:	23022.838 (rec:0.660, round:23022.178)	b=17.75	count=6000
Total loss:	21556.000 (rec:0.652, round:21555.348)	b=17.19	count=6500
Total loss:	20163.756 (rec:0.667, round:20163.088)	b=16.62	count=7000
Total loss:	18842.477 (rec:0.647, round:18841.830)	b=16.06	count=7500
Total loss:	17568.268 (rec:0.658, round:17567.609)	b=15.50	count=8000
Total loss:	16351.502 (rec:0.662, round:16350.840)	b=14.94	count=8500
Total loss:	15180.163 (rec:0.651, round:15179.512)	b=14.38	count=9000
Total loss:	14049.453 (rec:0.652, round:14048.801)	b=13.81	count=9500
Total loss:	12952.319 (rec:0.655, round:12951.664)	b=13.25	count=10000
Total loss:	11893.049 (rec:0.649, round:11892.399)	b=12.69	count=10500
Total loss:	10863.830 (rec:0.650, round:10863.180)	b=12.12	count=11000
Total loss:	9858.829 (rec:0.654, round:9858.175)	b=11.56	count=11500
Total loss:	8881.234 (rec:0.649, round:8880.585)	b=11.00	count=12000
Total loss:	7929.421 (rec:0.637, round:7928.784)	b=10.44	count=12500
Total loss:	7003.771 (rec:0.654, round:7003.117)	b=9.88	count=13000
Total loss:	6096.669 (rec:0.656, round:6096.014)	b=9.31	count=13500
Total loss:	5213.362 (rec:0.670, round:5212.692)	b=8.75	count=14000
Total loss:	4357.244 (rec:0.659, round:4356.584)	b=8.19	count=14500
Total loss:	3524.688 (rec:0.668, round:3524.021)	b=7.62	count=15000
Total loss:	2736.175 (rec:0.673, round:2735.502)	b=7.06	count=15500
Total loss:	1990.366 (rec:0.673, round:1989.693)	b=6.50	count=16000
Total loss:	1298.100 (rec:0.677, round:1297.423)	b=5.94	count=16500
Total loss:	689.670 (rec:0.683, round:688.987)	b=5.38	count=17000
Total loss:	275.098 (rec:0.674, round:274.424)	b=4.81	count=17500
Total loss:	91.950 (rec:0.693, round:91.257)	b=4.25	count=18000
Total loss:	25.986 (rec:0.679, round:25.307)	b=3.69	count=18500
Total loss:	5.173 (rec:0.693, round:4.480)	b=3.12	count=19000
Total loss:	1.017 (rec:0.683, round:0.334)	b=2.56	count=19500
Total loss:	0.698 (rec:0.693, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.6.
reconstructing blocks.7 ...
initializing raw input and raw output ...
adaround training for blocks.7 ...
wraping quantizers in blocks.7 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.720 (rec:0.720, round:0.000)	b=0.00	count=500
Total loss:	0.610 (rec:0.610, round:0.000)	b=0.00	count=1000
Total loss:	0.558 (rec:0.558, round:0.000)	b=0.00	count=1500
Total loss:	0.519 (rec:0.519, round:0.000)	b=0.00	count=2000
Total loss:	0.486 (rec:0.486, round:0.000)	b=0.00	count=2500
Total loss:	0.465 (rec:0.465, round:0.000)	b=0.00	count=3000
Total loss:	0.435 (rec:0.435, round:0.000)	b=0.00	count=3500
Total loss:	63380.086 (rec:0.428, round:63379.656)	b=20.00	count=4000
Total loss:	29644.201 (rec:0.429, round:29643.771)	b=19.44	count=4500
Total loss:	27227.359 (rec:0.418, round:27226.941)	b=18.88	count=5000
Total loss:	25534.504 (rec:0.417, round:25534.086)	b=18.31	count=5500
Total loss:	24030.682 (rec:0.407, round:24030.275)	b=17.75	count=6000
Total loss:	22613.393 (rec:0.395, round:22612.998)	b=17.19	count=6500
Total loss:	21256.566 (rec:0.393, round:21256.174)	b=16.62	count=7000
Total loss:	19940.527 (rec:0.395, round:19940.133)	b=16.06	count=7500
Total loss:	18659.682 (rec:0.392, round:18659.289)	b=15.50	count=8000
Total loss:	17415.650 (rec:0.395, round:17415.256)	b=14.94	count=8500
Total loss:	16198.440 (rec:0.389, round:16198.051)	b=14.38	count=9000
Total loss:	15016.104 (rec:0.380, round:15015.725)	b=13.81	count=9500
Total loss:	13864.100 (rec:0.378, round:13863.722)	b=13.25	count=10000
Total loss:	12746.825 (rec:0.399, round:12746.426)	b=12.69	count=10500
Total loss:	11651.138 (rec:0.385, round:11650.753)	b=12.12	count=11000
Total loss:	10583.291 (rec:0.387, round:10582.904)	b=11.56	count=11500
Total loss:	9536.006 (rec:0.389, round:9535.616)	b=11.00	count=12000
Total loss:	8511.468 (rec:0.388, round:8511.080)	b=10.44	count=12500
Total loss:	7508.145 (rec:0.381, round:7507.764)	b=9.88	count=13000
Total loss:	6537.160 (rec:0.387, round:6536.773)	b=9.31	count=13500
Total loss:	5594.073 (rec:0.391, round:5593.682)	b=8.75	count=14000
Total loss:	4676.397 (rec:0.392, round:4676.005)	b=8.19	count=14500
Total loss:	3785.653 (rec:0.399, round:3785.254)	b=7.62	count=15000
Total loss:	2935.755 (rec:0.400, round:2935.355)	b=7.06	count=15500
Total loss:	2135.539 (rec:0.401, round:2135.138)	b=6.50	count=16000
Total loss:	1397.104 (rec:0.411, round:1396.693)	b=5.94	count=16500
Total loss:	768.600 (rec:0.408, round:768.192)	b=5.38	count=17000
Total loss:	325.779 (rec:0.414, round:325.365)	b=4.81	count=17500
Total loss:	107.454 (rec:0.412, round:107.041)	b=4.25	count=18000
Total loss:	27.219 (rec:0.405, round:26.814)	b=3.69	count=18500
Total loss:	4.773 (rec:0.408, round:4.365)	b=3.12	count=19000
Total loss:	0.723 (rec:0.413, round:0.310)	b=2.56	count=19500
Total loss:	0.411 (rec:0.405, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.7.
reconstructing blocks.8 ...
initializing raw input and raw output ...
adaround training for blocks.8 ...
wraping quantizers in blocks.8 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.639 (rec:0.639, round:0.000)	b=0.00	count=500
Total loss:	0.553 (rec:0.553, round:0.000)	b=0.00	count=1000
Total loss:	0.501 (rec:0.501, round:0.000)	b=0.00	count=1500
Total loss:	0.476 (rec:0.476, round:0.000)	b=0.00	count=2000
Total loss:	0.452 (rec:0.452, round:0.000)	b=0.00	count=2500
Total loss:	0.434 (rec:0.434, round:0.000)	b=0.00	count=3000
Total loss:	0.404 (rec:0.404, round:0.000)	b=0.00	count=3500
Total loss:	64649.293 (rec:0.403, round:64648.891)	b=20.00	count=4000
Total loss:	30871.689 (rec:0.389, round:30871.301)	b=19.44	count=4500
Total loss:	28417.605 (rec:0.378, round:28417.227)	b=18.88	count=5000
Total loss:	26742.779 (rec:0.384, round:26742.395)	b=18.31	count=5500
Total loss:	25265.693 (rec:0.373, round:25265.320)	b=17.75	count=6000
Total loss:	23870.988 (rec:0.375, round:23870.613)	b=17.19	count=6500
Total loss:	22520.383 (rec:0.367, round:22520.016)	b=16.62	count=7000
Total loss:	21204.057 (rec:0.361, round:21203.695)	b=16.06	count=7500
Total loss:	19914.523 (rec:0.349, round:19914.174)	b=15.50	count=8000
Total loss:	18643.504 (rec:0.356, round:18643.148)	b=14.94	count=8500
Total loss:	17393.119 (rec:0.355, round:17392.764)	b=14.38	count=9000
Total loss:	16166.006 (rec:0.354, round:16165.652)	b=13.81	count=9500
Total loss:	14959.632 (rec:0.350, round:14959.282)	b=13.25	count=10000
Total loss:	13785.058 (rec:0.354, round:13784.703)	b=12.69	count=10500
Total loss:	12628.088 (rec:0.354, round:12627.733)	b=12.12	count=11000
Total loss:	11498.056 (rec:0.351, round:11497.705)	b=11.56	count=11500
Total loss:	10389.043 (rec:0.360, round:10388.684)	b=11.00	count=12000
Total loss:	9302.800 (rec:0.358, round:9302.441)	b=10.44	count=12500
Total loss:	8234.960 (rec:0.361, round:8234.599)	b=9.88	count=13000
Total loss:	7189.544 (rec:0.349, round:7189.194)	b=9.31	count=13500
Total loss:	6173.711 (rec:0.362, round:6173.349)	b=8.75	count=14000
Total loss:	5181.894 (rec:0.369, round:5181.525)	b=8.19	count=14500
Total loss:	4221.369 (rec:0.364, round:4221.005)	b=7.62	count=15000
Total loss:	3305.776 (rec:0.369, round:3305.406)	b=7.06	count=15500
Total loss:	2448.754 (rec:0.362, round:2448.392)	b=6.50	count=16000
Total loss:	1671.331 (rec:0.384, round:1670.947)	b=5.94	count=16500
Total loss:	1003.482 (rec:0.370, round:1003.113)	b=5.38	count=17000
Total loss:	491.754 (rec:0.377, round:491.377)	b=4.81	count=17500
Total loss:	175.231 (rec:0.380, round:174.851)	b=4.25	count=18000
Total loss:	41.296 (rec:0.380, round:40.916)	b=3.69	count=18500
Total loss:	6.021 (rec:0.384, round:5.638)	b=3.12	count=19000
Total loss:	0.799 (rec:0.391, round:0.408)	b=2.56	count=19500
Total loss:	0.419 (rec:0.397, round:0.022)	b=2.00	count=20000
finished reconstructing blocks.8.
reconstructing blocks.9 ...
initializing raw input and raw output ...
adaround training for blocks.9 ...
wraping quantizers in blocks.9 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.238 (rec:1.238, round:0.000)	b=0.00	count=500
Total loss:	1.112 (rec:1.112, round:0.000)	b=0.00	count=1000
Total loss:	1.020 (rec:1.020, round:0.000)	b=0.00	count=1500
Total loss:	0.997 (rec:0.997, round:0.000)	b=0.00	count=2000
Total loss:	0.902 (rec:0.902, round:0.000)	b=0.00	count=2500
Total loss:	0.916 (rec:0.916, round:0.000)	b=0.00	count=3000
Total loss:	0.811 (rec:0.811, round:0.000)	b=0.00	count=3500
Total loss:	65006.133 (rec:0.748, round:65005.383)	b=20.00	count=4000
Total loss:	32346.463 (rec:0.800, round:32345.664)	b=19.44	count=4500
Total loss:	29881.621 (rec:0.786, round:29880.836)	b=18.88	count=5000
Total loss:	28215.559 (rec:0.727, round:28214.832)	b=18.31	count=5500
Total loss:	26756.230 (rec:0.735, round:26755.496)	b=17.75	count=6000
Total loss:	25378.027 (rec:0.760, round:25377.268)	b=17.19	count=6500
Total loss:	24049.312 (rec:0.761, round:24048.553)	b=16.62	count=7000
Total loss:	22745.693 (rec:0.749, round:22744.943)	b=16.06	count=7500
Total loss:	21466.912 (rec:0.755, round:21466.158)	b=15.50	count=8000
Total loss:	20201.434 (rec:0.773, round:20200.660)	b=14.94	count=8500
Total loss:	18955.166 (rec:0.741, round:18954.426)	b=14.38	count=9000
Total loss:	17718.188 (rec:0.706, round:17717.480)	b=13.81	count=9500
Total loss:	16494.086 (rec:0.714, round:16493.371)	b=13.25	count=10000
Total loss:	15279.673 (rec:0.732, round:15278.940)	b=12.69	count=10500
Total loss:	14087.339 (rec:0.722, round:14086.617)	b=12.12	count=11000
Total loss:	12907.365 (rec:0.722, round:12906.644)	b=11.56	count=11500
Total loss:	11745.078 (rec:0.753, round:11744.325)	b=11.00	count=12000
Total loss:	10595.633 (rec:0.754, round:10594.878)	b=10.44	count=12500
Total loss:	9469.751 (rec:0.743, round:9469.008)	b=9.88	count=13000
Total loss:	8351.093 (rec:0.743, round:8350.350)	b=9.31	count=13500
Total loss:	7255.775 (rec:0.723, round:7255.053)	b=8.75	count=14000
Total loss:	6179.458 (rec:0.739, round:6178.720)	b=8.19	count=14500
Total loss:	5123.655 (rec:0.777, round:5122.878)	b=7.62	count=15000
Total loss:	4104.618 (rec:0.740, round:4103.878)	b=7.06	count=15500
Total loss:	3135.866 (rec:0.761, round:3135.105)	b=6.50	count=16000
Total loss:	2234.933 (rec:0.765, round:2234.167)	b=5.94	count=16500
Total loss:	1435.375 (rec:0.800, round:1434.575)	b=5.38	count=17000
Total loss:	775.037 (rec:0.796, round:774.241)	b=4.81	count=17500
Total loss:	317.266 (rec:0.789, round:316.477)	b=4.25	count=18000
Total loss:	81.815 (rec:0.775, round:81.040)	b=3.69	count=18500
Total loss:	11.094 (rec:0.785, round:10.309)	b=3.12	count=19000
Total loss:	1.388 (rec:0.823, round:0.565)	b=2.56	count=19500
Total loss:	0.798 (rec:0.789, round:0.009)	b=2.00	count=20000
finished reconstructing blocks.9.
reconstructing blocks.10 ...
initializing raw input and raw output ...
adaround training for blocks.10 ...
wraping quantizers in blocks.10 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.431 (rec:1.431, round:0.000)	b=0.00	count=500
Total loss:	1.154 (rec:1.154, round:0.000)	b=0.00	count=1000
Total loss:	1.035 (rec:1.035, round:0.000)	b=0.00	count=1500
Total loss:	0.992 (rec:0.992, round:0.000)	b=0.00	count=2000
Total loss:	0.864 (rec:0.864, round:0.000)	b=0.00	count=2500
Total loss:	0.843 (rec:0.843, round:0.000)	b=0.00	count=3000
Total loss:	0.848 (rec:0.848, round:0.000)	b=0.00	count=3500
Total loss:	65515.969 (rec:0.741, round:65515.227)	b=20.00	count=4000
Total loss:	32722.756 (rec:0.675, round:32722.082)	b=19.44	count=4500
Total loss:	30229.672 (rec:0.765, round:30228.906)	b=18.88	count=5000
Total loss:	28540.453 (rec:0.722, round:28539.730)	b=18.31	count=5500
Total loss:	27060.635 (rec:0.713, round:27059.922)	b=17.75	count=6000
Total loss:	25658.303 (rec:0.701, round:25657.602)	b=17.19	count=6500
Total loss:	24301.412 (rec:0.701, round:24300.711)	b=16.62	count=7000
Total loss:	22968.520 (rec:0.668, round:22967.852)	b=16.06	count=7500
Total loss:	21658.715 (rec:0.710, round:21658.004)	b=15.50	count=8000
Total loss:	20358.434 (rec:0.706, round:20357.727)	b=14.94	count=8500
Total loss:	19077.955 (rec:0.718, round:19077.238)	b=14.38	count=9000
Total loss:	17807.396 (rec:0.712, round:17806.686)	b=13.81	count=9500
Total loss:	16556.508 (rec:0.672, round:16555.836)	b=13.25	count=10000
Total loss:	15327.282 (rec:0.693, round:15326.590)	b=12.69	count=10500
Total loss:	14114.070 (rec:0.701, round:14113.369)	b=12.12	count=11000
Total loss:	12914.804 (rec:0.716, round:12914.088)	b=11.56	count=11500
Total loss:	11734.567 (rec:0.712, round:11733.855)	b=11.00	count=12000
Total loss:	10568.664 (rec:0.692, round:10567.973)	b=10.44	count=12500
Total loss:	9430.157 (rec:0.683, round:9429.475)	b=9.88	count=13000
Total loss:	8308.171 (rec:0.727, round:8307.444)	b=9.31	count=13500
Total loss:	7201.641 (rec:0.709, round:7200.932)	b=8.75	count=14000
Total loss:	6122.816 (rec:0.722, round:6122.094)	b=8.19	count=14500
Total loss:	5065.356 (rec:0.737, round:5064.619)	b=7.62	count=15000
Total loss:	4050.355 (rec:0.737, round:4049.618)	b=7.06	count=15500
Total loss:	3086.999 (rec:0.798, round:3086.200)	b=6.50	count=16000
Total loss:	2196.787 (rec:0.710, round:2196.077)	b=5.94	count=16500
Total loss:	1404.657 (rec:0.753, round:1403.904)	b=5.38	count=17000
Total loss:	758.563 (rec:0.771, round:757.792)	b=4.81	count=17500
Total loss:	309.405 (rec:0.786, round:308.619)	b=4.25	count=18000
Total loss:	81.525 (rec:0.781, round:80.744)	b=3.69	count=18500
Total loss:	11.781 (rec:0.825, round:10.957)	b=3.12	count=19000
Total loss:	1.446 (rec:0.838, round:0.608)	b=2.56	count=19500
Total loss:	0.838 (rec:0.823, round:0.015)	b=2.00	count=20000
finished reconstructing blocks.10.
reconstructing blocks.11 ...
initializing raw input and raw output ...
adaround training for blocks.11 ...
wraping quantizers in blocks.11 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.252 (rec:0.252, round:0.000)	b=0.00	count=500
Total loss:	0.186 (rec:0.186, round:0.000)	b=0.00	count=1000
Total loss:	0.168 (rec:0.168, round:0.000)	b=0.00	count=1500
Total loss:	0.150 (rec:0.150, round:0.000)	b=0.00	count=2000
Total loss:	0.135 (rec:0.135, round:0.000)	b=0.00	count=2500
Total loss:	0.126 (rec:0.126, round:0.000)	b=0.00	count=3000
Total loss:	0.119 (rec:0.119, round:0.000)	b=0.00	count=3500
Total loss:	65523.898 (rec:0.117, round:65523.781)	b=20.00	count=4000
Total loss:	30426.258 (rec:0.110, round:30426.148)	b=19.44	count=4500
Total loss:	28057.004 (rec:0.108, round:28056.896)	b=18.88	count=5000
Total loss:	26465.484 (rec:0.106, round:26465.379)	b=18.31	count=5500
Total loss:	25055.455 (rec:0.106, round:25055.348)	b=17.75	count=6000
Total loss:	23702.084 (rec:0.102, round:23701.982)	b=17.19	count=6500
Total loss:	22374.900 (rec:0.104, round:22374.797)	b=16.62	count=7000
Total loss:	21060.541 (rec:0.100, round:21060.441)	b=16.06	count=7500
Total loss:	19750.670 (rec:0.090, round:19750.580)	b=15.50	count=8000
Total loss:	18453.215 (rec:0.089, round:18453.125)	b=14.94	count=8500
Total loss:	17154.326 (rec:0.091, round:17154.234)	b=14.38	count=9000
Total loss:	15865.046 (rec:0.089, round:15864.957)	b=13.81	count=9500
Total loss:	14587.289 (rec:0.092, round:14587.197)	b=13.25	count=10000
Total loss:	13327.862 (rec:0.087, round:13327.775)	b=12.69	count=10500
Total loss:	12087.441 (rec:0.085, round:12087.356)	b=12.12	count=11000
Total loss:	10873.211 (rec:0.090, round:10873.121)	b=11.56	count=11500
Total loss:	9695.459 (rec:0.085, round:9695.374)	b=11.00	count=12000
Total loss:	8549.255 (rec:0.083, round:8549.172)	b=10.44	count=12500
Total loss:	7441.862 (rec:0.083, round:7441.779)	b=9.88	count=13000
Total loss:	6379.884 (rec:0.086, round:6379.798)	b=9.31	count=13500
Total loss:	5360.455 (rec:0.088, round:5360.367)	b=8.75	count=14000
Total loss:	4390.229 (rec:0.084, round:4390.146)	b=8.19	count=14500
Total loss:	3483.328 (rec:0.087, round:3483.241)	b=7.62	count=15000
Total loss:	2637.758 (rec:0.091, round:2637.667)	b=7.06	count=15500
Total loss:	1861.902 (rec:0.088, round:1861.815)	b=6.50	count=16000
Total loss:	1169.606 (rec:0.087, round:1169.519)	b=5.94	count=16500
Total loss:	599.120 (rec:0.086, round:599.034)	b=5.38	count=17000
Total loss:	243.266 (rec:0.089, round:243.177)	b=4.81	count=17500
Total loss:	80.901 (rec:0.089, round:80.812)	b=4.25	count=18000
Total loss:	21.601 (rec:0.092, round:21.509)	b=3.69	count=18500
Total loss:	4.080 (rec:0.093, round:3.987)	b=3.12	count=19000
Total loss:	0.434 (rec:0.090, round:0.344)	b=2.56	count=19500
Total loss:	0.110 (rec:0.093, round:0.018)	b=2.00	count=20000
finished reconstructing blocks.11.
reconstructing head ...
initializing raw input and raw output ...
adaround training for head ...
wraping quantizers in head ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.159 (rec:1.159, round:0.000)	b=0.00	count=500
Total loss:	0.593 (rec:0.593, round:0.000)	b=0.00	count=1000
Total loss:	0.514 (rec:0.514, round:0.000)	b=0.00	count=1500
Total loss:	0.339 (rec:0.339, round:0.000)	b=0.00	count=2000
Total loss:	0.268 (rec:0.268, round:0.000)	b=0.00	count=2500
Total loss:	0.147 (rec:0.147, round:0.000)	b=0.00	count=3000
Total loss:	0.149 (rec:0.149, round:0.000)	b=0.00	count=3500
Total loss:	7031.461 (rec:0.168, round:7031.293)	b=20.00	count=4000
Total loss:	3879.425 (rec:0.069, round:3879.357)	b=19.44	count=4500
Total loss:	3602.844 (rec:0.049, round:3602.795)	b=18.88	count=5000
Total loss:	3420.994 (rec:0.060, round:3420.934)	b=18.31	count=5500
Total loss:	3265.489 (rec:0.050, round:3265.439)	b=17.75	count=6000
Total loss:	3119.229 (rec:0.037, round:3119.192)	b=17.19	count=6500
Total loss:	2976.568 (rec:0.048, round:2976.521)	b=16.62	count=7000
Total loss:	2831.015 (rec:0.045, round:2830.970)	b=16.06	count=7500
Total loss:	2685.046 (rec:0.045, round:2685.000)	b=15.50	count=8000
Total loss:	2543.560 (rec:0.041, round:2543.518)	b=14.94	count=8500
Total loss:	2401.392 (rec:0.039, round:2401.353)	b=14.38	count=9000
Total loss:	2260.373 (rec:0.035, round:2260.338)	b=13.81	count=9500
Total loss:	2122.971 (rec:0.041, round:2122.930)	b=13.25	count=10000
Total loss:	1984.862 (rec:0.037, round:1984.825)	b=12.69	count=10500
Total loss:	1850.342 (rec:0.038, round:1850.304)	b=12.12	count=11000
Total loss:	1715.943 (rec:0.038, round:1715.906)	b=11.56	count=11500
Total loss:	1581.764 (rec:0.032, round:1581.732)	b=11.00	count=12000
Total loss:	1447.731 (rec:0.040, round:1447.691)	b=10.44	count=12500
Total loss:	1314.170 (rec:0.044, round:1314.126)	b=9.88	count=13000
Total loss:	1179.797 (rec:0.046, round:1179.752)	b=9.31	count=13500
Total loss:	1044.547 (rec:0.035, round:1044.512)	b=8.75	count=14000
Total loss:	909.476 (rec:0.038, round:909.438)	b=8.19	count=14500
Total loss:	772.961 (rec:0.034, round:772.927)	b=7.62	count=15000
Total loss:	639.372 (rec:0.042, round:639.331)	b=7.06	count=15500
Total loss:	511.535 (rec:0.042, round:511.493)	b=6.50	count=16000
Total loss:	387.291 (rec:0.047, round:387.244)	b=5.94	count=16500
Total loss:	270.646 (rec:0.044, round:270.602)	b=5.38	count=17000
Total loss:	166.367 (rec:0.046, round:166.321)	b=4.81	count=17500
Total loss:	78.661 (rec:0.050, round:78.611)	b=4.25	count=18000
Total loss:	24.225 (rec:0.044, round:24.181)	b=3.69	count=18500
Total loss:	3.738 (rec:0.041, round:3.697)	b=3.12	count=19000
Total loss:	0.324 (rec:0.050, round:0.274)	b=2.56	count=19500
Total loss:	0.058 (rec:0.051, round:0.007)	b=2.00	count=20000
finished reconstructing head.
2025-09-10 16:18:59 - mse guided block reconstruction finished.
Saving checkpoint to ./checkpoint/quant_result/20250910_1259/vit_base_w2_a2_optimsize_1024_mse_rinp.pth
Validating on calibration set after block reconstruction ...
Test: [0/32]	Time 0.657 (0.657)	Loss 6.7992 (6.7992)	Prec@1 3.125 (3.125)	Prec@5 9.375 (9.375)
Test: [10/32]	Time 0.076 (0.129)	Loss 6.5850 (6.4364)	Prec@1 9.375 (5.682)	Prec@5 12.500 (11.080)
Test: [20/32]	Time 0.076 (0.104)	Loss 6.5616 (6.3946)	Prec@1 6.250 (5.952)	Prec@5 9.375 (11.458)
Test: [30/32]	Time 0.076 (0.095)	Loss 6.4525 (6.3855)	Prec@1 3.125 (6.351)	Prec@5 6.250 (12.198)
 * Prec@1 6.348 Prec@5 12.305 Loss 6.385 Time 3.168
Validating on test set after block reconstruction ...
Test: [0/100]	Time 5.256 (5.256)	Loss 6.4628 (6.4628)	Prec@1 2.800 (2.800)	Prec@5 7.400 (7.400)
Test: [10/100]	Time 1.670 (2.003)	Loss 6.5960 (6.6212)	Prec@1 2.200 (2.382)	Prec@5 9.600 (6.964)
Test: [20/100]	Time 1.670 (1.845)	Loss 6.0367 (6.5809)	Prec@1 4.600 (2.457)	Prec@5 22.400 (8.295)
Test: [30/100]	Time 1.671 (1.788)	Loss 6.6675 (6.5606)	Prec@1 2.600 (2.871)	Prec@5 5.800 (8.787)
Test: [40/100]	Time 1.668 (1.760)	Loss 6.4603 (6.5736)	Prec@1 2.200 (2.815)	Prec@5 9.400 (8.385)
Test: [50/100]	Time 1.669 (1.742)	Loss 6.6790 (6.5662)	Prec@1 5.400 (2.686)	Prec@5 9.400 (7.961)
Test: [60/100]	Time 1.666 (1.730)	Loss 6.4443 (6.5735)	Prec@1 5.600 (2.472)	Prec@5 7.800 (7.390)
Test: [70/100]	Time 1.667 (1.722)	Loss 6.0965 (6.5715)	Prec@1 4.400 (2.363)	Prec@5 16.000 (7.127)
Test: [80/100]	Time 1.669 (1.715)	Loss 6.5018 (6.5680)	Prec@1 1.400 (2.277)	Prec@5 4.200 (6.822)
Test: [90/100]	Time 1.664 (1.710)	Loss 6.7359 (6.5713)	Prec@1 0.600 (2.165)	Prec@5 1.600 (6.622)
 * Prec@1 2.598 Prec@5 7.180 Loss 6.568 Time 170.899
2025-09-10 16:21:54 - finished the process.
Extracting logits from quantized and full-precision models...
Testing combinations:
  Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  Cluster numbers: [8, 16, 32, 64, 128, 256]
  PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.67%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.67%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.68%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.69%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.69%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.68%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.66%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.66%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.68%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.32%
Result: Top-1: 2.67%, Top-5: 7.32%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.31%
Result: Top-1: 2.67%, Top-5: 7.31%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.32%
Result: Top-1: 2.67%, Top-5: 7.32%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.67%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.31%
Result: Top-1: 2.69%, Top-5: 7.31%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.67%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.69%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.68%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.67%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.69%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.31%
Result: Top-1: 2.68%, Top-5: 7.31%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.69%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.69%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.68%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.67%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.66%
[Alpha=0.10] Top-5 Accuracy: 7.32%
Result: Top-1: 2.66%, Top-5: 7.32%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.69%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.69%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.67%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.64%
[Alpha=0.10] Top-5 Accuracy: 7.37%
Result: Top-1: 2.64%, Top-5: 7.37%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.69%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.68%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.68%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.71%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.71%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.30%
Result: Top-1: 2.69%, Top-5: 7.30%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.71%
[Alpha=0.10] Top-5 Accuracy: 7.39%
Result: Top-1: 2.71%, Top-5: 7.39%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.39%
Result: Top-1: 2.70%, Top-5: 7.39%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.33%
Result: Top-1: 2.70%, Top-5: 7.33%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.69%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.69%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.32%
Result: Top-1: 2.68%, Top-5: 7.32%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.67%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.70%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.35%
Result: Top-1: 2.70%, Top-5: 7.35%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.68%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.68%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.65%
[Alpha=0.10] Top-5 Accuracy: 7.29%
Result: Top-1: 2.65%, Top-5: 7.29%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.66%
[Alpha=0.10] Top-5 Accuracy: 7.34%
Result: Top-1: 2.66%, Top-5: 7.34%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.72%
[Alpha=0.10] Top-5 Accuracy: 7.39%
Result: Top-1: 2.72%, Top-5: 7.39%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.37%
Result: Top-1: 2.70%, Top-5: 7.37%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.71%
[Alpha=0.10] Top-5 Accuracy: 7.27%
Result: Top-1: 2.71%, Top-5: 7.27%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.31%
Result: Top-1: 2.70%, Top-5: 7.31%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.64%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.64%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.70%
[Alpha=0.10] Top-5 Accuracy: 7.40%
Result: Top-1: 2.70%, Top-5: 7.40%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.72%
[Alpha=0.10] Top-5 Accuracy: 7.36%
Result: Top-1: 2.72%, Top-5: 7.36%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 2.67%
[Alpha=0.10] Top-5 Accuracy: 7.38%
Result: Top-1: 2.67%, Top-5: 7.38%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.72%
[Alpha=0.20] Top-5 Accuracy: 7.45%
Result: Top-1: 2.72%, Top-5: 7.45%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.70%
[Alpha=0.20] Top-5 Accuracy: 7.36%
Result: Top-1: 2.70%, Top-5: 7.36%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.69%
[Alpha=0.20] Top-5 Accuracy: 7.35%
Result: Top-1: 2.69%, Top-5: 7.35%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.68%
[Alpha=0.20] Top-5 Accuracy: 7.35%
Result: Top-1: 2.68%, Top-5: 7.35%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.70%
[Alpha=0.20] Top-5 Accuracy: 7.36%
Result: Top-1: 2.70%, Top-5: 7.36%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.70%
[Alpha=0.20] Top-5 Accuracy: 7.36%
Result: Top-1: 2.70%, Top-5: 7.36%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.71%
[Alpha=0.20] Top-5 Accuracy: 7.36%
Result: Top-1: 2.71%, Top-5: 7.36%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.71%
[Alpha=0.20] Top-5 Accuracy: 7.36%
Result: Top-1: 2.71%, Top-5: 7.36%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.69%
[Alpha=0.20] Top-5 Accuracy: 7.37%
Result: Top-1: 2.69%, Top-5: 7.37%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.69%
[Alpha=0.20] Top-5 Accuracy: 7.37%
Result: Top-1: 2.69%, Top-5: 7.37%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.71%
[Alpha=0.20] Top-5 Accuracy: 7.40%
Result: Top-1: 2.71%, Top-5: 7.40%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.65%
[Alpha=0.20] Top-5 Accuracy: 7.32%
Result: Top-1: 2.65%, Top-5: 7.32%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.64%
[Alpha=0.20] Top-5 Accuracy: 7.31%
Result: Top-1: 2.64%, Top-5: 7.31%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.65%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.65%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.59%
[Alpha=0.20] Top-5 Accuracy: 7.29%
Result: Top-1: 2.59%, Top-5: 7.29%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.63%
[Alpha=0.20] Top-5 Accuracy: 7.29%
Result: Top-1: 2.63%, Top-5: 7.29%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.66%
[Alpha=0.20] Top-5 Accuracy: 7.30%
Result: Top-1: 2.66%, Top-5: 7.30%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.66%
[Alpha=0.20] Top-5 Accuracy: 7.34%
Result: Top-1: 2.66%, Top-5: 7.34%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.61%
[Alpha=0.20] Top-5 Accuracy: 7.37%
Result: Top-1: 2.61%, Top-5: 7.37%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.61%
[Alpha=0.20] Top-5 Accuracy: 7.31%
Result: Top-1: 2.61%, Top-5: 7.31%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.72%
[Alpha=0.20] Top-5 Accuracy: 7.37%
Result: Top-1: 2.72%, Top-5: 7.37%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.58%
[Alpha=0.20] Top-5 Accuracy: 7.34%
Result: Top-1: 2.58%, Top-5: 7.34%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.57%
[Alpha=0.20] Top-5 Accuracy: 7.36%
Result: Top-1: 2.57%, Top-5: 7.36%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.53%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.53%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.63%
[Alpha=0.20] Top-5 Accuracy: 7.35%
Result: Top-1: 2.63%, Top-5: 7.35%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.56%
[Alpha=0.20] Top-5 Accuracy: 7.28%
Result: Top-1: 2.56%, Top-5: 7.28%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.59%
[Alpha=0.20] Top-5 Accuracy: 7.30%
Result: Top-1: 2.59%, Top-5: 7.30%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.34%
Result: Top-1: 2.55%, Top-5: 7.34%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.28%
Result: Top-1: 2.55%, Top-5: 7.28%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.28%
Result: Top-1: 2.55%, Top-5: 7.28%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.73%
[Alpha=0.20] Top-5 Accuracy: 7.34%
Result: Top-1: 2.73%, Top-5: 7.34%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.59%
[Alpha=0.20] Top-5 Accuracy: 7.29%
Result: Top-1: 2.59%, Top-5: 7.29%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.54%
[Alpha=0.20] Top-5 Accuracy: 7.32%
Result: Top-1: 2.54%, Top-5: 7.32%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.51%
[Alpha=0.20] Top-5 Accuracy: 7.31%
Result: Top-1: 2.51%, Top-5: 7.31%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.49%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.49%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.49%
[Alpha=0.20] Top-5 Accuracy: 7.29%
Result: Top-1: 2.49%, Top-5: 7.29%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.34%
Result: Top-1: 2.55%, Top-5: 7.34%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.50%
[Alpha=0.20] Top-5 Accuracy: 7.28%
Result: Top-1: 2.50%, Top-5: 7.28%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.56%
[Alpha=0.20] Top-5 Accuracy: 7.31%
Result: Top-1: 2.56%, Top-5: 7.31%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.55%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.72%
[Alpha=0.20] Top-5 Accuracy: 7.35%
Result: Top-1: 2.72%, Top-5: 7.35%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.40%
Result: Top-1: 2.55%, Top-5: 7.40%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.50%
[Alpha=0.20] Top-5 Accuracy: 7.34%
Result: Top-1: 2.50%, Top-5: 7.34%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.53%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.53%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.50%
[Alpha=0.20] Top-5 Accuracy: 7.31%
Result: Top-1: 2.50%, Top-5: 7.31%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.55%
[Alpha=0.20] Top-5 Accuracy: 7.29%
Result: Top-1: 2.55%, Top-5: 7.29%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.47%
[Alpha=0.20] Top-5 Accuracy: 7.24%
Result: Top-1: 2.47%, Top-5: 7.24%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.45%
[Alpha=0.20] Top-5 Accuracy: 7.27%
Result: Top-1: 2.45%, Top-5: 7.27%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.53%
[Alpha=0.20] Top-5 Accuracy: 7.28%
Result: Top-1: 2.53%, Top-5: 7.28%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.51%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.51%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.73%
[Alpha=0.20] Top-5 Accuracy: 7.27%
Result: Top-1: 2.73%, Top-5: 7.27%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.48%
[Alpha=0.20] Top-5 Accuracy: 7.16%
Result: Top-1: 2.48%, Top-5: 7.16%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.54%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.54%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.51%
[Alpha=0.20] Top-5 Accuracy: 7.25%
Result: Top-1: 2.51%, Top-5: 7.25%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.49%
[Alpha=0.20] Top-5 Accuracy: 7.25%
Result: Top-1: 2.49%, Top-5: 7.25%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.48%
[Alpha=0.20] Top-5 Accuracy: 7.31%
Result: Top-1: 2.48%, Top-5: 7.31%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.50%
[Alpha=0.20] Top-5 Accuracy: 7.29%
Result: Top-1: 2.50%, Top-5: 7.29%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.52%
[Alpha=0.20] Top-5 Accuracy: 7.37%
Result: Top-1: 2.52%, Top-5: 7.37%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.44%
[Alpha=0.20] Top-5 Accuracy: 7.33%
Result: Top-1: 2.44%, Top-5: 7.33%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 2.51%
[Alpha=0.20] Top-5 Accuracy: 7.27%
Result: Top-1: 2.51%, Top-5: 7.27%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.47%
[Alpha=0.30] Top-5 Accuracy: 7.22%
Result: Top-1: 2.47%, Top-5: 7.22%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.21%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 2.21%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.20%
[Alpha=0.30] Top-5 Accuracy: 7.08%
Result: Top-1: 2.20%, Top-5: 7.08%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.22%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 2.22%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.23%
[Alpha=0.30] Top-5 Accuracy: 7.05%
Result: Top-1: 2.23%, Top-5: 7.05%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.21%
[Alpha=0.30] Top-5 Accuracy: 7.02%
Result: Top-1: 2.21%, Top-5: 7.02%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.22%
[Alpha=0.30] Top-5 Accuracy: 7.05%
Result: Top-1: 2.22%, Top-5: 7.05%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.21%
[Alpha=0.30] Top-5 Accuracy: 7.04%
Result: Top-1: 2.21%, Top-5: 7.04%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.20%
[Alpha=0.30] Top-5 Accuracy: 7.09%
Result: Top-1: 2.20%, Top-5: 7.09%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.20%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 2.20%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.48%
[Alpha=0.30] Top-5 Accuracy: 7.29%
Result: Top-1: 2.48%, Top-5: 7.29%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.95%
[Alpha=0.30] Top-5 Accuracy: 7.04%
Result: Top-1: 1.95%, Top-5: 7.04%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.97%
[Alpha=0.30] Top-5 Accuracy: 7.03%
Result: Top-1: 1.97%, Top-5: 7.03%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.00%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 2.00%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.91%
[Alpha=0.30] Top-5 Accuracy: 7.03%
Result: Top-1: 1.91%, Top-5: 7.03%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.89%
[Alpha=0.30] Top-5 Accuracy: 7.00%
Result: Top-1: 1.89%, Top-5: 7.00%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.01%
[Alpha=0.30] Top-5 Accuracy: 7.06%
Result: Top-1: 2.01%, Top-5: 7.06%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.02%
[Alpha=0.30] Top-5 Accuracy: 7.08%
Result: Top-1: 2.02%, Top-5: 7.08%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.08%
[Alpha=0.30] Top-5 Accuracy: 7.09%
Result: Top-1: 2.08%, Top-5: 7.09%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.91%
[Alpha=0.30] Top-5 Accuracy: 7.01%
Result: Top-1: 1.91%, Top-5: 7.01%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.49%
[Alpha=0.30] Top-5 Accuracy: 7.24%
Result: Top-1: 2.49%, Top-5: 7.24%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.82%
[Alpha=0.30] Top-5 Accuracy: 7.03%
Result: Top-1: 1.82%, Top-5: 7.03%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.86%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 1.86%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.83%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 1.83%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 6.99%
Result: Top-1: 1.90%, Top-5: 6.99%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.89%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 1.89%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.85%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 1.85%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.87%
[Alpha=0.30] Top-5 Accuracy: 7.11%
Result: Top-1: 1.87%, Top-5: 7.11%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.90%
[Alpha=0.30] Top-5 Accuracy: 7.03%
Result: Top-1: 1.90%, Top-5: 7.03%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.76%
[Alpha=0.30] Top-5 Accuracy: 7.00%
Result: Top-1: 1.76%, Top-5: 7.00%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.48%
[Alpha=0.30] Top-5 Accuracy: 7.21%
Result: Top-1: 2.48%, Top-5: 7.21%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.86%
[Alpha=0.30] Top-5 Accuracy: 7.07%
Result: Top-1: 1.86%, Top-5: 7.07%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.81%
[Alpha=0.30] Top-5 Accuracy: 7.10%
Result: Top-1: 1.81%, Top-5: 7.10%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.74%
[Alpha=0.30] Top-5 Accuracy: 7.14%
Result: Top-1: 1.74%, Top-5: 7.14%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.77%
[Alpha=0.30] Top-5 Accuracy: 7.14%
Result: Top-1: 1.77%, Top-5: 7.14%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.75%
[Alpha=0.30] Top-5 Accuracy: 6.99%
Result: Top-1: 1.75%, Top-5: 6.99%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.81%
[Alpha=0.30] Top-5 Accuracy: 7.10%
Result: Top-1: 1.81%, Top-5: 7.10%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.79%
[Alpha=0.30] Top-5 Accuracy: 7.11%
Result: Top-1: 1.79%, Top-5: 7.11%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.81%
[Alpha=0.30] Top-5 Accuracy: 7.06%
Result: Top-1: 1.81%, Top-5: 7.06%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.87%
[Alpha=0.30] Top-5 Accuracy: 7.08%
Result: Top-1: 1.87%, Top-5: 7.08%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.46%
[Alpha=0.30] Top-5 Accuracy: 7.10%
Result: Top-1: 2.46%, Top-5: 7.10%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.79%
[Alpha=0.30] Top-5 Accuracy: 7.18%
Result: Top-1: 1.79%, Top-5: 7.18%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.80%
[Alpha=0.30] Top-5 Accuracy: 7.16%
Result: Top-1: 1.80%, Top-5: 7.16%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.85%
[Alpha=0.30] Top-5 Accuracy: 7.10%
Result: Top-1: 1.85%, Top-5: 7.10%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.80%
[Alpha=0.30] Top-5 Accuracy: 7.04%
Result: Top-1: 1.80%, Top-5: 7.04%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.81%
[Alpha=0.30] Top-5 Accuracy: 7.08%
Result: Top-1: 1.81%, Top-5: 7.08%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.78%
[Alpha=0.30] Top-5 Accuracy: 6.99%
Result: Top-1: 1.78%, Top-5: 6.99%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 7.10%
Result: Top-1: 1.73%, Top-5: 7.10%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.78%
[Alpha=0.30] Top-5 Accuracy: 7.06%
Result: Top-1: 1.78%, Top-5: 7.06%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.74%
[Alpha=0.30] Top-5 Accuracy: 7.11%
Result: Top-1: 1.74%, Top-5: 7.11%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 2.37%
[Alpha=0.30] Top-5 Accuracy: 7.09%
Result: Top-1: 2.37%, Top-5: 7.09%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.76%
[Alpha=0.30] Top-5 Accuracy: 6.96%
Result: Top-1: 1.76%, Top-5: 6.96%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.78%
[Alpha=0.30] Top-5 Accuracy: 7.00%
Result: Top-1: 1.78%, Top-5: 7.00%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.80%
[Alpha=0.30] Top-5 Accuracy: 7.04%
Result: Top-1: 1.80%, Top-5: 7.04%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.82%
[Alpha=0.30] Top-5 Accuracy: 7.01%
Result: Top-1: 1.82%, Top-5: 7.01%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.82%
[Alpha=0.30] Top-5 Accuracy: 7.05%
Result: Top-1: 1.82%, Top-5: 7.05%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.74%
[Alpha=0.30] Top-5 Accuracy: 7.02%
Result: Top-1: 1.74%, Top-5: 7.02%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.83%
[Alpha=0.30] Top-5 Accuracy: 7.11%
Result: Top-1: 1.83%, Top-5: 7.11%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.73%
[Alpha=0.30] Top-5 Accuracy: 7.05%
Result: Top-1: 1.73%, Top-5: 7.05%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 1.76%
[Alpha=0.30] Top-5 Accuracy: 7.09%
Result: Top-1: 1.76%, Top-5: 7.09%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.81%
[Alpha=0.40] Top-5 Accuracy: 6.88%
Result: Top-1: 1.81%, Top-5: 6.88%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.23%
[Alpha=0.40] Top-5 Accuracy: 6.73%
Result: Top-1: 1.23%, Top-5: 6.73%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.23%
[Alpha=0.40] Top-5 Accuracy: 6.68%
Result: Top-1: 1.23%, Top-5: 6.68%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.25%
[Alpha=0.40] Top-5 Accuracy: 6.70%
Result: Top-1: 1.25%, Top-5: 6.70%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.18%
[Alpha=0.40] Top-5 Accuracy: 6.74%
Result: Top-1: 1.18%, Top-5: 6.74%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.21%
[Alpha=0.40] Top-5 Accuracy: 6.68%
Result: Top-1: 1.21%, Top-5: 6.68%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.19%
[Alpha=0.40] Top-5 Accuracy: 6.73%
Result: Top-1: 1.19%, Top-5: 6.73%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.19%
[Alpha=0.40] Top-5 Accuracy: 6.71%
Result: Top-1: 1.19%, Top-5: 6.71%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.24%
[Alpha=0.40] Top-5 Accuracy: 6.74%
Result: Top-1: 1.24%, Top-5: 6.74%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.24%
[Alpha=0.40] Top-5 Accuracy: 6.74%
Result: Top-1: 1.24%, Top-5: 6.74%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.86%
[Alpha=0.40] Top-5 Accuracy: 6.90%
Result: Top-1: 1.86%, Top-5: 6.90%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.10%
[Alpha=0.40] Top-5 Accuracy: 6.71%
Result: Top-1: 1.10%, Top-5: 6.71%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.13%
[Alpha=0.40] Top-5 Accuracy: 6.79%
Result: Top-1: 1.13%, Top-5: 6.79%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.12%
[Alpha=0.40] Top-5 Accuracy: 6.73%
Result: Top-1: 1.12%, Top-5: 6.73%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.09%
[Alpha=0.40] Top-5 Accuracy: 6.61%
Result: Top-1: 1.09%, Top-5: 6.61%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.03%
[Alpha=0.40] Top-5 Accuracy: 6.69%
Result: Top-1: 1.03%, Top-5: 6.69%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.14%
[Alpha=0.40] Top-5 Accuracy: 6.66%
Result: Top-1: 1.14%, Top-5: 6.66%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.11%
[Alpha=0.40] Top-5 Accuracy: 6.73%
Result: Top-1: 1.11%, Top-5: 6.73%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.23%
[Alpha=0.40] Top-5 Accuracy: 6.79%
Result: Top-1: 1.23%, Top-5: 6.79%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.04%
[Alpha=0.40] Top-5 Accuracy: 6.66%
Result: Top-1: 1.04%, Top-5: 6.66%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.81%
[Alpha=0.40] Top-5 Accuracy: 6.89%
Result: Top-1: 1.81%, Top-5: 6.89%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.02%
[Alpha=0.40] Top-5 Accuracy: 6.60%
Result: Top-1: 1.02%, Top-5: 6.60%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.09%
[Alpha=0.40] Top-5 Accuracy: 6.69%
Result: Top-1: 1.09%, Top-5: 6.69%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.07%
[Alpha=0.40] Top-5 Accuracy: 6.66%
Result: Top-1: 1.07%, Top-5: 6.66%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.11%
[Alpha=0.40] Top-5 Accuracy: 6.61%
Result: Top-1: 1.11%, Top-5: 6.61%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.06%
[Alpha=0.40] Top-5 Accuracy: 6.72%
Result: Top-1: 1.06%, Top-5: 6.72%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.03%
[Alpha=0.40] Top-5 Accuracy: 6.71%
Result: Top-1: 1.03%, Top-5: 6.71%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.11%
[Alpha=0.40] Top-5 Accuracy: 6.62%
Result: Top-1: 1.11%, Top-5: 6.62%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.05%
[Alpha=0.40] Top-5 Accuracy: 6.62%
Result: Top-1: 1.05%, Top-5: 6.62%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.99%
[Alpha=0.40] Top-5 Accuracy: 6.66%
Result: Top-1: 0.99%, Top-5: 6.66%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.88%
[Alpha=0.40] Top-5 Accuracy: 6.84%
Result: Top-1: 1.88%, Top-5: 6.84%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.05%
[Alpha=0.40] Top-5 Accuracy: 6.76%
Result: Top-1: 1.05%, Top-5: 6.76%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.11%
[Alpha=0.40] Top-5 Accuracy: 6.66%
Result: Top-1: 1.11%, Top-5: 6.66%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 6.70%
Result: Top-1: 1.08%, Top-5: 6.70%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.12%
[Alpha=0.40] Top-5 Accuracy: 6.71%
Result: Top-1: 1.12%, Top-5: 6.71%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 0.98%
[Alpha=0.40] Top-5 Accuracy: 6.69%
Result: Top-1: 0.98%, Top-5: 6.69%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.13%
[Alpha=0.40] Top-5 Accuracy: 6.74%
Result: Top-1: 1.13%, Top-5: 6.74%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 6.73%
Result: Top-1: 1.08%, Top-5: 6.73%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.03%
[Alpha=0.40] Top-5 Accuracy: 6.69%
Result: Top-1: 1.03%, Top-5: 6.69%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.16%
[Alpha=0.40] Top-5 Accuracy: 6.76%
Result: Top-1: 1.16%, Top-5: 6.76%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.75%
[Alpha=0.40] Top-5 Accuracy: 6.74%
Result: Top-1: 1.75%, Top-5: 6.74%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.06%
[Alpha=0.40] Top-5 Accuracy: 6.85%
Result: Top-1: 1.06%, Top-5: 6.85%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.10%
[Alpha=0.40] Top-5 Accuracy: 6.73%
Result: Top-1: 1.10%, Top-5: 6.73%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.19%
[Alpha=0.40] Top-5 Accuracy: 6.70%
Result: Top-1: 1.19%, Top-5: 6.70%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.11%
[Alpha=0.40] Top-5 Accuracy: 6.72%
Result: Top-1: 1.11%, Top-5: 6.72%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 6.62%
Result: Top-1: 1.08%, Top-5: 6.62%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.10%
[Alpha=0.40] Top-5 Accuracy: 6.70%
Result: Top-1: 1.10%, Top-5: 6.70%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.04%
[Alpha=0.40] Top-5 Accuracy: 6.67%
Result: Top-1: 1.04%, Top-5: 6.67%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.09%
[Alpha=0.40] Top-5 Accuracy: 6.70%
Result: Top-1: 1.09%, Top-5: 6.70%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.08%
[Alpha=0.40] Top-5 Accuracy: 6.72%
Result: Top-1: 1.08%, Top-5: 6.72%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.78%
[Alpha=0.40] Top-5 Accuracy: 6.70%
Result: Top-1: 1.78%, Top-5: 6.70%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.13%
[Alpha=0.40] Top-5 Accuracy: 6.52%
Result: Top-1: 1.13%, Top-5: 6.52%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.12%
[Alpha=0.40] Top-5 Accuracy: 6.57%
Result: Top-1: 1.12%, Top-5: 6.57%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.11%
[Alpha=0.40] Top-5 Accuracy: 6.67%
Result: Top-1: 1.11%, Top-5: 6.67%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.13%
[Alpha=0.40] Top-5 Accuracy: 6.62%
Result: Top-1: 1.13%, Top-5: 6.62%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.17%
[Alpha=0.40] Top-5 Accuracy: 6.60%
Result: Top-1: 1.17%, Top-5: 6.60%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.10%
[Alpha=0.40] Top-5 Accuracy: 6.65%
Result: Top-1: 1.10%, Top-5: 6.65%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.18%
[Alpha=0.40] Top-5 Accuracy: 6.67%
Result: Top-1: 1.18%, Top-5: 6.67%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.12%
[Alpha=0.40] Top-5 Accuracy: 6.68%
Result: Top-1: 1.12%, Top-5: 6.68%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 1.06%
[Alpha=0.40] Top-5 Accuracy: 6.65%
Result: Top-1: 1.06%, Top-5: 6.65%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.12%
[Alpha=0.50] Top-5 Accuracy: 6.36%
Result: Top-1: 1.12%, Top-5: 6.36%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.65%
[Alpha=0.50] Top-5 Accuracy: 6.28%
Result: Top-1: 0.65%, Top-5: 6.28%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.64%
[Alpha=0.50] Top-5 Accuracy: 6.27%
Result: Top-1: 0.64%, Top-5: 6.27%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.65%
[Alpha=0.50] Top-5 Accuracy: 6.24%
Result: Top-1: 0.65%, Top-5: 6.24%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 6.25%
Result: Top-1: 0.59%, Top-5: 6.25%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.63%
[Alpha=0.50] Top-5 Accuracy: 6.21%
Result: Top-1: 0.63%, Top-5: 6.21%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.58%
[Alpha=0.50] Top-5 Accuracy: 6.22%
Result: Top-1: 0.58%, Top-5: 6.22%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 6.23%
Result: Top-1: 0.59%, Top-5: 6.23%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.64%
[Alpha=0.50] Top-5 Accuracy: 6.24%
Result: Top-1: 0.64%, Top-5: 6.24%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.65%
[Alpha=0.50] Top-5 Accuracy: 6.26%
Result: Top-1: 0.65%, Top-5: 6.26%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 1.11%
[Alpha=0.50] Top-5 Accuracy: 6.34%
Result: Top-1: 1.11%, Top-5: 6.34%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 6.12%
Result: Top-1: 0.59%, Top-5: 6.12%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.66%
[Alpha=0.50] Top-5 Accuracy: 6.22%
Result: Top-1: 0.66%, Top-5: 6.22%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.56%
[Alpha=0.50] Top-5 Accuracy: 6.19%
Result: Top-1: 0.56%, Top-5: 6.19%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.57%
[Alpha=0.50] Top-5 Accuracy: 6.00%
Result: Top-1: 0.57%, Top-5: 6.00%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.52%
[Alpha=0.50] Top-5 Accuracy: 6.18%
Result: Top-1: 0.52%, Top-5: 6.18%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 6.16%
Result: Top-1: 0.59%, Top-5: 6.16%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 0.59%
[Alpha=0.50] Top-5 Accuracy: 6.18%
Result: Top-1: 0.59%, Top-5: 6.18%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=200
============================================================
slurmstepd-jnfat06: error: *** JOB 1643631 ON jnfat06 CANCELLED AT 2025-09-11T10:17:49 ***
