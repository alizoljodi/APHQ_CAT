2025-09-08 15:04:28,669 - INFO - Starting multi-seed experiment
2025-09-08 15:04:28,669 - INFO - Architecture: vit_small
2025-09-08 15:04:28,669 - INFO - Weight bits: 2
2025-09-08 15:04:28,669 - INFO - Activation bits: 2
2025-09-08 15:04:28,669 - INFO - Seeds: [1001, 1002, 1003]
2025-09-08 15:04:28,669 - INFO - Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
2025-09-08 15:04:28,669 - INFO - Cluster numbers: [8, 16, 32, 64, 128, 256]
2025-09-08 15:04:28,669 - INFO - PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]
2025-09-08 15:04:28,669 - INFO - Output directory: ./experiment_results/vit_small_w2_a2_20250908_150428
2025-09-08 15:04:28,670 - INFO - Checking basic requirements...
2025-09-08 15:04:28,670 - INFO - Basic checks passed
2025-09-08 15:04:28,670 - INFO - 
Starting experiments for 3 seeds...
2025-09-08 15:04:28,670 - INFO - Total parameter combinations: 600
2025-09-08 15:04:28,670 - INFO - Total experiments: 1800
2025-09-08 15:04:28,670 - INFO - 
============================================================
2025-09-08 15:04:28,670 - INFO - Running experiment 1/3 for seed 1001
2025-09-08 15:04:28,670 - INFO - ============================================================
2025-09-08 15:04:28,670 - INFO - Running experiment for seed 1001
2025-09-08 15:04:28,670 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model vit_small --w_bit 2 --a_bit 2 --seed 1001 --config ../configs/4bit/brecq_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-08 15:04:28,670 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/brecq_base
2025-09-08 15:05:00 - start the process.
Namespace(model='vit_small', config='../configs/4bit/brecq_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1001, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=2, calib_size=1000, calib_batch_size=32)
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 2
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: rinp
drop_prob: 1.0
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/vit_small_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/vit_small_patch16_224.augreg_in21k_ft_in1k)
[timm/vit_small_patch16_224.augreg_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 16.951 (16.951)	Loss 0.3666 (0.3666)	Prec@1 89.400 (89.400)	Prec@5 98.800 (98.800)
Test: [10/100]	Time 0.290 (2.328)	Loss 0.4641 (0.4857)	Prec@1 87.400 (86.218)	Prec@5 97.200 (97.618)
Test: [20/100]	Time 0.291 (1.923)	Loss 0.6792 (0.5288)	Prec@1 79.200 (85.114)	Prec@5 96.800 (97.457)
Test: [30/100]	Time 0.292 (1.597)	Loss 0.4284 (0.5582)	Prec@1 87.000 (84.335)	Prec@5 99.200 (97.419)
Test: [40/100]	Time 8.300 (1.745)	Loss 0.7823 (0.5542)	Prec@1 79.000 (84.546)	Prec@5 94.800 (97.312)
Test: [50/100]	Time 0.287 (1.632)	Loss 1.0516 (0.6089)	Prec@1 72.400 (82.988)	Prec@5 92.600 (96.859)
Test: [60/100]	Time 0.288 (1.590)	Loss 0.6787 (0.6213)	Prec@1 84.600 (82.859)	Prec@5 94.600 (96.659)
Test: [70/100]	Time 0.289 (1.558)	Loss 0.7787 (0.6469)	Prec@1 80.800 (82.141)	Prec@5 96.200 (96.434)
Test: [80/100]	Time 9.107 (1.679)	Loss 0.6024 (0.6574)	Prec@1 83.000 (81.943)	Prec@5 96.600 (96.244)
Test: [90/100]	Time 0.293 (1.668)	Loss 1.0445 (0.6776)	Prec@1 70.600 (81.284)	Prec@5 92.800 (96.066)
 * Prec@1 81.386 Prec@5 96.132 Loss 0.671 Time 163.729
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-08 15:08:11 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:07<09:33,  7.85s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:07<09:33,  7.85s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [00:30<19:30, 16.26s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [00:30<19:30, 16.26s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [00:39<15:26, 13.05s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [00:39<15:26, 13.05s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [01:14<25:38, 21.97s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [01:14<25:38, 21.97s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [01:43<28:00, 24.36s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [01:43<28:00, 24.36s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [02:13<29:44, 26.24s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [02:13<29:44, 26.24s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [02:44<30:54, 27.69s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [02:44<30:54, 27.69s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [03:06<28:35, 26.00s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [03:06<28:35, 26.00s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [03:15<22:34, 20.85s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [03:15<22:34, 20.85s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [03:51<27:09, 25.46s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [03:51<27:09, 25.46s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [04:20<27:47, 26.47s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [04:20<27:47, 26.47s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [04:50<28:32, 27.62s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [04:50<28:32, 27.62s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [05:21<29:03, 28.58s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [05:21<29:03, 28.58s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [05:44<26:44, 26.74s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [05:44<26:44, 26.74s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [05:53<21:12, 21.57s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [05:53<21:12, 21.57s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [06:29<24:59, 25.86s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [06:29<24:59, 25.86s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [06:58<25:28, 26.81s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [06:58<25:28, 26.81s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [07:28<25:58, 27.84s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [07:28<25:58, 27.84s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [07:59<26:18, 28.71s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [07:59<26:18, 28.71s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [08:21<24:09, 26.84s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [08:21<24:09, 26.84s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [08:31<19:07, 21.66s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [08:31<19:07, 21.66s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [09:07<22:29, 25.95s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [09:07<22:29, 25.95s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [09:36<22:49, 26.86s/it]calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [09:36<22:49, 26.86s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [10:06<23:11, 27.83s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [10:06<23:11, 27.83s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [10:37<23:26, 28.70s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [10:37<23:26, 28.70s/it]slurmstepd-jnfat06: error: *** JOB 1643447 ON jnfat06 CANCELLED AT 2025-09-08T15:19:31 ***
