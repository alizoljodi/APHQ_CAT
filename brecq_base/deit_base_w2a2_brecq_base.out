Starting Deit-Base W2A2 BRECQ experiment at Mon Sep  8 03:57:32 PM CEST 2025
2025-09-08 15:57:32,609 - INFO - Starting multi-seed experiment
2025-09-08 15:57:32,609 - INFO - Architecture: deit_base
2025-09-08 15:57:32,609 - INFO - Weight bits: 2
2025-09-08 15:57:32,609 - INFO - Activation bits: 2
2025-09-08 15:57:32,609 - INFO - Seeds: [1001, 1002, 1003]
2025-09-08 15:57:32,609 - INFO - Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
2025-09-08 15:57:32,609 - INFO - Cluster numbers: [8, 16, 32, 64, 128, 256]
2025-09-08 15:57:32,609 - INFO - PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]
2025-09-08 15:57:32,609 - INFO - Output directory: ./experiment_results/deit_base_w2_a2_20250908_155732
2025-09-08 15:57:32,609 - INFO - Checking basic requirements...
2025-09-08 15:57:32,618 - INFO - Basic checks passed
2025-09-08 15:57:32,618 - INFO - 
Starting experiments for 3 seeds...
2025-09-08 15:57:32,618 - INFO - Total parameter combinations: 600
2025-09-08 15:57:32,618 - INFO - Total experiments: 1800
2025-09-08 15:57:32,618 - INFO - 
============================================================
2025-09-08 15:57:32,618 - INFO - Running experiment 1/3 for seed 1001
2025-09-08 15:57:32,618 - INFO - ============================================================
2025-09-08 15:57:32,618 - INFO - Running experiment for seed 1001
2025-09-08 15:57:32,618 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model deit_base --w_bit 2 --a_bit 2 --seed 1001 --config ../configs/4bit/brecq_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-08 15:57:32,618 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/brecq_base
2025-09-08 15:57:35 - start the process.
Namespace(model='deit_base', config='../configs/4bit/brecq_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1001, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=2, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 2
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: rinp
drop_prob: 1.0
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/deit_base_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/deit_base_patch16_224.fb_in1k)
[timm/deit_base_patch16_224.fb_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 8.559 (8.559)	Loss 0.4608 (0.4608)	Prec@1 90.600 (90.600)	Prec@5 98.600 (98.600)
Test: [10/100]	Time 0.801 (1.722)	Loss 0.5691 (0.6237)	Prec@1 89.200 (86.582)	Prec@5 96.600 (97.473)
Test: [20/100]	Time 0.770 (1.277)	Loss 0.6565 (0.6262)	Prec@1 84.600 (86.752)	Prec@5 98.400 (97.533)
Test: [30/100]	Time 0.779 (1.244)	Loss 0.5879 (0.6391)	Prec@1 87.400 (86.348)	Prec@5 99.400 (97.548)
Test: [40/100]	Time 0.791 (1.241)	Loss 0.8276 (0.6411)	Prec@1 81.600 (86.317)	Prec@5 96.000 (97.507)
Test: [50/100]	Time 2.680 (1.454)	Loss 1.2987 (0.7189)	Prec@1 72.600 (84.408)	Prec@5 90.200 (96.710)
Test: [60/100]	Time 0.784 (1.401)	Loss 0.7880 (0.7396)	Prec@1 84.000 (83.977)	Prec@5 94.000 (96.462)
Test: [70/100]	Time 0.794 (1.396)	Loss 0.9197 (0.7745)	Prec@1 80.000 (83.039)	Prec@5 94.600 (96.127)
Test: [80/100]	Time 0.789 (1.350)	Loss 0.6823 (0.7935)	Prec@1 87.000 (82.738)	Prec@5 96.400 (95.849)
Test: [90/100]	Time 0.781 (1.384)	Loss 1.1798 (0.8183)	Prec@1 70.200 (82.015)	Prec@5 94.600 (95.679)
 * Prec@1 81.982 Prec@5 95.744 Loss 0.818 Time 140.956
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-08 16:00:30 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:11<14:22, 11.81s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:11<14:22, 11.81s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [01:25<57:43, 48.10s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [01:25<57:43, 48.10s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [01:50<44:34, 37.67s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [01:50<44:34, 37.67s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [03:01<59:24, 50.93s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [03:01<59:24, 50.93s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [04:02<1:02:32, 54.39s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [04:02<1:02:32, 54.39s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [05:54<1:23:57, 74.09s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [05:54<1:23:57, 74.09s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [07:49<1:37:45, 87.55s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [07:49<1:37:45, 87.55s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [09:05<1:32:09, 83.79s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [09:05<1:32:09, 83.79s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [09:32<1:11:21, 65.87s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [09:32<1:11:21, 65.87s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [10:43<1:12:12, 67.69s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [10:43<1:12:12, 67.69s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [11:44<1:08:49, 65.55s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [11:44<1:08:49, 65.55s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [13:36<1:22:26, 79.78s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [13:36<1:22:26, 79.78s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [15:32<1:32:02, 90.53s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [15:32<1:32:02, 90.53s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [16:47<1:26:00, 86.00s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [16:47<1:26:00, 86.00s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [17:14<1:06:55, 68.07s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [17:14<1:06:55, 68.07s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [18:26<1:06:57, 69.27s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [18:26<1:06:57, 69.27s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [19:27<1:03:24, 66.75s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [19:27<1:03:24, 66.75s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [21:20<1:15:17, 80.68s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [21:20<1:15:17, 80.68s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [23:15<1:23:33, 91.15s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [23:15<1:23:33, 91.15s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [24:31<1:17:49, 86.46s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [24:31<1:17:49, 86.46s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [24:57<1:00:29, 68.48s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [24:57<1:00:29, 68.48s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [26:10<1:00:23, 69.69s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [26:10<1:00:23, 69.69s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [27:11<56:58, 67.03s/it]  calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [27:11<56:58, 67.03s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [29:03<1:07:02, 80.46s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [29:03<1:07:02, 80.46s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [30:57<1:14:00, 90.63s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [30:57<1:14:00, 90.63s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [32:12<1:08:42, 85.89s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [32:12<1:08:42, 85.89s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [32:38<53:15, 67.99s/it]  calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [32:38<53:15, 67.99s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [33:50<53:02, 69.18s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [33:50<53:02, 69.18s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [34:51<49:58, 66.63s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [34:51<49:58, 66.63s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [36:44<59:05, 80.59s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [36:44<59:05, 80.59s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [38:39<1:05:13, 91.02s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [38:39<1:05:13, 91.02s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [39:55<1:00:33, 86.51s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [39:55<1:00:33, 86.51s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [40:21<46:44, 68.39s/it]  calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [40:21<46:44, 68.39s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [41:33<46:16, 69.40s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [41:33<46:16, 69.40s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [42:34<43:26, 66.82s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [42:34<43:26, 66.82s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [44:27<51:05, 80.67s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [44:27<51:05, 80.67s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [46:22<56:07, 91.02s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [46:22<56:07, 91.02s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [47:37<51:46, 86.28s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [47:37<51:46, 86.28s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [48:03<39:50, 68.29s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [48:03<39:50, 68.29s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [49:15<39:18, 69.37s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [49:15<39:18, 69.37s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [50:16<36:45, 66.82s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [50:16<36:45, 66.82s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [52:09<42:59, 80.61s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [52:09<42:59, 80.61s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [54:04<47:02, 91.04s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [54:04<47:02, 91.04s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [55:20<43:11, 86.39s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [55:20<43:11, 86.39s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [55:46<33:02, 68.37s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [55:46<33:02, 68.37s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [56:58<32:24, 69.45s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [56:58<32:24, 69.45s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [57:59<30:04, 66.84s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [57:59<30:04, 66.84s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [59:52<34:59, 80.74s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [59:52<34:59, 80.74s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [1:01:48<37:58, 91.14s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [1:01:48<37:58, 91.14s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [1:03:03<34:31, 86.32s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [1:03:03<34:31, 86.32s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [1:03:29<26:09, 68.26s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [1:03:29<26:09, 68.26s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [1:04:41<25:25, 69.32s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [1:04:41<25:25, 69.32s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [1:05:41<23:21, 66.72s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [1:05:41<23:21, 66.72s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [1:07:34<26:49, 80.49s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [1:07:34<26:49, 80.49s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [1:09:28<28:43, 90.71s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [1:09:28<28:43, 90.71s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [1:10:43<25:47, 85.99s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [1:10:43<25:47, 85.99s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [1:11:10<19:17, 68.10s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [1:11:10<19:17, 68.10s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [1:12:22<18:28, 69.26s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [1:12:22<18:28, 69.26s/it]calibrating blocks.9.attn.matmul2:  80%|███████▉  | 59/74 [1:13:22<16:40, 66.69s/it]calibrating blocks.9.mlp.fc1:  80%|███████▉  | 59/74 [1:13:22<16:40, 66.69s/it]     calibrating blocks.9.mlp.fc1:  81%|████████  | 60/74 [1:15:15<18:47, 80.51s/it]calibrating blocks.9.mlp.fc2:  81%|████████  | 60/74 [1:15:15<18:47, 80.51s/it]calibrating blocks.9.mlp.fc2:  82%|████████▏ | 61/74 [1:17:10<19:40, 90.80s/it]calibrating blocks.10.attn.qkv:  82%|████████▏ | 61/74 [1:17:10<19:40, 90.80s/it]calibrating blocks.10.attn.qkv:  84%|████████▍ | 62/74 [1:18:25<17:12, 86.07s/it]calibrating blocks.10.attn.proj:  84%|████████▍ | 62/74 [1:18:25<17:12, 86.07s/it]calibrating blocks.10.attn.proj:  85%|████████▌ | 63/74 [1:18:51<12:29, 68.13s/it]calibrating blocks.10.attn.matmul1:  85%|████████▌ | 63/74 [1:18:51<12:29, 68.13s/it]calibrating blocks.10.attn.matmul1:  86%|████████▋ | 64/74 [1:20:03<11:32, 69.24s/it]calibrating blocks.10.attn.matmul2:  86%|████████▋ | 64/74 [1:20:03<11:32, 69.24s/it]calibrating blocks.10.attn.matmul2:  88%|████████▊ | 65/74 [1:21:04<10:00, 66.71s/it]calibrating blocks.10.mlp.fc1:  88%|████████▊ | 65/74 [1:21:04<10:00, 66.71s/it]     calibrating blocks.10.mlp.fc1:  89%|████████▉ | 66/74 [1:22:57<10:45, 80.72s/it]calibrating blocks.10.mlp.fc2:  89%|████████▉ | 66/74 [1:22:57<10:45, 80.72s/it]calibrating blocks.10.mlp.fc2:  91%|█████████ | 67/74 [1:24:53<10:38, 91.28s/it]calibrating blocks.11.attn.qkv:  91%|█████████ | 67/74 [1:24:53<10:38, 91.28s/it]calibrating blocks.11.attn.qkv:  92%|█████████▏| 68/74 [1:26:09<08:40, 86.70s/it]calibrating blocks.11.attn.proj:  92%|█████████▏| 68/74 [1:26:09<08:40, 86.70s/it]calibrating blocks.11.attn.proj:  93%|█████████▎| 69/74 [1:26:36<05:43, 68.64s/it]calibrating blocks.11.attn.matmul1:  93%|█████████▎| 69/74 [1:26:36<05:43, 68.64s/it]calibrating blocks.11.attn.matmul1:  95%|█████████▍| 70/74 [1:27:47<04:38, 69.54s/it]calibrating blocks.11.attn.matmul2:  95%|█████████▍| 70/74 [1:27:47<04:38, 69.54s/it]calibrating blocks.11.attn.matmul2:  96%|█████████▌| 71/74 [1:28:48<03:20, 66.92s/it]calibrating blocks.11.mlp.fc1:  96%|█████████▌| 71/74 [1:28:48<03:20, 66.92s/it]     calibrating blocks.11.mlp.fc1:  97%|█████████▋| 72/74 [1:30:41<02:41, 80.85s/it]calibrating blocks.11.mlp.fc2:  97%|█████████▋| 72/74 [1:30:41<02:41, 80.85s/it]calibrating blocks.11.mlp.fc2:  99%|█████████▊| 73/74 [1:32:37<01:31, 91.22s/it]calibrating head:  99%|█████████▊| 73/74 [1:32:37<01:31, 91.22s/it]             calibrating head: 100%|██████████| 74/74 [1:32:41<00:00, 64.94s/it]calibrating head: 100%|██████████| 74/74 [1:32:41<00:00, 75.15s/it]
2025-09-08 17:33:38 - mse guided calibration finished.
Saving checkpoint to ./checkpoint/quant_result/20250908_1557/deit_base_w2_a2_calibsize_1000_mse.pth
Validating after calibration ...
Test: [0/100]	Time 17.731 (17.731)	Loss 7.0730 (7.0730)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [10/100]	Time 1.660 (3.333)	Loss 7.0507 (7.0802)	Prec@1 0.000 (0.000)	Prec@5 0.600 (0.055)
Test: [20/100]	Time 1.665 (2.537)	Loss 6.9634 (7.0605)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.038)
Test: [30/100]	Time 1.668 (2.256)	Loss 7.3708 (7.0545)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.026)
Test: [40/100]	Time 1.662 (2.111)	Loss 7.0120 (7.0568)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.020)
Test: [50/100]	Time 1.667 (2.023)	Loss 6.7204 (7.0141)	Prec@1 0.200 (0.012)	Prec@5 2.800 (0.161)
Test: [60/100]	Time 1.663 (1.964)	Loss 6.8615 (6.9927)	Prec@1 3.800 (0.072)	Prec@5 7.800 (0.311)
Test: [70/100]	Time 1.665 (1.921)	Loss 6.7039 (6.9814)	Prec@1 0.000 (0.062)	Prec@5 0.800 (0.282)
Test: [80/100]	Time 1.663 (1.889)	Loss 6.8755 (6.9669)	Prec@1 0.000 (0.133)	Prec@5 0.000 (0.605)
Test: [90/100]	Time 1.658 (1.864)	Loss 7.0807 (6.9530)	Prec@1 0.000 (0.125)	Prec@5 0.000 (0.571)
 * Prec@1 0.132 Prec@5 0.652 Loss 6.978 Time 184.686
Building calibrator ...
2025-09-08 17:37:09 - start mse guided block reconstruction
reconstructing patch_embed ...
initializing raw input and raw output ...
adaround training for patch_embed ...
wraping quantizers in patch_embed ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.059 (rec:0.059, round:0.000)	b=0.00	count=500
Total loss:	0.023 (rec:0.023, round:0.000)	b=0.00	count=1000
Total loss:	0.021 (rec:0.021, round:0.000)	b=0.00	count=1500
Total loss:	0.021 (rec:0.021, round:0.000)	b=0.00	count=2000
Total loss:	0.011 (rec:0.011, round:0.000)	b=0.00	count=2500
Total loss:	0.016 (rec:0.016, round:0.000)	b=0.00	count=3000
Total loss:	0.010 (rec:0.010, round:0.000)	b=0.00	count=3500
Total loss:	5565.968 (rec:0.010, round:5565.958)	b=20.00	count=4000
Total loss:	2839.605 (rec:0.035, round:2839.571)	b=19.44	count=4500
Total loss:	2618.970 (rec:0.031, round:2618.940)	b=18.88	count=5000
Total loss:	2474.905 (rec:0.020, round:2474.884)	b=18.31	count=5500
Total loss:	2350.559 (rec:0.030, round:2350.529)	b=17.75	count=6000
Total loss:	2232.240 (rec:0.022, round:2232.218)	b=17.19	count=6500
Total loss:	2114.562 (rec:0.022, round:2114.540)	b=16.62	count=7000
Total loss:	1994.048 (rec:0.030, round:1994.018)	b=16.06	count=7500
Total loss:	1870.487 (rec:0.012, round:1870.474)	b=15.50	count=8000
Total loss:	1743.730 (rec:0.022, round:1743.707)	b=14.94	count=8500
Total loss:	1617.022 (rec:0.019, round:1617.003)	b=14.38	count=9000
Total loss:	1486.166 (rec:0.019, round:1486.146)	b=13.81	count=9500
Total loss:	1352.134 (rec:0.025, round:1352.109)	b=13.25	count=10000
Total loss:	1215.610 (rec:0.037, round:1215.573)	b=12.69	count=10500
Total loss:	1077.721 (rec:0.027, round:1077.694)	b=12.12	count=11000
Total loss:	937.672 (rec:0.029, round:937.642)	b=11.56	count=11500
Total loss:	796.391 (rec:0.037, round:796.354)	b=11.00	count=12000
Total loss:	655.169 (rec:0.044, round:655.125)	b=10.44	count=12500
Total loss:	520.436 (rec:0.057, round:520.380)	b=9.88	count=13000
Total loss:	393.457 (rec:0.065, round:393.392)	b=9.31	count=13500
Total loss:	280.134 (rec:0.052, round:280.082)	b=8.75	count=14000
Total loss:	185.593 (rec:0.086, round:185.507)	b=8.19	count=14500
Total loss:	113.253 (rec:0.082, round:113.172)	b=7.62	count=15000
Total loss:	60.181 (rec:0.075, round:60.106)	b=7.06	count=15500
Total loss:	27.768 (rec:0.102, round:27.666)	b=6.50	count=16000
Total loss:	11.624 (rec:0.101, round:11.523)	b=5.94	count=16500
Total loss:	4.676 (rec:0.076, round:4.600)	b=5.38	count=17000
Total loss:	2.037 (rec:0.104, round:1.933)	b=4.81	count=17500
Total loss:	0.998 (rec:0.095, round:0.903)	b=4.25	count=18000
Total loss:	0.439 (rec:0.109, round:0.330)	b=3.69	count=18500
Total loss:	0.146 (rec:0.070, round:0.076)	b=3.12	count=19000
Total loss:	0.089 (rec:0.074, round:0.014)	b=2.56	count=19500
Total loss:	0.123 (rec:0.122, round:0.001)	b=2.00	count=20000
finished reconstructing patch_embed.
reconstructing blocks.0 ...
initializing raw input and raw output ...
adaround training for blocks.0 ...
wraping quantizers in blocks.0 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.063 (rec:1.063, round:0.000)	b=0.00	count=500
Total loss:	0.746 (rec:0.746, round:0.000)	b=0.00	count=1000
Total loss:	0.592 (rec:0.592, round:0.000)	b=0.00	count=1500
Total loss:	0.540 (rec:0.540, round:0.000)	b=0.00	count=2000
Total loss:	0.528 (rec:0.528, round:0.000)	b=0.00	count=2500
Total loss:	0.442 (rec:0.442, round:0.000)	b=0.00	count=3000
Total loss:	0.443 (rec:0.443, round:0.000)	b=0.00	count=3500
Total loss:	62367.051 (rec:0.418, round:62366.633)	b=20.00	count=4000
Total loss:	24130.688 (rec:0.419, round:24130.268)	b=19.44	count=4500
Total loss:	21942.902 (rec:0.413, round:21942.488)	b=18.88	count=5000
Total loss:	20470.521 (rec:0.402, round:20470.119)	b=18.31	count=5500
Total loss:	19191.162 (rec:0.401, round:19190.762)	b=17.75	count=6000
Total loss:	18000.084 (rec:0.415, round:17999.670)	b=17.19	count=6500
Total loss:	16872.494 (rec:0.388, round:16872.105)	b=16.62	count=7000
Total loss:	15795.720 (rec:0.384, round:15795.336)	b=16.06	count=7500
Total loss:	14755.796 (rec:0.401, round:14755.396)	b=15.50	count=8000
Total loss:	13752.303 (rec:0.375, round:13751.928)	b=14.94	count=8500
Total loss:	12791.648 (rec:0.383, round:12791.266)	b=14.38	count=9000
Total loss:	11854.800 (rec:0.364, round:11854.436)	b=13.81	count=9500
Total loss:	10942.811 (rec:0.395, round:10942.416)	b=13.25	count=10000
Total loss:	10053.021 (rec:0.356, round:10052.664)	b=12.69	count=10500
Total loss:	9187.176 (rec:0.366, round:9186.810)	b=12.12	count=11000
Total loss:	8331.476 (rec:0.363, round:8331.113)	b=11.56	count=11500
Total loss:	7496.399 (rec:0.325, round:7496.074)	b=11.00	count=12000
Total loss:	6683.986 (rec:0.399, round:6683.588)	b=10.44	count=12500
Total loss:	5885.331 (rec:0.444, round:5884.887)	b=9.88	count=13000
Total loss:	5104.459 (rec:0.417, round:5104.042)	b=9.31	count=13500
Total loss:	4348.650 (rec:0.411, round:4348.240)	b=8.75	count=14000
Total loss:	3621.781 (rec:0.407, round:3621.374)	b=8.19	count=14500
Total loss:	2932.815 (rec:0.425, round:2932.390)	b=7.62	count=15000
Total loss:	2281.989 (rec:0.425, round:2281.564)	b=7.06	count=15500
Total loss:	1681.762 (rec:0.404, round:1681.358)	b=6.50	count=16000
Total loss:	1155.823 (rec:0.474, round:1155.349)	b=5.94	count=16500
Total loss:	719.770 (rec:0.401, round:719.369)	b=5.38	count=17000
Total loss:	388.326 (rec:0.451, round:387.875)	b=4.81	count=17500
Total loss:	171.563 (rec:0.415, round:171.148)	b=4.25	count=18000
Total loss:	53.637 (rec:0.394, round:53.243)	b=3.69	count=18500
Total loss:	10.158 (rec:0.367, round:9.791)	b=3.12	count=19000
Total loss:	1.204 (rec:0.410, round:0.794)	b=2.56	count=19500
Total loss:	0.494 (rec:0.469, round:0.025)	b=2.00	count=20000
finished reconstructing blocks.0.
reconstructing blocks.1 ...
initializing raw input and raw output ...
adaround training for blocks.1 ...
wraping quantizers in blocks.1 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.628 (rec:1.628, round:0.000)	b=0.00	count=500
Total loss:	1.187 (rec:1.187, round:0.000)	b=0.00	count=1000
Total loss:	1.060 (rec:1.060, round:0.000)	b=0.00	count=1500
Total loss:	0.894 (rec:0.894, round:0.000)	b=0.00	count=2000
Total loss:	1.137 (rec:1.137, round:0.000)	b=0.00	count=2500
Total loss:	1.048 (rec:1.048, round:0.000)	b=0.00	count=3000
Total loss:	1.090 (rec:1.090, round:0.000)	b=0.00	count=3500
Total loss:	62701.238 (rec:1.028, round:62700.211)	b=20.00	count=4000
Total loss:	24712.188 (rec:1.093, round:24711.094)	b=19.44	count=4500
Total loss:	22074.217 (rec:0.998, round:22073.219)	b=18.88	count=5000
Total loss:	20239.141 (rec:1.016, round:20238.125)	b=18.31	count=5500
Total loss:	18675.426 (rec:1.011, round:18674.414)	b=17.75	count=6000
Total loss:	17304.889 (rec:1.092, round:17303.797)	b=17.19	count=6500
Total loss:	16082.122 (rec:0.999, round:16081.123)	b=16.62	count=7000
Total loss:	14966.418 (rec:1.002, round:14965.416)	b=16.06	count=7500
Total loss:	13934.831 (rec:1.056, round:13933.775)	b=15.50	count=8000
Total loss:	12967.789 (rec:0.951, round:12966.838)	b=14.94	count=8500
Total loss:	12046.747 (rec:1.011, round:12045.736)	b=14.38	count=9000
Total loss:	11159.182 (rec:1.020, round:11158.162)	b=13.81	count=9500
Total loss:	10315.034 (rec:1.042, round:10313.992)	b=13.25	count=10000
Total loss:	9488.329 (rec:1.153, round:9487.176)	b=12.69	count=10500
Total loss:	8684.407 (rec:1.041, round:8683.366)	b=12.12	count=11000
Total loss:	7897.075 (rec:1.033, round:7896.042)	b=11.56	count=11500
Total loss:	7125.798 (rec:1.015, round:7124.784)	b=11.00	count=12000
Total loss:	6373.393 (rec:0.980, round:6372.413)	b=10.44	count=12500
Total loss:	5640.445 (rec:1.023, round:5639.422)	b=9.88	count=13000
Total loss:	4925.453 (rec:1.130, round:4924.324)	b=9.31	count=13500
Total loss:	4230.419 (rec:1.056, round:4229.363)	b=8.75	count=14000
Total loss:	3555.945 (rec:0.969, round:3554.976)	b=8.19	count=14500
Total loss:	2909.872 (rec:1.026, round:2908.845)	b=7.62	count=15000
Total loss:	2301.277 (rec:1.061, round:2300.216)	b=7.06	count=15500
Total loss:	1735.763 (rec:1.062, round:1734.700)	b=6.50	count=16000
Total loss:	1232.495 (rec:0.978, round:1231.518)	b=5.94	count=16500
Total loss:	798.387 (rec:1.008, round:797.379)	b=5.38	count=17000
Total loss:	456.895 (rec:1.061, round:455.834)	b=4.81	count=17500
Total loss:	212.627 (rec:1.064, round:211.564)	b=4.25	count=18000
Total loss:	72.148 (rec:1.118, round:71.030)	b=3.69	count=18500
Total loss:	14.867 (rec:1.032, round:13.834)	b=3.12	count=19000
Total loss:	2.287 (rec:1.034, round:1.253)	b=2.56	count=19500
Total loss:	0.987 (rec:0.947, round:0.039)	b=2.00	count=20000
finished reconstructing blocks.1.
reconstructing blocks.2 ...
initializing raw input and raw output ...
adaround training for blocks.2 ...
wraping quantizers in blocks.2 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.895 (rec:0.895, round:0.000)	b=0.00	count=500
Total loss:	0.723 (rec:0.723, round:0.000)	b=0.00	count=1000
Total loss:	0.630 (rec:0.630, round:0.000)	b=0.00	count=1500
Total loss:	0.577 (rec:0.577, round:0.000)	b=0.00	count=2000
Total loss:	0.552 (rec:0.552, round:0.000)	b=0.00	count=2500
Total loss:	0.541 (rec:0.541, round:0.000)	b=0.00	count=3000
Total loss:	0.506 (rec:0.506, round:0.000)	b=0.00	count=3500
Total loss:	63408.797 (rec:0.521, round:63408.277)	b=20.00	count=4000
Total loss:	28452.072 (rec:0.508, round:28451.564)	b=19.44	count=4500
Total loss:	25998.469 (rec:0.507, round:25997.961)	b=18.88	count=5000
Total loss:	24245.074 (rec:0.503, round:24244.570)	b=18.31	count=5500
Total loss:	22671.293 (rec:0.440, round:22670.854)	b=17.75	count=6000
Total loss:	21200.070 (rec:0.442, round:21199.629)	b=17.19	count=6500
Total loss:	19790.656 (rec:0.480, round:19790.176)	b=16.62	count=7000
Total loss:	18432.492 (rec:0.489, round:18432.004)	b=16.06	count=7500
Total loss:	17126.172 (rec:0.427, round:17125.744)	b=15.50	count=8000
Total loss:	15874.692 (rec:0.464, round:15874.229)	b=14.94	count=8500
Total loss:	14672.474 (rec:0.453, round:14672.021)	b=14.38	count=9000
Total loss:	13510.643 (rec:0.461, round:13510.182)	b=13.81	count=9500
Total loss:	12396.156 (rec:0.436, round:12395.721)	b=13.25	count=10000
Total loss:	11324.186 (rec:0.429, round:11323.757)	b=12.69	count=10500
Total loss:	10292.125 (rec:0.420, round:10291.705)	b=12.12	count=11000
Total loss:	9293.457 (rec:0.440, round:9293.018)	b=11.56	count=11500
Total loss:	8332.394 (rec:0.431, round:8331.963)	b=11.00	count=12000
Total loss:	7403.982 (rec:0.423, round:7403.560)	b=10.44	count=12500
Total loss:	6502.097 (rec:0.423, round:6501.674)	b=9.88	count=13000
Total loss:	5634.448 (rec:0.451, round:5633.997)	b=9.31	count=13500
Total loss:	4797.236 (rec:0.496, round:4796.740)	b=8.75	count=14000
Total loss:	3999.342 (rec:0.464, round:3998.878)	b=8.19	count=14500
Total loss:	3238.367 (rec:0.461, round:3237.906)	b=7.62	count=15000
Total loss:	2518.793 (rec:0.433, round:2518.360)	b=7.06	count=15500
Total loss:	1846.666 (rec:0.457, round:1846.209)	b=6.50	count=16000
Total loss:	1220.641 (rec:0.460, round:1220.181)	b=5.94	count=16500
Total loss:	625.446 (rec:0.442, round:625.004)	b=5.38	count=17000
Total loss:	216.768 (rec:0.441, round:216.328)	b=4.81	count=17500
Total loss:	72.246 (rec:0.451, round:71.795)	b=4.25	count=18000
Total loss:	21.852 (rec:0.483, round:21.368)	b=3.69	count=18500
Total loss:	4.504 (rec:0.495, round:4.009)	b=3.12	count=19000
Total loss:	0.762 (rec:0.452, round:0.310)	b=2.56	count=19500
Total loss:	0.472 (rec:0.467, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.2.
reconstructing blocks.3 ...
initializing raw input and raw output ...
adaround training for blocks.3 ...
wraping quantizers in blocks.3 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.950 (rec:0.950, round:0.000)	b=0.00	count=500
Total loss:	0.870 (rec:0.870, round:0.000)	b=0.00	count=1000
Total loss:	0.782 (rec:0.782, round:0.000)	b=0.00	count=1500
Total loss:	0.754 (rec:0.754, round:0.000)	b=0.00	count=2000
Total loss:	0.706 (rec:0.706, round:0.000)	b=0.00	count=2500
Total loss:	0.685 (rec:0.685, round:0.000)	b=0.00	count=3000
Total loss:	0.645 (rec:0.645, round:0.000)	b=0.00	count=3500
Total loss:	63597.043 (rec:0.630, round:63596.414)	b=20.00	count=4000
Total loss:	29297.508 (rec:0.620, round:29296.887)	b=19.44	count=4500
Total loss:	26820.629 (rec:0.633, round:26819.996)	b=18.88	count=5000
Total loss:	25051.574 (rec:0.636, round:25050.938)	b=18.31	count=5500
Total loss:	23457.967 (rec:0.608, round:23457.359)	b=17.75	count=6000
Total loss:	21935.625 (rec:0.625, round:21935.000)	b=17.19	count=6500
Total loss:	20468.117 (rec:0.589, round:20467.527)	b=16.62	count=7000
Total loss:	19068.904 (rec:0.623, round:19068.281)	b=16.06	count=7500
Total loss:	17724.160 (rec:0.647, round:17723.514)	b=15.50	count=8000
Total loss:	16432.859 (rec:0.600, round:16432.260)	b=14.94	count=8500
Total loss:	15192.513 (rec:0.586, round:15191.927)	b=14.38	count=9000
Total loss:	13998.084 (rec:0.620, round:13997.464)	b=13.81	count=9500
Total loss:	12847.779 (rec:0.596, round:12847.184)	b=13.25	count=10000
Total loss:	11736.969 (rec:0.640, round:11736.329)	b=12.69	count=10500
Total loss:	10663.604 (rec:0.587, round:10663.018)	b=12.12	count=11000
Total loss:	9630.197 (rec:0.626, round:9629.571)	b=11.56	count=11500
Total loss:	8630.133 (rec:0.607, round:8629.525)	b=11.00	count=12000
Total loss:	7665.674 (rec:0.620, round:7665.054)	b=10.44	count=12500
Total loss:	6737.854 (rec:0.585, round:6737.270)	b=9.88	count=13000
Total loss:	5839.482 (rec:0.594, round:5838.888)	b=9.31	count=13500
Total loss:	4984.312 (rec:0.624, round:4983.689)	b=8.75	count=14000
Total loss:	4163.339 (rec:0.600, round:4162.739)	b=8.19	count=14500
Total loss:	3379.674 (rec:0.625, round:3379.049)	b=7.62	count=15000
Total loss:	2637.852 (rec:0.614, round:2637.238)	b=7.06	count=15500
Total loss:	1944.729 (rec:0.597, round:1944.131)	b=6.50	count=16000
Total loss:	1287.468 (rec:0.601, round:1286.867)	b=5.94	count=16500
Total loss:	637.760 (rec:0.599, round:637.161)	b=5.38	count=17000
Total loss:	199.570 (rec:0.598, round:198.972)	b=4.81	count=17500
Total loss:	63.033 (rec:0.631, round:62.403)	b=4.25	count=18000
Total loss:	19.141 (rec:0.609, round:18.532)	b=3.69	count=18500
Total loss:	4.083 (rec:0.630, round:3.453)	b=3.12	count=19000
Total loss:	0.880 (rec:0.621, round:0.259)	b=2.56	count=19500
Total loss:	0.645 (rec:0.641, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.3.
reconstructing blocks.4 ...
initializing raw input and raw output ...
adaround training for blocks.4 ...
wraping quantizers in blocks.4 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.013 (rec:1.013, round:0.000)	b=0.00	count=500
Total loss:	0.890 (rec:0.890, round:0.000)	b=0.00	count=1000
Total loss:	0.833 (rec:0.833, round:0.000)	b=0.00	count=1500
Total loss:	0.748 (rec:0.748, round:0.000)	b=0.00	count=2000
Total loss:	0.762 (rec:0.762, round:0.000)	b=0.00	count=2500
Total loss:	0.698 (rec:0.698, round:0.000)	b=0.00	count=3000
Total loss:	0.690 (rec:0.690, round:0.000)	b=0.00	count=3500
Total loss:	63630.621 (rec:0.645, round:63629.977)	b=20.00	count=4000
Total loss:	29846.602 (rec:0.659, round:29845.943)	b=19.44	count=4500
Total loss:	27395.088 (rec:0.623, round:27394.465)	b=18.88	count=5000
Total loss:	25688.443 (rec:0.640, round:25687.805)	b=18.31	count=5500
Total loss:	24176.771 (rec:0.640, round:24176.131)	b=17.75	count=6000
Total loss:	22747.684 (rec:0.627, round:22747.057)	b=17.19	count=6500
Total loss:	21385.705 (rec:0.607, round:21385.098)	b=16.62	count=7000
Total loss:	20059.129 (rec:0.613, round:20058.516)	b=16.06	count=7500
Total loss:	18756.219 (rec:0.609, round:18755.609)	b=15.50	count=8000
Total loss:	17487.035 (rec:0.612, round:17486.424)	b=14.94	count=8500
Total loss:	16247.350 (rec:0.598, round:16246.752)	b=14.38	count=9000
Total loss:	15033.678 (rec:0.612, round:15033.066)	b=13.81	count=9500
Total loss:	13844.561 (rec:0.625, round:13843.936)	b=13.25	count=10000
Total loss:	12671.014 (rec:0.620, round:12670.395)	b=12.69	count=10500
Total loss:	11526.896 (rec:0.641, round:11526.255)	b=12.12	count=11000
Total loss:	10409.936 (rec:0.603, round:10409.332)	b=11.56	count=11500
Total loss:	9318.147 (rec:0.628, round:9317.520)	b=11.00	count=12000
Total loss:	8251.291 (rec:0.620, round:8250.671)	b=10.44	count=12500
Total loss:	7214.769 (rec:0.642, round:7214.127)	b=9.88	count=13000
Total loss:	6212.274 (rec:0.648, round:6211.627)	b=9.31	count=13500
Total loss:	5240.600 (rec:0.659, round:5239.941)	b=8.75	count=14000
Total loss:	4323.799 (rec:0.649, round:4323.150)	b=8.19	count=14500
Total loss:	3472.591 (rec:0.628, round:3471.963)	b=7.62	count=15000
Total loss:	2687.177 (rec:0.647, round:2686.530)	b=7.06	count=15500
Total loss:	1968.026 (rec:0.647, round:1967.379)	b=6.50	count=16000
Total loss:	1300.198 (rec:0.640, round:1299.558)	b=5.94	count=16500
Total loss:	652.344 (rec:0.653, round:651.691)	b=5.38	count=17000
Total loss:	224.186 (rec:0.660, round:223.525)	b=4.81	count=17500
Total loss:	72.545 (rec:0.646, round:71.899)	b=4.25	count=18000
Total loss:	20.509 (rec:0.666, round:19.843)	b=3.69	count=18500
Total loss:	4.249 (rec:0.659, round:3.591)	b=3.12	count=19000
Total loss:	0.948 (rec:0.653, round:0.295)	b=2.56	count=19500
Total loss:	0.645 (rec:0.629, round:0.016)	b=2.00	count=20000
finished reconstructing blocks.4.
reconstructing blocks.5 ...
initializing raw input and raw output ...
adaround training for blocks.5 ...
wraping quantizers in blocks.5 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.096 (rec:1.096, round:0.000)	b=0.00	count=500
Total loss:	0.916 (rec:0.916, round:0.000)	b=0.00	count=1000
Total loss:	0.853 (rec:0.853, round:0.000)	b=0.00	count=1500
Total loss:	0.795 (rec:0.795, round:0.000)	b=0.00	count=2000
Total loss:	0.758 (rec:0.758, round:0.000)	b=0.00	count=2500
Total loss:	0.719 (rec:0.719, round:0.000)	b=0.00	count=3000
Total loss:	0.708 (rec:0.708, round:0.000)	b=0.00	count=3500
Total loss:	63352.520 (rec:0.683, round:63351.836)	b=20.00	count=4000
Total loss:	29889.391 (rec:0.711, round:29888.680)	b=19.44	count=4500
Total loss:	27422.805 (rec:0.688, round:27422.117)	b=18.88	count=5000
Total loss:	25735.520 (rec:0.670, round:25734.850)	b=18.31	count=5500
Total loss:	24260.646 (rec:0.673, round:24259.973)	b=17.75	count=6000
Total loss:	22882.984 (rec:0.649, round:22882.336)	b=17.19	count=6500
Total loss:	21569.975 (rec:0.666, round:21569.309)	b=16.62	count=7000
Total loss:	20302.691 (rec:0.646, round:20302.045)	b=16.06	count=7500
Total loss:	19073.426 (rec:0.653, round:19072.773)	b=15.50	count=8000
Total loss:	17866.453 (rec:0.665, round:17865.787)	b=14.94	count=8500
Total loss:	16691.752 (rec:0.642, round:16691.109)	b=14.38	count=9000
Total loss:	15535.497 (rec:0.643, round:15534.854)	b=13.81	count=9500
Total loss:	14402.917 (rec:0.642, round:14402.274)	b=13.25	count=10000
Total loss:	13291.859 (rec:0.650, round:13291.210)	b=12.69	count=10500
Total loss:	12197.453 (rec:0.638, round:12196.814)	b=12.12	count=11000
Total loss:	11123.678 (rec:0.639, round:11123.038)	b=11.56	count=11500
Total loss:	10068.898 (rec:0.637, round:10068.262)	b=11.00	count=12000
Total loss:	9025.395 (rec:0.647, round:9024.747)	b=10.44	count=12500
Total loss:	7996.708 (rec:0.642, round:7996.065)	b=9.88	count=13000
Total loss:	6991.532 (rec:0.642, round:6990.890)	b=9.31	count=13500
Total loss:	6002.962 (rec:0.645, round:6002.317)	b=8.75	count=14000
Total loss:	5039.293 (rec:0.672, round:5038.622)	b=8.19	count=14500
Total loss:	4105.084 (rec:0.644, round:4104.440)	b=7.62	count=15000
Total loss:	3203.344 (rec:0.651, round:3202.693)	b=7.06	count=15500
Total loss:	2343.969 (rec:0.666, round:2343.303)	b=6.50	count=16000
Total loss:	1555.834 (rec:0.675, round:1555.159)	b=5.94	count=16500
Total loss:	865.467 (rec:0.682, round:864.786)	b=5.38	count=17000
Total loss:	360.811 (rec:0.689, round:360.123)	b=4.81	count=17500
Total loss:	110.723 (rec:0.681, round:110.043)	b=4.25	count=18000
Total loss:	26.353 (rec:0.693, round:25.660)	b=3.69	count=18500
Total loss:	4.825 (rec:0.699, round:4.126)	b=3.12	count=19000
Total loss:	0.991 (rec:0.671, round:0.320)	b=2.56	count=19500
Total loss:	0.701 (rec:0.692, round:0.009)	b=2.00	count=20000
finished reconstructing blocks.5.
reconstructing blocks.6 ...
initializing raw input and raw output ...
adaround training for blocks.6 ...
wraping quantizers in blocks.6 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.062 (rec:1.062, round:0.000)	b=0.00	count=500
Total loss:	0.872 (rec:0.872, round:0.000)	b=0.00	count=1000
Total loss:	0.805 (rec:0.805, round:0.000)	b=0.00	count=1500
Total loss:	0.756 (rec:0.756, round:0.000)	b=0.00	count=2000
Total loss:	0.710 (rec:0.710, round:0.000)	b=0.00	count=2500
Total loss:	0.689 (rec:0.689, round:0.000)	b=0.00	count=3000
Total loss:	0.662 (rec:0.662, round:0.000)	b=0.00	count=3500
Total loss:	63541.477 (rec:0.641, round:63540.836)	b=20.00	count=4000
Total loss:	30244.762 (rec:0.644, round:30244.117)	b=19.44	count=4500
Total loss:	27781.660 (rec:0.630, round:27781.031)	b=18.88	count=5000
Total loss:	26091.086 (rec:0.619, round:26090.467)	b=18.31	count=5500
Total loss:	24609.631 (rec:0.618, round:24609.014)	b=17.75	count=6000
Total loss:	23231.299 (rec:0.603, round:23230.695)	b=17.19	count=6500
Total loss:	21906.607 (rec:0.594, round:21906.014)	b=16.62	count=7000
Total loss:	20623.840 (rec:0.595, round:20623.244)	b=16.06	count=7500
Total loss:	19375.791 (rec:0.594, round:19375.197)	b=15.50	count=8000
Total loss:	18165.057 (rec:0.581, round:18164.477)	b=14.94	count=8500
Total loss:	16980.484 (rec:0.589, round:16979.896)	b=14.38	count=9000
Total loss:	15814.405 (rec:0.571, round:15813.835)	b=13.81	count=9500
Total loss:	14672.794 (rec:0.581, round:14672.213)	b=13.25	count=10000
Total loss:	13554.574 (rec:0.565, round:13554.010)	b=12.69	count=10500
Total loss:	12446.157 (rec:0.587, round:12445.570)	b=12.12	count=11000
Total loss:	11357.007 (rec:0.588, round:11356.419)	b=11.56	count=11500
Total loss:	10288.646 (rec:0.570, round:10288.075)	b=11.00	count=12000
Total loss:	9237.801 (rec:0.580, round:9237.221)	b=10.44	count=12500
Total loss:	8203.024 (rec:0.577, round:8202.448)	b=9.88	count=13000
Total loss:	7182.103 (rec:0.606, round:7181.497)	b=9.31	count=13500
Total loss:	6171.425 (rec:0.582, round:6170.843)	b=8.75	count=14000
Total loss:	5184.569 (rec:0.594, round:5183.976)	b=8.19	count=14500
Total loss:	4228.187 (rec:0.603, round:4227.583)	b=7.62	count=15000
Total loss:	3305.050 (rec:0.596, round:3304.453)	b=7.06	count=15500
Total loss:	2423.546 (rec:0.594, round:2422.952)	b=6.50	count=16000
Total loss:	1612.157 (rec:0.601, round:1611.556)	b=5.94	count=16500
Total loss:	897.998 (rec:0.624, round:897.374)	b=5.38	count=17000
Total loss:	382.075 (rec:0.623, round:381.452)	b=4.81	count=17500
Total loss:	119.771 (rec:0.620, round:119.150)	b=4.25	count=18000
Total loss:	28.451 (rec:0.633, round:27.818)	b=3.69	count=18500
Total loss:	4.755 (rec:0.633, round:4.122)	b=3.12	count=19000
Total loss:	0.914 (rec:0.610, round:0.304)	b=2.56	count=19500
Total loss:	0.618 (rec:0.609, round:0.010)	b=2.00	count=20000
finished reconstructing blocks.6.
reconstructing blocks.7 ...
initializing raw input and raw output ...
adaround training for blocks.7 ...
wraping quantizers in blocks.7 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.229 (rec:1.229, round:0.000)	b=0.00	count=500
Total loss:	0.951 (rec:0.951, round:0.000)	b=0.00	count=1000
Total loss:	0.865 (rec:0.865, round:0.000)	b=0.00	count=1500
Total loss:	0.847 (rec:0.847, round:0.000)	b=0.00	count=2000
Total loss:	0.768 (rec:0.768, round:0.000)	b=0.00	count=2500
Total loss:	0.727 (rec:0.727, round:0.000)	b=0.00	count=3000
Total loss:	0.704 (rec:0.704, round:0.000)	b=0.00	count=3500
Total loss:	64046.047 (rec:0.717, round:64045.332)	b=20.00	count=4000
Total loss:	31386.852 (rec:0.706, round:31386.145)	b=19.44	count=4500
Total loss:	28963.719 (rec:0.694, round:28963.025)	b=18.88	count=5000
Total loss:	27326.068 (rec:0.687, round:27325.383)	b=18.31	count=5500
Total loss:	25899.496 (rec:0.683, round:25898.812)	b=17.75	count=6000
Total loss:	24568.760 (rec:0.668, round:24568.092)	b=17.19	count=6500
Total loss:	23287.676 (rec:0.677, round:23286.998)	b=16.62	count=7000
Total loss:	22048.527 (rec:0.664, round:22047.863)	b=16.06	count=7500
Total loss:	20835.338 (rec:0.672, round:20834.666)	b=15.50	count=8000
Total loss:	19643.561 (rec:0.675, round:19642.885)	b=14.94	count=8500
Total loss:	18462.064 (rec:0.664, round:18461.400)	b=14.38	count=9000
Total loss:	17289.223 (rec:0.655, round:17288.568)	b=13.81	count=9500
Total loss:	16128.452 (rec:0.677, round:16127.775)	b=13.25	count=10000
Total loss:	14979.792 (rec:0.682, round:14979.110)	b=12.69	count=10500
Total loss:	13834.581 (rec:0.681, round:13833.900)	b=12.12	count=11000
Total loss:	12703.463 (rec:0.682, round:12702.781)	b=11.56	count=11500
Total loss:	11579.365 (rec:0.667, round:11578.698)	b=11.00	count=12000
Total loss:	10458.602 (rec:0.689, round:10457.913)	b=10.44	count=12500
Total loss:	9343.784 (rec:0.681, round:9343.104)	b=9.88	count=13000
Total loss:	8235.146 (rec:0.694, round:8234.451)	b=9.31	count=13500
Total loss:	7135.316 (rec:0.690, round:7134.626)	b=8.75	count=14000
Total loss:	6051.532 (rec:0.711, round:6050.821)	b=8.19	count=14500
Total loss:	4987.541 (rec:0.712, round:4986.828)	b=7.62	count=15000
Total loss:	3956.256 (rec:0.714, round:3955.542)	b=7.06	count=15500
Total loss:	2966.228 (rec:0.732, round:2965.497)	b=6.50	count=16000
Total loss:	2030.776 (rec:0.742, round:2030.034)	b=5.94	count=16500
Total loss:	1193.120 (rec:0.733, round:1192.387)	b=5.38	count=17000
Total loss:	533.122 (rec:0.754, round:532.369)	b=4.81	count=17500
Total loss:	166.928 (rec:0.749, round:166.179)	b=4.25	count=18000
Total loss:	37.037 (rec:0.745, round:36.292)	b=3.69	count=18500
Total loss:	5.510 (rec:0.742, round:4.768)	b=3.12	count=19000
Total loss:	1.054 (rec:0.750, round:0.305)	b=2.56	count=19500
Total loss:	0.765 (rec:0.748, round:0.016)	b=2.00	count=20000
finished reconstructing blocks.7.
reconstructing blocks.8 ...
initializing raw input and raw output ...
adaround training for blocks.8 ...
wraping quantizers in blocks.8 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.333 (rec:1.333, round:0.000)	b=0.00	count=500
Total loss:	1.123 (rec:1.123, round:0.000)	b=0.00	count=1000
Total loss:	1.111 (rec:1.111, round:0.000)	b=0.00	count=1500
Total loss:	0.956 (rec:0.956, round:0.000)	b=0.00	count=2000
Total loss:	0.913 (rec:0.913, round:0.000)	b=0.00	count=2500
Total loss:	0.890 (rec:0.890, round:0.000)	b=0.00	count=3000
Total loss:	0.861 (rec:0.861, round:0.000)	b=0.00	count=3500
Total loss:	64478.668 (rec:0.825, round:64477.844)	b=20.00	count=4000
Total loss:	32108.262 (rec:0.824, round:32107.438)	b=19.44	count=4500
Total loss:	29674.303 (rec:0.819, round:29673.484)	b=18.88	count=5000
Total loss:	28029.945 (rec:0.824, round:28029.121)	b=18.31	count=5500
Total loss:	26598.453 (rec:0.805, round:26597.648)	b=17.75	count=6000
Total loss:	25249.842 (rec:0.808, round:25249.033)	b=17.19	count=6500
Total loss:	23962.807 (rec:0.812, round:23961.994)	b=16.62	count=7000
Total loss:	22708.158 (rec:0.829, round:22707.328)	b=16.06	count=7500
Total loss:	21474.707 (rec:0.811, round:21473.896)	b=15.50	count=8000
Total loss:	20258.555 (rec:0.772, round:20257.783)	b=14.94	count=8500
Total loss:	19063.225 (rec:0.778, round:19062.445)	b=14.38	count=9000
Total loss:	17883.709 (rec:0.795, round:17882.914)	b=13.81	count=9500
Total loss:	16704.002 (rec:0.811, round:16703.191)	b=13.25	count=10000
Total loss:	15540.726 (rec:0.782, round:15539.943)	b=12.69	count=10500
Total loss:	14385.868 (rec:0.782, round:14385.086)	b=12.12	count=11000
Total loss:	13238.206 (rec:0.814, round:13237.392)	b=11.56	count=11500
Total loss:	12091.332 (rec:0.817, round:12090.515)	b=11.00	count=12000
Total loss:	10958.514 (rec:0.817, round:10957.696)	b=10.44	count=12500
Total loss:	9832.032 (rec:0.841, round:9831.191)	b=9.88	count=13000
Total loss:	8709.667 (rec:0.806, round:8708.861)	b=9.31	count=13500
Total loss:	7597.307 (rec:0.829, round:7596.479)	b=8.75	count=14000
Total loss:	6504.311 (rec:0.815, round:6503.496)	b=8.19	count=14500
Total loss:	5422.924 (rec:0.855, round:5422.070)	b=7.62	count=15000
Total loss:	4364.885 (rec:0.843, round:4364.042)	b=7.06	count=15500
Total loss:	3347.599 (rec:0.876, round:3346.723)	b=6.50	count=16000
Total loss:	2386.805 (rec:0.876, round:2385.929)	b=5.94	count=16500
Total loss:	1515.139 (rec:0.860, round:1514.278)	b=5.38	count=17000
Total loss:	789.774 (rec:0.902, round:788.872)	b=4.81	count=17500
Total loss:	300.921 (rec:0.890, round:300.031)	b=4.25	count=18000
Total loss:	71.786 (rec:0.936, round:70.850)	b=3.69	count=18500
Total loss:	9.013 (rec:0.918, round:8.096)	b=3.12	count=19000
Total loss:	1.303 (rec:0.909, round:0.394)	b=2.56	count=19500
Total loss:	0.894 (rec:0.883, round:0.012)	b=2.00	count=20000
finished reconstructing blocks.8.
reconstructing blocks.9 ...
initializing raw input and raw output ...
adaround training for blocks.9 ...
wraping quantizers in blocks.9 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.303 (rec:1.303, round:0.000)	b=0.00	count=500
Total loss:	1.181 (rec:1.181, round:0.000)	b=0.00	count=1000
Total loss:	1.096 (rec:1.096, round:0.000)	b=0.00	count=1500
Total loss:	1.039 (rec:1.039, round:0.000)	b=0.00	count=2000
Total loss:	0.989 (rec:0.989, round:0.000)	b=0.00	count=2500
Total loss:	0.916 (rec:0.916, round:0.000)	b=0.00	count=3000
Total loss:	0.896 (rec:0.896, round:0.000)	b=0.00	count=3500
Total loss:	64930.887 (rec:0.863, round:64930.023)	b=20.00	count=4000
Total loss:	32543.088 (rec:0.880, round:32542.207)	b=19.44	count=4500
Total loss:	30094.570 (rec:0.903, round:30093.668)	b=18.88	count=5000
Total loss:	28453.746 (rec:0.869, round:28452.877)	b=18.31	count=5500
Total loss:	27013.451 (rec:0.847, round:27012.605)	b=17.75	count=6000
Total loss:	25655.932 (rec:0.878, round:25655.055)	b=17.19	count=6500
Total loss:	24353.762 (rec:0.816, round:24352.945)	b=16.62	count=7000
Total loss:	23073.127 (rec:0.819, round:23072.309)	b=16.06	count=7500
Total loss:	21810.707 (rec:0.808, round:21809.898)	b=15.50	count=8000
Total loss:	20567.535 (rec:0.834, round:20566.701)	b=14.94	count=8500
Total loss:	19343.699 (rec:0.806, round:19342.893)	b=14.38	count=9000
Total loss:	18128.498 (rec:0.853, round:18127.645)	b=13.81	count=9500
Total loss:	16923.570 (rec:0.840, round:16922.730)	b=13.25	count=10000
Total loss:	15732.897 (rec:0.848, round:15732.050)	b=12.69	count=10500
Total loss:	14547.086 (rec:0.820, round:14546.266)	b=12.12	count=11000
Total loss:	13369.045 (rec:0.847, round:13368.197)	b=11.56	count=11500
Total loss:	12202.682 (rec:0.825, round:12201.856)	b=11.00	count=12000
Total loss:	11042.823 (rec:0.824, round:11041.999)	b=10.44	count=12500
Total loss:	9896.216 (rec:0.843, round:9895.373)	b=9.88	count=13000
Total loss:	8758.737 (rec:0.847, round:8757.890)	b=9.31	count=13500
Total loss:	7632.024 (rec:0.872, round:7631.151)	b=8.75	count=14000
Total loss:	6526.274 (rec:0.863, round:6525.411)	b=8.19	count=14500
Total loss:	5446.247 (rec:0.894, round:5445.353)	b=7.62	count=15000
Total loss:	4396.674 (rec:0.859, round:4395.814)	b=7.06	count=15500
Total loss:	3385.287 (rec:0.900, round:3384.387)	b=6.50	count=16000
Total loss:	2439.224 (rec:0.922, round:2438.302)	b=5.94	count=16500
Total loss:	1585.460 (rec:0.945, round:1584.515)	b=5.38	count=17000
Total loss:	869.901 (rec:0.946, round:868.954)	b=4.81	count=17500
Total loss:	362.930 (rec:0.921, round:362.010)	b=4.25	count=18000
Total loss:	95.265 (rec:0.934, round:94.331)	b=3.69	count=18500
Total loss:	12.715 (rec:0.946, round:11.769)	b=3.12	count=19000
Total loss:	1.527 (rec:0.925, round:0.601)	b=2.56	count=19500
Total loss:	0.971 (rec:0.959, round:0.012)	b=2.00	count=20000
finished reconstructing blocks.9.
reconstructing blocks.10 ...
initializing raw input and raw output ...
adaround training for blocks.10 ...
wraping quantizers in blocks.10 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.100 (rec:1.100, round:0.000)	b=0.00	count=500
Total loss:	1.099 (rec:1.099, round:0.000)	b=0.00	count=1000
Total loss:	0.999 (rec:0.999, round:0.000)	b=0.00	count=1500
Total loss:	0.875 (rec:0.875, round:0.000)	b=0.00	count=2000
Total loss:	0.820 (rec:0.820, round:0.000)	b=0.00	count=2500
Total loss:	0.807 (rec:0.807, round:0.000)	b=0.00	count=3000
Total loss:	0.732 (rec:0.732, round:0.000)	b=0.00	count=3500
Total loss:	65230.715 (rec:0.757, round:65229.957)	b=20.00	count=4000
Total loss:	32787.559 (rec:0.711, round:32786.848)	b=19.44	count=4500
Total loss:	30299.275 (rec:0.717, round:30298.559)	b=18.88	count=5000
Total loss:	28606.516 (rec:0.681, round:28605.836)	b=18.31	count=5500
Total loss:	27119.457 (rec:0.671, round:27118.785)	b=17.75	count=6000
Total loss:	25703.889 (rec:0.650, round:25703.238)	b=17.19	count=6500
Total loss:	24321.727 (rec:0.650, round:24321.076)	b=16.62	count=7000
Total loss:	22971.297 (rec:0.656, round:22970.641)	b=16.06	count=7500
Total loss:	21638.062 (rec:0.676, round:21637.387)	b=15.50	count=8000
Total loss:	20311.625 (rec:0.653, round:20310.973)	b=14.94	count=8500
Total loss:	19002.871 (rec:0.679, round:19002.193)	b=14.38	count=9000
Total loss:	17710.432 (rec:0.650, round:17709.781)	b=13.81	count=9500
Total loss:	16436.221 (rec:0.627, round:16435.594)	b=13.25	count=10000
Total loss:	15180.424 (rec:0.641, round:15179.783)	b=12.69	count=10500
Total loss:	13938.551 (rec:0.661, round:13937.890)	b=12.12	count=11000
Total loss:	12711.073 (rec:0.657, round:12710.416)	b=11.56	count=11500
Total loss:	11513.755 (rec:0.644, round:11513.111)	b=11.00	count=12000
Total loss:	10339.417 (rec:0.666, round:10338.751)	b=10.44	count=12500
Total loss:	9190.189 (rec:0.655, round:9189.535)	b=9.88	count=13000
Total loss:	8071.408 (rec:0.673, round:8070.736)	b=9.31	count=13500
Total loss:	6976.792 (rec:0.701, round:6976.090)	b=8.75	count=14000
Total loss:	5905.713 (rec:0.701, round:5905.012)	b=8.19	count=14500
Total loss:	4872.298 (rec:0.682, round:4871.616)	b=7.62	count=15000
Total loss:	3882.948 (rec:0.710, round:3882.239)	b=7.06	count=15500
Total loss:	2943.346 (rec:0.716, round:2942.630)	b=6.50	count=16000
Total loss:	2082.466 (rec:0.691, round:2081.775)	b=5.94	count=16500
Total loss:	1327.853 (rec:0.707, round:1327.146)	b=5.38	count=17000
Total loss:	712.596 (rec:0.720, round:711.876)	b=4.81	count=17500
Total loss:	286.399 (rec:0.726, round:285.673)	b=4.25	count=18000
Total loss:	72.552 (rec:0.739, round:71.813)	b=3.69	count=18500
Total loss:	9.957 (rec:0.772, round:9.185)	b=3.12	count=19000
Total loss:	1.270 (rec:0.753, round:0.517)	b=2.56	count=19500
Total loss:	0.744 (rec:0.729, round:0.015)	b=2.00	count=20000
finished reconstructing blocks.10.
reconstructing blocks.11 ...
initializing raw input and raw output ...
adaround training for blocks.11 ...
wraping quantizers in blocks.11 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.683 (rec:0.683, round:0.000)	b=0.00	count=500
Total loss:	0.629 (rec:0.629, round:0.000)	b=0.00	count=1000
Total loss:	0.494 (rec:0.494, round:0.000)	b=0.00	count=1500
Total loss:	0.460 (rec:0.460, round:0.000)	b=0.00	count=2000
Total loss:	0.433 (rec:0.433, round:0.000)	b=0.00	count=2500
Total loss:	0.402 (rec:0.402, round:0.000)	b=0.00	count=3000
Total loss:	0.387 (rec:0.387, round:0.000)	b=0.00	count=3500
Total loss:	64765.797 (rec:0.366, round:64765.430)	b=20.00	count=4000
Total loss:	31408.291 (rec:0.377, round:31407.914)	b=19.44	count=4500
Total loss:	29017.389 (rec:0.364, round:29017.023)	b=18.88	count=5000
Total loss:	27403.084 (rec:0.369, round:27402.715)	b=18.31	count=5500
Total loss:	25979.613 (rec:0.340, round:25979.273)	b=17.75	count=6000
Total loss:	24625.361 (rec:0.349, round:24625.012)	b=17.19	count=6500
Total loss:	23298.352 (rec:0.342, round:23298.010)	b=16.62	count=7000
Total loss:	21990.785 (rec:0.359, round:21990.426)	b=16.06	count=7500
Total loss:	20691.348 (rec:0.337, round:20691.010)	b=15.50	count=8000
Total loss:	19398.596 (rec:0.337, round:19398.258)	b=14.94	count=8500
Total loss:	18110.422 (rec:0.327, round:18110.094)	b=14.38	count=9000
Total loss:	16827.320 (rec:0.331, round:16826.990)	b=13.81	count=9500
Total loss:	15561.670 (rec:0.347, round:15561.322)	b=13.25	count=10000
Total loss:	14305.741 (rec:0.334, round:14305.406)	b=12.69	count=10500
Total loss:	13079.277 (rec:0.341, round:13078.937)	b=12.12	count=11000
Total loss:	11875.429 (rec:0.337, round:11875.092)	b=11.56	count=11500
Total loss:	10696.625 (rec:0.335, round:10696.290)	b=11.00	count=12000
Total loss:	9540.144 (rec:0.335, round:9539.809)	b=10.44	count=12500
Total loss:	8412.584 (rec:0.354, round:8412.230)	b=9.88	count=13000
Total loss:	7325.169 (rec:0.321, round:7324.849)	b=9.31	count=13500
Total loss:	6268.355 (rec:0.347, round:6268.008)	b=8.75	count=14000
Total loss:	5254.049 (rec:0.345, round:5253.705)	b=8.19	count=14500
Total loss:	4279.363 (rec:0.349, round:4279.015)	b=7.62	count=15000
Total loss:	3351.387 (rec:0.339, round:3351.048)	b=7.06	count=15500
Total loss:	2485.796 (rec:0.349, round:2485.447)	b=6.50	count=16000
Total loss:	1699.408 (rec:0.356, round:1699.052)	b=5.94	count=16500
Total loss:	1014.225 (rec:0.357, round:1013.868)	b=5.38	count=17000
Total loss:	481.270 (rec:0.358, round:480.912)	b=4.81	count=17500
Total loss:	165.165 (rec:0.355, round:164.810)	b=4.25	count=18000
Total loss:	39.105 (rec:0.358, round:38.748)	b=3.69	count=18500
Total loss:	5.855 (rec:0.375, round:5.480)	b=3.12	count=19000
Total loss:	0.745 (rec:0.364, round:0.381)	b=2.56	count=19500
Total loss:	0.363 (rec:0.354, round:0.010)	b=2.00	count=20000
finished reconstructing blocks.11.
reconstructing head ...
initializing raw input and raw output ...
adaround training for head ...
wraping quantizers in head ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.224 (rec:1.224, round:0.000)	b=0.00	count=500
Total loss:	0.607 (rec:0.607, round:0.000)	b=0.00	count=1000
Total loss:	0.491 (rec:0.491, round:0.000)	b=0.00	count=1500
Total loss:	0.330 (rec:0.330, round:0.000)	b=0.00	count=2000
Total loss:	0.219 (rec:0.219, round:0.000)	b=0.00	count=2500
Total loss:	0.171 (rec:0.171, round:0.000)	b=0.00	count=3000
Total loss:	0.125 (rec:0.125, round:0.000)	b=0.00	count=3500
Total loss:	7041.535 (rec:0.097, round:7041.438)	b=20.00	count=4000
Total loss:	3871.717 (rec:0.084, round:3871.634)	b=19.44	count=4500
Total loss:	3592.561 (rec:0.081, round:3592.479)	b=18.88	count=5000
Total loss:	3410.728 (rec:0.071, round:3410.657)	b=18.31	count=5500
Total loss:	3255.941 (rec:0.053, round:3255.888)	b=17.75	count=6000
Total loss:	3107.645 (rec:0.053, round:3107.593)	b=17.19	count=6500
Total loss:	2964.648 (rec:0.055, round:2964.593)	b=16.62	count=7000
Total loss:	2820.453 (rec:0.045, round:2820.408)	b=16.06	count=7500
Total loss:	2677.976 (rec:0.043, round:2677.933)	b=15.50	count=8000
Total loss:	2535.536 (rec:0.047, round:2535.490)	b=14.94	count=8500
Total loss:	2394.363 (rec:0.045, round:2394.318)	b=14.38	count=9000
Total loss:	2256.347 (rec:0.044, round:2256.302)	b=13.81	count=9500
Total loss:	2118.839 (rec:0.049, round:2118.789)	b=13.25	count=10000
Total loss:	1980.691 (rec:0.044, round:1980.647)	b=12.69	count=10500
Total loss:	1842.734 (rec:0.043, round:1842.692)	b=12.12	count=11000
Total loss:	1706.296 (rec:0.043, round:1706.253)	b=11.56	count=11500
Total loss:	1570.448 (rec:0.041, round:1570.407)	b=11.00	count=12000
Total loss:	1434.881 (rec:0.048, round:1434.833)	b=10.44	count=12500
Total loss:	1298.676 (rec:0.044, round:1298.631)	b=9.88	count=13000
Total loss:	1162.064 (rec:0.039, round:1162.025)	b=9.31	count=13500
Total loss:	1025.629 (rec:0.046, round:1025.583)	b=8.75	count=14000
Total loss:	889.014 (rec:0.048, round:888.966)	b=8.19	count=14500
Total loss:	755.085 (rec:0.043, round:755.042)	b=7.62	count=15000
Total loss:	621.775 (rec:0.047, round:621.728)	b=7.06	count=15500
Total loss:	492.751 (rec:0.048, round:492.703)	b=6.50	count=16000
Total loss:	369.402 (rec:0.052, round:369.350)	b=5.94	count=16500
Total loss:	257.299 (rec:0.051, round:257.248)	b=5.38	count=17000
Total loss:	155.694 (rec:0.058, round:155.636)	b=4.81	count=17500
Total loss:	73.121 (rec:0.059, round:73.062)	b=4.25	count=18000
Total loss:	22.476 (rec:0.066, round:22.410)	b=3.69	count=18500
Total loss:	3.648 (rec:0.062, round:3.586)	b=3.12	count=19000
Total loss:	0.276 (rec:0.056, round:0.220)	b=2.56	count=19500
Total loss:	0.057 (rec:0.052, round:0.005)	b=2.00	count=20000
finished reconstructing head.
2025-09-08 19:16:13 - mse guided block reconstruction finished.
Saving checkpoint to ./checkpoint/quant_result/20250908_1557/deit_base_w2_a2_optimsize_1024_mse_rinp.pth
Validating on calibration set after block reconstruction ...
Test: [0/32]	Time 0.458 (0.458)	Loss 3.4347 (3.4347)	Prec@1 56.250 (56.250)	Prec@5 71.875 (71.875)
Test: [10/32]	Time 0.076 (0.111)	Loss 3.9179 (4.1474)	Prec@1 40.625 (38.920)	Prec@5 62.500 (56.250)
Test: [20/32]	Time 0.076 (0.094)	Loss 4.1865 (4.0605)	Prec@1 40.625 (39.583)	Prec@5 50.000 (56.994)
Test: [30/32]	Time 0.076 (0.088)	Loss 3.9978 (4.0694)	Prec@1 40.625 (38.810)	Prec@5 50.000 (56.552)
 * Prec@1 39.258 Prec@5 56.836 Loss 4.064 Time 2.923
Validating on test set after block reconstruction ...
Test: [0/100]	Time 15.741 (15.741)	Loss 4.5283 (4.5283)	Prec@1 25.000 (25.000)	Prec@5 48.600 (48.600)
Test: [10/100]	Time 1.666 (2.946)	Loss 5.1650 (5.3072)	Prec@1 15.800 (13.527)	Prec@5 33.000 (29.873)
Test: [20/100]	Time 1.662 (2.335)	Loss 5.1518 (5.2648)	Prec@1 12.200 (14.295)	Prec@5 32.000 (30.752)
Test: [30/100]	Time 1.665 (2.118)	Loss 4.7758 (5.1916)	Prec@1 22.400 (15.058)	Prec@5 45.400 (32.432)
Test: [40/100]	Time 1.663 (2.007)	Loss 5.3678 (5.2039)	Prec@1 11.000 (14.829)	Prec@5 23.600 (31.551)
Test: [50/100]	Time 1.664 (1.939)	Loss 5.5316 (5.2724)	Prec@1 10.600 (13.675)	Prec@5 20.600 (29.659)
Test: [60/100]	Time 1.662 (1.894)	Loss 5.2592 (5.2994)	Prec@1 15.200 (13.292)	Prec@5 26.800 (28.613)
Test: [70/100]	Time 1.663 (1.861)	Loss 5.4837 (5.3347)	Prec@1 10.600 (12.685)	Prec@5 21.400 (27.575)
Test: [80/100]	Time 1.660 (1.837)	Loss 5.6428 (5.3650)	Prec@1 10.800 (12.284)	Prec@5 21.000 (26.827)
Test: [90/100]	Time 1.662 (1.818)	Loss 5.5099 (5.3750)	Prec@1 13.600 (12.169)	Prec@5 23.600 (26.391)
 * Prec@1 12.464 Prec@5 26.550 Loss 5.384 Time 180.608
2025-09-08 19:19:17 - finished the process.
Extracting logits from quantized and full-precision models...
Testing combinations:
  Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  Cluster numbers: [8, 16, 32, 64, 128, 256]
  PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.63%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.78%
Result: Top-1: 12.63%, Top-5: 26.78%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.78%
Result: Top-1: 12.63%, Top-5: 26.78%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.75%
Result: Top-1: 12.63%, Top-5: 26.75%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.66%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.66%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.62%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.62%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.62%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.75%
Result: Top-1: 12.63%, Top-5: 26.75%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.64%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.62%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.61%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.61%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.60%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.60%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.63%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.62%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.64%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.65%
[Alpha=0.10] Top-5 Accuracy: 26.78%
Result: Top-1: 12.65%, Top-5: 26.78%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.61%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.61%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.62%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.61%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.61%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.61%
[Alpha=0.10] Top-5 Accuracy: 26.75%
Result: Top-1: 12.61%, Top-5: 26.75%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.66%
[Alpha=0.10] Top-5 Accuracy: 26.80%
Result: Top-1: 12.66%, Top-5: 26.80%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.59%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.59%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.60%
[Alpha=0.10] Top-5 Accuracy: 26.80%
Result: Top-1: 12.60%, Top-5: 26.80%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.84%
Result: Top-1: 12.64%, Top-5: 26.84%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.60%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.60%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.82%
Result: Top-1: 12.62%, Top-5: 26.82%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.63%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.65%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.65%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.66%
[Alpha=0.10] Top-5 Accuracy: 26.82%
Result: Top-1: 12.66%, Top-5: 26.82%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.58%
[Alpha=0.10] Top-5 Accuracy: 26.73%
Result: Top-1: 12.58%, Top-5: 26.73%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.64%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.80%
Result: Top-1: 12.64%, Top-5: 26.80%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.61%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.61%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.58%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.58%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.62%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.85%
Result: Top-1: 12.63%, Top-5: 26.85%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.68%
[Alpha=0.10] Top-5 Accuracy: 26.80%
Result: Top-1: 12.68%, Top-5: 26.80%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.63%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.60%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.60%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.59%
[Alpha=0.10] Top-5 Accuracy: 26.72%
Result: Top-1: 12.59%, Top-5: 26.72%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.78%
Result: Top-1: 12.64%, Top-5: 26.78%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.61%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.61%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.62%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.71%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.71%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.68%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.68%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.85%
Result: Top-1: 12.63%, Top-5: 26.85%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.65%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.65%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.63%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.65%
[Alpha=0.10] Top-5 Accuracy: 26.80%
Result: Top-1: 12.65%, Top-5: 26.80%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.73%
Result: Top-1: 12.62%, Top-5: 26.73%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.64%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.64%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.57%
[Alpha=0.10] Top-5 Accuracy: 26.74%
Result: Top-1: 12.57%, Top-5: 26.74%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.66%
[Alpha=0.10] Top-5 Accuracy: 26.82%
Result: Top-1: 12.66%, Top-5: 26.82%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.66%
[Alpha=0.10] Top-5 Accuracy: 26.79%
Result: Top-1: 12.66%, Top-5: 26.79%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.65%
[Alpha=0.10] Top-5 Accuracy: 26.88%
Result: Top-1: 12.65%, Top-5: 26.88%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.66%
[Alpha=0.10] Top-5 Accuracy: 26.76%
Result: Top-1: 12.66%, Top-5: 26.76%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.63%
[Alpha=0.10] Top-5 Accuracy: 26.77%
Result: Top-1: 12.63%, Top-5: 26.77%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.62%
[Alpha=0.10] Top-5 Accuracy: 26.81%
Result: Top-1: 12.62%, Top-5: 26.81%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 12.65%
[Alpha=0.10] Top-5 Accuracy: 26.72%
Result: Top-1: 12.65%, Top-5: 26.72%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.75%
[Alpha=0.20] Top-5 Accuracy: 26.85%
Result: Top-1: 12.75%, Top-5: 26.85%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.88%
Result: Top-1: 12.71%, Top-5: 26.88%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.74%
[Alpha=0.20] Top-5 Accuracy: 26.88%
Result: Top-1: 12.74%, Top-5: 26.88%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.89%
Result: Top-1: 12.73%, Top-5: 26.89%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.83%
Result: Top-1: 12.73%, Top-5: 26.83%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.72%
[Alpha=0.20] Top-5 Accuracy: 26.89%
Result: Top-1: 12.72%, Top-5: 26.89%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.88%
Result: Top-1: 12.73%, Top-5: 26.88%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.88%
Result: Top-1: 12.73%, Top-5: 26.88%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.74%
[Alpha=0.20] Top-5 Accuracy: 26.89%
Result: Top-1: 12.74%, Top-5: 26.89%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.75%
[Alpha=0.20] Top-5 Accuracy: 26.87%
Result: Top-1: 12.75%, Top-5: 26.87%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.72%
[Alpha=0.20] Top-5 Accuracy: 26.85%
Result: Top-1: 12.72%, Top-5: 26.85%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.70%
[Alpha=0.20] Top-5 Accuracy: 26.94%
Result: Top-1: 12.70%, Top-5: 26.94%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.68%
[Alpha=0.20] Top-5 Accuracy: 26.93%
Result: Top-1: 12.68%, Top-5: 26.93%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.87%
Result: Top-1: 12.73%, Top-5: 26.87%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.69%
[Alpha=0.20] Top-5 Accuracy: 26.84%
Result: Top-1: 12.69%, Top-5: 26.84%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.93%
Result: Top-1: 12.73%, Top-5: 26.93%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.68%
[Alpha=0.20] Top-5 Accuracy: 26.87%
Result: Top-1: 12.68%, Top-5: 26.87%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.65%
[Alpha=0.20] Top-5 Accuracy: 26.86%
Result: Top-1: 12.65%, Top-5: 26.86%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.72%
[Alpha=0.20] Top-5 Accuracy: 26.91%
Result: Top-1: 12.72%, Top-5: 26.91%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.91%
Result: Top-1: 12.71%, Top-5: 26.91%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.72%
[Alpha=0.20] Top-5 Accuracy: 26.83%
Result: Top-1: 12.72%, Top-5: 26.83%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.75%
[Alpha=0.20] Top-5 Accuracy: 26.96%
Result: Top-1: 12.75%, Top-5: 26.96%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.66%
[Alpha=0.20] Top-5 Accuracy: 26.87%
Result: Top-1: 12.66%, Top-5: 26.87%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.77%
[Alpha=0.20] Top-5 Accuracy: 26.99%
Result: Top-1: 12.77%, Top-5: 26.99%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.77%
[Alpha=0.20] Top-5 Accuracy: 27.01%
Result: Top-1: 12.77%, Top-5: 27.01%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.90%
Result: Top-1: 12.71%, Top-5: 26.90%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.95%
Result: Top-1: 12.71%, Top-5: 26.95%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.95%
Result: Top-1: 12.71%, Top-5: 26.95%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.96%
Result: Top-1: 12.73%, Top-5: 26.96%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.92%
Result: Top-1: 12.71%, Top-5: 26.92%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.68%
[Alpha=0.20] Top-5 Accuracy: 26.85%
Result: Top-1: 12.68%, Top-5: 26.85%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.92%
Result: Top-1: 12.73%, Top-5: 26.92%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.76%
[Alpha=0.20] Top-5 Accuracy: 26.92%
Result: Top-1: 12.76%, Top-5: 26.92%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.73%
[Alpha=0.20] Top-5 Accuracy: 26.95%
Result: Top-1: 12.73%, Top-5: 26.95%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.66%
[Alpha=0.20] Top-5 Accuracy: 26.91%
Result: Top-1: 12.66%, Top-5: 26.91%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.71%
[Alpha=0.20] Top-5 Accuracy: 26.96%
Result: Top-1: 12.71%, Top-5: 26.96%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.75%
[Alpha=0.20] Top-5 Accuracy: 26.97%
Result: Top-1: 12.75%, Top-5: 26.97%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.79%
[Alpha=0.20] Top-5 Accuracy: 26.98%
Result: Top-1: 12.79%, Top-5: 26.98%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.65%
[Alpha=0.20] Top-5 Accuracy: 26.97%
Result: Top-1: 12.65%, Top-5: 26.97%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.75%
[Alpha=0.20] Top-5 Accuracy: 26.87%
Result: Top-1: 12.75%, Top-5: 26.87%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.67%
[Alpha=0.20] Top-5 Accuracy: 26.81%
Result: Top-1: 12.67%, Top-5: 26.81%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.69%
[Alpha=0.20] Top-5 Accuracy: 26.94%
Result: Top-1: 12.69%, Top-5: 26.94%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.70%
[Alpha=0.20] Top-5 Accuracy: 26.91%
Result: Top-1: 12.70%, Top-5: 26.91%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.79%
[Alpha=0.20] Top-5 Accuracy: 26.97%
Result: Top-1: 12.79%, Top-5: 26.97%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.79%
[Alpha=0.20] Top-5 Accuracy: 26.98%
Result: Top-1: 12.79%, Top-5: 26.98%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.78%
[Alpha=0.20] Top-5 Accuracy: 27.06%
Result: Top-1: 12.78%, Top-5: 27.06%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.74%
[Alpha=0.20] Top-5 Accuracy: 27.05%
Result: Top-1: 12.74%, Top-5: 27.05%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.75%
[Alpha=0.20] Top-5 Accuracy: 27.01%
Result: Top-1: 12.75%, Top-5: 27.01%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.76%
[Alpha=0.20] Top-5 Accuracy: 26.97%
Result: Top-1: 12.76%, Top-5: 26.97%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.69%
[Alpha=0.20] Top-5 Accuracy: 26.87%
Result: Top-1: 12.69%, Top-5: 26.87%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.64%
[Alpha=0.20] Top-5 Accuracy: 26.79%
Result: Top-1: 12.64%, Top-5: 26.79%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.65%
[Alpha=0.20] Top-5 Accuracy: 26.97%
Result: Top-1: 12.65%, Top-5: 26.97%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.58%
[Alpha=0.20] Top-5 Accuracy: 26.89%
Result: Top-1: 12.58%, Top-5: 26.89%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.65%
[Alpha=0.20] Top-5 Accuracy: 26.97%
Result: Top-1: 12.65%, Top-5: 26.97%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.68%
[Alpha=0.20] Top-5 Accuracy: 26.88%
Result: Top-1: 12.68%, Top-5: 26.88%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.58%
[Alpha=0.20] Top-5 Accuracy: 27.02%
Result: Top-1: 12.58%, Top-5: 27.02%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.66%
[Alpha=0.20] Top-5 Accuracy: 26.94%
Result: Top-1: 12.66%, Top-5: 26.94%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.60%
[Alpha=0.20] Top-5 Accuracy: 26.92%
Result: Top-1: 12.60%, Top-5: 26.92%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.67%
[Alpha=0.20] Top-5 Accuracy: 26.86%
Result: Top-1: 12.67%, Top-5: 26.86%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 12.65%
[Alpha=0.20] Top-5 Accuracy: 26.88%
Result: Top-1: 12.65%, Top-5: 26.88%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.68%
[Alpha=0.30] Top-5 Accuracy: 26.96%
Result: Top-1: 12.68%, Top-5: 26.96%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.47%
[Alpha=0.30] Top-5 Accuracy: 26.89%
Result: Top-1: 12.47%, Top-5: 26.89%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.50%
[Alpha=0.30] Top-5 Accuracy: 26.83%
Result: Top-1: 12.50%, Top-5: 26.83%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.49%
[Alpha=0.30] Top-5 Accuracy: 26.83%
Result: Top-1: 12.49%, Top-5: 26.83%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.49%
[Alpha=0.30] Top-5 Accuracy: 26.82%
Result: Top-1: 12.49%, Top-5: 26.82%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.49%
[Alpha=0.30] Top-5 Accuracy: 26.81%
Result: Top-1: 12.49%, Top-5: 26.81%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.50%
[Alpha=0.30] Top-5 Accuracy: 26.81%
Result: Top-1: 12.50%, Top-5: 26.81%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.48%
[Alpha=0.30] Top-5 Accuracy: 26.84%
Result: Top-1: 12.48%, Top-5: 26.84%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.48%
[Alpha=0.30] Top-5 Accuracy: 26.82%
Result: Top-1: 12.48%, Top-5: 26.82%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.48%
[Alpha=0.30] Top-5 Accuracy: 26.86%
Result: Top-1: 12.48%, Top-5: 26.86%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.68%
[Alpha=0.30] Top-5 Accuracy: 26.98%
Result: Top-1: 12.68%, Top-5: 26.98%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.41%
[Alpha=0.30] Top-5 Accuracy: 26.88%
Result: Top-1: 12.41%, Top-5: 26.88%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.46%
[Alpha=0.30] Top-5 Accuracy: 26.85%
Result: Top-1: 12.46%, Top-5: 26.85%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.43%
[Alpha=0.30] Top-5 Accuracy: 26.72%
Result: Top-1: 12.43%, Top-5: 26.72%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.50%
[Alpha=0.30] Top-5 Accuracy: 26.76%
Result: Top-1: 12.50%, Top-5: 26.76%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.46%
[Alpha=0.30] Top-5 Accuracy: 26.78%
Result: Top-1: 12.46%, Top-5: 26.78%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.44%
[Alpha=0.30] Top-5 Accuracy: 26.81%
Result: Top-1: 12.44%, Top-5: 26.81%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.43%
[Alpha=0.30] Top-5 Accuracy: 26.79%
Result: Top-1: 12.43%, Top-5: 26.79%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.42%
[Alpha=0.30] Top-5 Accuracy: 26.84%
Result: Top-1: 12.42%, Top-5: 26.84%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.42%
[Alpha=0.30] Top-5 Accuracy: 26.74%
Result: Top-1: 12.42%, Top-5: 26.74%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.65%
[Alpha=0.30] Top-5 Accuracy: 26.95%
Result: Top-1: 12.65%, Top-5: 26.95%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.43%
[Alpha=0.30] Top-5 Accuracy: 26.88%
Result: Top-1: 12.43%, Top-5: 26.88%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.42%
[Alpha=0.30] Top-5 Accuracy: 26.77%
Result: Top-1: 12.42%, Top-5: 26.77%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.54%
[Alpha=0.30] Top-5 Accuracy: 27.03%
Result: Top-1: 12.54%, Top-5: 27.03%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.50%
[Alpha=0.30] Top-5 Accuracy: 26.86%
Result: Top-1: 12.50%, Top-5: 26.86%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.50%
[Alpha=0.30] Top-5 Accuracy: 26.76%
Result: Top-1: 12.50%, Top-5: 26.76%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.40%
[Alpha=0.30] Top-5 Accuracy: 26.76%
Result: Top-1: 12.40%, Top-5: 26.76%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.43%
[Alpha=0.30] Top-5 Accuracy: 26.83%
Result: Top-1: 12.43%, Top-5: 26.83%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.43%
[Alpha=0.30] Top-5 Accuracy: 26.91%
Result: Top-1: 12.43%, Top-5: 26.91%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.37%
[Alpha=0.30] Top-5 Accuracy: 26.75%
Result: Top-1: 12.37%, Top-5: 26.75%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.62%
[Alpha=0.30] Top-5 Accuracy: 26.94%
Result: Top-1: 12.62%, Top-5: 26.94%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.39%
[Alpha=0.30] Top-5 Accuracy: 26.81%
Result: Top-1: 12.39%, Top-5: 26.81%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.44%
[Alpha=0.30] Top-5 Accuracy: 26.75%
Result: Top-1: 12.44%, Top-5: 26.75%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.34%
[Alpha=0.30] Top-5 Accuracy: 26.81%
Result: Top-1: 12.34%, Top-5: 26.81%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.40%
[Alpha=0.30] Top-5 Accuracy: 26.73%
Result: Top-1: 12.40%, Top-5: 26.73%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.40%
[Alpha=0.30] Top-5 Accuracy: 26.81%
Result: Top-1: 12.40%, Top-5: 26.81%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.47%
[Alpha=0.30] Top-5 Accuracy: 26.83%
Result: Top-1: 12.47%, Top-5: 26.83%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.51%
[Alpha=0.30] Top-5 Accuracy: 26.94%
Result: Top-1: 12.51%, Top-5: 26.94%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.43%
[Alpha=0.30] Top-5 Accuracy: 26.88%
Result: Top-1: 12.43%, Top-5: 26.88%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.38%
[Alpha=0.30] Top-5 Accuracy: 26.78%
Result: Top-1: 12.38%, Top-5: 26.78%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.63%
[Alpha=0.30] Top-5 Accuracy: 26.84%
Result: Top-1: 12.63%, Top-5: 26.84%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.42%
[Alpha=0.30] Top-5 Accuracy: 26.75%
Result: Top-1: 12.42%, Top-5: 26.75%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.32%
[Alpha=0.30] Top-5 Accuracy: 26.69%
Result: Top-1: 12.32%, Top-5: 26.69%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.30%
[Alpha=0.30] Top-5 Accuracy: 26.74%
Result: Top-1: 12.30%, Top-5: 26.74%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.44%
[Alpha=0.30] Top-5 Accuracy: 26.82%
Result: Top-1: 12.44%, Top-5: 26.82%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.39%
[Alpha=0.30] Top-5 Accuracy: 26.89%
Result: Top-1: 12.39%, Top-5: 26.89%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.47%
[Alpha=0.30] Top-5 Accuracy: 26.91%
Result: Top-1: 12.47%, Top-5: 26.91%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.39%
[Alpha=0.30] Top-5 Accuracy: 26.86%
Result: Top-1: 12.39%, Top-5: 26.86%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.51%
[Alpha=0.30] Top-5 Accuracy: 26.85%
Result: Top-1: 12.51%, Top-5: 26.85%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.35%
[Alpha=0.30] Top-5 Accuracy: 26.68%
Result: Top-1: 12.35%, Top-5: 26.68%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.40%
[Alpha=0.30] Top-5 Accuracy: 26.63%
Result: Top-1: 12.40%, Top-5: 26.63%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.26%
[Alpha=0.30] Top-5 Accuracy: 26.73%
Result: Top-1: 12.26%, Top-5: 26.73%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.05%
[Alpha=0.30] Top-5 Accuracy: 26.58%
Result: Top-1: 12.05%, Top-5: 26.58%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.21%
[Alpha=0.30] Top-5 Accuracy: 26.67%
Result: Top-1: 12.21%, Top-5: 26.67%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.19%
[Alpha=0.30] Top-5 Accuracy: 26.61%
Result: Top-1: 12.19%, Top-5: 26.61%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.11%
[Alpha=0.30] Top-5 Accuracy: 26.75%
Result: Top-1: 12.11%, Top-5: 26.75%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.27%
[Alpha=0.30] Top-5 Accuracy: 26.68%
Result: Top-1: 12.27%, Top-5: 26.68%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.20%
[Alpha=0.30] Top-5 Accuracy: 26.65%
Result: Top-1: 12.20%, Top-5: 26.65%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.21%
[Alpha=0.30] Top-5 Accuracy: 26.55%
Result: Top-1: 12.21%, Top-5: 26.55%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 12.15%
[Alpha=0.30] Top-5 Accuracy: 26.63%
Result: Top-1: 12.15%, Top-5: 26.63%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.19%
[Alpha=0.40] Top-5 Accuracy: 26.72%
Result: Top-1: 12.19%, Top-5: 26.72%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.69%
[Alpha=0.40] Top-5 Accuracy: 26.26%
Result: Top-1: 10.69%, Top-5: 26.26%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.60%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.60%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.60%
[Alpha=0.40] Top-5 Accuracy: 26.21%
Result: Top-1: 10.60%, Top-5: 26.21%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.81%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.81%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.54%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.54%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.60%
[Alpha=0.40] Top-5 Accuracy: 26.18%
Result: Top-1: 10.60%, Top-5: 26.18%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.56%
[Alpha=0.40] Top-5 Accuracy: 26.18%
Result: Top-1: 10.56%, Top-5: 26.18%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.59%
[Alpha=0.40] Top-5 Accuracy: 26.18%
Result: Top-1: 10.59%, Top-5: 26.18%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.60%
[Alpha=0.40] Top-5 Accuracy: 26.19%
Result: Top-1: 10.60%, Top-5: 26.19%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.19%
[Alpha=0.40] Top-5 Accuracy: 26.71%
Result: Top-1: 12.19%, Top-5: 26.71%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.72%
[Alpha=0.40] Top-5 Accuracy: 26.26%
Result: Top-1: 10.72%, Top-5: 26.26%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.99%
[Alpha=0.40] Top-5 Accuracy: 26.32%
Result: Top-1: 10.99%, Top-5: 26.32%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.33%
[Alpha=0.40] Top-5 Accuracy: 25.95%
Result: Top-1: 10.33%, Top-5: 25.95%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.36%
[Alpha=0.40] Top-5 Accuracy: 25.94%
Result: Top-1: 10.36%, Top-5: 25.94%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.29%
[Alpha=0.40] Top-5 Accuracy: 25.86%
Result: Top-1: 10.29%, Top-5: 25.86%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.45%
[Alpha=0.40] Top-5 Accuracy: 26.14%
Result: Top-1: 10.45%, Top-5: 26.14%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.62%
[Alpha=0.40] Top-5 Accuracy: 26.19%
Result: Top-1: 10.62%, Top-5: 26.19%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.72%
[Alpha=0.40] Top-5 Accuracy: 26.19%
Result: Top-1: 10.72%, Top-5: 26.19%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.10%
[Alpha=0.40] Top-5 Accuracy: 25.98%
Result: Top-1: 10.10%, Top-5: 25.98%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.14%
[Alpha=0.40] Top-5 Accuracy: 26.71%
Result: Top-1: 12.14%, Top-5: 26.71%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.85%
[Alpha=0.40] Top-5 Accuracy: 26.29%
Result: Top-1: 10.85%, Top-5: 26.29%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.21%
[Alpha=0.40] Top-5 Accuracy: 26.04%
Result: Top-1: 10.21%, Top-5: 26.04%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.96%
[Alpha=0.40] Top-5 Accuracy: 26.48%
Result: Top-1: 10.96%, Top-5: 26.48%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.59%
[Alpha=0.40] Top-5 Accuracy: 26.27%
Result: Top-1: 10.59%, Top-5: 26.27%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.63%
[Alpha=0.40] Top-5 Accuracy: 26.00%
Result: Top-1: 10.63%, Top-5: 26.00%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.30%
[Alpha=0.40] Top-5 Accuracy: 26.15%
Result: Top-1: 10.30%, Top-5: 26.15%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.43%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.43%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.70%
[Alpha=0.40] Top-5 Accuracy: 26.46%
Result: Top-1: 10.70%, Top-5: 26.46%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.39%
[Alpha=0.40] Top-5 Accuracy: 26.24%
Result: Top-1: 10.39%, Top-5: 26.24%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.02%
[Alpha=0.40] Top-5 Accuracy: 26.73%
Result: Top-1: 12.02%, Top-5: 26.73%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.40%
[Alpha=0.40] Top-5 Accuracy: 26.20%
Result: Top-1: 10.40%, Top-5: 26.20%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.41%
[Alpha=0.40] Top-5 Accuracy: 26.18%
Result: Top-1: 10.41%, Top-5: 26.18%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.47%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.47%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.45%
[Alpha=0.40] Top-5 Accuracy: 26.16%
Result: Top-1: 10.45%, Top-5: 26.16%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.47%
[Alpha=0.40] Top-5 Accuracy: 26.11%
Result: Top-1: 10.47%, Top-5: 26.11%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.36%
[Alpha=0.40] Top-5 Accuracy: 26.14%
Result: Top-1: 10.36%, Top-5: 26.14%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.92%
[Alpha=0.40] Top-5 Accuracy: 26.47%
Result: Top-1: 10.92%, Top-5: 26.47%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.46%
[Alpha=0.40] Top-5 Accuracy: 26.29%
Result: Top-1: 10.46%, Top-5: 26.29%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.38%
[Alpha=0.40] Top-5 Accuracy: 26.05%
Result: Top-1: 10.38%, Top-5: 26.05%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.99%
[Alpha=0.40] Top-5 Accuracy: 26.51%
Result: Top-1: 11.99%, Top-5: 26.51%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.27%
[Alpha=0.40] Top-5 Accuracy: 26.02%
Result: Top-1: 10.27%, Top-5: 26.02%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.00%
[Alpha=0.40] Top-5 Accuracy: 25.85%
Result: Top-1: 10.00%, Top-5: 25.85%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.00%
[Alpha=0.40] Top-5 Accuracy: 26.09%
Result: Top-1: 10.00%, Top-5: 26.09%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.38%
[Alpha=0.40] Top-5 Accuracy: 26.12%
Result: Top-1: 10.38%, Top-5: 26.12%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.37%
[Alpha=0.40] Top-5 Accuracy: 26.20%
Result: Top-1: 10.37%, Top-5: 26.20%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.37%
[Alpha=0.40] Top-5 Accuracy: 26.19%
Result: Top-1: 10.37%, Top-5: 26.19%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.51%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.51%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.55%
[Alpha=0.40] Top-5 Accuracy: 26.17%
Result: Top-1: 10.55%, Top-5: 26.17%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.19%
[Alpha=0.40] Top-5 Accuracy: 25.84%
Result: Top-1: 10.19%, Top-5: 25.84%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.71%
[Alpha=0.40] Top-5 Accuracy: 26.25%
Result: Top-1: 11.71%, Top-5: 26.25%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.05%
[Alpha=0.40] Top-5 Accuracy: 25.78%
Result: Top-1: 10.05%, Top-5: 25.78%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.86%
[Alpha=0.40] Top-5 Accuracy: 25.69%
Result: Top-1: 9.86%, Top-5: 25.69%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.97%
[Alpha=0.40] Top-5 Accuracy: 25.64%
Result: Top-1: 9.97%, Top-5: 25.64%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.96%
[Alpha=0.40] Top-5 Accuracy: 25.66%
Result: Top-1: 9.96%, Top-5: 25.66%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.96%
[Alpha=0.40] Top-5 Accuracy: 25.67%
Result: Top-1: 9.96%, Top-5: 25.67%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 10.03%
[Alpha=0.40] Top-5 Accuracy: 25.73%
Result: Top-1: 10.03%, Top-5: 25.73%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.88%
[Alpha=0.40] Top-5 Accuracy: 25.73%
Result: Top-1: 9.88%, Top-5: 25.73%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.83%
[Alpha=0.40] Top-5 Accuracy: 25.62%
Result: Top-1: 9.83%, Top-5: 25.62%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 9.78%
[Alpha=0.40] Top-5 Accuracy: 25.67%
Result: Top-1: 9.78%, Top-5: 25.67%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 10.54%
[Alpha=0.50] Top-5 Accuracy: 26.03%
Result: Top-1: 10.54%, Top-5: 26.03%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.79%
[Alpha=0.50] Top-5 Accuracy: 25.57%
Result: Top-1: 6.79%, Top-5: 25.57%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.23%
[Alpha=0.50] Top-5 Accuracy: 25.49%
Result: Top-1: 6.23%, Top-5: 25.49%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.23%
[Alpha=0.50] Top-5 Accuracy: 25.51%
Result: Top-1: 6.23%, Top-5: 25.51%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.47%
[Alpha=0.50] Top-5 Accuracy: 25.32%
Result: Top-1: 6.47%, Top-5: 25.32%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.11%
[Alpha=0.50] Top-5 Accuracy: 25.42%
Result: Top-1: 6.11%, Top-5: 25.42%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.16%
[Alpha=0.50] Top-5 Accuracy: 25.40%
Result: Top-1: 6.16%, Top-5: 25.40%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.10%
[Alpha=0.50] Top-5 Accuracy: 25.46%
Result: Top-1: 6.10%, Top-5: 25.46%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.19%
[Alpha=0.50] Top-5 Accuracy: 25.39%
Result: Top-1: 6.19%, Top-5: 25.39%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.19%
[Alpha=0.50] Top-5 Accuracy: 25.53%
Result: Top-1: 6.19%, Top-5: 25.53%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 10.61%
[Alpha=0.50] Top-5 Accuracy: 26.02%
Result: Top-1: 10.61%, Top-5: 26.02%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.25%
[Alpha=0.50] Top-5 Accuracy: 25.59%
Result: Top-1: 7.25%, Top-5: 25.59%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.75%
[Alpha=0.50] Top-5 Accuracy: 25.46%
Result: Top-1: 7.75%, Top-5: 25.46%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 5.95%
[Alpha=0.50] Top-5 Accuracy: 25.07%
Result: Top-1: 5.95%, Top-5: 25.07%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 5.57%
[Alpha=0.50] Top-5 Accuracy: 24.93%
Result: Top-1: 5.57%, Top-5: 24.93%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 5.06%
[Alpha=0.50] Top-5 Accuracy: 24.89%
Result: Top-1: 5.06%, Top-5: 24.89%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.41%
[Alpha=0.50] Top-5 Accuracy: 25.39%
Result: Top-1: 6.41%, Top-5: 25.39%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.67%
[Alpha=0.50] Top-5 Accuracy: 25.29%
Result: Top-1: 6.67%, Top-5: 25.29%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.69%
[Alpha=0.50] Top-5 Accuracy: 25.31%
Result: Top-1: 6.69%, Top-5: 25.31%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 5.70%
[Alpha=0.50] Top-5 Accuracy: 25.13%
Result: Top-1: 5.70%, Top-5: 25.13%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 10.41%
[Alpha=0.50] Top-5 Accuracy: 25.87%
Result: Top-1: 10.41%, Top-5: 25.87%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.33%
[Alpha=0.50] Top-5 Accuracy: 25.47%
Result: Top-1: 7.33%, Top-5: 25.47%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 5.60%
[Alpha=0.50] Top-5 Accuracy: 25.13%
Result: Top-1: 5.60%, Top-5: 25.13%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.69%
[Alpha=0.50] Top-5 Accuracy: 25.63%
Result: Top-1: 7.69%, Top-5: 25.63%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.10%
[Alpha=0.50] Top-5 Accuracy: 25.45%
Result: Top-1: 7.10%, Top-5: 25.45%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.06%
[Alpha=0.50] Top-5 Accuracy: 25.01%
Result: Top-1: 6.06%, Top-5: 25.01%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.70%
[Alpha=0.50] Top-5 Accuracy: 25.42%
Result: Top-1: 6.70%, Top-5: 25.42%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.34%
[Alpha=0.50] Top-5 Accuracy: 25.25%
Result: Top-1: 6.34%, Top-5: 25.25%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.60%
[Alpha=0.50] Top-5 Accuracy: 25.63%
Result: Top-1: 7.60%, Top-5: 25.63%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.82%
[Alpha=0.50] Top-5 Accuracy: 25.29%
Result: Top-1: 6.82%, Top-5: 25.29%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 10.44%
[Alpha=0.50] Top-5 Accuracy: 25.92%
Result: Top-1: 10.44%, Top-5: 25.92%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.09%
[Alpha=0.50] Top-5 Accuracy: 25.26%
Result: Top-1: 7.09%, Top-5: 25.26%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.71%
[Alpha=0.50] Top-5 Accuracy: 25.25%
Result: Top-1: 6.71%, Top-5: 25.25%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.87%
[Alpha=0.50] Top-5 Accuracy: 25.14%
Result: Top-1: 6.87%, Top-5: 25.14%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.85%
[Alpha=0.50] Top-5 Accuracy: 25.13%
Result: Top-1: 6.85%, Top-5: 25.13%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.48%
[Alpha=0.50] Top-5 Accuracy: 25.11%
Result: Top-1: 6.48%, Top-5: 25.11%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.59%
[Alpha=0.50] Top-5 Accuracy: 25.15%
Result: Top-1: 6.59%, Top-5: 25.15%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.91%
[Alpha=0.50] Top-5 Accuracy: 25.53%
Result: Top-1: 7.91%, Top-5: 25.53%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.96%
[Alpha=0.50] Top-5 Accuracy: 25.20%
Result: Top-1: 6.96%, Top-5: 25.20%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.44%
[Alpha=0.50] Top-5 Accuracy: 25.13%
Result: Top-1: 6.44%, Top-5: 25.13%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 10.26%
[Alpha=0.50] Top-5 Accuracy: 25.53%
Result: Top-1: 10.26%, Top-5: 25.53%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.47%
[Alpha=0.50] Top-5 Accuracy: 24.94%
Result: Top-1: 6.47%, Top-5: 24.94%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.06%
[Alpha=0.50] Top-5 Accuracy: 24.80%
Result: Top-1: 6.06%, Top-5: 24.80%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.63%
[Alpha=0.50] Top-5 Accuracy: 24.96%
Result: Top-1: 6.63%, Top-5: 24.96%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.78%
[Alpha=0.50] Top-5 Accuracy: 24.95%
Result: Top-1: 6.78%, Top-5: 24.95%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.80%
[Alpha=0.50] Top-5 Accuracy: 25.08%
Result: Top-1: 6.80%, Top-5: 25.08%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.41%
[Alpha=0.50] Top-5 Accuracy: 25.09%
Result: Top-1: 6.41%, Top-5: 25.09%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 7.22%
[Alpha=0.50] Top-5 Accuracy: 25.13%
Result: Top-1: 7.22%, Top-5: 25.13%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.88%
[Alpha=0.50] Top-5 Accuracy: 25.18%
Result: Top-1: 6.88%, Top-5: 25.18%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.01%
[Alpha=0.50] Top-5 Accuracy: 24.73%
Result: Top-1: 6.01%, Top-5: 24.73%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.74%
[Alpha=0.50] Top-5 Accuracy: 25.06%
Result: Top-1: 9.74%, Top-5: 25.06%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.47%
[Alpha=0.50] Top-5 Accuracy: 24.38%
Result: Top-1: 6.47%, Top-5: 24.38%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.12%
[Alpha=0.50] Top-5 Accuracy: 23.98%
Result: Top-1: 6.12%, Top-5: 23.98%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.50%
[Alpha=0.50] Top-5 Accuracy: 24.18%
Result: Top-1: 6.50%, Top-5: 24.18%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.49%
[Alpha=0.50] Top-5 Accuracy: 24.29%
Result: Top-1: 6.49%, Top-5: 24.29%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.30%
[Alpha=0.50] Top-5 Accuracy: 24.15%
Result: Top-1: 6.30%, Top-5: 24.15%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.64%
[Alpha=0.50] Top-5 Accuracy: 24.42%
Result: Top-1: 6.64%, Top-5: 24.42%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.45%
[Alpha=0.50] Top-5 Accuracy: 24.27%
Result: Top-1: 6.45%, Top-5: 24.27%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 5.96%
[Alpha=0.50] Top-5 Accuracy: 24.07%
Result: Top-1: 5.96%, Top-5: 24.07%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 6.29%
[Alpha=0.50] Top-5 Accuracy: 24.42%
Result: Top-1: 6.29%, Top-5: 24.42%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 7.69%
[Alpha=0.60] Top-5 Accuracy: 24.79%
Result: Top-1: 7.69%, Top-5: 24.79%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.11%
[Alpha=0.60] Top-5 Accuracy: 24.52%
Result: Top-1: 4.11%, Top-5: 24.52%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.48%
[Alpha=0.60] Top-5 Accuracy: 24.41%
Result: Top-1: 3.48%, Top-5: 24.41%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.41%
[Alpha=0.60] Top-5 Accuracy: 24.43%
Result: Top-1: 3.41%, Top-5: 24.43%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.59%
[Alpha=0.60] Top-5 Accuracy: 24.07%
Result: Top-1: 2.59%, Top-5: 24.07%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.32%
[Alpha=0.60] Top-5 Accuracy: 24.35%
Result: Top-1: 3.32%, Top-5: 24.35%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.33%
[Alpha=0.60] Top-5 Accuracy: 24.36%
Result: Top-1: 3.33%, Top-5: 24.36%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.35%
[Alpha=0.60] Top-5 Accuracy: 24.38%
Result: Top-1: 3.35%, Top-5: 24.38%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.30%
[Alpha=0.60] Top-5 Accuracy: 24.35%
Result: Top-1: 3.30%, Top-5: 24.35%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.48%
[Alpha=0.60] Top-5 Accuracy: 24.42%
Result: Top-1: 3.48%, Top-5: 24.42%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 7.53%
[Alpha=0.60] Top-5 Accuracy: 24.72%
Result: Top-1: 7.53%, Top-5: 24.72%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.65%
[Alpha=0.60] Top-5 Accuracy: 24.19%
Result: Top-1: 4.65%, Top-5: 24.19%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.30%
[Alpha=0.60] Top-5 Accuracy: 24.19%
Result: Top-1: 4.30%, Top-5: 24.19%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.88%
[Alpha=0.60] Top-5 Accuracy: 23.75%
Result: Top-1: 2.88%, Top-5: 23.75%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 1.87%
[Alpha=0.60] Top-5 Accuracy: 23.54%
Result: Top-1: 1.87%, Top-5: 23.54%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 1.64%
[Alpha=0.60] Top-5 Accuracy: 23.54%
Result: Top-1: 1.64%, Top-5: 23.54%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.90%
[Alpha=0.60] Top-5 Accuracy: 23.95%
Result: Top-1: 2.90%, Top-5: 23.95%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.86%
[Alpha=0.60] Top-5 Accuracy: 23.82%
Result: Top-1: 2.86%, Top-5: 23.82%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.93%
[Alpha=0.60] Top-5 Accuracy: 23.80%
Result: Top-1: 2.93%, Top-5: 23.80%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.65%
[Alpha=0.60] Top-5 Accuracy: 23.75%
Result: Top-1: 2.65%, Top-5: 23.75%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 7.42%
[Alpha=0.60] Top-5 Accuracy: 24.45%
Result: Top-1: 7.42%, Top-5: 24.45%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.21%
[Alpha=0.60] Top-5 Accuracy: 24.06%
Result: Top-1: 4.21%, Top-5: 24.06%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.67%
[Alpha=0.60] Top-5 Accuracy: 23.59%
Result: Top-1: 2.67%, Top-5: 23.59%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.27%
[Alpha=0.60] Top-5 Accuracy: 24.08%
Result: Top-1: 4.27%, Top-5: 24.08%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.40%
[Alpha=0.60] Top-5 Accuracy: 23.79%
Result: Top-1: 4.40%, Top-5: 23.79%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 2.49%
[Alpha=0.60] Top-5 Accuracy: 23.57%
Result: Top-1: 2.49%, Top-5: 23.57%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.23%
[Alpha=0.60] Top-5 Accuracy: 23.99%
Result: Top-1: 4.23%, Top-5: 23.99%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.25%
[Alpha=0.60] Top-5 Accuracy: 23.77%
Result: Top-1: 3.25%, Top-5: 23.77%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.51%
[Alpha=0.60] Top-5 Accuracy: 23.81%
Result: Top-1: 4.51%, Top-5: 23.81%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.82%
[Alpha=0.60] Top-5 Accuracy: 23.60%
Result: Top-1: 3.82%, Top-5: 23.60%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 7.43%
[Alpha=0.60] Top-5 Accuracy: 24.45%
Result: Top-1: 7.43%, Top-5: 24.45%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.38%
[Alpha=0.60] Top-5 Accuracy: 23.55%
Result: Top-1: 4.38%, Top-5: 23.55%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.11%
[Alpha=0.60] Top-5 Accuracy: 23.72%
Result: Top-1: 4.11%, Top-5: 23.72%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.73%
[Alpha=0.60] Top-5 Accuracy: 23.13%
Result: Top-1: 3.73%, Top-5: 23.13%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.63%
[Alpha=0.60] Top-5 Accuracy: 23.41%
Result: Top-1: 3.63%, Top-5: 23.41%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.16%
[Alpha=0.60] Top-5 Accuracy: 23.19%
Result: Top-1: 3.16%, Top-5: 23.19%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.55%
[Alpha=0.60] Top-5 Accuracy: 23.27%
Result: Top-1: 3.55%, Top-5: 23.27%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.75%
[Alpha=0.60] Top-5 Accuracy: 23.93%
Result: Top-1: 4.75%, Top-5: 23.93%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.96%
[Alpha=0.60] Top-5 Accuracy: 23.32%
Result: Top-1: 3.96%, Top-5: 23.32%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.48%
[Alpha=0.60] Top-5 Accuracy: 23.44%
Result: Top-1: 3.48%, Top-5: 23.44%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 7.17%
[Alpha=0.60] Top-5 Accuracy: 23.94%
Result: Top-1: 7.17%, Top-5: 23.94%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.56%
[Alpha=0.60] Top-5 Accuracy: 22.98%
Result: Top-1: 3.56%, Top-5: 22.98%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.51%
[Alpha=0.60] Top-5 Accuracy: 22.78%
Result: Top-1: 3.51%, Top-5: 22.78%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.84%
[Alpha=0.60] Top-5 Accuracy: 23.04%
Result: Top-1: 3.84%, Top-5: 23.04%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.94%
[Alpha=0.60] Top-5 Accuracy: 22.81%
Result: Top-1: 3.94%, Top-5: 22.81%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.75%
[Alpha=0.60] Top-5 Accuracy: 23.11%
Result: Top-1: 3.75%, Top-5: 23.11%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.76%
[Alpha=0.60] Top-5 Accuracy: 23.00%
Result: Top-1: 3.76%, Top-5: 23.00%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 4.58%
[Alpha=0.60] Top-5 Accuracy: 23.14%
Result: Top-1: 4.58%, Top-5: 23.14%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.68%
[Alpha=0.60] Top-5 Accuracy: 23.16%
Result: Top-1: 3.68%, Top-5: 23.16%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.16%
[Alpha=0.60] Top-5 Accuracy: 22.69%
Result: Top-1: 3.16%, Top-5: 22.69%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 6.72%
[Alpha=0.60] Top-5 Accuracy: 22.96%
Result: Top-1: 6.72%, Top-5: 22.96%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.71%
[Alpha=0.60] Top-5 Accuracy: 21.84%
Result: Top-1: 3.71%, Top-5: 21.84%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.39%
[Alpha=0.60] Top-5 Accuracy: 21.51%
Result: Top-1: 3.39%, Top-5: 21.51%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.79%
[Alpha=0.60] Top-5 Accuracy: 21.83%
Result: Top-1: 3.79%, Top-5: 21.83%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.71%
[Alpha=0.60] Top-5 Accuracy: 22.06%
Result: Top-1: 3.71%, Top-5: 22.06%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.62%
[Alpha=0.60] Top-5 Accuracy: 21.73%
Result: Top-1: 3.62%, Top-5: 21.73%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.65%
[Alpha=0.60] Top-5 Accuracy: 21.78%
Result: Top-1: 3.65%, Top-5: 21.78%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.73%
[Alpha=0.60] Top-5 Accuracy: 21.98%
Result: Top-1: 3.73%, Top-5: 21.98%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.27%
[Alpha=0.60] Top-5 Accuracy: 21.69%
Result: Top-1: 3.27%, Top-5: 21.69%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 3.86%
[Alpha=0.60] Top-5 Accuracy: 22.18%
Result: Top-1: 3.86%, Top-5: 22.18%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 4.21%
[Alpha=0.70] Top-5 Accuracy: 22.60%
Result: Top-1: 4.21%, Top-5: 22.60%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.23%
[Alpha=0.70] Top-5 Accuracy: 22.01%
Result: Top-1: 2.23%, Top-5: 22.01%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.96%
[Alpha=0.70] Top-5 Accuracy: 21.79%
Result: Top-1: 1.96%, Top-5: 21.79%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.96%
[Alpha=0.70] Top-5 Accuracy: 21.90%
Result: Top-1: 1.96%, Top-5: 21.90%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.04%
[Alpha=0.70] Top-5 Accuracy: 21.47%
Result: Top-1: 1.04%, Top-5: 21.47%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.89%
[Alpha=0.70] Top-5 Accuracy: 21.78%
Result: Top-1: 1.89%, Top-5: 21.78%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.90%
[Alpha=0.70] Top-5 Accuracy: 21.79%
Result: Top-1: 1.90%, Top-5: 21.79%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.96%
[Alpha=0.70] Top-5 Accuracy: 21.81%
Result: Top-1: 1.96%, Top-5: 21.81%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.83%
[Alpha=0.70] Top-5 Accuracy: 21.84%
Result: Top-1: 1.83%, Top-5: 21.84%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.03%
[Alpha=0.70] Top-5 Accuracy: 21.96%
Result: Top-1: 2.03%, Top-5: 21.96%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 4.05%
[Alpha=0.70] Top-5 Accuracy: 22.49%
Result: Top-1: 4.05%, Top-5: 22.49%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.73%
[Alpha=0.70] Top-5 Accuracy: 21.56%
Result: Top-1: 2.73%, Top-5: 21.56%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.10%
[Alpha=0.70] Top-5 Accuracy: 21.65%
Result: Top-1: 2.10%, Top-5: 21.65%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.12%
[Alpha=0.70] Top-5 Accuracy: 21.18%
Result: Top-1: 1.12%, Top-5: 21.18%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.63%
[Alpha=0.70] Top-5 Accuracy: 21.04%
Result: Top-1: 0.63%, Top-5: 21.04%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.63%
[Alpha=0.70] Top-5 Accuracy: 21.05%
Result: Top-1: 0.63%, Top-5: 21.05%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.11%
[Alpha=0.70] Top-5 Accuracy: 21.51%
Result: Top-1: 1.11%, Top-5: 21.51%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.88%
[Alpha=0.70] Top-5 Accuracy: 21.35%
Result: Top-1: 0.88%, Top-5: 21.35%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 0.98%
[Alpha=0.70] Top-5 Accuracy: 21.18%
Result: Top-1: 0.98%, Top-5: 21.18%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.13%
[Alpha=0.70] Top-5 Accuracy: 21.02%
Result: Top-1: 1.13%, Top-5: 21.02%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 3.99%
[Alpha=0.70] Top-5 Accuracy: 22.11%
Result: Top-1: 3.99%, Top-5: 22.11%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.08%
[Alpha=0.70] Top-5 Accuracy: 21.16%
Result: Top-1: 2.08%, Top-5: 21.16%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.21%
[Alpha=0.70] Top-5 Accuracy: 20.75%
Result: Top-1: 1.21%, Top-5: 20.75%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.87%
[Alpha=0.70] Top-5 Accuracy: 21.09%
Result: Top-1: 1.87%, Top-5: 21.09%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.11%
[Alpha=0.70] Top-5 Accuracy: 20.76%
Result: Top-1: 2.11%, Top-5: 20.76%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.01%
[Alpha=0.70] Top-5 Accuracy: 20.91%
Result: Top-1: 1.01%, Top-5: 20.91%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.18%
[Alpha=0.70] Top-5 Accuracy: 20.96%
Result: Top-1: 2.18%, Top-5: 20.96%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.43%
[Alpha=0.70] Top-5 Accuracy: 21.16%
Result: Top-1: 1.43%, Top-5: 21.16%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.09%
[Alpha=0.70] Top-5 Accuracy: 20.80%
Result: Top-1: 2.09%, Top-5: 20.80%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.68%
[Alpha=0.70] Top-5 Accuracy: 20.31%
Result: Top-1: 1.68%, Top-5: 20.31%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 3.96%
[Alpha=0.70] Top-5 Accuracy: 21.88%
Result: Top-1: 3.96%, Top-5: 21.88%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.07%
[Alpha=0.70] Top-5 Accuracy: 20.02%
Result: Top-1: 2.07%, Top-5: 20.02%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.26%
[Alpha=0.70] Top-5 Accuracy: 20.54%
Result: Top-1: 2.26%, Top-5: 20.54%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.71%
[Alpha=0.70] Top-5 Accuracy: 19.81%
Result: Top-1: 1.71%, Top-5: 19.81%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.82%
[Alpha=0.70] Top-5 Accuracy: 20.56%
Result: Top-1: 1.82%, Top-5: 20.56%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.55%
[Alpha=0.70] Top-5 Accuracy: 19.85%
Result: Top-1: 1.55%, Top-5: 19.85%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.67%
[Alpha=0.70] Top-5 Accuracy: 20.14%
Result: Top-1: 1.67%, Top-5: 20.14%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.41%
[Alpha=0.70] Top-5 Accuracy: 20.77%
Result: Top-1: 2.41%, Top-5: 20.77%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.87%
[Alpha=0.70] Top-5 Accuracy: 20.11%
Result: Top-1: 1.87%, Top-5: 20.11%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.77%
[Alpha=0.70] Top-5 Accuracy: 20.41%
Result: Top-1: 1.77%, Top-5: 20.41%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 3.80%
[Alpha=0.70] Top-5 Accuracy: 21.06%
Result: Top-1: 3.80%, Top-5: 21.06%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.72%
[Alpha=0.70] Top-5 Accuracy: 19.53%
Result: Top-1: 1.72%, Top-5: 19.53%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.90%
[Alpha=0.70] Top-5 Accuracy: 19.34%
Result: Top-1: 1.90%, Top-5: 19.34%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.90%
[Alpha=0.70] Top-5 Accuracy: 19.69%
Result: Top-1: 1.90%, Top-5: 19.69%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.10%
[Alpha=0.70] Top-5 Accuracy: 19.20%
Result: Top-1: 2.10%, Top-5: 19.20%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.90%
[Alpha=0.70] Top-5 Accuracy: 19.99%
Result: Top-1: 1.90%, Top-5: 19.99%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.93%
[Alpha=0.70] Top-5 Accuracy: 19.50%
Result: Top-1: 1.93%, Top-5: 19.50%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.40%
[Alpha=0.70] Top-5 Accuracy: 19.85%
Result: Top-1: 2.40%, Top-5: 19.85%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.66%
[Alpha=0.70] Top-5 Accuracy: 19.97%
Result: Top-1: 1.66%, Top-5: 19.97%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.65%
[Alpha=0.70] Top-5 Accuracy: 19.19%
Result: Top-1: 1.65%, Top-5: 19.19%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 3.78%
[Alpha=0.70] Top-5 Accuracy: 19.93%
Result: Top-1: 3.78%, Top-5: 19.93%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.05%
[Alpha=0.70] Top-5 Accuracy: 18.21%
Result: Top-1: 2.05%, Top-5: 18.21%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.72%
[Alpha=0.70] Top-5 Accuracy: 17.82%
Result: Top-1: 1.72%, Top-5: 17.82%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.97%
[Alpha=0.70] Top-5 Accuracy: 18.22%
Result: Top-1: 1.97%, Top-5: 18.22%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.05%
[Alpha=0.70] Top-5 Accuracy: 18.34%
Result: Top-1: 2.05%, Top-5: 18.34%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.09%
[Alpha=0.70] Top-5 Accuracy: 18.12%
Result: Top-1: 2.09%, Top-5: 18.12%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.80%
[Alpha=0.70] Top-5 Accuracy: 18.17%
Result: Top-1: 1.80%, Top-5: 18.17%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.93%
[Alpha=0.70] Top-5 Accuracy: 18.49%
Result: Top-1: 1.93%, Top-5: 18.49%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 1.79%
[Alpha=0.70] Top-5 Accuracy: 18.28%
Result: Top-1: 1.79%, Top-5: 18.28%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 2.24%
[Alpha=0.70] Top-5 Accuracy: 18.73%
Result: Top-1: 2.24%, Top-5: 18.73%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.68%
[Alpha=0.80] Top-5 Accuracy: 18.52%
Result: Top-1: 1.68%, Top-5: 18.52%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.02%
[Alpha=0.80] Top-5 Accuracy: 17.52%
Result: Top-1: 1.02%, Top-5: 17.52%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.89%
[Alpha=0.80] Top-5 Accuracy: 17.01%
Result: Top-1: 0.89%, Top-5: 17.01%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.89%
[Alpha=0.80] Top-5 Accuracy: 17.05%
Result: Top-1: 0.89%, Top-5: 17.05%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.52%
[Alpha=0.80] Top-5 Accuracy: 16.83%
Result: Top-1: 0.52%, Top-5: 16.83%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.88%
[Alpha=0.80] Top-5 Accuracy: 16.85%
Result: Top-1: 0.88%, Top-5: 16.85%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.86%
[Alpha=0.80] Top-5 Accuracy: 16.93%
Result: Top-1: 0.86%, Top-5: 16.93%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.91%
[Alpha=0.80] Top-5 Accuracy: 16.91%
Result: Top-1: 0.91%, Top-5: 16.91%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.80%
[Alpha=0.80] Top-5 Accuracy: 17.00%
Result: Top-1: 0.80%, Top-5: 17.00%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.93%
[Alpha=0.80] Top-5 Accuracy: 17.01%
Result: Top-1: 0.93%, Top-5: 17.01%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.52%
[Alpha=0.80] Top-5 Accuracy: 18.06%
Result: Top-1: 1.52%, Top-5: 18.06%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.18%
[Alpha=0.80] Top-5 Accuracy: 16.42%
Result: Top-1: 1.18%, Top-5: 16.42%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.88%
[Alpha=0.80] Top-5 Accuracy: 17.07%
Result: Top-1: 0.88%, Top-5: 17.07%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.45%
[Alpha=0.80] Top-5 Accuracy: 16.30%
Result: Top-1: 0.45%, Top-5: 16.30%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.39%
[Alpha=0.80] Top-5 Accuracy: 16.30%
Result: Top-1: 0.39%, Top-5: 16.30%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.41%
[Alpha=0.80] Top-5 Accuracy: 16.29%
Result: Top-1: 0.41%, Top-5: 16.29%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.46%
[Alpha=0.80] Top-5 Accuracy: 16.83%
Result: Top-1: 0.46%, Top-5: 16.83%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.38%
[Alpha=0.80] Top-5 Accuracy: 16.51%
Result: Top-1: 0.38%, Top-5: 16.51%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.40%
[Alpha=0.80] Top-5 Accuracy: 16.53%
Result: Top-1: 0.40%, Top-5: 16.53%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.51%
[Alpha=0.80] Top-5 Accuracy: 16.26%
Result: Top-1: 0.51%, Top-5: 16.26%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.53%
[Alpha=0.80] Top-5 Accuracy: 17.69%
Result: Top-1: 1.53%, Top-5: 17.69%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.92%
[Alpha=0.80] Top-5 Accuracy: 16.01%
Result: Top-1: 0.92%, Top-5: 16.01%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.53%
[Alpha=0.80] Top-5 Accuracy: 15.61%
Result: Top-1: 0.53%, Top-5: 15.61%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.81%
[Alpha=0.80] Top-5 Accuracy: 15.90%
Result: Top-1: 0.81%, Top-5: 15.90%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.84%
[Alpha=0.80] Top-5 Accuracy: 15.55%
Result: Top-1: 0.84%, Top-5: 15.55%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.51%
[Alpha=0.80] Top-5 Accuracy: 16.35%
Result: Top-1: 0.51%, Top-5: 16.35%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.95%
[Alpha=0.80] Top-5 Accuracy: 15.64%
Result: Top-1: 0.95%, Top-5: 15.64%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.68%
[Alpha=0.80] Top-5 Accuracy: 16.22%
Result: Top-1: 0.68%, Top-5: 16.22%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.83%
[Alpha=0.80] Top-5 Accuracy: 15.67%
Result: Top-1: 0.83%, Top-5: 15.67%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.66%
[Alpha=0.80] Top-5 Accuracy: 14.61%
Result: Top-1: 0.66%, Top-5: 14.61%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.58%
[Alpha=0.80] Top-5 Accuracy: 17.50%
Result: Top-1: 1.58%, Top-5: 17.50%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.87%
[Alpha=0.80] Top-5 Accuracy: 14.52%
Result: Top-1: 0.87%, Top-5: 14.52%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.08%
[Alpha=0.80] Top-5 Accuracy: 15.68%
Result: Top-1: 1.08%, Top-5: 15.68%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.73%
[Alpha=0.80] Top-5 Accuracy: 14.30%
Result: Top-1: 0.73%, Top-5: 14.30%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.95%
[Alpha=0.80] Top-5 Accuracy: 15.80%
Result: Top-1: 0.95%, Top-5: 15.80%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.75%
[Alpha=0.80] Top-5 Accuracy: 14.61%
Result: Top-1: 0.75%, Top-5: 14.61%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.80%
[Alpha=0.80] Top-5 Accuracy: 14.87%
Result: Top-1: 0.80%, Top-5: 14.87%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.12%
[Alpha=0.80] Top-5 Accuracy: 15.74%
Result: Top-1: 1.12%, Top-5: 15.74%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.89%
[Alpha=0.80] Top-5 Accuracy: 14.71%
Result: Top-1: 0.89%, Top-5: 14.71%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.82%
[Alpha=0.80] Top-5 Accuracy: 15.50%
Result: Top-1: 0.82%, Top-5: 15.50%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.64%
[Alpha=0.80] Top-5 Accuracy: 16.46%
Result: Top-1: 1.64%, Top-5: 16.46%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.80%
[Alpha=0.80] Top-5 Accuracy: 14.51%
Result: Top-1: 0.80%, Top-5: 14.51%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.97%
[Alpha=0.80] Top-5 Accuracy: 14.39%
Result: Top-1: 0.97%, Top-5: 14.39%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.88%
[Alpha=0.80] Top-5 Accuracy: 14.64%
Result: Top-1: 0.88%, Top-5: 14.64%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.11%
[Alpha=0.80] Top-5 Accuracy: 14.22%
Result: Top-1: 1.11%, Top-5: 14.22%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.99%
[Alpha=0.80] Top-5 Accuracy: 14.99%
Result: Top-1: 0.99%, Top-5: 14.99%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.99%
[Alpha=0.80] Top-5 Accuracy: 14.47%
Result: Top-1: 0.99%, Top-5: 14.47%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.15%
[Alpha=0.80] Top-5 Accuracy: 14.92%
Result: Top-1: 1.15%, Top-5: 14.92%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.80%
[Alpha=0.80] Top-5 Accuracy: 14.82%
Result: Top-1: 0.80%, Top-5: 14.82%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.96%
[Alpha=0.80] Top-5 Accuracy: 14.41%
Result: Top-1: 0.96%, Top-5: 14.41%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.83%
[Alpha=0.80] Top-5 Accuracy: 15.45%
Result: Top-1: 1.83%, Top-5: 15.45%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.13%
[Alpha=0.80] Top-5 Accuracy: 13.66%
Result: Top-1: 1.13%, Top-5: 13.66%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.95%
[Alpha=0.80] Top-5 Accuracy: 13.18%
Result: Top-1: 0.95%, Top-5: 13.18%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.03%
[Alpha=0.80] Top-5 Accuracy: 13.76%
Result: Top-1: 1.03%, Top-5: 13.76%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.12%
[Alpha=0.80] Top-5 Accuracy: 13.69%
Result: Top-1: 1.12%, Top-5: 13.69%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.27%
[Alpha=0.80] Top-5 Accuracy: 13.44%
Result: Top-1: 1.27%, Top-5: 13.44%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.01%
[Alpha=0.80] Top-5 Accuracy: 13.60%
Result: Top-1: 1.01%, Top-5: 13.60%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.03%
[Alpha=0.80] Top-5 Accuracy: 13.92%
Result: Top-1: 1.03%, Top-5: 13.92%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 0.97%
[Alpha=0.80] Top-5 Accuracy: 13.69%
Result: Top-1: 0.97%, Top-5: 13.69%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 1.25%
[Alpha=0.80] Top-5 Accuracy: 14.26%
Result: Top-1: 1.25%, Top-5: 14.26%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.61%
[Alpha=0.90] Top-5 Accuracy: 10.66%
Result: Top-1: 0.61%, Top-5: 10.66%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.47%
[Alpha=0.90] Top-5 Accuracy: 9.23%
Result: Top-1: 0.47%, Top-5: 9.23%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.43%
[Alpha=0.90] Top-5 Accuracy: 8.53%
Result: Top-1: 0.43%, Top-5: 8.53%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.41%
[Alpha=0.90] Top-5 Accuracy: 8.69%
Result: Top-1: 0.41%, Top-5: 8.69%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.36%
[Alpha=0.90] Top-5 Accuracy: 8.62%
Result: Top-1: 0.36%, Top-5: 8.62%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.40%
[Alpha=0.90] Top-5 Accuracy: 8.53%
Result: Top-1: 0.40%, Top-5: 8.53%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.40%
[Alpha=0.90] Top-5 Accuracy: 8.58%
Result: Top-1: 0.40%, Top-5: 8.58%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.42%
[Alpha=0.90] Top-5 Accuracy: 8.54%
Result: Top-1: 0.42%, Top-5: 8.54%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.39%
[Alpha=0.90] Top-5 Accuracy: 8.68%
Result: Top-1: 0.39%, Top-5: 8.68%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.43%
[Alpha=0.90] Top-5 Accuracy: 8.61%
Result: Top-1: 0.43%, Top-5: 8.61%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.60%
[Alpha=0.90] Top-5 Accuracy: 10.49%
Result: Top-1: 0.60%, Top-5: 10.49%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.52%
[Alpha=0.90] Top-5 Accuracy: 8.43%
Result: Top-1: 0.52%, Top-5: 8.43%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.41%
[Alpha=0.90] Top-5 Accuracy: 9.26%
Result: Top-1: 0.41%, Top-5: 9.26%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 8.68%
Result: Top-1: 0.33%, Top-5: 8.68%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.35%
[Alpha=0.90] Top-5 Accuracy: 8.61%
Result: Top-1: 0.35%, Top-5: 8.61%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.35%
[Alpha=0.90] Top-5 Accuracy: 8.45%
Result: Top-1: 0.35%, Top-5: 8.45%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 8.94%
Result: Top-1: 0.33%, Top-5: 8.94%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.32%
[Alpha=0.90] Top-5 Accuracy: 8.58%
Result: Top-1: 0.32%, Top-5: 8.58%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.33%
[Alpha=0.90] Top-5 Accuracy: 8.63%
Result: Top-1: 0.33%, Top-5: 8.63%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.35%
[Alpha=0.90] Top-5 Accuracy: 8.41%
Result: Top-1: 0.35%, Top-5: 8.41%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.60%
[Alpha=0.90] Top-5 Accuracy: 10.48%
Result: Top-1: 0.60%, Top-5: 10.48%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.51%
[Alpha=0.90] Top-5 Accuracy: 8.88%
Result: Top-1: 0.51%, Top-5: 8.88%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.34%
[Alpha=0.90] Top-5 Accuracy: 8.04%
Result: Top-1: 0.34%, Top-5: 8.04%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.43%
[Alpha=0.90] Top-5 Accuracy: 9.01%
Result: Top-1: 0.43%, Top-5: 9.01%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.46%
[Alpha=0.90] Top-5 Accuracy: 8.20%
Result: Top-1: 0.46%, Top-5: 8.20%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.39%
[Alpha=0.90] Top-5 Accuracy: 8.89%
Result: Top-1: 0.39%, Top-5: 8.89%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.48%
[Alpha=0.90] Top-5 Accuracy: 8.29%
Result: Top-1: 0.48%, Top-5: 8.29%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.41%
[Alpha=0.90] Top-5 Accuracy: 8.65%
Result: Top-1: 0.41%, Top-5: 8.65%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.43%
[Alpha=0.90] Top-5 Accuracy: 8.80%
Result: Top-1: 0.43%, Top-5: 8.80%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.36%
[Alpha=0.90] Top-5 Accuracy: 7.73%
Result: Top-1: 0.36%, Top-5: 7.73%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.62%
[Alpha=0.90] Top-5 Accuracy: 10.41%
Result: Top-1: 0.62%, Top-5: 10.41%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.49%
[Alpha=0.90] Top-5 Accuracy: 8.26%
Result: Top-1: 0.49%, Top-5: 8.26%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.55%
[Alpha=0.90] Top-5 Accuracy: 9.27%
Result: Top-1: 0.55%, Top-5: 9.27%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.42%
[Alpha=0.90] Top-5 Accuracy: 7.72%
Result: Top-1: 0.42%, Top-5: 7.72%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.57%
[Alpha=0.90] Top-5 Accuracy: 9.17%
Result: Top-1: 0.57%, Top-5: 9.17%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.46%
[Alpha=0.90] Top-5 Accuracy: 8.12%
Result: Top-1: 0.46%, Top-5: 8.12%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.46%
[Alpha=0.90] Top-5 Accuracy: 8.36%
Result: Top-1: 0.46%, Top-5: 8.36%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.52%
[Alpha=0.90] Top-5 Accuracy: 9.16%
Result: Top-1: 0.52%, Top-5: 9.16%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.47%
[Alpha=0.90] Top-5 Accuracy: 8.23%
Result: Top-1: 0.47%, Top-5: 8.23%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.48%
[Alpha=0.90] Top-5 Accuracy: 9.07%
Result: Top-1: 0.48%, Top-5: 9.07%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.74%
[Alpha=0.90] Top-5 Accuracy: 10.41%
Result: Top-1: 0.74%, Top-5: 10.41%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.49%
[Alpha=0.90] Top-5 Accuracy: 8.96%
Result: Top-1: 0.49%, Top-5: 8.96%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.56%
[Alpha=0.90] Top-5 Accuracy: 8.64%
Result: Top-1: 0.56%, Top-5: 8.64%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.51%
[Alpha=0.90] Top-5 Accuracy: 8.71%
Result: Top-1: 0.51%, Top-5: 8.71%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.63%
[Alpha=0.90] Top-5 Accuracy: 8.65%
Result: Top-1: 0.63%, Top-5: 8.65%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.57%
[Alpha=0.90] Top-5 Accuracy: 9.36%
Result: Top-1: 0.57%, Top-5: 9.36%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.59%
[Alpha=0.90] Top-5 Accuracy: 9.07%
Result: Top-1: 0.59%, Top-5: 9.07%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.62%
[Alpha=0.90] Top-5 Accuracy: 9.26%
Result: Top-1: 0.62%, Top-5: 9.26%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.50%
[Alpha=0.90] Top-5 Accuracy: 8.93%
Result: Top-1: 0.50%, Top-5: 8.93%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.60%
[Alpha=0.90] Top-5 Accuracy: 8.90%
Result: Top-1: 0.60%, Top-5: 8.90%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.90%
[Alpha=0.90] Top-5 Accuracy: 9.95%
Result: Top-1: 0.90%, Top-5: 9.95%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.72%
[Alpha=0.90] Top-5 Accuracy: 9.04%
Result: Top-1: 0.72%, Top-5: 9.04%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.64%
[Alpha=0.90] Top-5 Accuracy: 8.52%
Result: Top-1: 0.64%, Top-5: 8.52%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.66%
[Alpha=0.90] Top-5 Accuracy: 8.90%
Result: Top-1: 0.66%, Top-5: 8.90%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.74%
[Alpha=0.90] Top-5 Accuracy: 8.96%
Result: Top-1: 0.74%, Top-5: 8.96%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.83%
[Alpha=0.90] Top-5 Accuracy: 8.97%
Result: Top-1: 0.83%, Top-5: 8.97%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.65%
[Alpha=0.90] Top-5 Accuracy: 8.63%
Result: Top-1: 0.65%, Top-5: 8.63%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.65%
[Alpha=0.90] Top-5 Accuracy: 9.24%
Result: Top-1: 0.65%, Top-5: 9.24%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.58%
[Alpha=0.90] Top-5 Accuracy: 8.85%
Result: Top-1: 0.58%, Top-5: 8.85%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 0.78%
[Alpha=0.90] Top-5 Accuracy: 9.11%
Result: Top-1: 0.78%, Top-5: 9.11%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.36%
[Alpha=1.00] Top-5 Accuracy: 3.67%
Result: Top-1: 0.36%, Top-5: 3.67%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 3.06%
Result: Top-1: 0.34%, Top-5: 3.06%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.35%
[Alpha=1.00] Top-5 Accuracy: 2.83%
Result: Top-1: 0.35%, Top-5: 2.83%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 2.89%
Result: Top-1: 0.33%, Top-5: 2.89%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 2.73%
Result: Top-1: 0.33%, Top-5: 2.73%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 2.81%
Result: Top-1: 0.33%, Top-5: 2.81%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 2.81%
Result: Top-1: 0.33%, Top-5: 2.81%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 2.78%
Result: Top-1: 0.34%, Top-5: 2.78%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 2.89%
Result: Top-1: 0.33%, Top-5: 2.89%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 2.84%
Result: Top-1: 0.34%, Top-5: 2.84%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.38%
[Alpha=1.00] Top-5 Accuracy: 3.92%
Result: Top-1: 0.38%, Top-5: 3.92%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.35%
[Alpha=1.00] Top-5 Accuracy: 3.16%
Result: Top-1: 0.35%, Top-5: 3.16%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.31%
[Alpha=1.00] Top-5 Accuracy: 3.29%
Result: Top-1: 0.31%, Top-5: 3.29%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.31%
[Alpha=1.00] Top-5 Accuracy: 2.95%
Result: Top-1: 0.31%, Top-5: 2.95%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 3.14%
Result: Top-1: 0.34%, Top-5: 3.14%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 3.10%
Result: Top-1: 0.34%, Top-5: 3.10%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 3.18%
Result: Top-1: 0.32%, Top-5: 3.18%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.31%
[Alpha=1.00] Top-5 Accuracy: 3.08%
Result: Top-1: 0.31%, Top-5: 3.08%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 2.99%
Result: Top-1: 0.32%, Top-5: 2.99%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 3.05%
Result: Top-1: 0.32%, Top-5: 3.05%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.36%
[Alpha=1.00] Top-5 Accuracy: 4.04%
Result: Top-1: 0.36%, Top-5: 4.04%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.37%
[Alpha=1.00] Top-5 Accuracy: 3.67%
Result: Top-1: 0.37%, Top-5: 3.67%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.32%
[Alpha=1.00] Top-5 Accuracy: 2.96%
Result: Top-1: 0.32%, Top-5: 2.96%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 4.14%
Result: Top-1: 0.34%, Top-5: 4.14%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.37%
[Alpha=1.00] Top-5 Accuracy: 3.44%
Result: Top-1: 0.37%, Top-5: 3.44%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 3.46%
Result: Top-1: 0.34%, Top-5: 3.46%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.36%
[Alpha=1.00] Top-5 Accuracy: 3.35%
Result: Top-1: 0.36%, Top-5: 3.35%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.34%
[Alpha=1.00] Top-5 Accuracy: 3.36%
Result: Top-1: 0.34%, Top-5: 3.36%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 3.70%
Result: Top-1: 0.33%, Top-5: 3.70%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.33%
[Alpha=1.00] Top-5 Accuracy: 3.21%
Result: Top-1: 0.33%, Top-5: 3.21%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.39%
[Alpha=1.00] Top-5 Accuracy: 4.42%
Result: Top-1: 0.39%, Top-5: 4.42%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.38%
[Alpha=1.00] Top-5 Accuracy: 3.81%
Result: Top-1: 0.38%, Top-5: 3.81%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.38%
[Alpha=1.00] Top-5 Accuracy: 4.22%
Result: Top-1: 0.38%, Top-5: 4.22%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.35%
[Alpha=1.00] Top-5 Accuracy: 3.62%
Result: Top-1: 0.35%, Top-5: 3.62%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.40%
[Alpha=1.00] Top-5 Accuracy: 4.28%
Result: Top-1: 0.40%, Top-5: 4.28%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.38%
[Alpha=1.00] Top-5 Accuracy: 3.65%
Result: Top-1: 0.38%, Top-5: 3.65%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.36%
[Alpha=1.00] Top-5 Accuracy: 3.83%
Result: Top-1: 0.36%, Top-5: 3.83%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.39%
[Alpha=1.00] Top-5 Accuracy: 4.53%
Result: Top-1: 0.39%, Top-5: 4.53%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.37%
[Alpha=1.00] Top-5 Accuracy: 3.80%
Result: Top-1: 0.37%, Top-5: 3.80%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.36%
[Alpha=1.00] Top-5 Accuracy: 4.11%
Result: Top-1: 0.36%, Top-5: 4.11%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.43%
[Alpha=1.00] Top-5 Accuracy: 5.01%
Result: Top-1: 0.43%, Top-5: 5.01%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.37%
[Alpha=1.00] Top-5 Accuracy: 4.84%
Result: Top-1: 0.37%, Top-5: 4.84%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.42%
[Alpha=1.00] Top-5 Accuracy: 4.67%
Result: Top-1: 0.42%, Top-5: 4.67%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.40%
[Alpha=1.00] Top-5 Accuracy: 4.58%
Result: Top-1: 0.40%, Top-5: 4.58%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.47%
[Alpha=1.00] Top-5 Accuracy: 4.71%
Result: Top-1: 0.47%, Top-5: 4.71%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.41%
[Alpha=1.00] Top-5 Accuracy: 4.78%
Result: Top-1: 0.41%, Top-5: 4.78%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.43%
[Alpha=1.00] Top-5 Accuracy: 5.08%
Result: Top-1: 0.43%, Top-5: 5.08%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.40%
[Alpha=1.00] Top-5 Accuracy: 4.97%
Result: Top-1: 0.40%, Top-5: 4.97%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.40%
[Alpha=1.00] Top-5 Accuracy: 4.88%
Result: Top-1: 0.40%, Top-5: 4.88%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.42%
[Alpha=1.00] Top-5 Accuracy: 4.88%
Result: Top-1: 0.42%, Top-5: 4.88%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.56%
[Alpha=1.00] Top-5 Accuracy: 5.44%
Result: Top-1: 0.56%, Top-5: 5.44%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.56%
[Alpha=1.00] Top-5 Accuracy: 5.64%
Result: Top-1: 0.56%, Top-5: 5.64%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.49%
[Alpha=1.00] Top-5 Accuracy: 5.16%
Result: Top-1: 0.49%, Top-5: 5.16%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.51%
[Alpha=1.00] Top-5 Accuracy: 5.33%
Result: Top-1: 0.51%, Top-5: 5.33%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.56%
[Alpha=1.00] Top-5 Accuracy: 5.70%
Result: Top-1: 0.56%, Top-5: 5.70%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.59%
[Alpha=1.00] Top-5 Accuracy: 5.54%
Result: Top-1: 0.59%, Top-5: 5.54%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.48%
[Alpha=1.00] Top-5 Accuracy: 5.31%
Result: Top-1: 0.48%, Top-5: 5.31%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.47%
[Alpha=1.00] Top-5 Accuracy: 5.38%
Result: Top-1: 0.47%, Top-5: 5.38%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.45%
[Alpha=1.00] Top-5 Accuracy: 5.20%
Result: Top-1: 0.45%, Top-5: 5.20%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 0.59%
[Alpha=1.00] Top-5 Accuracy: 5.49%
Result: Top-1: 0.59%, Top-5: 5.49%

================================================================================
SUMMARY OF ALL RESULTS
================================================================================
Alpha    Clusters   PCA_dim    Top-1      Top-5     
--------------------------------------------------
0.10     8          1          12.63      26.76     
0.10     8          25         12.63      26.78     
0.10     8          50         12.63      26.78     
0.10     8          75         12.63      26.75     
0.10     8          100        12.66      26.76     
0.10     8          125        12.62      26.76     
0.10     8          150        12.62      26.76     
0.10     8          175        12.62      26.76     
0.10     8          200        12.63      26.75     
0.10     8          220        12.64      26.77     
0.10     16         1          12.62      26.76     
0.10     16         25         12.61      26.79     
0.10     16         50         12.60      26.79     
0.10     16         75         12.63      26.77     
0.10     16         100        12.62      26.81     
0.10     16         125        12.64      26.77     
0.10     16         150        12.65      26.78     
0.10     16         175        12.61      26.77     
0.10     16         200        12.62      26.79     
0.10     16         220        12.61      26.77     
0.10     32         1          12.61      26.75     
0.10     32         25         12.66      26.80     
0.10     32         50         12.59      26.77     
0.10     32         75         12.60      26.80     
0.10     32         100        12.64      26.84     
0.10     32         125        12.60      26.76     
0.10     32         150        12.62      26.82     
0.10     32         175        12.63      26.81     
0.10     32         200        12.65      26.81     
0.10     32         220        12.66      26.82     
0.10     64         1          12.58      26.73     
0.10     64         25         12.64      26.79     
0.10     64         50         12.64      26.80     
0.10     64         75         12.61      26.77     
0.10     64         100        12.58      26.76     
0.10     64         125        12.62      26.81     
0.10     64         150        12.63      26.85     
0.10     64         175        12.68      26.80     
0.10     64         200        12.63      26.81     
0.10     64         220        12.60      26.77     
0.10     128        1          12.59      26.72     
0.10     128        25         12.64      26.78     
0.10     128        50         12.61      26.77     
0.10     128        75         12.62      26.79     
0.10     128        100        12.71      26.81     
0.10     128        125        12.68      26.79     
0.10     128        150        12.63      26.85     
0.10     128        175        12.65      26.76     
0.10     128        200        12.63      26.81     
0.10     128        220        12.65      26.80     
0.10     256        1          12.62      26.73     
0.10     256        25         12.64      26.79     
0.10     256        50         12.57      26.74     
0.10     256        75         12.66      26.82     
0.10     256        100        12.66      26.79     
0.10     256        125        12.65      26.88     
0.10     256        150        12.66      26.76     
0.10     256        175        12.63      26.77     
0.10     256        200        12.62      26.81     
0.10     256        220        12.65      26.72     
0.20     8          1          12.75      26.85     
0.20     8          25         12.71      26.88     
0.20     8          50         12.74      26.88     
0.20     8          75         12.73      26.89     
0.20     8          100        12.73      26.83     
0.20     8          125        12.72      26.89     
0.20     8          150        12.73      26.88     
0.20     8          175        12.73      26.88     
0.20     8          200        12.74      26.89     
0.20     8          220        12.75      26.87     
0.20     16         1          12.72      26.85     
0.20     16         25         12.70      26.94     
0.20     16         50         12.68      26.93     
0.20     16         75         12.73      26.87     
0.20     16         100        12.69      26.84     
0.20     16         125        12.73      26.93     
0.20     16         150        12.68      26.87     
0.20     16         175        12.65      26.86     
0.20     16         200        12.72      26.91     
0.20     16         220        12.71      26.91     
0.20     32         1          12.72      26.83     
0.20     32         25         12.75      26.96     
0.20     32         50         12.66      26.87     
0.20     32         75         12.77      26.99     
0.20     32         100        12.77      27.01     
0.20     32         125        12.71      26.90     
0.20     32         150        12.71      26.95     
0.20     32         175        12.71      26.95     
0.20     32         200        12.73      26.96     
0.20     32         220        12.71      26.92     
0.20     64         1          12.68      26.85     
0.20     64         25         12.73      26.92     
0.20     64         50         12.76      26.92     
0.20     64         75         12.73      26.95     
0.20     64         100        12.66      26.91     
0.20     64         125        12.71      26.96     
0.20     64         150        12.75      26.97     
0.20     64         175        12.79      26.98     
0.20     64         200        12.65      26.97     
0.20     64         220        12.75      26.87     
0.20     128        1          12.67      26.81     
0.20     128        25         12.69      26.94     
0.20     128        50         12.70      26.91     
0.20     128        75         12.79      26.97     
0.20     128        100        12.79      26.98     
0.20     128        125        12.78      27.06     
0.20     128        150        12.74      27.05     
0.20     128        175        12.75      27.01     
0.20     128        200        12.76      26.97     
0.20     128        220        12.69      26.87     
0.20     256        1          12.64      26.79     
0.20     256        25         12.65      26.97     
0.20     256        50         12.58      26.89     
0.20     256        75         12.65      26.97     
0.20     256        100        12.68      26.88     
0.20     256        125        12.58      27.02     
0.20     256        150        12.66      26.94     
0.20     256        175        12.60      26.92     
0.20     256        200        12.67      26.86     
0.20     256        220        12.65      26.88     
0.30     8          1          12.68      26.96     
0.30     8          25         12.47      26.89     
0.30     8          50         12.50      26.83     
0.30     8          75         12.49      26.83     
0.30     8          100        12.49      26.82     
0.30     8          125        12.49      26.81     
0.30     8          150        12.50      26.81     
0.30     8          175        12.48      26.84     
0.30     8          200        12.48      26.82     
0.30     8          220        12.48      26.86     
0.30     16         1          12.68      26.98     
0.30     16         25         12.41      26.88     
0.30     16         50         12.46      26.85     
0.30     16         75         12.43      26.72     
0.30     16         100        12.50      26.76     
0.30     16         125        12.46      26.78     
0.30     16         150        12.44      26.81     
0.30     16         175        12.43      26.79     
0.30     16         200        12.42      26.84     
0.30     16         220        12.42      26.74     
0.30     32         1          12.65      26.95     
0.30     32         25         12.43      26.88     
0.30     32         50         12.42      26.77     
0.30     32         75         12.54      27.03     
0.30     32         100        12.50      26.86     
0.30     32         125        12.50      26.76     
0.30     32         150        12.40      26.76     
0.30     32         175        12.43      26.83     
0.30     32         200        12.43      26.91     
0.30     32         220        12.37      26.75     
0.30     64         1          12.62      26.94     
0.30     64         25         12.39      26.81     
0.30     64         50         12.44      26.75     
0.30     64         75         12.34      26.81     
0.30     64         100        12.40      26.73     
0.30     64         125        12.40      26.81     
0.30     64         150        12.47      26.83     
0.30     64         175        12.51      26.94     
0.30     64         200        12.43      26.88     
0.30     64         220        12.38      26.78     
0.30     128        1          12.63      26.84     
0.30     128        25         12.42      26.75     
0.30     128        50         12.32      26.69     
0.30     128        75         12.30      26.74     
0.30     128        100        12.44      26.82     
0.30     128        125        12.39      26.89     
0.30     128        150        12.47      26.91     
0.30     128        175        12.39      26.86     
0.30     128        200        12.51      26.85     
0.30     128        220        12.35      26.68     
0.30     256        1          12.40      26.63     
0.30     256        25         12.26      26.73     
0.30     256        50         12.05      26.58     
0.30     256        75         12.21      26.67     
0.30     256        100        12.19      26.61     
0.30     256        125        12.11      26.75     
0.30     256        150        12.27      26.68     
0.30     256        175        12.20      26.65     
0.30     256        200        12.21      26.55     
0.30     256        220        12.15      26.63     
0.40     8          1          12.19      26.72     
0.40     8          25         10.69      26.26     
0.40     8          50         10.60      26.17     
0.40     8          75         10.60      26.21     
0.40     8          100        10.81      26.17     
0.40     8          125        10.54      26.17     
0.40     8          150        10.60      26.18     
0.40     8          175        10.56      26.18     
0.40     8          200        10.59      26.18     
0.40     8          220        10.60      26.19     
0.40     16         1          12.19      26.71     
0.40     16         25         10.72      26.26     
0.40     16         50         10.99      26.32     
0.40     16         75         10.33      25.95     
0.40     16         100        10.36      25.94     
0.40     16         125        10.29      25.86     
0.40     16         150        10.45      26.14     
0.40     16         175        10.62      26.19     
0.40     16         200        10.72      26.19     
0.40     16         220        10.10      25.98     
0.40     32         1          12.14      26.71     
0.40     32         25         10.85      26.29     
0.40     32         50         10.21      26.04     
0.40     32         75         10.96      26.48     
0.40     32         100        10.59      26.27     
0.40     32         125        10.63      26.00     
0.40     32         150        10.30      26.15     
0.40     32         175        10.43      26.17     
0.40     32         200        10.70      26.46     
0.40     32         220        10.39      26.24     
0.40     64         1          12.02      26.73     
0.40     64         25         10.40      26.20     
0.40     64         50         10.41      26.18     
0.40     64         75         10.47      26.17     
0.40     64         100        10.45      26.16     
0.40     64         125        10.47      26.11     
0.40     64         150        10.36      26.14     
0.40     64         175        10.92      26.47     
0.40     64         200        10.46      26.29     
0.40     64         220        10.38      26.05     
0.40     128        1          11.99      26.51     
0.40     128        25         10.27      26.02     
0.40     128        50         10.00      25.85     
0.40     128        75         10.00      26.09     
0.40     128        100        10.38      26.12     
0.40     128        125        10.37      26.20     
0.40     128        150        10.37      26.19     
0.40     128        175        10.51      26.17     
0.40     128        200        10.55      26.17     
0.40     128        220        10.19      25.84     
0.40     256        1          11.71      26.25     
0.40     256        25         10.05      25.78     
0.40     256        50         9.86       25.69     
0.40     256        75         9.97       25.64     
0.40     256        100        9.96       25.66     
0.40     256        125        9.96       25.67     
0.40     256        150        10.03      25.73     
0.40     256        175        9.88       25.73     
0.40     256        200        9.83       25.62     
0.40     256        220        9.78       25.67     
0.50     8          1          10.54      26.03     
0.50     8          25         6.79       25.57     
0.50     8          50         6.23       25.49     
0.50     8          75         6.23       25.51     
0.50     8          100        6.47       25.32     
0.50     8          125        6.11       25.42     
0.50     8          150        6.16       25.40     
0.50     8          175        6.10       25.46     
0.50     8          200        6.19       25.39     
0.50     8          220        6.19       25.53     
0.50     16         1          10.61      26.02     
0.50     16         25         7.25       25.59     
0.50     16         50         7.75       25.46     
0.50     16         75         5.95       25.07     
0.50     16         100        5.57       24.93     
0.50     16         125        5.06       24.89     
0.50     16         150        6.41       25.39     
0.50     16         175        6.67       25.29     
0.50     16         200        6.69       25.31     
0.50     16         220        5.70       25.13     
0.50     32         1          10.41      25.87     
0.50     32         25         7.33       25.47     
0.50     32         50         5.60       25.13     
0.50     32         75         7.69       25.63     
0.50     32         100        7.10       25.45     
0.50     32         125        6.06       25.01     
0.50     32         150        6.70       25.42     
0.50     32         175        6.34       25.25     
0.50     32         200        7.60       25.63     
0.50     32         220        6.82       25.29     
0.50     64         1          10.44      25.92     
0.50     64         25         7.09       25.26     
0.50     64         50         6.71       25.25     
0.50     64         75         6.87       25.14     
0.50     64         100        6.85       25.13     
0.50     64         125        6.48       25.11     
0.50     64         150        6.59       25.15     
0.50     64         175        7.91       25.53     
0.50     64         200        6.96       25.20     
0.50     64         220        6.44       25.13     
0.50     128        1          10.26      25.53     
0.50     128        25         6.47       24.94     
0.50     128        50         6.06       24.80     
0.50     128        75         6.63       24.96     
0.50     128        100        6.78       24.95     
0.50     128        125        6.80       25.08     
0.50     128        150        6.41       25.09     
0.50     128        175        7.22       25.13     
0.50     128        200        6.88       25.18     
0.50     128        220        6.01       24.73     
0.50     256        1          9.74       25.06     
0.50     256        25         6.47       24.38     
0.50     256        50         6.12       23.98     
0.50     256        75         6.50       24.18     
0.50     256        100        6.49       24.29     
0.50     256        125        6.30       24.15     
0.50     256        150        6.64       24.42     
0.50     256        175        6.45       24.27     
0.50     256        200        5.96       24.07     
0.50     256        220        6.29       24.42     
0.60     8          1          7.69       24.79     
0.60     8          25         4.11       24.52     
0.60     8          50         3.48       24.41     
0.60     8          75         3.41       24.43     
0.60     8          100        2.59       24.07     
0.60     8          125        3.32       24.35     
0.60     8          150        3.33       24.36     
0.60     8          175        3.35       24.38     
0.60     8          200        3.30       24.35     
0.60     8          220        3.48       24.42     
0.60     16         1          7.53       24.72     
0.60     16         25         4.65       24.19     
0.60     16         50         4.30       24.19     
0.60     16         75         2.88       23.75     
0.60     16         100        1.87       23.54     
0.60     16         125        1.64       23.54     
0.60     16         150        2.90       23.95     
0.60     16         175        2.86       23.82     
0.60     16         200        2.93       23.80     
0.60     16         220        2.65       23.75     
0.60     32         1          7.42       24.45     
0.60     32         25         4.21       24.06     
0.60     32         50         2.67       23.59     
0.60     32         75         4.27       24.08     
0.60     32         100        4.40       23.79     
0.60     32         125        2.49       23.57     
0.60     32         150        4.23       23.99     
0.60     32         175        3.25       23.77     
0.60     32         200        4.51       23.81     
0.60     32         220        3.82       23.60     
0.60     64         1          7.43       24.45     
0.60     64         25         4.38       23.55     
0.60     64         50         4.11       23.72     
0.60     64         75         3.73       23.13     
0.60     64         100        3.63       23.41     
0.60     64         125        3.16       23.19     
0.60     64         150        3.55       23.27     
0.60     64         175        4.75       23.93     
0.60     64         200        3.96       23.32     
0.60     64         220        3.48       23.44     
0.60     128        1          7.17       23.94     
0.60     128        25         3.56       22.98     
0.60     128        50         3.51       22.78     
0.60     128        75         3.84       23.04     
0.60     128        100        3.94       22.81     
0.60     128        125        3.75       23.11     
0.60     128        150        3.76       23.00     
0.60     128        175        4.58       23.14     
0.60     128        200        3.68       23.16     
0.60     128        220        3.16       22.69     
0.60     256        1          6.72       22.96     
0.60     256        25         3.71       21.84     
0.60     256        50         3.39       21.51     
0.60     256        75         3.79       21.83     
0.60     256        100        3.71       22.06     
0.60     256        125        3.62       21.73     
0.60     256        150        3.65       21.78     
0.60     256        175        3.73       21.98     
0.60     256        200        3.27       21.69     
0.60     256        220        3.86       22.18     
0.70     8          1          4.21       22.60     
0.70     8          25         2.23       22.01     
0.70     8          50         1.96       21.79     
0.70     8          75         1.96       21.90     
0.70     8          100        1.04       21.47     
0.70     8          125        1.89       21.78     
0.70     8          150        1.90       21.79     
0.70     8          175        1.96       21.81     
0.70     8          200        1.83       21.84     
0.70     8          220        2.03       21.96     
0.70     16         1          4.05       22.49     
0.70     16         25         2.73       21.56     
0.70     16         50         2.10       21.65     
0.70     16         75         1.12       21.18     
0.70     16         100        0.63       21.04     
0.70     16         125        0.63       21.05     
0.70     16         150        1.11       21.51     
0.70     16         175        0.88       21.35     
0.70     16         200        0.98       21.18     
0.70     16         220        1.13       21.02     
0.70     32         1          3.99       22.11     
0.70     32         25         2.08       21.16     
0.70     32         50         1.21       20.75     
0.70     32         75         1.87       21.09     
0.70     32         100        2.11       20.76     
0.70     32         125        1.01       20.91     
0.70     32         150        2.18       20.96     
0.70     32         175        1.43       21.16     
0.70     32         200        2.09       20.80     
0.70     32         220        1.68       20.31     
0.70     64         1          3.96       21.88     
0.70     64         25         2.07       20.02     
0.70     64         50         2.26       20.54     
0.70     64         75         1.71       19.81     
0.70     64         100        1.82       20.56     
0.70     64         125        1.55       19.85     
0.70     64         150        1.67       20.14     
0.70     64         175        2.41       20.77     
0.70     64         200        1.87       20.11     
0.70     64         220        1.77       20.41     
0.70     128        1          3.80       21.06     
0.70     128        25         1.72       19.53     
0.70     128        50         1.90       19.34     
0.70     128        75         1.90       19.69     
0.70     128        100        2.10       19.20     
0.70     128        125        1.90       19.99     
0.70     128        150        1.93       19.50     
0.70     128        175        2.40       19.85     
0.70     128        200        1.66       19.97     
0.70     128        220        1.65       19.19     
0.70     256        1          3.78       19.93     
0.70     256        25         2.05       18.21     
0.70     256        50         1.72       17.82     
0.70     256        75         1.97       18.22     
0.70     256        100        2.05       18.34     
0.70     256        125        2.09       18.12     
0.70     256        150        1.80       18.17     
0.70     256        175        1.93       18.49     
0.70     256        200        1.79       18.28     
0.70     256        220        2.24       18.73     
0.80     8          1          1.68       18.52     
0.80     8          25         1.02       17.52     
0.80     8          50         0.89       17.01     
0.80     8          75         0.89       17.05     
0.80     8          100        0.52       16.83     
0.80     8          125        0.88       16.85     
0.80     8          150        0.86       16.93     
0.80     8          175        0.91       16.91     
0.80     8          200        0.80       17.00     
0.80     8          220        0.93       17.01     
0.80     16         1          1.52       18.06     
0.80     16         25         1.18       16.42     
0.80     16         50         0.88       17.07     
0.80     16         75         0.45       16.30     
0.80     16         100        0.39       16.30     
0.80     16         125        0.41       16.29     
0.80     16         150        0.46       16.83     
0.80     16         175        0.38       16.51     
0.80     16         200        0.40       16.53     
0.80     16         220        0.51       16.26     
0.80     32         1          1.53       17.69     
0.80     32         25         0.92       16.01     
0.80     32         50         0.53       15.61     
0.80     32         75         0.81       15.90     
0.80     32         100        0.84       15.55     
0.80     32         125        0.51       16.35     
0.80     32         150        0.95       15.64     
0.80     32         175        0.68       16.22     
0.80     32         200        0.83       15.67     
0.80     32         220        0.66       14.61     
0.80     64         1          1.58       17.50     
0.80     64         25         0.87       14.52     
0.80     64         50         1.08       15.68     
0.80     64         75         0.73       14.30     
0.80     64         100        0.95       15.80     
0.80     64         125        0.75       14.61     
0.80     64         150        0.80       14.87     
0.80     64         175        1.12       15.74     
0.80     64         200        0.89       14.71     
0.80     64         220        0.82       15.50     
0.80     128        1          1.64       16.46     
0.80     128        25         0.80       14.51     
0.80     128        50         0.97       14.39     
0.80     128        75         0.88       14.64     
0.80     128        100        1.11       14.22     
0.80     128        125        0.99       14.99     
0.80     128        150        0.99       14.47     
0.80     128        175        1.15       14.92     
0.80     128        200        0.80       14.82     
0.80     128        220        0.96       14.41     
0.80     256        1          1.83       15.45     
0.80     256        25         1.13       13.66     
0.80     256        50         0.95       13.18     
0.80     256        75         1.03       13.76     
0.80     256        100        1.12       13.69     
0.80     256        125        1.27       13.44     
0.80     256        150        1.01       13.60     
0.80     256        175        1.03       13.92     
0.80     256        200        0.97       13.69     
0.80     256        220        1.25       14.26     
0.90     8          1          0.61       10.66     
0.90     8          25         0.47       9.23      
0.90     8          50         0.43       8.53      
0.90     8          75         0.41       8.69      
0.90     8          100        0.36       8.62      
0.90     8          125        0.40       8.53      
0.90     8          150        0.40       8.58      
0.90     8          175        0.42       8.54      
0.90     8          200        0.39       8.68      
0.90     8          220        0.43       8.61      
0.90     16         1          0.60       10.49     
0.90     16         25         0.52       8.43      
0.90     16         50         0.41       9.26      
0.90     16         75         0.33       8.68      
0.90     16         100        0.35       8.61      
0.90     16         125        0.35       8.45      
0.90     16         150        0.33       8.94      
0.90     16         175        0.32       8.58      
0.90     16         200        0.33       8.63      
0.90     16         220        0.35       8.41      
0.90     32         1          0.60       10.48     
0.90     32         25         0.51       8.88      
0.90     32         50         0.34       8.04      
0.90     32         75         0.43       9.01      
0.90     32         100        0.46       8.20      
0.90     32         125        0.39       8.89      
0.90     32         150        0.48       8.29      
0.90     32         175        0.41       8.65      
0.90     32         200        0.43       8.80      
0.90     32         220        0.36       7.73      
0.90     64         1          0.62       10.41     
0.90     64         25         0.49       8.26      
0.90     64         50         0.55       9.27      
0.90     64         75         0.42       7.72      
0.90     64         100        0.57       9.17      
0.90     64         125        0.46       8.12      
0.90     64         150        0.46       8.36      
0.90     64         175        0.52       9.16      
0.90     64         200        0.47       8.23      
0.90     64         220        0.48       9.07      
0.90     128        1          0.74       10.41     
0.90     128        25         0.49       8.96      
0.90     128        50         0.56       8.64      
0.90     128        75         0.51       8.71      
0.90     128        100        0.63       8.65      
0.90     128        125        0.57       9.36      
0.90     128        150        0.59       9.07      
0.90     128        175        0.62       9.26      
0.90     128        200        0.50       8.93      
0.90     128        220        0.60       8.90      
0.90     256        1          0.90       9.95      
0.90     256        25         0.72       9.04      
0.90     256        50         0.64       8.52      
0.90     256        75         0.66       8.90      
0.90     256        100        0.74       8.96      
0.90     256        125        0.83       8.97      
0.90     256        150        0.65       8.63      
0.90     256        175        0.65       9.24      
0.90     256        200        0.58       8.85      
0.90     256        220        0.78       9.11      
1.00     8          1          0.36       3.67      
1.00     8          25         0.34       3.06      
1.00     8          50         0.35       2.83      
1.00     8          75         0.33       2.89      
1.00     8          100        0.33       2.73      
1.00     8          125        0.33       2.81      
1.00     8          150        0.33       2.81      
1.00     8          175        0.34       2.78      
1.00     8          200        0.33       2.89      
1.00     8          220        0.34       2.84      
1.00     16         1          0.38       3.92      
1.00     16         25         0.35       3.16      
1.00     16         50         0.31       3.29      
1.00     16         75         0.31       2.95      
1.00     16         100        0.34       3.14      
1.00     16         125        0.34       3.10      
1.00     16         150        0.32       3.18      
1.00     16         175        0.31       3.08      
1.00     16         200        0.32       2.99      
1.00     16         220        0.32       3.05      
1.00     32         1          0.36       4.04      
1.00     32         25         0.37       3.67      
1.00     32         50         0.32       2.96      
1.00     32         75         0.34       4.14      
1.00     32         100        0.37       3.44      
1.00     32         125        0.34       3.46      
1.00     32         150        0.36       3.35      
1.00     32         175        0.34       3.36      
1.00     32         200        0.33       3.70      
1.00     32         220        0.33       3.21      
1.00     64         1          0.39       4.42      
1.00     64         25         0.38       3.81      
1.00     64         50         0.38       4.22      
1.00     64         75         0.35       3.62      
1.00     64         100        0.40       4.28      
1.00     64         125        0.38       3.65      
1.00     64         150        0.36       3.83      
1.00     64         175        0.39       4.53      
1.00     64         200        0.37       3.80      
1.00     64         220        0.36       4.11      
1.00     128        1          0.43       5.01      
1.00     128        25         0.37       4.84      
1.00     128        50         0.42       4.67      
1.00     128        75         0.40       4.58      
1.00     128        100        0.47       4.71      
1.00     128        125        0.41       4.78      
1.00     128        150        0.43       5.08      
1.00     128        175        0.40       4.97      
1.00     128        200        0.40       4.88      
1.00     128        220        0.42       4.88      
1.00     256        1          0.56       5.44      
1.00     256        25         0.56       5.64      
1.00     256        50         0.49       5.16      
1.00     256        75         0.51       5.33      
1.00     256        100        0.56       5.70      
1.00     256        125        0.59       5.54      
1.00     256        150        0.48       5.31      
1.00     256        175        0.47       5.38      
1.00     256        200        0.45       5.20      
1.00     256        220        0.59       5.49      

BEST RESULT:
  Alpha: 0.2
  Clusters: 64
  PCA_dim: 175
  Top-1 Accuracy: 12.79%
  Top-5 Accuracy: 26.98%
2025-09-10 13:08:21,766 - INFO - Experiment for seed 1001 completed in 162649.15 seconds
2025-09-10 13:08:21,768 - INFO - SUCCESS: Experiment for seed 1001 completed successfully
2025-09-10 13:08:21,772 - INFO - Looking for results in: ./checkpoint/quant_result/20250910_1259
2025-09-10 13:08:21,775 - INFO - Parsed 0 reconstructed results from log file for seed 1001
2025-09-10 13:08:21,775 - INFO - Parsed 0 baseline results from log file for seed 1001
2025-09-10 13:08:21,775 - INFO - Seed 1001 completed successfully
2025-09-10 13:08:21,775 - INFO - Sleeping for 0.5 seconds before next seed...
2025-09-10 13:08:22,275 - INFO - 
============================================================
2025-09-10 13:08:22,275 - INFO - Running experiment 2/3 for seed 1002
2025-09-10 13:08:22,275 - INFO - ============================================================
2025-09-10 13:08:22,277 - INFO - Running experiment for seed 1002
2025-09-10 13:08:22,277 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model deit_base --w_bit 2 --a_bit 2 --seed 1002 --config ../configs/4bit/brecq_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-10 13:08:22,277 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/brecq_base
2025-09-10 13:08:35 - start the process.
Namespace(model='deit_base', config='../configs/4bit/brecq_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1002, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=2, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 2
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: rinp
drop_prob: 1.0
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/deit_base_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/deit_base_patch16_224.fb_in1k)
[timm/deit_base_patch16_224.fb_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 18.298 (18.298)	Loss 0.4608 (0.4608)	Prec@1 90.600 (90.600)	Prec@5 98.600 (98.600)
Test: [10/100]	Time 0.774 (2.703)	Loss 0.5691 (0.6237)	Prec@1 89.200 (86.582)	Prec@5 96.600 (97.473)
Test: [20/100]	Time 0.782 (2.050)	Loss 0.6565 (0.6262)	Prec@1 84.600 (86.752)	Prec@5 98.400 (97.533)
Test: [30/100]	Time 0.788 (1.662)	Loss 0.5879 (0.6391)	Prec@1 87.400 (86.348)	Prec@5 99.400 (97.548)
Test: [40/100]	Time 0.797 (1.470)	Loss 0.8276 (0.6411)	Prec@1 81.600 (86.317)	Prec@5 96.000 (97.507)
Test: [50/100]	Time 0.787 (1.337)	Loss 1.2987 (0.7189)	Prec@1 72.600 (84.408)	Prec@5 90.200 (96.710)
Test: [60/100]	Time 0.797 (1.248)	Loss 0.7880 (0.7396)	Prec@1 84.000 (83.977)	Prec@5 94.000 (96.462)
Test: [70/100]	Time 0.795 (1.184)	Loss 0.9197 (0.7745)	Prec@1 80.000 (83.039)	Prec@5 94.600 (96.127)
Test: [80/100]	Time 0.803 (1.136)	Loss 0.6823 (0.7935)	Prec@1 87.000 (82.738)	Prec@5 96.400 (95.849)
Test: [90/100]	Time 0.800 (1.099)	Loss 1.1798 (0.8183)	Prec@1 70.200 (82.015)	Prec@5 94.600 (95.679)
 * Prec@1 81.982 Prec@5 95.744 Loss 0.818 Time 109.908
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-10 13:11:12 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:11<14:19, 11.78s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:11<14:19, 11.78s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [01:25<57:43, 48.11s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [01:25<57:43, 48.11s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [01:50<44:35, 37.68s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [01:50<44:35, 37.68s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [03:02<59:30, 51.00s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [03:02<59:30, 51.00s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [04:02<1:02:37, 54.46s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [04:02<1:02:37, 54.46s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [05:54<1:23:52, 74.00s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [05:54<1:23:52, 74.00s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [07:49<1:37:41, 87.49s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [07:49<1:37:41, 87.49s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [09:05<1:32:03, 83.69s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [09:05<1:32:03, 83.69s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [09:31<1:11:18, 65.83s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [09:31<1:11:18, 65.83s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [10:43<1:12:15, 67.74s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [10:43<1:12:15, 67.74s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [11:44<1:08:50, 65.57s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [11:44<1:08:50, 65.57s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [13:37<1:22:29, 79.83s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [13:37<1:22:29, 79.83s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [15:32<1:32:02, 90.52s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [15:32<1:32:02, 90.52s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [16:47<1:25:58, 85.97s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [16:47<1:25:58, 85.97s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [17:14<1:06:54, 68.05s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [17:14<1:06:54, 68.05s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [18:26<1:07:01, 69.34s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [18:26<1:07:01, 69.34s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [19:27<1:03:32, 66.89s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [19:27<1:03:32, 66.89s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [21:20<1:15:24, 80.80s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [21:20<1:15:24, 80.80s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [23:16<1:23:43, 91.35s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [23:16<1:23:43, 91.35s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [24:32<1:18:04, 86.75s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [24:32<1:18:04, 86.75s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [24:59<1:00:40, 68.68s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [24:59<1:00:40, 68.68s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [26:11<1:00:18, 69.58s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [26:11<1:00:18, 69.58s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [27:11<56:53, 66.93s/it]  calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [27:11<56:53, 66.93s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [29:04<1:07:19, 80.78s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [29:04<1:07:19, 80.78s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [31:00<1:14:29, 91.21s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [31:00<1:14:29, 91.21s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [32:15<1:09:05, 86.36s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [32:15<1:09:05, 86.36s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [32:41<53:34, 68.40s/it]  calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [32:41<53:34, 68.40s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [33:53<53:14, 69.44s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [33:53<53:14, 69.44s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [34:54<50:08, 66.87s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [34:54<50:08, 66.87s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [36:47<59:10, 80.69s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [36:47<59:10, 80.69s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [38:43<1:05:19, 91.15s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [38:43<1:05:19, 91.15s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [39:59<1:00:36, 86.58s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [39:59<1:00:36, 86.58s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [40:25<46:51, 68.57s/it]  calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [40:25<46:51, 68.57s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [41:37<46:27, 69.69s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [41:37<46:27, 69.69s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [42:39<43:37, 67.11s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [42:39<43:37, 67.11s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [44:32<51:13, 80.89s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [44:32<51:13, 80.89s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [46:26<56:09, 91.07s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [46:26<56:09, 91.07s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [47:41<51:43, 86.19s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [47:41<51:43, 86.19s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [48:07<39:45, 68.16s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [48:07<39:45, 68.16s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [49:19<39:13, 69.22s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [49:19<39:13, 69.22s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [50:20<36:39, 66.65s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [50:20<36:39, 66.65s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [52:12<42:49, 80.28s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [52:12<42:49, 80.28s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [54:06<46:44, 90.45s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [54:06<46:44, 90.45s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [55:20<42:49, 85.65s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [55:20<42:49, 85.65s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [55:46<32:41, 67.63s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [55:46<32:41, 67.63s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [56:57<32:06, 68.80s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [56:57<32:06, 68.80s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [57:58<29:50, 66.31s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [57:58<29:50, 66.31s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [59:51<34:45, 80.20s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [59:51<34:45, 80.20s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [1:01:46<37:48, 90.73s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [1:01:46<37:48, 90.73s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [1:03:02<34:30, 86.29s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [1:03:02<34:30, 86.29s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [1:03:28<26:12, 68.35s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [1:03:28<26:12, 68.35s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [1:04:41<25:30, 69.55s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [1:04:41<25:30, 69.55s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [1:05:42<23:27, 67.04s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [1:05:42<23:27, 67.04s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [1:07:35<26:59, 80.95s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [1:07:35<26:59, 80.95s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [1:09:31<28:55, 91.35s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [1:09:31<28:55, 91.35s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [1:10:47<26:02, 86.80s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [1:10:47<26:02, 86.80s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [1:11:14<19:28, 68.71s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [1:11:14<19:28, 68.71s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [1:12:26<18:38, 69.91s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [1:12:26<18:38, 69.91s/it]calibrating blocks.9.attn.matmul2:  80%|███████▉  | 59/74 [1:13:28<16:50, 67.38s/it]calibrating blocks.9.mlp.fc1:  80%|███████▉  | 59/74 [1:13:28<16:50, 67.38s/it]     calibrating blocks.9.mlp.fc1:  81%|████████  | 60/74 [1:15:21<18:56, 81.14s/it]calibrating blocks.9.mlp.fc2:  81%|████████  | 60/74 [1:15:21<18:56, 81.14s/it]calibrating blocks.9.mlp.fc2:  82%|████████▏ | 61/74 [1:17:17<19:49, 91.48s/it]calibrating blocks.10.attn.qkv:  82%|████████▏ | 61/74 [1:17:17<19:49, 91.48s/it]calibrating blocks.10.attn.qkv:  84%|████████▍ | 62/74 [1:18:33<17:24, 87.01s/it]calibrating blocks.10.attn.proj:  84%|████████▍ | 62/74 [1:18:33<17:24, 87.01s/it]calibrating blocks.10.attn.proj:  85%|████████▌ | 63/74 [1:19:00<12:37, 68.87s/it]calibrating blocks.10.attn.matmul1:  85%|████████▌ | 63/74 [1:19:00<12:37, 68.87s/it]calibrating blocks.10.attn.matmul1:  86%|████████▋ | 64/74 [1:20:12<11:37, 69.75s/it]calibrating blocks.10.attn.matmul2:  86%|████████▋ | 64/74 [1:20:12<11:37, 69.75s/it]calibrating blocks.10.attn.matmul2:  88%|████████▊ | 65/74 [1:21:12<10:03, 67.05s/it]calibrating blocks.10.mlp.fc1:  88%|████████▊ | 65/74 [1:21:12<10:03, 67.05s/it]     calibrating blocks.10.mlp.fc1:  89%|████████▉ | 66/74 [1:23:05<10:45, 80.72s/it]calibrating blocks.10.mlp.fc2:  89%|████████▉ | 66/74 [1:23:05<10:45, 80.72s/it]calibrating blocks.10.mlp.fc2:  91%|█████████ | 67/74 [1:25:00<10:36, 90.94s/it]calibrating blocks.11.attn.qkv:  91%|█████████ | 67/74 [1:25:00<10:36, 90.94s/it]calibrating blocks.11.attn.qkv:  92%|█████████▏| 68/74 [1:26:15<08:36, 86.16s/it]calibrating blocks.11.attn.proj:  92%|█████████▏| 68/74 [1:26:15<08:36, 86.16s/it]calibrating blocks.11.attn.proj:  93%|█████████▎| 69/74 [1:26:41<05:40, 68.18s/it]calibrating blocks.11.attn.matmul1:  93%|█████████▎| 69/74 [1:26:41<05:40, 68.18s/it]calibrating blocks.11.attn.matmul1:  95%|█████████▍| 70/74 [1:27:53<04:36, 69.21s/it]calibrating blocks.11.attn.matmul2:  95%|█████████▍| 70/74 [1:27:53<04:36, 69.21s/it]calibrating blocks.11.attn.matmul2:  96%|█████████▌| 71/74 [1:28:53<03:20, 66.70s/it]calibrating blocks.11.mlp.fc1:  96%|█████████▌| 71/74 [1:28:53<03:20, 66.70s/it]     calibrating blocks.11.mlp.fc1:  97%|█████████▋| 72/74 [1:30:47<02:41, 80.76s/it]calibrating blocks.11.mlp.fc2:  97%|█████████▋| 72/74 [1:30:47<02:41, 80.76s/it]calibrating blocks.11.mlp.fc2:  99%|█████████▊| 73/74 [1:32:43<01:31, 91.21s/it]calibrating head:  99%|█████████▊| 73/74 [1:32:43<01:31, 91.21s/it]             calibrating head: 100%|██████████| 74/74 [1:32:46<00:00, 64.92s/it]calibrating head: 100%|██████████| 74/74 [1:32:46<00:00, 75.22s/it]
2025-09-10 14:44:19 - mse guided calibration finished.
Saving checkpoint to ./checkpoint/quant_result/20250910_1308/deit_base_w2_a2_calibsize_1000_mse.pth
Validating after calibration ...
Test: [0/100]	Time 4.830 (4.830)	Loss 7.0502 (7.0502)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [10/100]	Time 1.663 (1.950)	Loss 7.0022 (7.1024)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [20/100]	Time 1.660 (1.812)	Loss 6.9650 (7.0667)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [30/100]	Time 1.662 (1.763)	Loss 7.3913 (7.0547)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [40/100]	Time 1.659 (1.738)	Loss 7.1117 (7.0538)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.000)
Test: [50/100]	Time 1.660 (1.722)	Loss 6.7762 (7.0185)	Prec@1 0.000 (0.000)	Prec@5 0.000 (0.012)
Test: [60/100]	Time 1.662 (1.712)	Loss 6.9009 (6.9993)	Prec@1 1.800 (0.033)	Prec@5 8.200 (0.285)
Test: [70/100]	Time 1.660 (1.705)	Loss 6.8002 (6.9893)	Prec@1 0.000 (0.028)	Prec@5 0.200 (0.248)
Test: [80/100]	Time 1.660 (1.699)	Loss 6.9390 (6.9729)	Prec@1 0.000 (0.143)	Prec@5 0.000 (0.556)
Test: [90/100]	Time 1.657 (1.695)	Loss 7.0725 (6.9559)	Prec@1 0.000 (0.130)	Prec@5 0.000 (0.525)
 * Prec@1 0.150 Prec@5 0.608 Loss 6.985 Time 169.379
Building calibrator ...
2025-09-10 14:47:14 - start mse guided block reconstruction
reconstructing patch_embed ...
initializing raw input and raw output ...
adaround training for patch_embed ...
wraping quantizers in patch_embed ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.053 (rec:0.053, round:0.000)	b=0.00	count=500
Total loss:	0.035 (rec:0.035, round:0.000)	b=0.00	count=1000
Total loss:	0.025 (rec:0.025, round:0.000)	b=0.00	count=1500
Total loss:	0.015 (rec:0.015, round:0.000)	b=0.00	count=2000
Total loss:	0.019 (rec:0.019, round:0.000)	b=0.00	count=2500
Total loss:	0.012 (rec:0.012, round:0.000)	b=0.00	count=3000
Total loss:	0.014 (rec:0.014, round:0.000)	b=0.00	count=3500
Total loss:	5566.206 (rec:0.011, round:5566.195)	b=20.00	count=4000
Total loss:	2853.249 (rec:0.029, round:2853.220)	b=19.44	count=4500
Total loss:	2633.506 (rec:0.020, round:2633.486)	b=18.88	count=5000
Total loss:	2489.768 (rec:0.021, round:2489.747)	b=18.31	count=5500
Total loss:	2363.665 (rec:0.023, round:2363.642)	b=17.75	count=6000
Total loss:	2245.479 (rec:0.022, round:2245.457)	b=17.19	count=6500
Total loss:	2125.805 (rec:0.019, round:2125.786)	b=16.62	count=7000
Total loss:	2005.446 (rec:0.018, round:2005.428)	b=16.06	count=7500
Total loss:	1881.788 (rec:0.022, round:1881.765)	b=15.50	count=8000
Total loss:	1755.143 (rec:0.039, round:1755.104)	b=14.94	count=8500
Total loss:	1625.484 (rec:0.027, round:1625.457)	b=14.38	count=9000
Total loss:	1492.771 (rec:0.017, round:1492.754)	b=13.81	count=9500
Total loss:	1356.619 (rec:0.039, round:1356.580)	b=13.25	count=10000
Total loss:	1219.820 (rec:0.035, round:1219.785)	b=12.69	count=10500
Total loss:	1079.798 (rec:0.036, round:1079.762)	b=12.12	count=11000
Total loss:	938.623 (rec:0.030, round:938.593)	b=11.56	count=11500
Total loss:	796.898 (rec:0.045, round:796.853)	b=11.00	count=12000
Total loss:	656.398 (rec:0.036, round:656.362)	b=10.44	count=12500
Total loss:	520.755 (rec:0.055, round:520.701)	b=9.88	count=13000
Total loss:	394.471 (rec:0.049, round:394.422)	b=9.31	count=13500
Total loss:	280.737 (rec:0.096, round:280.641)	b=8.75	count=14000
Total loss:	184.125 (rec:0.066, round:184.058)	b=8.19	count=14500
Total loss:	110.731 (rec:0.066, round:110.666)	b=7.62	count=15000
Total loss:	59.195 (rec:0.089, round:59.106)	b=7.06	count=15500
Total loss:	26.934 (rec:0.094, round:26.840)	b=6.50	count=16000
Total loss:	11.548 (rec:0.095, round:11.453)	b=5.94	count=16500
Total loss:	4.785 (rec:0.111, round:4.674)	b=5.38	count=17000
Total loss:	2.213 (rec:0.118, round:2.096)	b=4.81	count=17500
Total loss:	1.100 (rec:0.116, round:0.985)	b=4.25	count=18000
Total loss:	0.496 (rec:0.105, round:0.391)	b=3.69	count=18500
Total loss:	0.184 (rec:0.119, round:0.065)	b=3.12	count=19000
Total loss:	0.137 (rec:0.134, round:0.003)	b=2.56	count=19500
Total loss:	0.100 (rec:0.100, round:0.000)	b=2.00	count=20000
finished reconstructing patch_embed.
reconstructing blocks.0 ...
initializing raw input and raw output ...
adaround training for blocks.0 ...
wraping quantizers in blocks.0 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.130 (rec:1.130, round:0.000)	b=0.00	count=500
Total loss:	0.769 (rec:0.769, round:0.000)	b=0.00	count=1000
Total loss:	0.600 (rec:0.600, round:0.000)	b=0.00	count=1500
Total loss:	0.650 (rec:0.650, round:0.000)	b=0.00	count=2000
Total loss:	0.524 (rec:0.524, round:0.000)	b=0.00	count=2500
Total loss:	0.469 (rec:0.469, round:0.000)	b=0.00	count=3000
Total loss:	0.473 (rec:0.473, round:0.000)	b=0.00	count=3500
Total loss:	62228.070 (rec:0.439, round:62227.633)	b=20.00	count=4000
Total loss:	23981.533 (rec:0.486, round:23981.047)	b=19.44	count=4500
Total loss:	21795.379 (rec:0.421, round:21794.957)	b=18.88	count=5000
Total loss:	20325.051 (rec:0.415, round:20324.635)	b=18.31	count=5500
Total loss:	19047.551 (rec:0.427, round:19047.125)	b=17.75	count=6000
Total loss:	17852.934 (rec:0.413, round:17852.521)	b=17.19	count=6500
Total loss:	16727.162 (rec:0.461, round:16726.701)	b=16.62	count=7000
Total loss:	15651.203 (rec:0.417, round:15650.786)	b=16.06	count=7500
Total loss:	14605.163 (rec:0.436, round:14604.727)	b=15.50	count=8000
Total loss:	13601.238 (rec:0.409, round:13600.829)	b=14.94	count=8500
Total loss:	12634.779 (rec:0.364, round:12634.415)	b=14.38	count=9000
Total loss:	11700.917 (rec:0.385, round:11700.531)	b=13.81	count=9500
Total loss:	10791.939 (rec:0.378, round:10791.562)	b=13.25	count=10000
Total loss:	9910.607 (rec:0.477, round:9910.131)	b=12.69	count=10500
Total loss:	9044.495 (rec:0.388, round:9044.107)	b=12.12	count=11000
Total loss:	8201.816 (rec:0.461, round:8201.355)	b=11.56	count=11500
Total loss:	7377.616 (rec:0.461, round:7377.155)	b=11.00	count=12000
Total loss:	6575.679 (rec:0.467, round:6575.212)	b=10.44	count=12500
Total loss:	5792.213 (rec:0.464, round:5791.749)	b=9.88	count=13000
Total loss:	5028.468 (rec:0.354, round:5028.114)	b=9.31	count=13500
Total loss:	4283.275 (rec:0.397, round:4282.877)	b=8.75	count=14000
Total loss:	3567.473 (rec:0.429, round:3567.043)	b=8.19	count=14500
Total loss:	2887.994 (rec:0.418, round:2887.576)	b=7.62	count=15000
Total loss:	2245.337 (rec:0.404, round:2244.933)	b=7.06	count=15500
Total loss:	1658.810 (rec:0.451, round:1658.358)	b=6.50	count=16000
Total loss:	1138.891 (rec:0.425, round:1138.466)	b=5.94	count=16500
Total loss:	707.729 (rec:0.424, round:707.305)	b=5.38	count=17000
Total loss:	380.206 (rec:0.472, round:379.734)	b=4.81	count=17500
Total loss:	166.621 (rec:0.449, round:166.172)	b=4.25	count=18000
Total loss:	52.473 (rec:0.446, round:52.027)	b=3.69	count=18500
Total loss:	10.063 (rec:0.428, round:9.635)	b=3.12	count=19000
Total loss:	1.269 (rec:0.482, round:0.787)	b=2.56	count=19500
Total loss:	0.413 (rec:0.388, round:0.025)	b=2.00	count=20000
finished reconstructing blocks.0.
reconstructing blocks.1 ...
initializing raw input and raw output ...
adaround training for blocks.1 ...
wraping quantizers in blocks.1 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.650 (rec:1.650, round:0.000)	b=0.00	count=500
Total loss:	1.073 (rec:1.073, round:0.000)	b=0.00	count=1000
Total loss:	1.119 (rec:1.119, round:0.000)	b=0.00	count=1500
Total loss:	0.940 (rec:0.940, round:0.000)	b=0.00	count=2000
Total loss:	1.082 (rec:1.082, round:0.000)	b=0.00	count=2500
Total loss:	1.032 (rec:1.032, round:0.000)	b=0.00	count=3000
Total loss:	1.018 (rec:1.018, round:0.000)	b=0.00	count=3500
Total loss:	62785.133 (rec:0.980, round:62784.152)	b=20.00	count=4000
Total loss:	24761.939 (rec:1.112, round:24760.828)	b=19.44	count=4500
Total loss:	22156.539 (rec:0.970, round:22155.570)	b=18.88	count=5000
Total loss:	20342.221 (rec:1.092, round:20341.129)	b=18.31	count=5500
Total loss:	18804.391 (rec:0.978, round:18803.412)	b=17.75	count=6000
Total loss:	17444.381 (rec:0.900, round:17443.480)	b=17.19	count=6500
Total loss:	16221.523 (rec:0.843, round:16220.681)	b=16.62	count=7000
Total loss:	15095.106 (rec:0.900, round:15094.207)	b=16.06	count=7500
Total loss:	14052.019 (rec:1.058, round:14050.961)	b=15.50	count=8000
Total loss:	13067.776 (rec:0.956, round:13066.820)	b=14.94	count=8500
Total loss:	12129.860 (rec:1.046, round:12128.814)	b=14.38	count=9000
Total loss:	11232.248 (rec:0.934, round:11231.314)	b=13.81	count=9500
Total loss:	10370.580 (rec:0.980, round:10369.601)	b=13.25	count=10000
Total loss:	9533.523 (rec:0.963, round:9532.561)	b=12.69	count=10500
Total loss:	8725.171 (rec:1.032, round:8724.139)	b=12.12	count=11000
Total loss:	7929.920 (rec:1.024, round:7928.896)	b=11.56	count=11500
Total loss:	7154.038 (rec:0.981, round:7153.057)	b=11.00	count=12000
Total loss:	6396.798 (rec:1.091, round:6395.707)	b=10.44	count=12500
Total loss:	5656.379 (rec:1.048, round:5655.331)	b=9.88	count=13000
Total loss:	4935.095 (rec:1.054, round:4934.041)	b=9.31	count=13500
Total loss:	4230.060 (rec:0.869, round:4229.191)	b=8.75	count=14000
Total loss:	3548.924 (rec:1.034, round:3547.890)	b=8.19	count=14500
Total loss:	2898.390 (rec:0.977, round:2897.414)	b=7.62	count=15000
Total loss:	2287.712 (rec:0.942, round:2286.770)	b=7.06	count=15500
Total loss:	1722.699 (rec:0.954, round:1721.746)	b=6.50	count=16000
Total loss:	1218.731 (rec:0.953, round:1217.779)	b=5.94	count=16500
Total loss:	789.646 (rec:0.863, round:788.783)	b=5.38	count=17000
Total loss:	452.162 (rec:0.944, round:451.218)	b=4.81	count=17500
Total loss:	209.354 (rec:0.964, round:208.390)	b=4.25	count=18000
Total loss:	70.977 (rec:1.004, round:69.973)	b=3.69	count=18500
Total loss:	14.695 (rec:0.994, round:13.701)	b=3.12	count=19000
Total loss:	2.164 (rec:0.879, round:1.284)	b=2.56	count=19500
Total loss:	1.097 (rec:1.056, round:0.041)	b=2.00	count=20000
finished reconstructing blocks.1.
reconstructing blocks.2 ...
initializing raw input and raw output ...
adaround training for blocks.2 ...
wraping quantizers in blocks.2 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.929 (rec:0.929, round:0.000)	b=0.00	count=500
Total loss:	0.798 (rec:0.798, round:0.000)	b=0.00	count=1000
Total loss:	0.709 (rec:0.709, round:0.000)	b=0.00	count=1500
Total loss:	0.615 (rec:0.615, round:0.000)	b=0.00	count=2000
Total loss:	0.606 (rec:0.606, round:0.000)	b=0.00	count=2500
Total loss:	0.545 (rec:0.545, round:0.000)	b=0.00	count=3000
Total loss:	0.537 (rec:0.537, round:0.000)	b=0.00	count=3500
Total loss:	63384.176 (rec:0.542, round:63383.633)	b=20.00	count=4000
Total loss:	28520.771 (rec:0.565, round:28520.207)	b=19.44	count=4500
Total loss:	26057.379 (rec:0.594, round:26056.785)	b=18.88	count=5000
Total loss:	24296.307 (rec:0.497, round:24295.809)	b=18.31	count=5500
Total loss:	22714.871 (rec:0.468, round:22714.404)	b=17.75	count=6000
Total loss:	21233.420 (rec:0.493, round:21232.926)	b=17.19	count=6500
Total loss:	19823.568 (rec:0.491, round:19823.078)	b=16.62	count=7000
Total loss:	18465.268 (rec:0.480, round:18464.787)	b=16.06	count=7500
Total loss:	17153.289 (rec:0.457, round:17152.832)	b=15.50	count=8000
Total loss:	15894.281 (rec:0.455, round:15893.826)	b=14.94	count=8500
Total loss:	14683.870 (rec:0.448, round:14683.422)	b=14.38	count=9000
Total loss:	13518.368 (rec:0.451, round:13517.917)	b=13.81	count=9500
Total loss:	12406.278 (rec:0.489, round:12405.790)	b=13.25	count=10000
Total loss:	11335.494 (rec:0.475, round:11335.020)	b=12.69	count=10500
Total loss:	10306.428 (rec:0.505, round:10305.923)	b=12.12	count=11000
Total loss:	9310.081 (rec:0.462, round:9309.619)	b=11.56	count=11500
Total loss:	8343.878 (rec:0.498, round:8343.380)	b=11.00	count=12000
Total loss:	7414.987 (rec:0.457, round:7414.530)	b=10.44	count=12500
Total loss:	6514.649 (rec:0.503, round:6514.146)	b=9.88	count=13000
Total loss:	5646.346 (rec:0.488, round:5645.858)	b=9.31	count=13500
Total loss:	4812.701 (rec:0.456, round:4812.244)	b=8.75	count=14000
Total loss:	4015.169 (rec:0.429, round:4014.740)	b=8.19	count=14500
Total loss:	3255.829 (rec:0.455, round:3255.374)	b=7.62	count=15000
Total loss:	2533.469 (rec:0.495, round:2532.974)	b=7.06	count=15500
Total loss:	1864.320 (rec:0.454, round:1863.865)	b=6.50	count=16000
Total loss:	1239.442 (rec:0.487, round:1238.955)	b=5.94	count=16500
Total loss:	643.397 (rec:0.488, round:642.910)	b=5.38	count=17000
Total loss:	220.863 (rec:0.564, round:220.299)	b=4.81	count=17500
Total loss:	72.902 (rec:0.474, round:72.428)	b=4.25	count=18000
Total loss:	21.973 (rec:0.491, round:21.483)	b=3.69	count=18500
Total loss:	4.446 (rec:0.507, round:3.939)	b=3.12	count=19000
Total loss:	0.785 (rec:0.468, round:0.317)	b=2.56	count=19500
Total loss:	0.508 (rec:0.498, round:0.010)	b=2.00	count=20000
finished reconstructing blocks.2.
reconstructing blocks.3 ...
initializing raw input and raw output ...
adaround training for blocks.3 ...
wraping quantizers in blocks.3 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.976 (rec:0.976, round:0.000)	b=0.00	count=500
Total loss:	0.892 (rec:0.892, round:0.000)	b=0.00	count=1000
Total loss:	0.789 (rec:0.789, round:0.000)	b=0.00	count=1500
Total loss:	0.790 (rec:0.790, round:0.000)	b=0.00	count=2000
Total loss:	0.732 (rec:0.732, round:0.000)	b=0.00	count=2500
Total loss:	0.711 (rec:0.711, round:0.000)	b=0.00	count=3000
Total loss:	0.722 (rec:0.722, round:0.000)	b=0.00	count=3500
Total loss:	63558.988 (rec:0.641, round:63558.348)	b=20.00	count=4000
Total loss:	29324.682 (rec:0.627, round:29324.055)	b=19.44	count=4500
Total loss:	26836.227 (rec:0.644, round:26835.582)	b=18.88	count=5000
Total loss:	25065.664 (rec:0.677, round:25064.986)	b=18.31	count=5500
Total loss:	23474.100 (rec:0.636, round:23473.463)	b=17.75	count=6000
Total loss:	21950.496 (rec:0.618, round:21949.879)	b=17.19	count=6500
Total loss:	20483.967 (rec:0.637, round:20483.330)	b=16.62	count=7000
Total loss:	19084.461 (rec:0.595, round:19083.865)	b=16.06	count=7500
Total loss:	17747.312 (rec:0.641, round:17746.672)	b=15.50	count=8000
Total loss:	16457.492 (rec:0.620, round:16456.871)	b=14.94	count=8500
Total loss:	15223.238 (rec:0.626, round:15222.612)	b=14.38	count=9000
Total loss:	14031.683 (rec:0.607, round:14031.076)	b=13.81	count=9500
Total loss:	12886.562 (rec:0.599, round:12885.964)	b=13.25	count=10000
Total loss:	11776.388 (rec:0.591, round:11775.797)	b=12.69	count=10500
Total loss:	10701.568 (rec:0.593, round:10700.976)	b=12.12	count=11000
Total loss:	9672.317 (rec:0.606, round:9671.712)	b=11.56	count=11500
Total loss:	8673.694 (rec:0.601, round:8673.094)	b=11.00	count=12000
Total loss:	7711.243 (rec:0.591, round:7710.652)	b=10.44	count=12500
Total loss:	6782.824 (rec:0.645, round:6782.179)	b=9.88	count=13000
Total loss:	5883.870 (rec:0.638, round:5883.232)	b=9.31	count=13500
Total loss:	5019.301 (rec:0.635, round:5018.666)	b=8.75	count=14000
Total loss:	4195.674 (rec:0.648, round:4195.026)	b=8.19	count=14500
Total loss:	3405.247 (rec:0.657, round:3404.589)	b=7.62	count=15000
Total loss:	2664.835 (rec:0.639, round:2664.197)	b=7.06	count=15500
Total loss:	1970.592 (rec:0.613, round:1969.979)	b=6.50	count=16000
Total loss:	1319.321 (rec:0.626, round:1318.695)	b=5.94	count=16500
Total loss:	677.836 (rec:0.596, round:677.240)	b=5.38	count=17000
Total loss:	211.019 (rec:0.628, round:210.391)	b=4.81	count=17500
Total loss:	62.878 (rec:0.662, round:62.215)	b=4.25	count=18000
Total loss:	18.870 (rec:0.635, round:18.235)	b=3.69	count=18500
Total loss:	4.092 (rec:0.664, round:3.428)	b=3.12	count=19000
Total loss:	0.903 (rec:0.633, round:0.269)	b=2.56	count=19500
Total loss:	0.658 (rec:0.653, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.3.
reconstructing blocks.4 ...
initializing raw input and raw output ...
adaround training for blocks.4 ...
wraping quantizers in blocks.4 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.021 (rec:1.021, round:0.000)	b=0.00	count=500
Total loss:	0.923 (rec:0.923, round:0.000)	b=0.00	count=1000
Total loss:	0.843 (rec:0.843, round:0.000)	b=0.00	count=1500
Total loss:	0.771 (rec:0.771, round:0.000)	b=0.00	count=2000
Total loss:	0.742 (rec:0.742, round:0.000)	b=0.00	count=2500
Total loss:	0.684 (rec:0.684, round:0.000)	b=0.00	count=3000
Total loss:	0.680 (rec:0.680, round:0.000)	b=0.00	count=3500
Total loss:	63616.508 (rec:0.648, round:63615.859)	b=20.00	count=4000
Total loss:	29850.641 (rec:0.664, round:29849.977)	b=19.44	count=4500
Total loss:	27406.303 (rec:0.643, round:27405.660)	b=18.88	count=5000
Total loss:	25704.230 (rec:0.652, round:25703.578)	b=18.31	count=5500
Total loss:	24180.523 (rec:0.640, round:24179.883)	b=17.75	count=6000
Total loss:	22755.197 (rec:0.642, round:22754.555)	b=17.19	count=6500
Total loss:	21390.758 (rec:0.628, round:21390.129)	b=16.62	count=7000
Total loss:	20060.771 (rec:0.643, round:20060.129)	b=16.06	count=7500
Total loss:	18769.521 (rec:0.635, round:18768.887)	b=15.50	count=8000
Total loss:	17501.248 (rec:0.623, round:17500.625)	b=14.94	count=8500
Total loss:	16259.180 (rec:0.609, round:16258.570)	b=14.38	count=9000
Total loss:	15044.059 (rec:0.627, round:15043.432)	b=13.81	count=9500
Total loss:	13849.893 (rec:0.629, round:13849.264)	b=13.25	count=10000
Total loss:	12679.811 (rec:0.622, round:12679.188)	b=12.69	count=10500
Total loss:	11535.168 (rec:0.628, round:11534.540)	b=12.12	count=11000
Total loss:	10420.188 (rec:0.633, round:10419.555)	b=11.56	count=11500
Total loss:	9326.150 (rec:0.642, round:9325.508)	b=11.00	count=12000
Total loss:	8257.950 (rec:0.619, round:8257.332)	b=10.44	count=12500
Total loss:	7222.794 (rec:0.629, round:7222.165)	b=9.88	count=13000
Total loss:	6219.510 (rec:0.659, round:6218.852)	b=9.31	count=13500
Total loss:	5249.485 (rec:0.686, round:5248.799)	b=8.75	count=14000
Total loss:	4334.954 (rec:0.653, round:4334.301)	b=8.19	count=14500
Total loss:	3487.222 (rec:0.659, round:3486.562)	b=7.62	count=15000
Total loss:	2698.604 (rec:0.655, round:2697.949)	b=7.06	count=15500
Total loss:	1979.118 (rec:0.677, round:1978.441)	b=6.50	count=16000
Total loss:	1308.256 (rec:0.635, round:1307.622)	b=5.94	count=16500
Total loss:	652.905 (rec:0.653, round:652.252)	b=5.38	count=17000
Total loss:	223.204 (rec:0.632, round:222.572)	b=4.81	count=17500
Total loss:	72.943 (rec:0.634, round:72.309)	b=4.25	count=18000
Total loss:	20.421 (rec:0.659, round:19.762)	b=3.69	count=18500
Total loss:	4.224 (rec:0.671, round:3.552)	b=3.12	count=19000
Total loss:	0.965 (rec:0.670, round:0.294)	b=2.56	count=19500
Total loss:	0.676 (rec:0.660, round:0.016)	b=2.00	count=20000
finished reconstructing blocks.4.
reconstructing blocks.5 ...
initializing raw input and raw output ...
adaround training for blocks.5 ...
wraping quantizers in blocks.5 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.066 (rec:1.066, round:0.000)	b=0.00	count=500
Total loss:	0.910 (rec:0.910, round:0.000)	b=0.00	count=1000
Total loss:	0.861 (rec:0.861, round:0.000)	b=0.00	count=1500
Total loss:	0.804 (rec:0.804, round:0.000)	b=0.00	count=2000
Total loss:	0.763 (rec:0.763, round:0.000)	b=0.00	count=2500
Total loss:	0.725 (rec:0.725, round:0.000)	b=0.00	count=3000
Total loss:	0.714 (rec:0.714, round:0.000)	b=0.00	count=3500
Total loss:	63357.773 (rec:0.677, round:63357.098)	b=20.00	count=4000
Total loss:	29876.408 (rec:0.699, round:29875.709)	b=19.44	count=4500
Total loss:	27409.539 (rec:0.674, round:27408.865)	b=18.88	count=5000
Total loss:	25719.234 (rec:0.677, round:25718.559)	b=18.31	count=5500
Total loss:	24233.055 (rec:0.657, round:24232.398)	b=17.75	count=6000
Total loss:	22855.010 (rec:0.646, round:22854.363)	b=17.19	count=6500
Total loss:	21537.219 (rec:0.654, round:21536.564)	b=16.62	count=7000
Total loss:	20268.170 (rec:0.641, round:20267.529)	b=16.06	count=7500
Total loss:	19034.064 (rec:0.643, round:19033.422)	b=15.50	count=8000
Total loss:	17827.787 (rec:0.619, round:17827.168)	b=14.94	count=8500
Total loss:	16651.424 (rec:0.643, round:16650.781)	b=14.38	count=9000
Total loss:	15499.688 (rec:0.639, round:15499.049)	b=13.81	count=9500
Total loss:	14369.258 (rec:0.638, round:14368.620)	b=13.25	count=10000
Total loss:	13259.152 (rec:0.648, round:13258.504)	b=12.69	count=10500
Total loss:	12169.763 (rec:0.645, round:12169.118)	b=12.12	count=11000
Total loss:	11101.377 (rec:0.645, round:11100.732)	b=11.56	count=11500
Total loss:	10048.786 (rec:0.659, round:10048.127)	b=11.00	count=12000
Total loss:	9006.235 (rec:0.657, round:9005.578)	b=10.44	count=12500
Total loss:	7981.349 (rec:0.641, round:7980.708)	b=9.88	count=13000
Total loss:	6973.968 (rec:0.656, round:6973.312)	b=9.31	count=13500
Total loss:	5986.967 (rec:0.672, round:5986.295)	b=8.75	count=14000
Total loss:	5019.418 (rec:0.644, round:5018.774)	b=8.19	count=14500
Total loss:	4076.479 (rec:0.651, round:4075.828)	b=7.62	count=15000
Total loss:	3178.083 (rec:0.662, round:3177.421)	b=7.06	count=15500
Total loss:	2326.606 (rec:0.667, round:2325.939)	b=6.50	count=16000
Total loss:	1546.705 (rec:0.685, round:1546.020)	b=5.94	count=16500
Total loss:	862.767 (rec:0.663, round:862.104)	b=5.38	count=17000
Total loss:	376.426 (rec:0.686, round:375.740)	b=4.81	count=17500
Total loss:	123.583 (rec:0.686, round:122.897)	b=4.25	count=18000
Total loss:	26.191 (rec:0.688, round:25.504)	b=3.69	count=18500
Total loss:	4.687 (rec:0.701, round:3.986)	b=3.12	count=19000
Total loss:	1.019 (rec:0.709, round:0.310)	b=2.56	count=19500
Total loss:	0.689 (rec:0.684, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.5.
reconstructing blocks.6 ...
initializing raw input and raw output ...
adaround training for blocks.6 ...
wraping quantizers in blocks.6 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.096 (rec:1.096, round:0.000)	b=0.00	count=500
Total loss:	0.886 (rec:0.886, round:0.000)	b=0.00	count=1000
Total loss:	0.819 (rec:0.819, round:0.000)	b=0.00	count=1500
Total loss:	0.768 (rec:0.768, round:0.000)	b=0.00	count=2000
Total loss:	0.716 (rec:0.716, round:0.000)	b=0.00	count=2500
Total loss:	0.702 (rec:0.702, round:0.000)	b=0.00	count=3000
Total loss:	0.662 (rec:0.662, round:0.000)	b=0.00	count=3500
Total loss:	63546.332 (rec:0.653, round:63545.680)	b=20.00	count=4000
Total loss:	30254.648 (rec:0.651, round:30253.996)	b=19.44	count=4500
Total loss:	27808.420 (rec:0.647, round:27807.773)	b=18.88	count=5000
Total loss:	26120.418 (rec:0.632, round:26119.785)	b=18.31	count=5500
Total loss:	24638.695 (rec:0.617, round:24638.078)	b=17.75	count=6000
Total loss:	23252.639 (rec:0.609, round:23252.029)	b=17.19	count=6500
Total loss:	21929.197 (rec:0.608, round:21928.590)	b=16.62	count=7000
Total loss:	20646.469 (rec:0.597, round:20645.871)	b=16.06	count=7500
Total loss:	19403.291 (rec:0.610, round:19402.682)	b=15.50	count=8000
Total loss:	18189.729 (rec:0.611, round:18189.117)	b=14.94	count=8500
Total loss:	16998.762 (rec:0.604, round:16998.158)	b=14.38	count=9000
Total loss:	15835.509 (rec:0.583, round:15834.926)	b=13.81	count=9500
Total loss:	14688.386 (rec:0.591, round:14687.795)	b=13.25	count=10000
Total loss:	13564.133 (rec:0.593, round:13563.539)	b=12.69	count=10500
Total loss:	12458.426 (rec:0.595, round:12457.830)	b=12.12	count=11000
Total loss:	11375.548 (rec:0.578, round:11374.970)	b=11.56	count=11500
Total loss:	10310.025 (rec:0.584, round:10309.441)	b=11.00	count=12000
Total loss:	9255.401 (rec:0.596, round:9254.805)	b=10.44	count=12500
Total loss:	8216.326 (rec:0.589, round:8215.736)	b=9.88	count=13000
Total loss:	7192.753 (rec:0.586, round:7192.167)	b=9.31	count=13500
Total loss:	6183.413 (rec:0.604, round:6182.809)	b=8.75	count=14000
Total loss:	5195.269 (rec:0.596, round:5194.673)	b=8.19	count=14500
Total loss:	4234.841 (rec:0.597, round:4234.244)	b=7.62	count=15000
Total loss:	3311.266 (rec:0.599, round:3310.667)	b=7.06	count=15500
Total loss:	2429.981 (rec:0.612, round:2429.369)	b=6.50	count=16000
Total loss:	1622.317 (rec:0.627, round:1621.689)	b=5.94	count=16500
Total loss:	908.609 (rec:0.626, round:907.983)	b=5.38	count=17000
Total loss:	390.412 (rec:0.647, round:389.765)	b=4.81	count=17500
Total loss:	126.636 (rec:0.629, round:126.008)	b=4.25	count=18000
Total loss:	29.854 (rec:0.634, round:29.220)	b=3.69	count=18500
Total loss:	4.885 (rec:0.641, round:4.244)	b=3.12	count=19000
Total loss:	0.960 (rec:0.653, round:0.308)	b=2.56	count=19500
Total loss:	0.642 (rec:0.632, round:0.010)	b=2.00	count=20000
finished reconstructing blocks.6.
reconstructing blocks.7 ...
initializing raw input and raw output ...
adaround training for blocks.7 ...
wraping quantizers in blocks.7 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.184 (rec:1.184, round:0.000)	b=0.00	count=500
Total loss:	0.908 (rec:0.908, round:0.000)	b=0.00	count=1000
Total loss:	0.830 (rec:0.830, round:0.000)	b=0.00	count=1500
Total loss:	0.798 (rec:0.798, round:0.000)	b=0.00	count=2000
Total loss:	0.733 (rec:0.733, round:0.000)	b=0.00	count=2500
Total loss:	0.712 (rec:0.712, round:0.000)	b=0.00	count=3000
Total loss:	0.673 (rec:0.673, round:0.000)	b=0.00	count=3500
Total loss:	64058.734 (rec:0.678, round:64058.055)	b=20.00	count=4000
Total loss:	31313.232 (rec:0.672, round:31312.561)	b=19.44	count=4500
Total loss:	28899.729 (rec:0.670, round:28899.059)	b=18.88	count=5000
Total loss:	27271.199 (rec:0.659, round:27270.539)	b=18.31	count=5500
Total loss:	25852.289 (rec:0.653, round:25851.637)	b=17.75	count=6000
Total loss:	24528.223 (rec:0.637, round:24527.586)	b=17.19	count=6500
Total loss:	23255.545 (rec:0.636, round:23254.908)	b=16.62	count=7000
Total loss:	22012.979 (rec:0.639, round:22012.340)	b=16.06	count=7500
Total loss:	20789.361 (rec:0.652, round:20788.709)	b=15.50	count=8000
Total loss:	19590.986 (rec:0.638, round:19590.348)	b=14.94	count=8500
Total loss:	18408.461 (rec:0.648, round:18407.812)	b=14.38	count=9000
Total loss:	17238.064 (rec:0.639, round:17237.426)	b=13.81	count=9500
Total loss:	16080.293 (rec:0.638, round:16079.654)	b=13.25	count=10000
Total loss:	14928.507 (rec:0.659, round:14927.848)	b=12.69	count=10500
Total loss:	13786.473 (rec:0.638, round:13785.835)	b=12.12	count=11000
Total loss:	12650.901 (rec:0.648, round:12650.253)	b=11.56	count=11500
Total loss:	11522.705 (rec:0.659, round:11522.046)	b=11.00	count=12000
Total loss:	10401.000 (rec:0.656, round:10400.344)	b=10.44	count=12500
Total loss:	9285.697 (rec:0.654, round:9285.043)	b=9.88	count=13000
Total loss:	8178.998 (rec:0.666, round:8178.332)	b=9.31	count=13500
Total loss:	7082.216 (rec:0.657, round:7081.559)	b=8.75	count=14000
Total loss:	5999.010 (rec:0.664, round:5998.347)	b=8.19	count=14500
Total loss:	4935.983 (rec:0.674, round:4935.310)	b=7.62	count=15000
Total loss:	3906.470 (rec:0.681, round:3905.790)	b=7.06	count=15500
Total loss:	2920.845 (rec:0.697, round:2920.147)	b=6.50	count=16000
Total loss:	1997.893 (rec:0.705, round:1997.188)	b=5.94	count=16500
Total loss:	1168.996 (rec:0.712, round:1168.284)	b=5.38	count=17000
Total loss:	521.553 (rec:0.708, round:520.845)	b=4.81	count=17500
Total loss:	163.449 (rec:0.719, round:162.730)	b=4.25	count=18000
Total loss:	36.401 (rec:0.721, round:35.680)	b=3.69	count=18500
Total loss:	5.406 (rec:0.719, round:4.687)	b=3.12	count=19000
Total loss:	0.999 (rec:0.720, round:0.279)	b=2.56	count=19500
Total loss:	0.722 (rec:0.718, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.7.
reconstructing blocks.8 ...
initializing raw input and raw output ...
adaround training for blocks.8 ...
wraping quantizers in blocks.8 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.318 (rec:1.318, round:0.000)	b=0.00	count=500
Total loss:	1.112 (rec:1.112, round:0.000)	b=0.00	count=1000
Total loss:	0.994 (rec:0.994, round:0.000)	b=0.00	count=1500
Total loss:	0.947 (rec:0.947, round:0.000)	b=0.00	count=2000
Total loss:	0.889 (rec:0.889, round:0.000)	b=0.00	count=2500
Total loss:	0.885 (rec:0.885, round:0.000)	b=0.00	count=3000
Total loss:	0.809 (rec:0.809, round:0.000)	b=0.00	count=3500
Total loss:	64463.074 (rec:0.810, round:64462.266)	b=20.00	count=4000
Total loss:	32003.564 (rec:0.803, round:32002.762)	b=19.44	count=4500
Total loss:	29577.047 (rec:0.827, round:29576.221)	b=18.88	count=5000
Total loss:	27935.168 (rec:0.808, round:27934.359)	b=18.31	count=5500
Total loss:	26501.668 (rec:0.789, round:26500.879)	b=17.75	count=6000
Total loss:	25160.344 (rec:0.796, round:25159.547)	b=17.19	count=6500
Total loss:	23864.115 (rec:0.786, round:23863.330)	b=16.62	count=7000
Total loss:	22610.133 (rec:0.773, round:22609.359)	b=16.06	count=7500
Total loss:	21380.281 (rec:0.774, round:21379.508)	b=15.50	count=8000
Total loss:	20169.260 (rec:0.771, round:20168.488)	b=14.94	count=8500
Total loss:	18970.408 (rec:0.775, round:18969.633)	b=14.38	count=9000
Total loss:	17783.996 (rec:0.779, round:17783.217)	b=13.81	count=9500
Total loss:	16612.555 (rec:0.758, round:16611.797)	b=13.25	count=10000
Total loss:	15448.872 (rec:0.783, round:15448.089)	b=12.69	count=10500
Total loss:	14301.311 (rec:0.768, round:14300.543)	b=12.12	count=11000
Total loss:	13156.646 (rec:0.777, round:13155.869)	b=11.56	count=11500
Total loss:	12019.867 (rec:0.772, round:12019.095)	b=11.00	count=12000
Total loss:	10892.346 (rec:0.789, round:10891.557)	b=10.44	count=12500
Total loss:	9770.976 (rec:0.790, round:9770.186)	b=9.88	count=13000
Total loss:	8654.223 (rec:0.761, round:8653.462)	b=9.31	count=13500
Total loss:	7548.309 (rec:0.810, round:7547.499)	b=8.75	count=14000
Total loss:	6449.745 (rec:0.820, round:6448.925)	b=8.19	count=14500
Total loss:	5371.908 (rec:0.798, round:5371.111)	b=7.62	count=15000
Total loss:	4317.778 (rec:0.820, round:4316.958)	b=7.06	count=15500
Total loss:	3307.319 (rec:0.835, round:3306.483)	b=6.50	count=16000
Total loss:	2351.121 (rec:0.859, round:2350.262)	b=5.94	count=16500
Total loss:	1488.479 (rec:0.846, round:1487.634)	b=5.38	count=17000
Total loss:	767.950 (rec:0.867, round:767.084)	b=4.81	count=17500
Total loss:	283.068 (rec:0.851, round:282.217)	b=4.25	count=18000
Total loss:	66.177 (rec:0.871, round:65.307)	b=3.69	count=18500
Total loss:	8.271 (rec:0.892, round:7.380)	b=3.12	count=19000
Total loss:	1.266 (rec:0.895, round:0.371)	b=2.56	count=19500
Total loss:	0.887 (rec:0.879, round:0.008)	b=2.00	count=20000
finished reconstructing blocks.8.
reconstructing blocks.9 ...
initializing raw input and raw output ...
adaround training for blocks.9 ...
wraping quantizers in blocks.9 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.252 (rec:1.252, round:0.000)	b=0.00	count=500
Total loss:	1.135 (rec:1.135, round:0.000)	b=0.00	count=1000
Total loss:	1.158 (rec:1.158, round:0.000)	b=0.00	count=1500
Total loss:	1.039 (rec:1.039, round:0.000)	b=0.00	count=2000
Total loss:	0.967 (rec:0.967, round:0.000)	b=0.00	count=2500
Total loss:	0.920 (rec:0.920, round:0.000)	b=0.00	count=3000
Total loss:	0.902 (rec:0.902, round:0.000)	b=0.00	count=3500
Total loss:	64951.207 (rec:0.846, round:64950.359)	b=20.00	count=4000
Total loss:	32507.164 (rec:0.824, round:32506.340)	b=19.44	count=4500
Total loss:	30066.117 (rec:0.852, round:30065.266)	b=18.88	count=5000
Total loss:	28416.072 (rec:0.832, round:28415.240)	b=18.31	count=5500
Total loss:	26970.541 (rec:0.826, round:26969.715)	b=17.75	count=6000
Total loss:	25616.014 (rec:0.838, round:25615.176)	b=17.19	count=6500
Total loss:	24311.828 (rec:0.850, round:24310.979)	b=16.62	count=7000
Total loss:	23038.264 (rec:0.821, round:23037.441)	b=16.06	count=7500
Total loss:	21782.484 (rec:0.816, round:21781.668)	b=15.50	count=8000
Total loss:	20546.854 (rec:0.827, round:20546.027)	b=14.94	count=8500
Total loss:	19322.307 (rec:0.779, round:19321.527)	b=14.38	count=9000
Total loss:	18104.814 (rec:0.800, round:18104.016)	b=13.81	count=9500
Total loss:	16900.016 (rec:0.808, round:16899.207)	b=13.25	count=10000
Total loss:	15709.066 (rec:0.808, round:15708.258)	b=12.69	count=10500
Total loss:	14528.392 (rec:0.841, round:14527.550)	b=12.12	count=11000
Total loss:	13354.896 (rec:0.807, round:13354.090)	b=11.56	count=11500
Total loss:	12192.403 (rec:0.839, round:12191.564)	b=11.00	count=12000
Total loss:	11033.122 (rec:0.841, round:11032.281)	b=10.44	count=12500
Total loss:	9881.422 (rec:0.847, round:9880.575)	b=9.88	count=13000
Total loss:	8741.435 (rec:0.836, round:8740.599)	b=9.31	count=13500
Total loss:	7619.687 (rec:0.847, round:7618.840)	b=8.75	count=14000
Total loss:	6518.806 (rec:0.859, round:6517.947)	b=8.19	count=14500
Total loss:	5437.964 (rec:0.882, round:5437.083)	b=7.62	count=15000
Total loss:	4377.719 (rec:0.907, round:4376.812)	b=7.06	count=15500
Total loss:	3362.082 (rec:0.871, round:3361.211)	b=6.50	count=16000
Total loss:	2419.453 (rec:0.869, round:2418.584)	b=5.94	count=16500
Total loss:	1565.988 (rec:0.886, round:1565.103)	b=5.38	count=17000
Total loss:	856.562 (rec:0.901, round:855.660)	b=4.81	count=17500
Total loss:	352.621 (rec:0.903, round:351.718)	b=4.25	count=18000
Total loss:	90.100 (rec:0.913, round:89.187)	b=3.69	count=18500
Total loss:	12.251 (rec:0.947, round:11.304)	b=3.12	count=19000
Total loss:	1.514 (rec:0.944, round:0.570)	b=2.56	count=19500
Total loss:	0.967 (rec:0.958, round:0.009)	b=2.00	count=20000
finished reconstructing blocks.9.
reconstructing blocks.10 ...
initializing raw input and raw output ...
adaround training for blocks.10 ...
wraping quantizers in blocks.10 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.360 (rec:1.360, round:0.000)	b=0.00	count=500
Total loss:	1.092 (rec:1.092, round:0.000)	b=0.00	count=1000
Total loss:	0.989 (rec:0.989, round:0.000)	b=0.00	count=1500
Total loss:	0.935 (rec:0.935, round:0.000)	b=0.00	count=2000
Total loss:	0.885 (rec:0.885, round:0.000)	b=0.00	count=2500
Total loss:	0.819 (rec:0.819, round:0.000)	b=0.00	count=3000
Total loss:	0.828 (rec:0.828, round:0.000)	b=0.00	count=3500
Total loss:	65202.250 (rec:0.728, round:65201.523)	b=20.00	count=4000
Total loss:	32856.277 (rec:0.714, round:32855.562)	b=19.44	count=4500
Total loss:	30369.814 (rec:0.767, round:30369.047)	b=18.88	count=5000
Total loss:	28680.279 (rec:0.745, round:28679.535)	b=18.31	count=5500
Total loss:	27182.199 (rec:0.716, round:27181.482)	b=17.75	count=6000
Total loss:	25767.174 (rec:0.701, round:25766.473)	b=17.19	count=6500
Total loss:	24389.881 (rec:0.721, round:24389.160)	b=16.62	count=7000
Total loss:	23031.117 (rec:0.718, round:23030.398)	b=16.06	count=7500
Total loss:	21696.850 (rec:0.716, round:21696.133)	b=15.50	count=8000
Total loss:	20378.719 (rec:0.685, round:20378.033)	b=14.94	count=8500
Total loss:	19069.918 (rec:0.714, round:19069.203)	b=14.38	count=9000
Total loss:	17768.932 (rec:0.666, round:17768.266)	b=13.81	count=9500
Total loss:	16482.697 (rec:0.690, round:16482.006)	b=13.25	count=10000
Total loss:	15216.562 (rec:0.685, round:15215.877)	b=12.69	count=10500
Total loss:	13977.104 (rec:0.700, round:13976.404)	b=12.12	count=11000
Total loss:	12755.910 (rec:0.719, round:12755.190)	b=11.56	count=11500
Total loss:	11560.370 (rec:0.679, round:11559.691)	b=11.00	count=12000
Total loss:	10382.019 (rec:0.731, round:10381.288)	b=10.44	count=12500
Total loss:	9229.195 (rec:0.704, round:9228.491)	b=9.88	count=13000
Total loss:	8107.569 (rec:0.681, round:8106.888)	b=9.31	count=13500
Total loss:	7007.731 (rec:0.700, round:7007.031)	b=8.75	count=14000
Total loss:	5939.622 (rec:0.730, round:5938.892)	b=8.19	count=14500
Total loss:	4899.593 (rec:0.729, round:4898.865)	b=7.62	count=15000
Total loss:	3907.577 (rec:0.739, round:3906.838)	b=7.06	count=15500
Total loss:	2972.362 (rec:0.753, round:2971.609)	b=6.50	count=16000
Total loss:	2103.625 (rec:0.776, round:2102.849)	b=5.94	count=16500
Total loss:	1342.726 (rec:0.762, round:1341.964)	b=5.38	count=17000
Total loss:	722.286 (rec:0.769, round:721.517)	b=4.81	count=17500
Total loss:	291.423 (rec:0.760, round:290.663)	b=4.25	count=18000
Total loss:	74.285 (rec:0.784, round:73.502)	b=3.69	count=18500
Total loss:	10.052 (rec:0.783, round:9.269)	b=3.12	count=19000
Total loss:	1.276 (rec:0.773, round:0.503)	b=2.56	count=19500
Total loss:	0.801 (rec:0.793, round:0.009)	b=2.00	count=20000
finished reconstructing blocks.10.
reconstructing blocks.11 ...
initializing raw input and raw output ...
adaround training for blocks.11 ...
wraping quantizers in blocks.11 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.762 (rec:0.762, round:0.000)	b=0.00	count=500
Total loss:	0.602 (rec:0.602, round:0.000)	b=0.00	count=1000
Total loss:	0.558 (rec:0.558, round:0.000)	b=0.00	count=1500
Total loss:	0.485 (rec:0.485, round:0.000)	b=0.00	count=2000
Total loss:	0.450 (rec:0.450, round:0.000)	b=0.00	count=2500
Total loss:	0.418 (rec:0.418, round:0.000)	b=0.00	count=3000
Total loss:	0.403 (rec:0.403, round:0.000)	b=0.00	count=3500
Total loss:	64714.926 (rec:0.392, round:64714.535)	b=20.00	count=4000
Total loss:	31390.871 (rec:0.384, round:31390.488)	b=19.44	count=4500
Total loss:	29003.498 (rec:0.370, round:29003.129)	b=18.88	count=5000
Total loss:	27401.959 (rec:0.396, round:27401.562)	b=18.31	count=5500
Total loss:	25986.254 (rec:0.375, round:25985.879)	b=17.75	count=6000
Total loss:	24629.020 (rec:0.376, round:24628.645)	b=17.19	count=6500
Total loss:	23306.143 (rec:0.357, round:23305.785)	b=16.62	count=7000
Total loss:	21997.426 (rec:0.355, round:21997.070)	b=16.06	count=7500
Total loss:	20706.527 (rec:0.337, round:20706.191)	b=15.50	count=8000
Total loss:	19422.582 (rec:0.347, round:19422.236)	b=14.94	count=8500
Total loss:	18144.590 (rec:0.346, round:18144.244)	b=14.38	count=9000
Total loss:	16872.523 (rec:0.339, round:16872.186)	b=13.81	count=9500
Total loss:	15613.333 (rec:0.341, round:15612.992)	b=13.25	count=10000
Total loss:	14370.887 (rec:0.334, round:14370.553)	b=12.69	count=10500
Total loss:	13147.117 (rec:0.326, round:13146.791)	b=12.12	count=11000
Total loss:	11943.030 (rec:0.352, round:11942.679)	b=11.56	count=11500
Total loss:	10761.555 (rec:0.332, round:10761.223)	b=11.00	count=12000
Total loss:	9604.687 (rec:0.344, round:9604.343)	b=10.44	count=12500
Total loss:	8487.116 (rec:0.332, round:8486.785)	b=9.88	count=13000
Total loss:	7396.020 (rec:0.344, round:7395.676)	b=9.31	count=13500
Total loss:	6333.061 (rec:0.347, round:6332.713)	b=8.75	count=14000
Total loss:	5313.049 (rec:0.333, round:5312.716)	b=8.19	count=14500
Total loss:	4334.794 (rec:0.334, round:4334.459)	b=7.62	count=15000
Total loss:	3405.548 (rec:0.348, round:3405.200)	b=7.06	count=15500
Total loss:	2536.275 (rec:0.353, round:2535.922)	b=6.50	count=16000
Total loss:	1739.662 (rec:0.357, round:1739.304)	b=5.94	count=16500
Total loss:	1042.202 (rec:0.347, round:1041.855)	b=5.38	count=17000
Total loss:	497.971 (rec:0.342, round:497.629)	b=4.81	count=17500
Total loss:	170.191 (rec:0.364, round:169.826)	b=4.25	count=18000
Total loss:	38.942 (rec:0.365, round:38.577)	b=3.69	count=18500
Total loss:	5.450 (rec:0.377, round:5.073)	b=3.12	count=19000
Total loss:	0.693 (rec:0.372, round:0.321)	b=2.56	count=19500
Total loss:	0.367 (rec:0.361, round:0.005)	b=2.00	count=20000
finished reconstructing blocks.11.
reconstructing head ...
initializing raw input and raw output ...
adaround training for head ...
wraping quantizers in head ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.408 (rec:1.408, round:0.000)	b=0.00	count=500
Total loss:	0.845 (rec:0.845, round:0.000)	b=0.00	count=1000
Total loss:	0.491 (rec:0.491, round:0.000)	b=0.00	count=1500
Total loss:	0.375 (rec:0.375, round:0.000)	b=0.00	count=2000
Total loss:	0.273 (rec:0.273, round:0.000)	b=0.00	count=2500
Total loss:	0.212 (rec:0.212, round:0.000)	b=0.00	count=3000
Total loss:	0.169 (rec:0.169, round:0.000)	b=0.00	count=3500
Total loss:	7000.799 (rec:0.149, round:7000.650)	b=20.00	count=4000
Total loss:	3823.923 (rec:0.120, round:3823.802)	b=19.44	count=4500
Total loss:	3550.283 (rec:0.093, round:3550.190)	b=18.88	count=5000
Total loss:	3370.592 (rec:0.083, round:3370.509)	b=18.31	count=5500
Total loss:	3220.192 (rec:0.083, round:3220.109)	b=17.75	count=6000
Total loss:	3080.423 (rec:0.063, round:3080.360)	b=17.19	count=6500
Total loss:	2942.767 (rec:0.074, round:2942.694)	b=16.62	count=7000
Total loss:	2805.812 (rec:0.063, round:2805.749)	b=16.06	count=7500
Total loss:	2669.852 (rec:0.056, round:2669.796)	b=15.50	count=8000
Total loss:	2534.297 (rec:0.045, round:2534.252)	b=14.94	count=8500
Total loss:	2397.212 (rec:0.062, round:2397.150)	b=14.38	count=9000
Total loss:	2261.058 (rec:0.047, round:2261.011)	b=13.81	count=9500
Total loss:	2124.537 (rec:0.051, round:2124.486)	b=13.25	count=10000
Total loss:	1986.278 (rec:0.050, round:1986.228)	b=12.69	count=10500
Total loss:	1844.828 (rec:0.053, round:1844.775)	b=12.12	count=11000
Total loss:	1705.794 (rec:0.051, round:1705.743)	b=11.56	count=11500
Total loss:	1565.453 (rec:0.043, round:1565.410)	b=11.00	count=12000
Total loss:	1425.346 (rec:0.047, round:1425.299)	b=10.44	count=12500
Total loss:	1285.905 (rec:0.053, round:1285.852)	b=9.88	count=13000
Total loss:	1146.530 (rec:0.045, round:1146.485)	b=9.31	count=13500
Total loss:	1008.403 (rec:0.046, round:1008.357)	b=8.75	count=14000
Total loss:	870.877 (rec:0.047, round:870.830)	b=8.19	count=14500
Total loss:	738.346 (rec:0.048, round:738.298)	b=7.62	count=15000
Total loss:	608.578 (rec:0.054, round:608.524)	b=7.06	count=15500
Total loss:	481.592 (rec:0.048, round:481.544)	b=6.50	count=16000
Total loss:	362.463 (rec:0.049, round:362.414)	b=5.94	count=16500
Total loss:	251.068 (rec:0.056, round:251.012)	b=5.38	count=17000
Total loss:	152.339 (rec:0.055, round:152.284)	b=4.81	count=17500
Total loss:	71.888 (rec:0.055, round:71.833)	b=4.25	count=18000
Total loss:	22.030 (rec:0.060, round:21.970)	b=3.69	count=18500
Total loss:	3.469 (rec:0.057, round:3.411)	b=3.12	count=19000
Total loss:	0.269 (rec:0.057, round:0.212)	b=2.56	count=19500
Total loss:	0.065 (rec:0.061, round:0.005)	b=2.00	count=20000
finished reconstructing head.
2025-09-10 16:26:40 - mse guided block reconstruction finished.
Saving checkpoint to ./checkpoint/quant_result/20250910_1308/deit_base_w2_a2_optimsize_1024_mse_rinp.pth
Validating on calibration set after block reconstruction ...
Test: [0/32]	Time 0.563 (0.563)	Loss 3.9355 (3.9355)	Prec@1 31.250 (31.250)	Prec@5 65.625 (65.625)
Test: [10/32]	Time 0.076 (0.120)	Loss 4.3130 (4.0193)	Prec@1 34.375 (38.920)	Prec@5 56.250 (57.386)
Test: [20/32]	Time 0.076 (0.099)	Loss 3.8228 (3.8779)	Prec@1 37.500 (40.030)	Prec@5 56.250 (59.077)
Test: [30/32]	Time 0.076 (0.092)	Loss 4.3516 (3.9372)	Prec@1 28.125 (38.911)	Prec@5 53.125 (57.964)
 * Prec@1 39.258 Prec@5 58.594 Loss 3.927 Time 3.067
Validating on test set after block reconstruction ...
Test: [0/100]	Time 13.916 (13.916)	Loss 4.5575 (4.5575)	Prec@1 25.200 (25.200)	Prec@5 49.200 (49.200)
Test: [10/100]	Time 1.665 (2.779)	Loss 5.0159 (5.2493)	Prec@1 18.800 (15.255)	Prec@5 40.000 (30.455)
Test: [20/100]	Time 1.662 (2.248)	Loss 5.1243 (5.1794)	Prec@1 15.000 (16.429)	Prec@5 34.800 (32.457)
Test: [30/100]	Time 1.666 (2.060)	Loss 4.4627 (5.1594)	Prec@1 28.000 (16.181)	Prec@5 49.000 (32.742)
Test: [40/100]	Time 1.667 (1.964)	Loss 5.0071 (5.1740)	Prec@1 14.600 (15.917)	Prec@5 32.600 (32.522)
Test: [50/100]	Time 1.669 (1.906)	Loss 5.3365 (5.2266)	Prec@1 10.400 (15.133)	Prec@5 23.000 (31.031)
Test: [60/100]	Time 1.669 (1.867)	Loss 4.9236 (5.2517)	Prec@1 20.600 (14.620)	Prec@5 33.200 (30.210)
Test: [70/100]	Time 1.666 (1.839)	Loss 5.3689 (5.2777)	Prec@1 12.200 (14.059)	Prec@5 21.800 (29.270)
Test: [80/100]	Time 1.667 (1.817)	Loss 5.4328 (5.3103)	Prec@1 12.400 (13.659)	Prec@5 22.200 (28.543)
Test: [90/100]	Time 1.663 (1.801)	Loss 5.3287 (5.3076)	Prec@1 10.600 (13.516)	Prec@5 24.200 (28.343)
 * Prec@1 13.876 Prec@5 28.696 Loss 5.303 Time 179.105
2025-09-10 16:29:43 - finished the process.
Extracting logits from quantized and full-precision models...
Testing combinations:
  Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  Cluster numbers: [8, 16, 32, 64, 128, 256]
  PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.85%
Result: Top-1: 13.99%, Top-5: 28.85%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.85%
Result: Top-1: 14.03%, Top-5: 28.85%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.02%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.03%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.02%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.05%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.02%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.84%
Result: Top-1: 14.04%, Top-5: 28.84%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 14.05%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.05%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.85%
Result: Top-1: 13.99%, Top-5: 28.85%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.03%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.01%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 14.03%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.05%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.01%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.90%
Result: Top-1: 14.03%, Top-5: 28.90%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.00%
[Alpha=0.10] Top-5 Accuracy: 28.85%
Result: Top-1: 14.00%, Top-5: 28.85%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.01%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 14.05%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.00%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 14.00%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.01%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.06%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 14.06%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.92%
Result: Top-1: 13.99%, Top-5: 28.92%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.90%
Result: Top-1: 14.04%, Top-5: 28.90%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 13.99%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.04%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.02%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.87%
Result: Top-1: 14.03%, Top-5: 28.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.06%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.06%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.97%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 13.97%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.01%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.93%
Result: Top-1: 14.05%, Top-5: 28.93%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.92%
Result: Top-1: 14.03%, Top-5: 28.92%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.90%
Result: Top-1: 14.04%, Top-5: 28.90%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.01%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.00%
[Alpha=0.10] Top-5 Accuracy: 28.85%
Result: Top-1: 14.00%, Top-5: 28.85%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.98%
[Alpha=0.10] Top-5 Accuracy: 28.90%
Result: Top-1: 13.98%, Top-5: 28.90%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 13.99%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.97%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 13.97%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.94%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 13.94%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.02%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.03%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.00%
[Alpha=0.10] Top-5 Accuracy: 28.93%
Result: Top-1: 14.00%, Top-5: 28.93%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.01%
[Alpha=0.10] Top-5 Accuracy: 28.89%
Result: Top-1: 14.01%, Top-5: 28.89%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.05%
[Alpha=0.10] Top-5 Accuracy: 28.90%
Result: Top-1: 14.05%, Top-5: 28.90%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.06%
[Alpha=0.10] Top-5 Accuracy: 28.93%
Result: Top-1: 14.06%, Top-5: 28.93%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.83%
Result: Top-1: 14.02%, Top-5: 28.83%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.03%
[Alpha=0.10] Top-5 Accuracy: 28.93%
Result: Top-1: 14.03%, Top-5: 28.93%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 14.04%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.95%
[Alpha=0.10] Top-5 Accuracy: 28.86%
Result: Top-1: 13.95%, Top-5: 28.86%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.96%
[Alpha=0.10] Top-5 Accuracy: 29.00%
Result: Top-1: 13.96%, Top-5: 29.00%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.91%
Result: Top-1: 13.99%, Top-5: 28.91%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.88%
Result: Top-1: 14.04%, Top-5: 28.88%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.04%
[Alpha=0.10] Top-5 Accuracy: 28.91%
Result: Top-1: 14.04%, Top-5: 28.91%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.99%
[Alpha=0.10] Top-5 Accuracy: 28.84%
Result: Top-1: 13.99%, Top-5: 28.84%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.93%
Result: Top-1: 14.02%, Top-5: 28.93%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.85%
Result: Top-1: 14.02%, Top-5: 28.85%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 13.94%
[Alpha=0.10] Top-5 Accuracy: 28.84%
Result: Top-1: 13.94%, Top-5: 28.84%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 14.02%
[Alpha=0.10] Top-5 Accuracy: 28.82%
Result: Top-1: 14.02%, Top-5: 28.82%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.08%
[Alpha=0.20] Top-5 Accuracy: 28.98%
Result: Top-1: 14.08%, Top-5: 28.98%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.10%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.10%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.02%
Result: Top-1: 14.12%, Top-5: 29.02%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 28.98%
Result: Top-1: 14.13%, Top-5: 28.98%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.12%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.15%
[Alpha=0.20] Top-5 Accuracy: 29.00%
Result: Top-1: 14.15%, Top-5: 29.00%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.10%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.10%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.14%
[Alpha=0.20] Top-5 Accuracy: 29.02%
Result: Top-1: 14.14%, Top-5: 29.02%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.15%
[Alpha=0.20] Top-5 Accuracy: 29.02%
Result: Top-1: 14.15%, Top-5: 29.02%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.14%
[Alpha=0.20] Top-5 Accuracy: 29.00%
Result: Top-1: 14.14%, Top-5: 29.00%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.06%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.06%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.12%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.10%
[Alpha=0.20] Top-5 Accuracy: 29.03%
Result: Top-1: 14.10%, Top-5: 29.03%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.09%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.09%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.12%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.09%
[Alpha=0.20] Top-5 Accuracy: 29.05%
Result: Top-1: 14.09%, Top-5: 29.05%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.14%
[Alpha=0.20] Top-5 Accuracy: 29.10%
Result: Top-1: 14.14%, Top-5: 29.10%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.11%
[Alpha=0.20] Top-5 Accuracy: 29.03%
Result: Top-1: 14.11%, Top-5: 29.03%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.10%
[Alpha=0.20] Top-5 Accuracy: 29.02%
Result: Top-1: 14.10%, Top-5: 29.02%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.13%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.05%
[Alpha=0.20] Top-5 Accuracy: 28.96%
Result: Top-1: 14.05%, Top-5: 28.96%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.13%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.22%
[Alpha=0.20] Top-5 Accuracy: 28.99%
Result: Top-1: 14.22%, Top-5: 28.99%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.14%
[Alpha=0.20] Top-5 Accuracy: 29.03%
Result: Top-1: 14.14%, Top-5: 29.03%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.16%
[Alpha=0.20] Top-5 Accuracy: 28.98%
Result: Top-1: 14.16%, Top-5: 28.98%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.13%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 29.06%
Result: Top-1: 14.13%, Top-5: 29.06%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.13%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.16%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.16%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.15%
[Alpha=0.20] Top-5 Accuracy: 29.00%
Result: Top-1: 14.15%, Top-5: 29.00%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.04%
[Alpha=0.20] Top-5 Accuracy: 28.96%
Result: Top-1: 14.04%, Top-5: 28.96%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 28.99%
Result: Top-1: 14.13%, Top-5: 28.99%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.10%
[Alpha=0.20] Top-5 Accuracy: 29.09%
Result: Top-1: 14.10%, Top-5: 29.09%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.13%
[Alpha=0.20] Top-5 Accuracy: 29.07%
Result: Top-1: 14.13%, Top-5: 29.07%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.18%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.18%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.12%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.07%
[Alpha=0.20] Top-5 Accuracy: 28.99%
Result: Top-1: 14.07%, Top-5: 28.99%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.08%
[Alpha=0.20] Top-5 Accuracy: 29.05%
Result: Top-1: 14.08%, Top-5: 29.05%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.05%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.05%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.08%
[Alpha=0.20] Top-5 Accuracy: 28.91%
Result: Top-1: 14.08%, Top-5: 28.91%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 13.98%
[Alpha=0.20] Top-5 Accuracy: 28.97%
Result: Top-1: 13.98%, Top-5: 28.97%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.10%
[Alpha=0.20] Top-5 Accuracy: 29.08%
Result: Top-1: 14.10%, Top-5: 29.08%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.03%
[Alpha=0.20] Top-5 Accuracy: 29.05%
Result: Top-1: 14.03%, Top-5: 29.05%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.07%
Result: Top-1: 14.12%, Top-5: 29.07%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.07%
[Alpha=0.20] Top-5 Accuracy: 29.05%
Result: Top-1: 14.07%, Top-5: 29.05%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.12%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.16%
[Alpha=0.20] Top-5 Accuracy: 29.05%
Result: Top-1: 14.16%, Top-5: 29.05%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.02%
[Alpha=0.20] Top-5 Accuracy: 28.97%
Result: Top-1: 14.02%, Top-5: 28.97%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.12%
[Alpha=0.20] Top-5 Accuracy: 29.04%
Result: Top-1: 14.12%, Top-5: 29.04%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.11%
[Alpha=0.20] Top-5 Accuracy: 28.90%
Result: Top-1: 14.11%, Top-5: 28.90%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 13.97%
[Alpha=0.20] Top-5 Accuracy: 28.96%
Result: Top-1: 13.97%, Top-5: 28.96%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.09%
[Alpha=0.20] Top-5 Accuracy: 29.10%
Result: Top-1: 14.09%, Top-5: 29.10%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.04%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.04%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.08%
[Alpha=0.20] Top-5 Accuracy: 28.91%
Result: Top-1: 14.08%, Top-5: 28.91%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 13.98%
[Alpha=0.20] Top-5 Accuracy: 29.03%
Result: Top-1: 13.98%, Top-5: 29.03%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.09%
[Alpha=0.20] Top-5 Accuracy: 28.92%
Result: Top-1: 14.09%, Top-5: 28.92%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.07%
[Alpha=0.20] Top-5 Accuracy: 29.01%
Result: Top-1: 14.07%, Top-5: 29.01%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.00%
[Alpha=0.20] Top-5 Accuracy: 28.96%
Result: Top-1: 14.00%, Top-5: 28.96%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 14.00%
[Alpha=0.20] Top-5 Accuracy: 28.93%
Result: Top-1: 14.00%, Top-5: 28.93%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 13.92%
[Alpha=0.20] Top-5 Accuracy: 28.82%
Result: Top-1: 13.92%, Top-5: 28.82%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.09%
[Alpha=0.30] Top-5 Accuracy: 29.05%
Result: Top-1: 14.09%, Top-5: 29.05%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.01%
[Alpha=0.30] Top-5 Accuracy: 28.91%
Result: Top-1: 14.01%, Top-5: 28.91%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.00%
[Alpha=0.30] Top-5 Accuracy: 28.94%
Result: Top-1: 14.00%, Top-5: 28.94%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.94%
[Alpha=0.30] Top-5 Accuracy: 28.85%
Result: Top-1: 13.94%, Top-5: 28.85%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.00%
[Alpha=0.30] Top-5 Accuracy: 28.95%
Result: Top-1: 14.00%, Top-5: 28.95%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.98%
[Alpha=0.30] Top-5 Accuracy: 28.86%
Result: Top-1: 13.98%, Top-5: 28.86%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.01%
[Alpha=0.30] Top-5 Accuracy: 28.91%
Result: Top-1: 14.01%, Top-5: 28.91%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.02%
[Alpha=0.30] Top-5 Accuracy: 28.92%
Result: Top-1: 14.02%, Top-5: 28.92%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.98%
[Alpha=0.30] Top-5 Accuracy: 28.87%
Result: Top-1: 13.98%, Top-5: 28.87%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.95%
[Alpha=0.30] Top-5 Accuracy: 28.91%
Result: Top-1: 13.95%, Top-5: 28.91%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.09%
[Alpha=0.30] Top-5 Accuracy: 29.03%
Result: Top-1: 14.09%, Top-5: 29.03%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.00%
[Alpha=0.30] Top-5 Accuracy: 29.05%
Result: Top-1: 14.00%, Top-5: 29.05%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.99%
[Alpha=0.30] Top-5 Accuracy: 29.02%
Result: Top-1: 13.99%, Top-5: 29.02%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.98%
[Alpha=0.30] Top-5 Accuracy: 28.92%
Result: Top-1: 13.98%, Top-5: 28.92%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.99%
[Alpha=0.30] Top-5 Accuracy: 28.97%
Result: Top-1: 13.99%, Top-5: 28.97%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.97%
[Alpha=0.30] Top-5 Accuracy: 28.93%
Result: Top-1: 13.97%, Top-5: 28.93%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.05%
[Alpha=0.30] Top-5 Accuracy: 29.04%
Result: Top-1: 14.05%, Top-5: 29.04%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.00%
[Alpha=0.30] Top-5 Accuracy: 29.00%
Result: Top-1: 14.00%, Top-5: 29.00%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.01%
[Alpha=0.30] Top-5 Accuracy: 28.95%
Result: Top-1: 14.01%, Top-5: 28.95%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.01%
[Alpha=0.30] Top-5 Accuracy: 28.95%
Result: Top-1: 14.01%, Top-5: 28.95%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.06%
[Alpha=0.30] Top-5 Accuracy: 29.03%
Result: Top-1: 14.06%, Top-5: 29.03%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.03%
[Alpha=0.30] Top-5 Accuracy: 29.04%
Result: Top-1: 14.03%, Top-5: 29.04%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.14%
[Alpha=0.30] Top-5 Accuracy: 29.07%
Result: Top-1: 14.14%, Top-5: 29.07%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.02%
[Alpha=0.30] Top-5 Accuracy: 28.96%
Result: Top-1: 14.02%, Top-5: 28.96%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.07%
[Alpha=0.30] Top-5 Accuracy: 28.95%
Result: Top-1: 14.07%, Top-5: 28.95%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.99%
[Alpha=0.30] Top-5 Accuracy: 28.98%
Result: Top-1: 13.99%, Top-5: 28.98%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.93%
[Alpha=0.30] Top-5 Accuracy: 28.96%
Result: Top-1: 13.93%, Top-5: 28.96%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.92%
[Alpha=0.30] Top-5 Accuracy: 29.01%
Result: Top-1: 13.92%, Top-5: 29.01%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.04%
[Alpha=0.30] Top-5 Accuracy: 28.97%
Result: Top-1: 14.04%, Top-5: 28.97%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.02%
[Alpha=0.30] Top-5 Accuracy: 29.05%
Result: Top-1: 14.02%, Top-5: 29.05%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.96%
[Alpha=0.30] Top-5 Accuracy: 29.07%
Result: Top-1: 13.96%, Top-5: 29.07%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.94%
[Alpha=0.30] Top-5 Accuracy: 29.01%
Result: Top-1: 13.94%, Top-5: 29.01%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.04%
[Alpha=0.30] Top-5 Accuracy: 29.06%
Result: Top-1: 14.04%, Top-5: 29.06%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.96%
[Alpha=0.30] Top-5 Accuracy: 29.00%
Result: Top-1: 13.96%, Top-5: 29.00%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 14.04%
[Alpha=0.30] Top-5 Accuracy: 28.88%
Result: Top-1: 14.04%, Top-5: 28.88%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.95%
[Alpha=0.30] Top-5 Accuracy: 28.94%
Result: Top-1: 13.95%, Top-5: 28.94%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.96%
[Alpha=0.30] Top-5 Accuracy: 28.98%
Result: Top-1: 13.96%, Top-5: 28.98%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.96%
[Alpha=0.30] Top-5 Accuracy: 28.98%
Result: Top-1: 13.96%, Top-5: 28.98%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.92%
[Alpha=0.30] Top-5 Accuracy: 28.98%
Result: Top-1: 13.92%, Top-5: 28.98%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.90%
[Alpha=0.30] Top-5 Accuracy: 28.80%
Result: Top-1: 13.90%, Top-5: 28.80%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.91%
[Alpha=0.30] Top-5 Accuracy: 28.99%
Result: Top-1: 13.91%, Top-5: 28.99%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.90%
[Alpha=0.30] Top-5 Accuracy: 28.91%
Result: Top-1: 13.90%, Top-5: 28.91%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.85%
[Alpha=0.30] Top-5 Accuracy: 28.83%
Result: Top-1: 13.85%, Top-5: 28.83%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.93%
[Alpha=0.30] Top-5 Accuracy: 28.99%
Result: Top-1: 13.93%, Top-5: 28.99%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.74%
[Alpha=0.30] Top-5 Accuracy: 28.82%
Result: Top-1: 13.74%, Top-5: 28.82%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.85%
[Alpha=0.30] Top-5 Accuracy: 28.83%
Result: Top-1: 13.85%, Top-5: 28.83%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.97%
[Alpha=0.30] Top-5 Accuracy: 28.97%
Result: Top-1: 13.97%, Top-5: 28.97%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.88%
[Alpha=0.30] Top-5 Accuracy: 28.85%
Result: Top-1: 13.88%, Top-5: 28.85%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.89%
[Alpha=0.30] Top-5 Accuracy: 28.85%
Result: Top-1: 13.89%, Top-5: 28.85%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.79%
[Alpha=0.30] Top-5 Accuracy: 28.70%
Result: Top-1: 13.79%, Top-5: 28.70%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.85%
[Alpha=0.30] Top-5 Accuracy: 28.81%
Result: Top-1: 13.85%, Top-5: 28.81%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.79%
[Alpha=0.30] Top-5 Accuracy: 28.76%
Result: Top-1: 13.79%, Top-5: 28.76%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.65%
[Alpha=0.30] Top-5 Accuracy: 28.70%
Result: Top-1: 13.65%, Top-5: 28.70%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.71%
[Alpha=0.30] Top-5 Accuracy: 28.59%
Result: Top-1: 13.71%, Top-5: 28.59%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.76%
[Alpha=0.30] Top-5 Accuracy: 28.71%
Result: Top-1: 13.76%, Top-5: 28.71%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.76%
[Alpha=0.30] Top-5 Accuracy: 28.62%
Result: Top-1: 13.76%, Top-5: 28.62%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.78%
[Alpha=0.30] Top-5 Accuracy: 28.58%
Result: Top-1: 13.78%, Top-5: 28.58%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.80%
[Alpha=0.30] Top-5 Accuracy: 28.76%
Result: Top-1: 13.80%, Top-5: 28.76%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.74%
[Alpha=0.30] Top-5 Accuracy: 28.69%
Result: Top-1: 13.74%, Top-5: 28.69%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 13.60%
[Alpha=0.30] Top-5 Accuracy: 28.42%
Result: Top-1: 13.60%, Top-5: 28.42%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 13.93%
[Alpha=0.40] Top-5 Accuracy: 28.92%
Result: Top-1: 13.93%, Top-5: 28.92%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.18%
[Alpha=0.40] Top-5 Accuracy: 28.27%
Result: Top-1: 12.18%, Top-5: 28.27%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.25%
[Alpha=0.40] Top-5 Accuracy: 28.34%
Result: Top-1: 12.25%, Top-5: 28.34%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.37%
[Alpha=0.40] Top-5 Accuracy: 28.52%
Result: Top-1: 12.37%, Top-5: 28.52%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.33%
[Alpha=0.40] Top-5 Accuracy: 28.38%
Result: Top-1: 12.33%, Top-5: 28.38%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.55%
[Alpha=0.40] Top-5 Accuracy: 28.46%
Result: Top-1: 12.55%, Top-5: 28.46%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.21%
[Alpha=0.40] Top-5 Accuracy: 28.25%
Result: Top-1: 12.21%, Top-5: 28.25%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.64%
[Alpha=0.40] Top-5 Accuracy: 28.38%
Result: Top-1: 12.64%, Top-5: 28.38%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.55%
[Alpha=0.40] Top-5 Accuracy: 28.46%
Result: Top-1: 12.55%, Top-5: 28.46%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.56%
[Alpha=0.40] Top-5 Accuracy: 28.53%
Result: Top-1: 12.56%, Top-5: 28.53%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 13.90%
[Alpha=0.40] Top-5 Accuracy: 28.85%
Result: Top-1: 13.90%, Top-5: 28.85%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.72%
[Alpha=0.40] Top-5 Accuracy: 28.46%
Result: Top-1: 12.72%, Top-5: 28.46%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.61%
[Alpha=0.40] Top-5 Accuracy: 28.53%
Result: Top-1: 12.61%, Top-5: 28.53%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.44%
[Alpha=0.40] Top-5 Accuracy: 28.39%
Result: Top-1: 12.44%, Top-5: 28.39%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.69%
[Alpha=0.40] Top-5 Accuracy: 28.50%
Result: Top-1: 12.69%, Top-5: 28.50%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.25%
[Alpha=0.40] Top-5 Accuracy: 28.42%
Result: Top-1: 12.25%, Top-5: 28.42%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.84%
[Alpha=0.40] Top-5 Accuracy: 28.54%
Result: Top-1: 12.84%, Top-5: 28.54%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.50%
[Alpha=0.40] Top-5 Accuracy: 28.53%
Result: Top-1: 12.50%, Top-5: 28.53%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.65%
[Alpha=0.40] Top-5 Accuracy: 28.52%
Result: Top-1: 12.65%, Top-5: 28.52%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.43%
[Alpha=0.40] Top-5 Accuracy: 28.49%
Result: Top-1: 12.43%, Top-5: 28.49%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 13.84%
[Alpha=0.40] Top-5 Accuracy: 28.85%
Result: Top-1: 13.84%, Top-5: 28.85%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.91%
[Alpha=0.40] Top-5 Accuracy: 28.57%
Result: Top-1: 12.91%, Top-5: 28.57%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.95%
[Alpha=0.40] Top-5 Accuracy: 28.63%
Result: Top-1: 12.95%, Top-5: 28.63%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.44%
[Alpha=0.40] Top-5 Accuracy: 28.52%
Result: Top-1: 12.44%, Top-5: 28.52%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.75%
[Alpha=0.40] Top-5 Accuracy: 28.53%
Result: Top-1: 12.75%, Top-5: 28.53%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.33%
[Alpha=0.40] Top-5 Accuracy: 28.42%
Result: Top-1: 12.33%, Top-5: 28.42%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.38%
[Alpha=0.40] Top-5 Accuracy: 28.43%
Result: Top-1: 12.38%, Top-5: 28.43%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.48%
[Alpha=0.40] Top-5 Accuracy: 28.57%
Result: Top-1: 12.48%, Top-5: 28.57%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.46%
[Alpha=0.40] Top-5 Accuracy: 28.41%
Result: Top-1: 12.46%, Top-5: 28.41%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.81%
[Alpha=0.40] Top-5 Accuracy: 28.55%
Result: Top-1: 12.81%, Top-5: 28.55%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 13.73%
[Alpha=0.40] Top-5 Accuracy: 28.72%
Result: Top-1: 13.73%, Top-5: 28.72%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.57%
[Alpha=0.40] Top-5 Accuracy: 28.44%
Result: Top-1: 12.57%, Top-5: 28.44%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.63%
[Alpha=0.40] Top-5 Accuracy: 28.55%
Result: Top-1: 12.63%, Top-5: 28.55%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.30%
[Alpha=0.40] Top-5 Accuracy: 28.38%
Result: Top-1: 12.30%, Top-5: 28.38%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.41%
[Alpha=0.40] Top-5 Accuracy: 28.36%
Result: Top-1: 12.41%, Top-5: 28.36%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.46%
[Alpha=0.40] Top-5 Accuracy: 28.53%
Result: Top-1: 12.46%, Top-5: 28.53%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.61%
[Alpha=0.40] Top-5 Accuracy: 28.40%
Result: Top-1: 12.61%, Top-5: 28.40%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.42%
[Alpha=0.40] Top-5 Accuracy: 28.50%
Result: Top-1: 12.42%, Top-5: 28.50%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.46%
[Alpha=0.40] Top-5 Accuracy: 28.39%
Result: Top-1: 12.46%, Top-5: 28.39%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.18%
[Alpha=0.40] Top-5 Accuracy: 27.97%
Result: Top-1: 12.18%, Top-5: 27.97%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 13.63%
[Alpha=0.40] Top-5 Accuracy: 28.67%
Result: Top-1: 13.63%, Top-5: 28.67%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.18%
[Alpha=0.40] Top-5 Accuracy: 28.25%
Result: Top-1: 12.18%, Top-5: 28.25%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.14%
[Alpha=0.40] Top-5 Accuracy: 28.10%
Result: Top-1: 12.14%, Top-5: 28.10%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.28%
[Alpha=0.40] Top-5 Accuracy: 28.31%
Result: Top-1: 12.28%, Top-5: 28.31%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.91%
[Alpha=0.40] Top-5 Accuracy: 28.00%
Result: Top-1: 11.91%, Top-5: 28.00%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.29%
[Alpha=0.40] Top-5 Accuracy: 28.04%
Result: Top-1: 12.29%, Top-5: 28.04%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.20%
[Alpha=0.40] Top-5 Accuracy: 28.27%
Result: Top-1: 12.20%, Top-5: 28.27%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.30%
[Alpha=0.40] Top-5 Accuracy: 28.11%
Result: Top-1: 12.30%, Top-5: 28.11%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.42%
[Alpha=0.40] Top-5 Accuracy: 28.15%
Result: Top-1: 12.42%, Top-5: 28.15%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.11%
[Alpha=0.40] Top-5 Accuracy: 27.88%
Result: Top-1: 12.11%, Top-5: 27.88%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 13.38%
[Alpha=0.40] Top-5 Accuracy: 28.22%
Result: Top-1: 13.38%, Top-5: 28.22%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.94%
[Alpha=0.40] Top-5 Accuracy: 27.76%
Result: Top-1: 11.94%, Top-5: 27.76%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.02%
[Alpha=0.40] Top-5 Accuracy: 27.78%
Result: Top-1: 12.02%, Top-5: 27.78%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.92%
[Alpha=0.40] Top-5 Accuracy: 27.67%
Result: Top-1: 11.92%, Top-5: 27.67%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 12.06%
[Alpha=0.40] Top-5 Accuracy: 27.81%
Result: Top-1: 12.06%, Top-5: 27.81%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.84%
[Alpha=0.40] Top-5 Accuracy: 27.71%
Result: Top-1: 11.84%, Top-5: 27.71%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.63%
[Alpha=0.40] Top-5 Accuracy: 27.66%
Result: Top-1: 11.63%, Top-5: 27.66%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.99%
[Alpha=0.40] Top-5 Accuracy: 27.80%
Result: Top-1: 11.99%, Top-5: 27.80%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.98%
[Alpha=0.40] Top-5 Accuracy: 27.79%
Result: Top-1: 11.98%, Top-5: 27.79%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 11.98%
[Alpha=0.40] Top-5 Accuracy: 27.56%
Result: Top-1: 11.98%, Top-5: 27.56%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 12.84%
[Alpha=0.50] Top-5 Accuracy: 28.35%
Result: Top-1: 12.84%, Top-5: 28.35%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 8.30%
[Alpha=0.50] Top-5 Accuracy: 27.65%
Result: Top-1: 8.30%, Top-5: 27.65%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 8.32%
[Alpha=0.50] Top-5 Accuracy: 27.72%
Result: Top-1: 8.32%, Top-5: 27.72%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.61%
[Alpha=0.50] Top-5 Accuracy: 27.85%
Result: Top-1: 9.61%, Top-5: 27.85%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 8.70%
[Alpha=0.50] Top-5 Accuracy: 27.80%
Result: Top-1: 8.70%, Top-5: 27.80%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.25%
[Alpha=0.50] Top-5 Accuracy: 27.62%
Result: Top-1: 9.25%, Top-5: 27.62%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 8.33%
[Alpha=0.50] Top-5 Accuracy: 27.69%
Result: Top-1: 8.33%, Top-5: 27.69%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 8.81%
[Alpha=0.50] Top-5 Accuracy: 27.59%
Result: Top-1: 8.81%, Top-5: 27.59%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.31%
[Alpha=0.50] Top-5 Accuracy: 27.59%
Result: Top-1: 9.31%, Top-5: 27.59%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.38%
[Alpha=0.50] Top-5 Accuracy: 27.68%
Result: Top-1: 9.38%, Top-5: 27.68%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 12.78%
[Alpha=0.50] Top-5 Accuracy: 28.24%
Result: Top-1: 12.78%, Top-5: 28.24%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 8.89%
[Alpha=0.50] Top-5 Accuracy: 27.58%
Result: Top-1: 8.89%, Top-5: 27.58%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.62%
[Alpha=0.50] Top-5 Accuracy: 27.89%
Result: Top-1: 9.62%, Top-5: 27.89%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.19%
[Alpha=0.50] Top-5 Accuracy: 27.61%
Result: Top-1: 9.19%, Top-5: 27.61%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 9.32%
[Alpha=0.50] Top-5 Accuracy: 27.67%
Result: Top-1: 9.32%, Top-5: 27.67%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=125
============================================================
slurmstepd-jnfat05: error: *** JOB 1643623 ON jnfat05 CANCELLED AT 2025-09-11T10:17:34 ***
