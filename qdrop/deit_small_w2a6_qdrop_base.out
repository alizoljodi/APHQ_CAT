Starting Deit-Small W2A6 QDROP experiment at Sun Sep 14 02:27:47 PM CEST 2025
2025-09-14 14:27:50,896 - INFO - Starting multi-seed experiment
2025-09-14 14:27:50,897 - INFO - Architecture: deit_small
2025-09-14 14:27:50,897 - INFO - Weight bits: 2
2025-09-14 14:27:50,897 - INFO - Activation bits: 6
2025-09-14 14:27:50,897 - INFO - Seeds: [1001, 1002, 1003]
2025-09-14 14:27:50,897 - INFO - Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
2025-09-14 14:27:50,897 - INFO - Cluster numbers: [8, 16, 32, 64, 128, 256]
2025-09-14 14:27:50,897 - INFO - PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]
2025-09-14 14:27:50,897 - INFO - Output directory: ./experiment_results/deit_small_w2_a6_20250914_142750
2025-09-14 14:27:50,897 - INFO - Checking basic requirements...
2025-09-14 14:27:50,898 - INFO - Basic checks passed
2025-09-14 14:27:50,898 - INFO - 
Starting experiments for 3 seeds...
2025-09-14 14:27:50,898 - INFO - Total parameter combinations: 600
2025-09-14 14:27:50,898 - INFO - Total experiments: 1800
2025-09-14 14:27:50,899 - INFO - 
============================================================
2025-09-14 14:27:50,899 - INFO - Running experiment 1/3 for seed 1001
2025-09-14 14:27:50,899 - INFO - ============================================================
2025-09-14 14:27:50,899 - INFO - Running experiment for seed 1001
2025-09-14 14:27:50,899 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model deit_small --w_bit 2 --a_bit 6 --seed 1001 --config ../configs/4bit/qdrop_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-14 14:27:50,899 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/qdrop
2025-09-14 14:45:07 - start the process.
Namespace(model='deit_small', config='../configs/4bit/qdrop_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1001, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=6, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 6
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: qdrop
drop_prob: 0.5
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/deit_small_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/deit_small_patch16_224.fb_in1k)
[timm/deit_small_patch16_224.fb_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 13.390 (13.390)	Loss 0.5675 (0.5675)	Prec@1 87.800 (87.800)	Prec@5 98.200 (98.200)
Test: [10/100]	Time 0.302 (2.333)	Loss 0.6371 (0.6845)	Prec@1 88.400 (85.000)	Prec@5 96.400 (96.909)
Test: [20/100]	Time 0.305 (1.567)	Loss 0.7345 (0.6957)	Prec@1 81.200 (84.838)	Prec@5 97.400 (96.914)
Test: [30/100]	Time 0.306 (1.254)	Loss 0.6521 (0.7044)	Prec@1 84.400 (84.368)	Prec@5 98.200 (97.000)
Test: [40/100]	Time 0.307 (1.038)	Loss 0.8969 (0.7041)	Prec@1 77.000 (84.463)	Prec@5 95.600 (96.995)
Test: [50/100]	Time 0.308 (0.920)	Loss 1.2925 (0.7827)	Prec@1 69.800 (82.345)	Prec@5 90.600 (96.122)
Test: [60/100]	Time 0.437 (0.838)	Loss 0.9169 (0.8059)	Prec@1 80.200 (81.770)	Prec@5 92.800 (95.780)
Test: [70/100]	Time 0.317 (0.765)	Loss 0.9785 (0.8407)	Prec@1 78.000 (80.800)	Prec@5 95.200 (95.434)
Test: [80/100]	Time 0.310 (0.712)	Loss 0.7631 (0.8600)	Prec@1 83.400 (80.464)	Prec@5 96.000 (95.160)
Test: [90/100]	Time 0.304 (0.672)	Loss 1.2795 (0.8835)	Prec@1 68.400 (79.752)	Prec@5 91.000 (94.985)
 * Prec@1 79.848 Prec@5 95.054 Loss 0.878 Time 64.043
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-14 14:46:54 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:06<07:24,  6.09s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:06<07:24,  6.09s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [00:27<18:18, 15.26s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [00:27<18:18, 15.26s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [00:37<14:50, 12.54s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [00:37<14:50, 12.54s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [01:12<25:17, 21.67s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [01:12<25:17, 21.67s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [01:41<27:43, 24.11s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [01:41<27:43, 24.11s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [02:11<29:46, 26.27s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [02:11<29:46, 26.27s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [02:41<30:39, 27.46s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [02:41<30:39, 27.46s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [03:03<28:16, 25.71s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [03:03<28:16, 25.71s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [03:13<22:23, 20.67s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [03:13<22:23, 20.67s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [03:48<27:02, 25.36s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [03:48<27:02, 25.36s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [04:17<27:40, 26.36s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [04:17<27:40, 26.36s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [04:48<28:31, 27.60s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [04:48<28:31, 27.60s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [05:17<28:47, 28.31s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [05:17<28:47, 28.31s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [05:40<26:29, 26.50s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [05:40<26:29, 26.50s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [05:49<20:59, 21.35s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [05:49<20:59, 21.35s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [06:25<24:48, 25.67s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [06:25<24:48, 25.67s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [06:53<25:09, 26.48s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [06:53<25:09, 26.48s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [07:24<25:48, 27.65s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [07:24<25:48, 27.65s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [07:54<26:06, 28.49s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [07:54<26:06, 28.49s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [08:17<24:04, 26.75s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [08:17<24:04, 26.75s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [08:27<19:07, 21.66s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [08:27<19:07, 21.66s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [09:03<22:34, 26.06s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [09:03<22:34, 26.06s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [09:32<22:51, 26.90s/it]calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [09:32<22:51, 26.90s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [10:02<23:17, 27.94s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [10:02<23:17, 27.94s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [10:32<23:19, 28.56s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [10:32<23:19, 28.56s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [10:54<21:21, 26.69s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [10:54<21:21, 26.69s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [11:04<16:54, 21.58s/it]calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [11:04<16:54, 21.58s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [11:40<19:56, 26.00s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [11:40<19:56, 26.00s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [12:09<20:04, 26.76s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [12:09<20:04, 26.76s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [12:39<20:24, 27.82s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [12:39<20:24, 27.82s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [13:09<20:22, 28.43s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [13:09<20:22, 28.43s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [13:31<18:35, 26.55s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [13:31<18:35, 26.55s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [13:41<14:37, 21.41s/it]calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [13:41<14:37, 21.41s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [14:17<17:09, 25.74s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [14:17<17:09, 25.74s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [14:45<17:18, 26.62s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [14:45<17:18, 26.62s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [15:16<17:35, 27.77s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [15:16<17:35, 27.77s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [15:45<17:30, 28.38s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [15:45<17:30, 28.38s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [16:07<15:53, 26.48s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [16:07<15:53, 26.48s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [16:17<12:29, 21.43s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [16:17<12:29, 21.43s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [16:53<14:35, 25.76s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [16:53<14:35, 25.76s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [17:22<14:39, 26.67s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [17:22<14:39, 26.67s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [17:52<14:50, 27.83s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [17:52<14:50, 27.83s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [18:22<14:41, 28.44s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [18:22<14:41, 28.44s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [18:44<13:15, 26.52s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [18:44<13:15, 26.52s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [18:54<10:20, 21.41s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [18:54<10:20, 21.41s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [19:30<12:01, 25.75s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [19:30<12:01, 25.75s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [19:58<11:57, 26.58s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [19:58<11:57, 26.58s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [20:28<11:57, 27.59s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [20:28<11:57, 27.59s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [20:58<11:46, 28.26s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [20:58<11:46, 28.26s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [21:20<10:35, 26.49s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [21:20<10:35, 26.49s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [21:30<08:12, 21.43s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [21:30<08:12, 21.43s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [22:06<09:28, 25.83s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [22:06<09:28, 25.83s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [22:35<09:22, 26.80s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [22:35<09:22, 26.80s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [23:06<09:19, 27.96s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [23:06<09:19, 27.96s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [23:36<09:03, 28.58s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [23:36<09:03, 28.58s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [23:58<07:59, 26.66s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [23:58<07:59, 26.66s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [24:07<06:05, 21.47s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [24:07<06:05, 21.47s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [24:43<06:51, 25.75s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [24:43<06:51, 25.75s/it]calibrating blocks.9.attn.matmul2:  80%|███████▉  | 59/74 [25:12<06:39, 26.65s/it]calibrating blocks.9.mlp.fc1:  80%|███████▉  | 59/74 [25:12<06:39, 26.65s/it]     calibrating blocks.9.mlp.fc1:  81%|████████  | 60/74 [25:42<06:27, 27.68s/it]calibrating blocks.9.mlp.fc2:  81%|████████  | 60/74 [25:42<06:27, 27.68s/it]calibrating blocks.9.mlp.fc2:  82%|████████▏ | 61/74 [26:12<06:08, 28.33s/it]calibrating blocks.10.attn.qkv:  82%|████████▏ | 61/74 [26:12<06:08, 28.33s/it]calibrating blocks.10.attn.qkv:  84%|████████▍ | 62/74 [26:34<05:18, 26.52s/it]calibrating blocks.10.attn.proj:  84%|████████▍ | 62/74 [26:34<05:18, 26.52s/it]calibrating blocks.10.attn.proj:  85%|████████▌ | 63/74 [26:44<03:55, 21.44s/it]calibrating blocks.10.attn.matmul1:  85%|████████▌ | 63/74 [26:44<03:55, 21.44s/it]calibrating blocks.10.attn.matmul1:  86%|████████▋ | 64/74 [27:20<04:18, 25.83s/it]calibrating blocks.10.attn.matmul2:  86%|████████▋ | 64/74 [27:20<04:18, 25.83s/it]calibrating blocks.10.attn.matmul2:  88%|████████▊ | 65/74 [27:49<04:01, 26.82s/it]calibrating blocks.10.mlp.fc1:  88%|████████▊ | 65/74 [27:49<04:01, 26.82s/it]     calibrating blocks.10.mlp.fc1:  89%|████████▉ | 66/74 [28:19<03:42, 27.82s/it]calibrating blocks.10.mlp.fc2:  89%|████████▉ | 66/74 [28:19<03:42, 27.82s/it]calibrating blocks.10.mlp.fc2:  91%|█████████ | 67/74 [28:49<03:18, 28.40s/it]calibrating blocks.11.attn.qkv:  91%|█████████ | 67/74 [28:49<03:18, 28.40s/it]calibrating blocks.11.attn.qkv:  92%|█████████▏| 68/74 [29:11<02:39, 26.60s/it]calibrating blocks.11.attn.proj:  92%|█████████▏| 68/74 [29:11<02:39, 26.60s/it]calibrating blocks.11.attn.proj:  93%|█████████▎| 69/74 [29:21<01:47, 21.47s/it]calibrating blocks.11.attn.matmul1:  93%|█████████▎| 69/74 [29:21<01:47, 21.47s/it]calibrating blocks.11.attn.matmul1:  95%|█████████▍| 70/74 [29:56<01:43, 25.78s/it]calibrating blocks.11.attn.matmul2:  95%|█████████▍| 70/74 [29:56<01:43, 25.78s/it]calibrating blocks.11.attn.matmul2:  96%|█████████▌| 71/74 [30:25<01:19, 26.66s/it]calibrating blocks.11.mlp.fc1:  96%|█████████▌| 71/74 [30:25<01:19, 26.66s/it]     calibrating blocks.11.mlp.fc1:  97%|█████████▋| 72/74 [30:56<00:55, 27.83s/it]calibrating blocks.11.mlp.fc2:  97%|█████████▋| 72/74 [30:56<00:55, 27.83s/it]calibrating blocks.11.mlp.fc2:  99%|█████████▊| 73/74 [31:26<00:28, 28.69s/it]calibrating head:  99%|█████████▊| 73/74 [31:26<00:28, 28.69s/it]             calibrating head: 100%|██████████| 74/74 [31:28<00:00, 20.64s/it]calibrating head: 100%|██████████| 74/74 [31:28<00:00, 25.52s/it]
2025-09-14 15:18:28 - mse guided calibration finished.
Saving checkpoint to ./checkpoint/quant_result/20250914_1445/deit_small_w2_a6_calibsize_1000_mse.pth
Validating after calibration ...
Test: [0/100]	Time 3.880 (3.880)	Loss 5.1391 (5.1391)	Prec@1 15.400 (15.400)	Prec@5 39.600 (39.600)
Test: [10/100]	Time 0.789 (1.094)	Loss 6.0400 (5.9434)	Prec@1 4.600 (6.273)	Prec@5 15.200 (16.927)
Test: [20/100]	Time 0.790 (0.950)	Loss 5.7950 (6.0155)	Prec@1 8.200 (5.971)	Prec@5 21.200 (15.657)
Test: [30/100]	Time 0.794 (0.898)	Loss 5.6601 (6.0287)	Prec@1 7.800 (5.529)	Prec@5 17.400 (14.794)
Test: [40/100]	Time 0.789 (0.872)	Loss 6.1217 (6.0105)	Prec@1 2.200 (5.800)	Prec@5 9.800 (15.327)
Test: [50/100]	Time 0.789 (0.857)	Loss 6.6556 (6.0580)	Prec@1 2.200 (5.463)	Prec@5 6.000 (14.212)
Test: [60/100]	Time 0.791 (0.847)	Loss 6.0161 (6.0808)	Prec@1 5.600 (5.443)	Prec@5 13.600 (13.970)
Test: [70/100]	Time 0.795 (0.839)	Loss 6.8746 (6.0938)	Prec@1 0.800 (5.318)	Prec@5 3.600 (13.825)
Test: [80/100]	Time 0.792 (0.833)	Loss 6.6141 (6.1273)	Prec@1 1.200 (5.057)	Prec@5 4.000 (13.198)
Test: [90/100]	Time 0.795 (0.829)	Loss 6.0294 (6.1353)	Prec@1 10.600 (5.099)	Prec@5 20.600 (13.165)
 * Prec@1 5.450 Prec@5 13.672 Loss 6.123 Time 82.755
Building calibrator ...
2025-09-14 15:19:55 - start mse guided block reconstruction
reconstructing patch_embed ...
initializing raw input and raw output ...
adaround training for patch_embed ...
wraping quantizers in patch_embed ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.022 (rec:0.022, round:0.000)	b=0.00	count=500
Total loss:	0.015 (rec:0.015, round:0.000)	b=0.00	count=1000
Total loss:	0.009 (rec:0.009, round:0.000)	b=0.00	count=1500
Total loss:	0.012 (rec:0.012, round:0.000)	b=0.00	count=2000
Total loss:	0.009 (rec:0.009, round:0.000)	b=0.00	count=2500
Total loss:	0.007 (rec:0.007, round:0.000)	b=0.00	count=3000
Total loss:	0.009 (rec:0.009, round:0.000)	b=0.00	count=3500
Total loss:	2785.448 (rec:0.004, round:2785.444)	b=20.00	count=4000
Total loss:	1452.288 (rec:0.020, round:1452.268)	b=19.44	count=4500
Total loss:	1340.130 (rec:0.011, round:1340.119)	b=18.88	count=5000
Total loss:	1268.149 (rec:0.014, round:1268.135)	b=18.31	count=5500
Total loss:	1205.134 (rec:0.011, round:1205.123)	b=17.75	count=6000
Total loss:	1145.950 (rec:0.011, round:1145.939)	b=17.19	count=6500
Total loss:	1084.057 (rec:0.011, round:1084.046)	b=16.62	count=7000
Total loss:	1024.570 (rec:0.014, round:1024.556)	b=16.06	count=7500
Total loss:	963.857 (rec:0.009, round:963.849)	b=15.50	count=8000
Total loss:	899.462 (rec:0.012, round:899.450)	b=14.94	count=8500
Total loss:	833.910 (rec:0.012, round:833.899)	b=14.38	count=9000
Total loss:	768.339 (rec:0.009, round:768.330)	b=13.81	count=9500
Total loss:	701.224 (rec:0.016, round:701.208)	b=13.25	count=10000
Total loss:	632.543 (rec:0.014, round:632.529)	b=12.69	count=10500
Total loss:	563.862 (rec:0.026, round:563.836)	b=12.12	count=11000
Total loss:	493.503 (rec:0.018, round:493.484)	b=11.56	count=11500
Total loss:	423.710 (rec:0.024, round:423.686)	b=11.00	count=12000
Total loss:	353.144 (rec:0.029, round:353.115)	b=10.44	count=12500
Total loss:	284.391 (rec:0.022, round:284.369)	b=9.88	count=13000
Total loss:	218.737 (rec:0.022, round:218.715)	b=9.31	count=13500
Total loss:	160.627 (rec:0.045, round:160.582)	b=8.75	count=14000
Total loss:	108.765 (rec:0.024, round:108.741)	b=8.19	count=14500
Total loss:	67.933 (rec:0.037, round:67.896)	b=7.62	count=15000
Total loss:	36.882 (rec:0.042, round:36.840)	b=7.06	count=15500
Total loss:	17.179 (rec:0.055, round:17.124)	b=6.50	count=16000
Total loss:	6.544 (rec:0.060, round:6.484)	b=5.94	count=16500
Total loss:	2.441 (rec:0.053, round:2.388)	b=5.38	count=17000
Total loss:	1.248 (rec:0.065, round:1.183)	b=4.81	count=17500
Total loss:	0.649 (rec:0.080, round:0.569)	b=4.25	count=18000
Total loss:	0.293 (rec:0.055, round:0.238)	b=3.69	count=18500
Total loss:	0.150 (rec:0.072, round:0.078)	b=3.12	count=19000
Total loss:	0.069 (rec:0.063, round:0.006)	b=2.56	count=19500
Total loss:	0.055 (rec:0.055, round:0.000)	b=2.00	count=20000
finished reconstructing patch_embed.
reconstructing blocks.0 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.0 ...
wraping quantizers in blocks.0 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.506 (rec:0.506, round:0.000)	b=0.00	count=500
Total loss:	0.420 (rec:0.420, round:0.000)	b=0.00	count=1000
Total loss:	0.387 (rec:0.387, round:0.000)	b=0.00	count=1500
Total loss:	0.330 (rec:0.330, round:0.000)	b=0.00	count=2000
Total loss:	0.346 (rec:0.346, round:0.000)	b=0.00	count=2500
Total loss:	0.308 (rec:0.308, round:0.000)	b=0.00	count=3000
Total loss:	0.332 (rec:0.332, round:0.000)	b=0.00	count=3500
Total loss:	15852.941 (rec:0.267, round:15852.674)	b=20.00	count=4000
Total loss:	7674.813 (rec:0.319, round:7674.494)	b=19.44	count=4500
Total loss:	7002.921 (rec:0.299, round:7002.622)	b=18.88	count=5000
Total loss:	6556.104 (rec:0.331, round:6555.772)	b=18.31	count=5500
Total loss:	6180.302 (rec:0.303, round:6179.999)	b=17.75	count=6000
Total loss:	5841.071 (rec:0.331, round:5840.740)	b=17.19	count=6500
Total loss:	5515.520 (rec:0.353, round:5515.167)	b=16.62	count=7000
Total loss:	5201.252 (rec:0.346, round:5200.906)	b=16.06	count=7500
Total loss:	4897.785 (rec:0.316, round:4897.470)	b=15.50	count=8000
Total loss:	4598.535 (rec:0.310, round:4598.225)	b=14.94	count=8500
Total loss:	4309.900 (rec:0.354, round:4309.546)	b=14.38	count=9000
Total loss:	4021.684 (rec:0.364, round:4021.320)	b=13.81	count=9500
Total loss:	3732.624 (rec:0.370, round:3732.254)	b=13.25	count=10000
Total loss:	3441.375 (rec:0.387, round:3440.987)	b=12.69	count=10500
Total loss:	3150.660 (rec:0.372, round:3150.288)	b=12.12	count=11000
Total loss:	2856.020 (rec:0.354, round:2855.666)	b=11.56	count=11500
Total loss:	2562.624 (rec:0.376, round:2562.249)	b=11.00	count=12000
Total loss:	2268.062 (rec:0.432, round:2267.630)	b=10.44	count=12500
Total loss:	1971.485 (rec:0.508, round:1970.977)	b=9.88	count=13000
Total loss:	1677.317 (rec:0.448, round:1676.870)	b=9.31	count=13500
Total loss:	1385.029 (rec:0.514, round:1384.516)	b=8.75	count=14000
Total loss:	1108.014 (rec:0.526, round:1107.488)	b=8.19	count=14500
Total loss:	847.952 (rec:0.567, round:847.385)	b=7.62	count=15000
Total loss:	610.544 (rec:0.580, round:609.964)	b=7.06	count=15500
Total loss:	408.948 (rec:0.633, round:408.316)	b=6.50	count=16000
Total loss:	252.864 (rec:0.627, round:252.237)	b=5.94	count=16500
Total loss:	140.565 (rec:0.666, round:139.899)	b=5.38	count=17000
Total loss:	68.077 (rec:0.731, round:67.346)	b=4.81	count=17500
Total loss:	26.752 (rec:0.699, round:26.053)	b=4.25	count=18000
Total loss:	7.707 (rec:0.701, round:7.006)	b=3.69	count=18500
Total loss:	1.974 (rec:0.762, round:1.212)	b=3.12	count=19000
Total loss:	0.859 (rec:0.712, round:0.147)	b=2.56	count=19500
Total loss:	0.730 (rec:0.708, round:0.021)	b=2.00	count=20000
finished reconstructing blocks.0.
reconstructing blocks.1 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.1 ...
wraping quantizers in blocks.1 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.796 (rec:0.796, round:0.000)	b=0.00	count=500
Total loss:	0.673 (rec:0.673, round:0.000)	b=0.00	count=1000
Total loss:	0.685 (rec:0.685, round:0.000)	b=0.00	count=1500
Total loss:	0.632 (rec:0.632, round:0.000)	b=0.00	count=2000
Total loss:	0.636 (rec:0.636, round:0.000)	b=0.00	count=2500
Total loss:	0.621 (rec:0.621, round:0.000)	b=0.00	count=3000
Total loss:	0.573 (rec:0.573, round:0.000)	b=0.00	count=3500
Total loss:	16036.125 (rec:0.583, round:16035.542)	b=20.00	count=4000
Total loss:	8067.363 (rec:0.626, round:8066.737)	b=19.44	count=4500
Total loss:	7419.151 (rec:0.641, round:7418.510)	b=18.88	count=5000
Total loss:	6997.191 (rec:0.641, round:6996.551)	b=18.31	count=5500
Total loss:	6641.389 (rec:0.656, round:6640.733)	b=17.75	count=6000
Total loss:	6310.728 (rec:0.585, round:6310.143)	b=17.19	count=6500
Total loss:	5997.614 (rec:0.599, round:5997.015)	b=16.62	count=7000
Total loss:	5696.540 (rec:0.639, round:5695.901)	b=16.06	count=7500
Total loss:	5402.106 (rec:0.621, round:5401.485)	b=15.50	count=8000
Total loss:	5107.936 (rec:0.589, round:5107.347)	b=14.94	count=8500
Total loss:	4815.819 (rec:0.622, round:4815.198)	b=14.38	count=9000
Total loss:	4521.430 (rec:0.615, round:4520.814)	b=13.81	count=9500
Total loss:	4225.791 (rec:0.649, round:4225.142)	b=13.25	count=10000
Total loss:	3928.922 (rec:0.601, round:3928.321)	b=12.69	count=10500
Total loss:	3629.911 (rec:0.636, round:3629.275)	b=12.12	count=11000
Total loss:	3326.550 (rec:0.644, round:3325.906)	b=11.56	count=11500
Total loss:	3020.948 (rec:0.693, round:3020.256)	b=11.00	count=12000
Total loss:	2707.807 (rec:0.644, round:2707.163)	b=10.44	count=12500
Total loss:	2394.946 (rec:0.674, round:2394.271)	b=9.88	count=13000
Total loss:	2076.669 (rec:0.778, round:2075.892)	b=9.31	count=13500
Total loss:	1752.956 (rec:0.668, round:1752.287)	b=8.75	count=14000
Total loss:	1432.852 (rec:0.697, round:1432.155)	b=8.19	count=14500
Total loss:	1116.278 (rec:0.782, round:1115.496)	b=7.62	count=15000
Total loss:	818.437 (rec:0.829, round:817.608)	b=7.06	count=15500
Total loss:	548.152 (rec:0.814, round:547.337)	b=6.50	count=16000
Total loss:	321.327 (rec:0.842, round:320.484)	b=5.94	count=16500
Total loss:	159.384 (rec:0.846, round:158.538)	b=5.38	count=17000
Total loss:	65.727 (rec:0.832, round:64.895)	b=4.81	count=17500
Total loss:	22.771 (rec:0.856, round:21.915)	b=4.25	count=18000
Total loss:	6.476 (rec:0.902, round:5.574)	b=3.69	count=18500
Total loss:	1.843 (rec:0.875, round:0.968)	b=3.12	count=19000
Total loss:	0.865 (rec:0.781, round:0.084)	b=2.56	count=19500
Total loss:	0.867 (rec:0.861, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.1.
reconstructing blocks.2 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.2 ...
wraping quantizers in blocks.2 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.964 (rec:0.964, round:0.000)	b=0.00	count=500
Total loss:	0.899 (rec:0.899, round:0.000)	b=0.00	count=1000
Total loss:	0.887 (rec:0.887, round:0.000)	b=0.00	count=1500
Total loss:	0.842 (rec:0.842, round:0.000)	b=0.00	count=2000
Total loss:	0.809 (rec:0.809, round:0.000)	b=0.00	count=2500
Total loss:	0.770 (rec:0.770, round:0.000)	b=0.00	count=3000
Total loss:	0.767 (rec:0.767, round:0.000)	b=0.00	count=3500
Total loss:	16063.294 (rec:0.764, round:16062.529)	b=20.00	count=4000
Total loss:	8274.581 (rec:0.839, round:8273.742)	b=19.44	count=4500
Total loss:	7636.852 (rec:0.838, round:7636.014)	b=18.88	count=5000
Total loss:	7224.656 (rec:0.805, round:7223.851)	b=18.31	count=5500
Total loss:	6878.047 (rec:0.770, round:6877.277)	b=17.75	count=6000
Total loss:	6564.911 (rec:0.776, round:6564.135)	b=17.19	count=6500
Total loss:	6265.407 (rec:0.808, round:6264.599)	b=16.62	count=7000
Total loss:	5973.909 (rec:0.755, round:5973.154)	b=16.06	count=7500
Total loss:	5686.928 (rec:0.796, round:5686.132)	b=15.50	count=8000
Total loss:	5403.191 (rec:0.817, round:5402.375)	b=14.94	count=8500
Total loss:	5117.473 (rec:0.806, round:5116.667)	b=14.38	count=9000
Total loss:	4832.357 (rec:0.856, round:4831.501)	b=13.81	count=9500
Total loss:	4542.475 (rec:0.853, round:4541.622)	b=13.25	count=10000
Total loss:	4251.271 (rec:0.838, round:4250.433)	b=12.69	count=10500
Total loss:	3958.306 (rec:0.873, round:3957.434)	b=12.12	count=11000
Total loss:	3659.569 (rec:0.827, round:3658.742)	b=11.56	count=11500
Total loss:	3351.872 (rec:0.888, round:3350.984)	b=11.00	count=12000
Total loss:	3039.126 (rec:0.871, round:3038.255)	b=10.44	count=12500
Total loss:	2718.900 (rec:0.888, round:2718.012)	b=9.88	count=13000
Total loss:	2390.902 (rec:0.855, round:2390.047)	b=9.31	count=13500
Total loss:	2055.180 (rec:0.894, round:2054.286)	b=8.75	count=14000
Total loss:	1716.567 (rec:0.908, round:1715.659)	b=8.19	count=14500
Total loss:	1381.655 (rec:0.926, round:1380.729)	b=7.62	count=15000
Total loss:	1054.850 (rec:0.953, round:1053.897)	b=7.06	count=15500
Total loss:	743.306 (rec:0.976, round:742.330)	b=6.50	count=16000
Total loss:	471.094 (rec:0.981, round:470.112)	b=5.94	count=16500
Total loss:	253.853 (rec:1.060, round:252.792)	b=5.38	count=17000
Total loss:	106.736 (rec:1.037, round:105.698)	b=4.81	count=17500
Total loss:	34.880 (rec:1.057, round:33.824)	b=4.25	count=18000
Total loss:	9.283 (rec:1.037, round:8.245)	b=3.69	count=18500
Total loss:	2.351 (rec:1.038, round:1.313)	b=3.12	count=19000
Total loss:	1.193 (rec:1.106, round:0.087)	b=2.56	count=19500
Total loss:	1.061 (rec:1.059, round:0.002)	b=2.00	count=20000
finished reconstructing blocks.2.
reconstructing blocks.3 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.3 ...
wraping quantizers in blocks.3 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.936 (rec:0.936, round:0.000)	b=0.00	count=500
Total loss:	0.850 (rec:0.850, round:0.000)	b=0.00	count=1000
Total loss:	0.865 (rec:0.865, round:0.000)	b=0.00	count=1500
Total loss:	0.823 (rec:0.823, round:0.000)	b=0.00	count=2000
Total loss:	0.798 (rec:0.798, round:0.000)	b=0.00	count=2500
Total loss:	0.820 (rec:0.820, round:0.000)	b=0.00	count=3000
Total loss:	0.770 (rec:0.770, round:0.000)	b=0.00	count=3500
Total loss:	16193.597 (rec:0.770, round:16192.826)	b=20.00	count=4000
Total loss:	8323.723 (rec:0.805, round:8322.918)	b=19.44	count=4500
Total loss:	7706.257 (rec:0.783, round:7705.474)	b=18.88	count=5000
Total loss:	7311.037 (rec:0.790, round:7310.246)	b=18.31	count=5500
Total loss:	6973.384 (rec:0.813, round:6972.570)	b=17.75	count=6000
Total loss:	6664.076 (rec:0.813, round:6663.263)	b=17.19	count=6500
Total loss:	6368.495 (rec:0.787, round:6367.708)	b=16.62	count=7000
Total loss:	6083.963 (rec:0.795, round:6083.167)	b=16.06	count=7500
Total loss:	5806.992 (rec:0.772, round:5806.220)	b=15.50	count=8000
Total loss:	5527.223 (rec:0.783, round:5526.440)	b=14.94	count=8500
Total loss:	5250.316 (rec:0.797, round:5249.519)	b=14.38	count=9000
Total loss:	4972.689 (rec:0.822, round:4971.867)	b=13.81	count=9500
Total loss:	4696.685 (rec:0.790, round:4695.895)	b=13.25	count=10000
Total loss:	4411.841 (rec:0.815, round:4411.026)	b=12.69	count=10500
Total loss:	4124.830 (rec:0.783, round:4124.047)	b=12.12	count=11000
Total loss:	3830.763 (rec:0.814, round:3829.949)	b=11.56	count=11500
Total loss:	3530.653 (rec:0.808, round:3529.846)	b=11.00	count=12000
Total loss:	3225.831 (rec:0.814, round:3225.017)	b=10.44	count=12500
Total loss:	2915.168 (rec:0.843, round:2914.325)	b=9.88	count=13000
Total loss:	2594.493 (rec:0.818, round:2593.676)	b=9.31	count=13500
Total loss:	2269.751 (rec:0.859, round:2268.892)	b=8.75	count=14000
Total loss:	1941.073 (rec:0.834, round:1940.239)	b=8.19	count=14500
Total loss:	1611.474 (rec:0.858, round:1610.616)	b=7.62	count=15000
Total loss:	1279.956 (rec:0.860, round:1279.096)	b=7.06	count=15500
Total loss:	957.648 (rec:0.875, round:956.773)	b=6.50	count=16000
Total loss:	655.794 (rec:0.939, round:654.856)	b=5.94	count=16500
Total loss:	390.800 (rec:0.917, round:389.883)	b=5.38	count=17000
Total loss:	185.471 (rec:0.931, round:184.539)	b=4.81	count=17500
Total loss:	68.572 (rec:0.978, round:67.593)	b=4.25	count=18000
Total loss:	18.219 (rec:0.954, round:17.265)	b=3.69	count=18500
Total loss:	3.146 (rec:0.979, round:2.167)	b=3.12	count=19000
Total loss:	1.079 (rec:0.990, round:0.090)	b=2.56	count=19500
Total loss:	0.933 (rec:0.930, round:0.003)	b=2.00	count=20000
finished reconstructing blocks.3.
reconstructing blocks.4 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.4 ...
wraping quantizers in blocks.4 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.022 (rec:1.022, round:0.000)	b=0.00	count=500
Total loss:	0.968 (rec:0.968, round:0.000)	b=0.00	count=1000
Total loss:	0.937 (rec:0.937, round:0.000)	b=0.00	count=1500
Total loss:	0.908 (rec:0.908, round:0.000)	b=0.00	count=2000
Total loss:	0.908 (rec:0.908, round:0.000)	b=0.00	count=2500
Total loss:	0.880 (rec:0.880, round:0.000)	b=0.00	count=3000
Total loss:	0.901 (rec:0.901, round:0.000)	b=0.00	count=3500
Total loss:	16200.843 (rec:0.872, round:16199.971)	b=20.00	count=4000
Total loss:	8349.885 (rec:0.912, round:8348.974)	b=19.44	count=4500
Total loss:	7738.887 (rec:0.884, round:7738.003)	b=18.88	count=5000
Total loss:	7345.641 (rec:0.868, round:7344.772)	b=18.31	count=5500
Total loss:	7014.395 (rec:0.870, round:7013.525)	b=17.75	count=6000
Total loss:	6705.672 (rec:0.866, round:6704.807)	b=17.19	count=6500
Total loss:	6414.665 (rec:0.868, round:6413.797)	b=16.62	count=7000
Total loss:	6134.663 (rec:0.950, round:6133.713)	b=16.06	count=7500
Total loss:	5859.526 (rec:0.864, round:5858.662)	b=15.50	count=8000
Total loss:	5582.794 (rec:0.914, round:5581.881)	b=14.94	count=8500
Total loss:	5304.923 (rec:0.910, round:5304.013)	b=14.38	count=9000
Total loss:	5030.409 (rec:0.876, round:5029.533)	b=13.81	count=9500
Total loss:	4753.030 (rec:0.882, round:4752.147)	b=13.25	count=10000
Total loss:	4473.624 (rec:0.904, round:4472.720)	b=12.69	count=10500
Total loss:	4187.082 (rec:0.915, round:4186.167)	b=12.12	count=11000
Total loss:	3895.525 (rec:0.898, round:3894.626)	b=11.56	count=11500
Total loss:	3596.324 (rec:0.916, round:3595.409)	b=11.00	count=12000
Total loss:	3291.443 (rec:0.975, round:3290.468)	b=10.44	count=12500
Total loss:	2980.209 (rec:0.883, round:2979.326)	b=9.88	count=13000
Total loss:	2663.055 (rec:0.926, round:2662.129)	b=9.31	count=13500
Total loss:	2341.904 (rec:0.951, round:2340.953)	b=8.75	count=14000
Total loss:	2015.581 (rec:0.900, round:2014.680)	b=8.19	count=14500
Total loss:	1685.282 (rec:0.925, round:1684.357)	b=7.62	count=15000
Total loss:	1356.288 (rec:0.961, round:1355.327)	b=7.06	count=15500
Total loss:	1034.388 (rec:0.974, round:1033.414)	b=6.50	count=16000
Total loss:	725.720 (rec:1.001, round:724.719)	b=5.94	count=16500
Total loss:	448.782 (rec:1.015, round:447.767)	b=5.38	count=17000
Total loss:	231.188 (rec:1.025, round:230.162)	b=4.81	count=17500
Total loss:	96.530 (rec:1.043, round:95.487)	b=4.25	count=18000
Total loss:	30.893 (rec:1.014, round:29.879)	b=3.69	count=18500
Total loss:	6.420 (rec:1.041, round:5.379)	b=3.12	count=19000
Total loss:	1.425 (rec:1.085, round:0.341)	b=2.56	count=19500
Total loss:	1.020 (rec:1.016, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.4.
reconstructing blocks.5 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.5 ...
wraping quantizers in blocks.5 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.172 (rec:1.172, round:0.000)	b=0.00	count=500
Total loss:	1.082 (rec:1.082, round:0.000)	b=0.00	count=1000
Total loss:	1.106 (rec:1.106, round:0.000)	b=0.00	count=1500
Total loss:	1.036 (rec:1.036, round:0.000)	b=0.00	count=2000
Total loss:	1.026 (rec:1.026, round:0.000)	b=0.00	count=2500
Total loss:	1.028 (rec:1.028, round:0.000)	b=0.00	count=3000
Total loss:	1.037 (rec:1.037, round:0.000)	b=0.00	count=3500
Total loss:	16202.925 (rec:1.046, round:16201.879)	b=20.00	count=4000
Total loss:	8324.233 (rec:1.015, round:8323.219)	b=19.44	count=4500
Total loss:	7718.714 (rec:1.033, round:7717.682)	b=18.88	count=5000
Total loss:	7328.829 (rec:1.010, round:7327.818)	b=18.31	count=5500
Total loss:	7003.107 (rec:1.027, round:7002.081)	b=17.75	count=6000
Total loss:	6704.977 (rec:1.007, round:6703.970)	b=17.19	count=6500
Total loss:	6420.883 (rec:1.036, round:6419.847)	b=16.62	count=7000
Total loss:	6145.172 (rec:0.976, round:6144.195)	b=16.06	count=7500
Total loss:	5873.788 (rec:1.017, round:5872.771)	b=15.50	count=8000
Total loss:	5603.316 (rec:1.042, round:5602.274)	b=14.94	count=8500
Total loss:	5334.802 (rec:0.981, round:5333.822)	b=14.38	count=9000
Total loss:	5063.434 (rec:1.050, round:5062.384)	b=13.81	count=9500
Total loss:	4786.917 (rec:1.071, round:4785.847)	b=13.25	count=10000
Total loss:	4509.606 (rec:1.004, round:4508.602)	b=12.69	count=10500
Total loss:	4226.904 (rec:1.049, round:4225.855)	b=12.12	count=11000
Total loss:	3941.524 (rec:1.002, round:3940.523)	b=11.56	count=11500
Total loss:	3646.865 (rec:1.005, round:3645.860)	b=11.00	count=12000
Total loss:	3346.832 (rec:1.008, round:3345.824)	b=10.44	count=12500
Total loss:	3039.079 (rec:1.020, round:3038.059)	b=9.88	count=13000
Total loss:	2724.394 (rec:1.053, round:2723.342)	b=9.31	count=13500
Total loss:	2407.134 (rec:1.051, round:2406.083)	b=8.75	count=14000
Total loss:	2086.250 (rec:1.018, round:2085.232)	b=8.19	count=14500
Total loss:	1759.122 (rec:1.039, round:1758.083)	b=7.62	count=15000
Total loss:	1432.026 (rec:1.087, round:1430.939)	b=7.06	count=15500
Total loss:	1105.887 (rec:1.061, round:1104.826)	b=6.50	count=16000
Total loss:	793.926 (rec:1.082, round:792.845)	b=5.94	count=16500
Total loss:	510.967 (rec:1.115, round:509.852)	b=5.38	count=17000
Total loss:	281.289 (rec:1.167, round:280.122)	b=4.81	count=17500
Total loss:	128.280 (rec:1.186, round:127.094)	b=4.25	count=18000
Total loss:	44.710 (rec:1.099, round:43.611)	b=3.69	count=18500
Total loss:	8.431 (rec:1.142, round:7.288)	b=3.12	count=19000
Total loss:	1.538 (rec:1.198, round:0.340)	b=2.56	count=19500
Total loss:	1.138 (rec:1.135, round:0.003)	b=2.00	count=20000
finished reconstructing blocks.5.
reconstructing blocks.6 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.6 ...
wraping quantizers in blocks.6 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.421 (rec:1.421, round:0.000)	b=0.00	count=500
Total loss:	1.321 (rec:1.321, round:0.000)	b=0.00	count=1000
Total loss:	1.380 (rec:1.380, round:0.000)	b=0.00	count=1500
Total loss:	1.329 (rec:1.329, round:0.000)	b=0.00	count=2000
Total loss:	1.221 (rec:1.221, round:0.000)	b=0.00	count=2500
Total loss:	1.313 (rec:1.313, round:0.000)	b=0.00	count=3000
Total loss:	1.230 (rec:1.230, round:0.000)	b=0.00	count=3500
Total loss:	16173.835 (rec:1.259, round:16172.576)	b=20.00	count=4000
Total loss:	8379.147 (rec:1.282, round:8377.865)	b=19.44	count=4500
Total loss:	7782.250 (rec:1.271, round:7780.979)	b=18.88	count=5000
Total loss:	7400.097 (rec:1.341, round:7398.756)	b=18.31	count=5500
Total loss:	7079.202 (rec:1.267, round:7077.935)	b=17.75	count=6000
Total loss:	6784.063 (rec:1.286, round:6782.777)	b=17.19	count=6500
Total loss:	6507.343 (rec:1.232, round:6506.110)	b=16.62	count=7000
Total loss:	6235.817 (rec:1.245, round:6234.572)	b=16.06	count=7500
Total loss:	5968.732 (rec:1.244, round:5967.488)	b=15.50	count=8000
Total loss:	5701.924 (rec:1.194, round:5700.730)	b=14.94	count=8500
Total loss:	5438.590 (rec:1.224, round:5437.366)	b=14.38	count=9000
Total loss:	5169.896 (rec:1.279, round:5168.618)	b=13.81	count=9500
Total loss:	4898.209 (rec:1.217, round:4896.992)	b=13.25	count=10000
Total loss:	4622.555 (rec:1.276, round:4621.279)	b=12.69	count=10500
Total loss:	4342.461 (rec:1.194, round:4341.267)	b=12.12	count=11000
Total loss:	4055.109 (rec:1.292, round:4053.818)	b=11.56	count=11500
Total loss:	3756.869 (rec:1.280, round:3755.589)	b=11.00	count=12000
Total loss:	3454.618 (rec:1.301, round:3453.318)	b=10.44	count=12500
Total loss:	3148.824 (rec:1.343, round:3147.481)	b=9.88	count=13000
Total loss:	2834.188 (rec:1.299, round:2832.889)	b=9.31	count=13500
Total loss:	2515.053 (rec:1.341, round:2513.713)	b=8.75	count=14000
Total loss:	2187.844 (rec:1.343, round:2186.502)	b=8.19	count=14500
Total loss:	1855.908 (rec:1.310, round:1854.598)	b=7.62	count=15000
Total loss:	1519.912 (rec:1.339, round:1518.573)	b=7.06	count=15500
Total loss:	1187.402 (rec:1.325, round:1186.077)	b=6.50	count=16000
Total loss:	865.009 (rec:1.357, round:863.652)	b=5.94	count=16500
Total loss:	568.076 (rec:1.355, round:566.721)	b=5.38	count=17000
Total loss:	316.287 (rec:1.356, round:314.931)	b=4.81	count=17500
Total loss:	138.268 (rec:1.351, round:136.918)	b=4.25	count=18000
Total loss:	43.312 (rec:1.401, round:41.911)	b=3.69	count=18500
Total loss:	8.265 (rec:1.388, round:6.877)	b=3.12	count=19000
Total loss:	1.739 (rec:1.407, round:0.332)	b=2.56	count=19500
Total loss:	1.355 (rec:1.349, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.6.
reconstructing blocks.7 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.7 ...
wraping quantizers in blocks.7 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.862 (rec:1.862, round:0.000)	b=0.00	count=500
Total loss:	1.771 (rec:1.771, round:0.000)	b=0.00	count=1000
Total loss:	1.669 (rec:1.669, round:0.000)	b=0.00	count=1500
Total loss:	1.743 (rec:1.743, round:0.000)	b=0.00	count=2000
Total loss:	1.573 (rec:1.573, round:0.000)	b=0.00	count=2500
Total loss:	1.599 (rec:1.599, round:0.000)	b=0.00	count=3000
Total loss:	1.626 (rec:1.626, round:0.000)	b=0.00	count=3500
Total loss:	16249.118 (rec:1.641, round:16247.477)	b=20.00	count=4000
Total loss:	8462.096 (rec:1.610, round:8460.485)	b=19.44	count=4500
Total loss:	7868.694 (rec:1.585, round:7867.109)	b=18.88	count=5000
Total loss:	7487.401 (rec:1.628, round:7485.773)	b=18.31	count=5500
Total loss:	7167.192 (rec:1.625, round:7165.566)	b=17.75	count=6000
Total loss:	6869.430 (rec:1.708, round:6867.723)	b=17.19	count=6500
Total loss:	6586.276 (rec:1.622, round:6584.655)	b=16.62	count=7000
Total loss:	6308.431 (rec:1.636, round:6306.794)	b=16.06	count=7500
Total loss:	6036.204 (rec:1.591, round:6034.613)	b=15.50	count=8000
Total loss:	5767.618 (rec:1.610, round:5766.008)	b=14.94	count=8500
Total loss:	5497.892 (rec:1.632, round:5496.260)	b=14.38	count=9000
Total loss:	5226.177 (rec:1.612, round:5224.564)	b=13.81	count=9500
Total loss:	4954.571 (rec:1.600, round:4952.971)	b=13.25	count=10000
Total loss:	4675.349 (rec:1.597, round:4673.752)	b=12.69	count=10500
Total loss:	4390.962 (rec:1.630, round:4389.333)	b=12.12	count=11000
Total loss:	4102.626 (rec:1.613, round:4101.013)	b=11.56	count=11500
Total loss:	3811.584 (rec:1.782, round:3809.802)	b=11.00	count=12000
Total loss:	3513.638 (rec:1.622, round:3512.016)	b=10.44	count=12500
Total loss:	3206.531 (rec:1.639, round:3204.892)	b=9.88	count=13000
Total loss:	2898.481 (rec:1.582, round:2896.899)	b=9.31	count=13500
Total loss:	2581.083 (rec:1.622, round:2579.461)	b=8.75	count=14000
Total loss:	2260.675 (rec:1.745, round:2258.929)	b=8.19	count=14500
Total loss:	1932.148 (rec:1.692, round:1930.457)	b=7.62	count=15000
Total loss:	1602.792 (rec:1.739, round:1601.053)	b=7.06	count=15500
Total loss:	1275.361 (rec:1.705, round:1273.656)	b=6.50	count=16000
Total loss:	956.146 (rec:1.592, round:954.555)	b=5.94	count=16500
Total loss:	653.540 (rec:1.602, round:651.938)	b=5.38	count=17000
Total loss:	387.422 (rec:1.758, round:385.664)	b=4.81	count=17500
Total loss:	182.624 (rec:1.754, round:180.869)	b=4.25	count=18000
Total loss:	59.632 (rec:1.710, round:57.922)	b=3.69	count=18500
Total loss:	11.274 (rec:1.694, round:9.581)	b=3.12	count=19000
Total loss:	2.305 (rec:1.792, round:0.512)	b=2.56	count=19500
Total loss:	1.783 (rec:1.775, round:0.008)	b=2.00	count=20000
finished reconstructing blocks.7.
reconstructing blocks.8 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.8 ...
wraping quantizers in blocks.8 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.788 (rec:1.788, round:0.000)	b=0.00	count=500
Total loss:	1.777 (rec:1.777, round:0.000)	b=0.00	count=1000
Total loss:	1.787 (rec:1.787, round:0.000)	b=0.00	count=1500
Total loss:	1.692 (rec:1.692, round:0.000)	b=0.00	count=2000
Total loss:	1.612 (rec:1.612, round:0.000)	b=0.00	count=2500
Total loss:	1.602 (rec:1.602, round:0.000)	b=0.00	count=3000
Total loss:	1.664 (rec:1.664, round:0.000)	b=0.00	count=3500
Total loss:	16263.187 (rec:1.591, round:16261.596)	b=20.00	count=4000
Total loss:	8407.396 (rec:1.614, round:8405.781)	b=19.44	count=4500
Total loss:	7809.902 (rec:1.671, round:7808.231)	b=18.88	count=5000
Total loss:	7422.562 (rec:1.641, round:7420.921)	b=18.31	count=5500
Total loss:	7096.483 (rec:1.574, round:7094.909)	b=17.75	count=6000
Total loss:	6795.907 (rec:1.600, round:6794.307)	b=17.19	count=6500
Total loss:	6508.125 (rec:1.637, round:6506.488)	b=16.62	count=7000
Total loss:	6225.748 (rec:1.600, round:6224.148)	b=16.06	count=7500
Total loss:	5949.351 (rec:1.625, round:5947.726)	b=15.50	count=8000
Total loss:	5669.823 (rec:1.604, round:5668.219)	b=14.94	count=8500
Total loss:	5394.771 (rec:1.688, round:5393.084)	b=14.38	count=9000
Total loss:	5119.298 (rec:1.604, round:5117.694)	b=13.81	count=9500
Total loss:	4838.686 (rec:1.666, round:4837.020)	b=13.25	count=10000
Total loss:	4557.716 (rec:1.584, round:4556.132)	b=12.69	count=10500
Total loss:	4273.741 (rec:1.628, round:4272.113)	b=12.12	count=11000
Total loss:	3982.167 (rec:1.646, round:3980.521)	b=11.56	count=11500
Total loss:	3688.557 (rec:1.676, round:3686.881)	b=11.00	count=12000
Total loss:	3386.777 (rec:1.566, round:3385.211)	b=10.44	count=12500
Total loss:	3084.289 (rec:1.564, round:3082.725)	b=9.88	count=13000
Total loss:	2778.934 (rec:1.629, round:2777.304)	b=9.31	count=13500
Total loss:	2465.382 (rec:1.685, round:2463.697)	b=8.75	count=14000
Total loss:	2153.208 (rec:1.750, round:2151.458)	b=8.19	count=14500
Total loss:	1835.608 (rec:1.622, round:1833.985)	b=7.62	count=15000
Total loss:	1517.934 (rec:1.646, round:1516.288)	b=7.06	count=15500
Total loss:	1203.679 (rec:1.670, round:1202.009)	b=6.50	count=16000
Total loss:	899.654 (rec:1.634, round:898.020)	b=5.94	count=16500
Total loss:	613.009 (rec:1.668, round:611.341)	b=5.38	count=17000
Total loss:	361.020 (rec:1.658, round:359.361)	b=4.81	count=17500
Total loss:	168.612 (rec:1.712, round:166.900)	b=4.25	count=18000
Total loss:	55.499 (rec:1.718, round:53.781)	b=3.69	count=18500
Total loss:	10.582 (rec:1.696, round:8.886)	b=3.12	count=19000
Total loss:	2.273 (rec:1.781, round:0.491)	b=2.56	count=19500
Total loss:	1.792 (rec:1.785, round:0.007)	b=2.00	count=20000
finished reconstructing blocks.8.
reconstructing blocks.9 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.9 ...
wraping quantizers in blocks.9 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.943 (rec:1.943, round:0.000)	b=0.00	count=500
Total loss:	1.939 (rec:1.939, round:0.000)	b=0.00	count=1000
Total loss:	1.781 (rec:1.781, round:0.000)	b=0.00	count=1500
Total loss:	1.805 (rec:1.805, round:0.000)	b=0.00	count=2000
Total loss:	1.733 (rec:1.733, round:0.000)	b=0.00	count=2500
Total loss:	1.780 (rec:1.780, round:0.000)	b=0.00	count=3000
Total loss:	1.705 (rec:1.705, round:0.000)	b=0.00	count=3500
Total loss:	16181.769 (rec:1.771, round:16179.998)	b=20.00	count=4000
Total loss:	8211.253 (rec:1.781, round:8209.472)	b=19.44	count=4500
Total loss:	7611.781 (rec:1.708, round:7610.073)	b=18.88	count=5000
Total loss:	7221.457 (rec:1.729, round:7219.728)	b=18.31	count=5500
Total loss:	6883.920 (rec:1.685, round:6882.235)	b=17.75	count=6000
Total loss:	6565.372 (rec:1.752, round:6563.620)	b=17.19	count=6500
Total loss:	6261.218 (rec:1.717, round:6259.501)	b=16.62	count=7000
Total loss:	5966.257 (rec:1.660, round:5964.597)	b=16.06	count=7500
Total loss:	5676.216 (rec:1.733, round:5674.482)	b=15.50	count=8000
Total loss:	5390.433 (rec:1.761, round:5388.672)	b=14.94	count=8500
Total loss:	5104.661 (rec:1.699, round:5102.961)	b=14.38	count=9000
Total loss:	4821.796 (rec:1.626, round:4820.170)	b=13.81	count=9500
Total loss:	4537.284 (rec:1.688, round:4535.596)	b=13.25	count=10000
Total loss:	4252.248 (rec:1.744, round:4250.504)	b=12.69	count=10500
Total loss:	3967.473 (rec:1.696, round:3965.777)	b=12.12	count=11000
Total loss:	3683.029 (rec:1.697, round:3681.332)	b=11.56	count=11500
Total loss:	3393.615 (rec:1.681, round:3391.934)	b=11.00	count=12000
Total loss:	3104.904 (rec:1.677, round:3103.228)	b=10.44	count=12500
Total loss:	2812.646 (rec:1.692, round:2810.955)	b=9.88	count=13000
Total loss:	2520.978 (rec:1.669, round:2519.309)	b=9.31	count=13500
Total loss:	2227.812 (rec:1.778, round:2226.034)	b=8.75	count=14000
Total loss:	1933.292 (rec:1.796, round:1931.496)	b=8.19	count=14500
Total loss:	1640.507 (rec:1.746, round:1638.761)	b=7.62	count=15000
Total loss:	1349.683 (rec:1.694, round:1347.990)	b=7.06	count=15500
Total loss:	1059.712 (rec:1.763, round:1057.950)	b=6.50	count=16000
Total loss:	785.734 (rec:1.741, round:783.993)	b=5.94	count=16500
Total loss:	529.458 (rec:1.728, round:527.731)	b=5.38	count=17000
Total loss:	305.142 (rec:1.762, round:303.380)	b=4.81	count=17500
Total loss:	136.846 (rec:1.725, round:135.120)	b=4.25	count=18000
Total loss:	41.788 (rec:1.776, round:40.012)	b=3.69	count=18500
Total loss:	7.874 (rec:1.849, round:6.025)	b=3.12	count=19000
Total loss:	2.080 (rec:1.749, round:0.331)	b=2.56	count=19500
Total loss:	1.865 (rec:1.861, round:0.003)	b=2.00	count=20000
finished reconstructing blocks.9.
reconstructing blocks.10 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.10 ...
wraping quantizers in blocks.10 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.946 (rec:1.946, round:0.000)	b=0.00	count=500
Total loss:	1.964 (rec:1.964, round:0.000)	b=0.00	count=1000
Total loss:	1.906 (rec:1.906, round:0.000)	b=0.00	count=1500
Total loss:	1.878 (rec:1.878, round:0.000)	b=0.00	count=2000
Total loss:	1.812 (rec:1.812, round:0.000)	b=0.00	count=2500
Total loss:	1.772 (rec:1.772, round:0.000)	b=0.00	count=3000
Total loss:	1.851 (rec:1.851, round:0.000)	b=0.00	count=3500
Total loss:	16054.251 (rec:1.818, round:16052.434)	b=20.00	count=4000
Total loss:	7945.442 (rec:1.772, round:7943.671)	b=19.44	count=4500
Total loss:	7344.802 (rec:1.768, round:7343.034)	b=18.88	count=5000
Total loss:	6937.677 (rec:1.691, round:6935.986)	b=18.31	count=5500
Total loss:	6585.567 (rec:1.719, round:6583.849)	b=17.75	count=6000
Total loss:	6255.284 (rec:1.780, round:6253.504)	b=17.19	count=6500
Total loss:	5932.185 (rec:1.739, round:5930.446)	b=16.62	count=7000
Total loss:	5619.313 (rec:1.632, round:5617.681)	b=16.06	count=7500
Total loss:	5314.813 (rec:1.676, round:5313.137)	b=15.50	count=8000
Total loss:	5015.650 (rec:1.731, round:5013.919)	b=14.94	count=8500
Total loss:	4717.744 (rec:1.733, round:4716.011)	b=14.38	count=9000
Total loss:	4425.649 (rec:1.686, round:4423.963)	b=13.81	count=9500
Total loss:	4135.919 (rec:1.771, round:4134.147)	b=13.25	count=10000
Total loss:	3850.849 (rec:1.696, round:3849.153)	b=12.69	count=10500
Total loss:	3567.785 (rec:1.757, round:3566.028)	b=12.12	count=11000
Total loss:	3286.374 (rec:1.820, round:3284.553)	b=11.56	count=11500
Total loss:	3008.583 (rec:1.759, round:3006.823)	b=11.00	count=12000
Total loss:	2733.132 (rec:1.845, round:2731.287)	b=10.44	count=12500
Total loss:	2458.557 (rec:1.689, round:2456.868)	b=9.88	count=13000
Total loss:	2186.589 (rec:1.734, round:2184.855)	b=9.31	count=13500
Total loss:	1915.397 (rec:1.732, round:1913.664)	b=8.75	count=14000
Total loss:	1645.024 (rec:1.782, round:1643.241)	b=8.19	count=14500
Total loss:	1379.626 (rec:1.763, round:1377.863)	b=7.62	count=15000
Total loss:	1118.376 (rec:1.758, round:1116.619)	b=7.06	count=15500
Total loss:	865.923 (rec:1.749, round:864.173)	b=6.50	count=16000
Total loss:	622.837 (rec:1.764, round:621.073)	b=5.94	count=16500
Total loss:	397.015 (rec:1.754, round:395.261)	b=5.38	count=17000
Total loss:	213.436 (rec:1.852, round:211.584)	b=4.81	count=17500
Total loss:	88.034 (rec:1.841, round:86.194)	b=4.25	count=18000
Total loss:	25.394 (rec:1.759, round:23.635)	b=3.69	count=18500
Total loss:	4.953 (rec:1.762, round:3.191)	b=3.12	count=19000
Total loss:	2.057 (rec:1.881, round:0.176)	b=2.56	count=19500
Total loss:	1.748 (rec:1.744, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.10.
reconstructing blocks.11 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.11 ...
wraping quantizers in blocks.11 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.505 (rec:1.505, round:0.000)	b=0.00	count=500
Total loss:	1.332 (rec:1.332, round:0.000)	b=0.00	count=1000
Total loss:	1.425 (rec:1.425, round:0.000)	b=0.00	count=1500
Total loss:	1.447 (rec:1.447, round:0.000)	b=0.00	count=2000
Total loss:	1.363 (rec:1.363, round:0.000)	b=0.00	count=2500
Total loss:	1.377 (rec:1.377, round:0.000)	b=0.00	count=3000
Total loss:	1.371 (rec:1.371, round:0.000)	b=0.00	count=3500
Total loss:	16337.371 (rec:1.357, round:16336.015)	b=20.00	count=4000
Total loss:	8050.113 (rec:1.251, round:8048.862)	b=19.44	count=4500
Total loss:	7445.455 (rec:1.310, round:7444.145)	b=18.88	count=5000
Total loss:	7040.744 (rec:1.325, round:7039.419)	b=18.31	count=5500
Total loss:	6694.916 (rec:1.301, round:6693.615)	b=17.75	count=6000
Total loss:	6365.120 (rec:1.315, round:6363.805)	b=17.19	count=6500
Total loss:	6047.111 (rec:1.357, round:6045.754)	b=16.62	count=7000
Total loss:	5734.208 (rec:1.284, round:5732.925)	b=16.06	count=7500
Total loss:	5428.268 (rec:1.282, round:5426.986)	b=15.50	count=8000
Total loss:	5122.778 (rec:1.266, round:5121.512)	b=14.94	count=8500
Total loss:	4823.112 (rec:1.302, round:4821.811)	b=14.38	count=9000
Total loss:	4523.368 (rec:1.288, round:4522.079)	b=13.81	count=9500
Total loss:	4226.151 (rec:1.367, round:4224.784)	b=13.25	count=10000
Total loss:	3933.797 (rec:1.300, round:3932.498)	b=12.69	count=10500
Total loss:	3642.599 (rec:1.325, round:3641.273)	b=12.12	count=11000
Total loss:	3353.879 (rec:1.263, round:3352.616)	b=11.56	count=11500
Total loss:	3065.734 (rec:1.309, round:3064.425)	b=11.00	count=12000
Total loss:	2780.023 (rec:1.351, round:2778.672)	b=10.44	count=12500
Total loss:	2497.854 (rec:1.297, round:2496.557)	b=9.88	count=13000
Total loss:	2221.508 (rec:1.299, round:2220.208)	b=9.31	count=13500
Total loss:	1949.200 (rec:1.310, round:1947.890)	b=8.75	count=14000
Total loss:	1679.260 (rec:1.294, round:1677.965)	b=8.19	count=14500
Total loss:	1412.897 (rec:1.307, round:1411.589)	b=7.62	count=15000
Total loss:	1151.616 (rec:1.254, round:1150.362)	b=7.06	count=15500
Total loss:	892.565 (rec:1.353, round:891.213)	b=6.50	count=16000
Total loss:	642.755 (rec:1.274, round:641.481)	b=5.94	count=16500
Total loss:	401.910 (rec:1.298, round:400.612)	b=5.38	count=17000
Total loss:	196.808 (rec:1.295, round:195.512)	b=4.81	count=17500
Total loss:	71.525 (rec:1.327, round:70.198)	b=4.25	count=18000
Total loss:	18.964 (rec:1.328, round:17.636)	b=3.69	count=18500
Total loss:	3.719 (rec:1.352, round:2.367)	b=3.12	count=19000
Total loss:	1.404 (rec:1.272, round:0.132)	b=2.56	count=19500
Total loss:	1.364 (rec:1.362, round:0.001)	b=2.00	count=20000
finished reconstructing blocks.11.
reconstructing head ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for head ...
wraping quantizers in head ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.419 (rec:1.419, round:0.000)	b=0.00	count=500
Total loss:	1.396 (rec:1.396, round:0.000)	b=0.00	count=1000
Total loss:	1.046 (rec:1.046, round:0.000)	b=0.00	count=1500
Total loss:	0.788 (rec:0.788, round:0.000)	b=0.00	count=2000
Total loss:	0.712 (rec:0.712, round:0.000)	b=0.00	count=2500
Total loss:	0.845 (rec:0.845, round:0.000)	b=0.00	count=3000
Total loss:	0.727 (rec:0.727, round:0.000)	b=0.00	count=3500
Total loss:	3519.067 (rec:0.607, round:3518.460)	b=20.00	count=4000
Total loss:	2041.279 (rec:0.642, round:2040.637)	b=19.44	count=4500
Total loss:	1900.170 (rec:0.425, round:1899.745)	b=18.88	count=5000
Total loss:	1809.616 (rec:0.472, round:1809.144)	b=18.31	count=5500
Total loss:	1733.025 (rec:0.515, round:1732.511)	b=17.75	count=6000
Total loss:	1663.038 (rec:0.338, round:1662.700)	b=17.19	count=6500
Total loss:	1596.756 (rec:0.486, round:1596.271)	b=16.62	count=7000
Total loss:	1530.996 (rec:0.322, round:1530.674)	b=16.06	count=7500
Total loss:	1466.410 (rec:0.389, round:1466.022)	b=15.50	count=8000
Total loss:	1403.597 (rec:0.337, round:1403.260)	b=14.94	count=8500
Total loss:	1341.565 (rec:0.297, round:1341.268)	b=14.38	count=9000
Total loss:	1281.545 (rec:0.383, round:1281.162)	b=13.81	count=9500
Total loss:	1220.982 (rec:0.372, round:1220.610)	b=13.25	count=10000
Total loss:	1161.201 (rec:0.317, round:1160.884)	b=12.69	count=10500
Total loss:	1101.386 (rec:0.369, round:1101.016)	b=12.12	count=11000
Total loss:	1039.554 (rec:0.396, round:1039.159)	b=11.56	count=11500
Total loss:	977.511 (rec:0.316, round:977.194)	b=11.00	count=12000
Total loss:	914.905 (rec:0.262, round:914.644)	b=10.44	count=12500
Total loss:	851.762 (rec:0.316, round:851.447)	b=9.88	count=13000
Total loss:	786.145 (rec:0.254, round:785.891)	b=9.31	count=13500
Total loss:	721.984 (rec:0.377, round:721.607)	b=8.75	count=14000
Total loss:	654.903 (rec:0.320, round:654.583)	b=8.19	count=14500
Total loss:	585.620 (rec:0.332, round:585.287)	b=7.62	count=15000
Total loss:	516.121 (rec:0.328, round:515.793)	b=7.06	count=15500
Total loss:	445.681 (rec:0.279, round:445.401)	b=6.50	count=16000
Total loss:	374.825 (rec:0.239, round:374.586)	b=5.94	count=16500
Total loss:	303.837 (rec:0.297, round:303.539)	b=5.38	count=17000
Total loss:	232.977 (rec:0.317, round:232.660)	b=4.81	count=17500
Total loss:	164.351 (rec:0.306, round:164.045)	b=4.25	count=18000
Total loss:	101.321 (rec:0.309, round:101.012)	b=3.69	count=18500
Total loss:	47.771 (rec:0.323, round:47.448)	b=3.12	count=19000
Total loss:	12.830 (rec:0.306, round:12.524)	b=2.56	count=19500
Total loss:	1.694 (rec:0.347, round:1.347)	b=2.00	count=20000
finished reconstructing head.
2025-09-14 16:19:47 - mse guided block reconstruction finished.
Saving checkpoint to ./checkpoint/quant_result/20250914_1445/deit_small_w2_a6_optimsize_1024_mse_qdrop.pth
Validating on calibration set after block reconstruction ...
Test: [0/32]	Time 0.411 (0.411)	Loss 0.9246 (0.9246)	Prec@1 81.250 (81.250)	Prec@5 93.750 (93.750)
Test: [10/32]	Time 0.025 (0.063)	Loss 1.1720 (1.2231)	Prec@1 84.375 (78.125)	Prec@5 93.750 (92.614)
Test: [20/32]	Time 0.025 (0.045)	Loss 0.8907 (1.1953)	Prec@1 84.375 (78.571)	Prec@5 100.000 (93.452)
Test: [30/32]	Time 0.025 (0.039)	Loss 1.2519 (1.1357)	Prec@1 81.250 (80.343)	Prec@5 93.750 (94.355)
 * Prec@1 80.762 Prec@5 94.434 Loss 1.127 Time 1.331
Validating on test set after block reconstruction ...
Test: [0/100]	Time 4.068 (4.068)	Loss 1.3604 (1.3604)	Prec@1 77.800 (77.800)	Prec@5 94.200 (94.200)
Test: [10/100]	Time 0.788 (1.105)	Loss 1.7973 (1.6992)	Prec@1 71.200 (71.873)	Prec@5 91.000 (92.182)
Test: [20/100]	Time 0.785 (0.953)	Loss 1.7763 (1.6827)	Prec@1 63.400 (69.971)	Prec@5 92.000 (92.229)
Test: [30/100]	Time 0.786 (0.900)	Loss 1.6243 (1.6379)	Prec@1 70.600 (69.748)	Prec@5 94.000 (92.761)
Test: [40/100]	Time 0.791 (0.873)	Loss 1.8431 (1.6392)	Prec@1 58.600 (70.151)	Prec@5 90.400 (92.600)
Test: [50/100]	Time 0.790 (0.857)	Loss 2.4494 (1.7319)	Prec@1 52.200 (68.188)	Prec@5 80.200 (91.020)
Test: [60/100]	Time 0.789 (0.846)	Loss 1.8893 (1.7609)	Prec@1 65.800 (67.711)	Prec@5 88.400 (90.449)
Test: [70/100]	Time 0.790 (0.838)	Loss 2.1942 (1.8058)	Prec@1 58.200 (66.659)	Prec@5 85.200 (89.665)
Test: [80/100]	Time 0.796 (0.833)	Loss 2.0167 (1.8401)	Prec@1 62.600 (66.210)	Prec@5 89.000 (89.104)
Test: [90/100]	Time 0.785 (0.828)	Loss 2.0608 (1.8728)	Prec@1 59.200 (65.433)	Prec@5 85.200 (88.679)
 * Prec@1 65.714 Prec@5 88.820 Loss 1.864 Time 82.648
2025-09-14 16:21:11 - finished the process.
Extracting logits from quantized and full-precision models...
Testing combinations:
  Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  Cluster numbers: [8, 16, 32, 64, 128, 256]
  PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.89%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.89%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.91%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.91%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.91%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.91%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.92%
[Alpha=0.10] Top-5 Accuracy: 88.83%
Result: Top-1: 65.92%, Top-5: 88.83%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.84%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.84%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.88%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.88%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.89%
[Alpha=0.10] Top-5 Accuracy: 88.87%
Result: Top-1: 65.89%, Top-5: 88.87%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.98%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.98%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.89%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.89%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.87%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.87%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.94%
[Alpha=0.10] Top-5 Accuracy: 88.87%
Result: Top-1: 65.94%, Top-5: 88.87%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.86%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.86%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.78%
[Alpha=0.10] Top-5 Accuracy: 88.89%
Result: Top-1: 65.78%, Top-5: 88.89%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.85%
[Alpha=0.10] Top-5 Accuracy: 88.83%
Result: Top-1: 65.85%, Top-5: 88.83%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.89%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.89%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.88%
[Alpha=0.10] Top-5 Accuracy: 88.87%
Result: Top-1: 65.88%, Top-5: 88.87%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.90%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.90%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.98%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.98%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.82%
[Alpha=0.10] Top-5 Accuracy: 88.80%
Result: Top-1: 65.82%, Top-5: 88.80%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.93%
[Alpha=0.10] Top-5 Accuracy: 88.82%
Result: Top-1: 65.93%, Top-5: 88.82%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.83%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.83%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.87%
[Alpha=0.10] Top-5 Accuracy: 88.82%
Result: Top-1: 65.87%, Top-5: 88.82%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.89%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.89%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.82%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.82%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.88%
[Alpha=0.10] Top-5 Accuracy: 88.87%
Result: Top-1: 65.88%, Top-5: 88.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.86%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.86%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.90%
[Alpha=0.10] Top-5 Accuracy: 88.87%
Result: Top-1: 65.90%, Top-5: 88.87%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.81%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.81%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.86%
[Alpha=0.10] Top-5 Accuracy: 88.84%
Result: Top-1: 65.86%, Top-5: 88.84%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.86%
[Alpha=0.10] Top-5 Accuracy: 88.82%
Result: Top-1: 65.86%, Top-5: 88.82%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.83%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.83%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.91%
[Alpha=0.10] Top-5 Accuracy: 88.81%
Result: Top-1: 65.91%, Top-5: 88.81%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.80%
[Alpha=0.10] Top-5 Accuracy: 88.80%
Result: Top-1: 65.80%, Top-5: 88.80%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.83%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.83%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.85%
[Alpha=0.10] Top-5 Accuracy: 88.86%
Result: Top-1: 65.85%, Top-5: 88.86%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.90%
[Alpha=0.10] Top-5 Accuracy: 88.85%
Result: Top-1: 65.90%, Top-5: 88.85%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.85%
[Alpha=0.10] Top-5 Accuracy: 88.82%
Result: Top-1: 65.85%, Top-5: 88.82%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.89%
[Alpha=0.10] Top-5 Accuracy: 88.89%
Result: Top-1: 65.89%, Top-5: 88.89%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.95%
[Alpha=0.10] Top-5 Accuracy: 88.81%
Result: Top-1: 65.95%, Top-5: 88.81%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.76%
[Alpha=0.10] Top-5 Accuracy: 88.79%
Result: Top-1: 65.76%, Top-5: 88.79%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.67%
[Alpha=0.10] Top-5 Accuracy: 88.81%
Result: Top-1: 65.67%, Top-5: 88.81%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.73%
[Alpha=0.10] Top-5 Accuracy: 88.81%
Result: Top-1: 65.73%, Top-5: 88.81%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.71%
[Alpha=0.10] Top-5 Accuracy: 88.77%
Result: Top-1: 65.71%, Top-5: 88.77%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.67%
[Alpha=0.10] Top-5 Accuracy: 88.71%
Result: Top-1: 65.67%, Top-5: 88.71%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.39%
[Alpha=0.10] Top-5 Accuracy: 88.50%
Result: Top-1: 65.39%, Top-5: 88.50%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.79%
[Alpha=0.10] Top-5 Accuracy: 88.81%
Result: Top-1: 65.79%, Top-5: 88.81%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.76%
[Alpha=0.10] Top-5 Accuracy: 88.80%
Result: Top-1: 65.76%, Top-5: 88.80%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.79%
[Alpha=0.10] Top-5 Accuracy: 88.83%
Result: Top-1: 65.79%, Top-5: 88.83%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.74%
[Alpha=0.10] Top-5 Accuracy: 88.83%
Result: Top-1: 65.74%, Top-5: 88.83%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.73%
[Alpha=0.10] Top-5 Accuracy: 88.74%
Result: Top-1: 65.73%, Top-5: 88.74%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 64.47%
[Alpha=0.10] Top-5 Accuracy: 88.32%
Result: Top-1: 64.47%, Top-5: 88.32%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.23%
[Alpha=0.10] Top-5 Accuracy: 88.58%
Result: Top-1: 65.23%, Top-5: 88.58%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 64.50%
[Alpha=0.10] Top-5 Accuracy: 88.37%
Result: Top-1: 64.50%, Top-5: 88.37%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.03%
[Alpha=0.10] Top-5 Accuracy: 88.63%
Result: Top-1: 65.03%, Top-5: 88.63%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.37%
[Alpha=0.10] Top-5 Accuracy: 88.69%
Result: Top-1: 65.37%, Top-5: 88.69%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.36%
[Alpha=0.10] Top-5 Accuracy: 88.61%
Result: Top-1: 65.36%, Top-5: 88.61%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.17%
[Alpha=0.10] Top-5 Accuracy: 88.61%
Result: Top-1: 65.17%, Top-5: 88.61%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.41%
[Alpha=0.10] Top-5 Accuracy: 88.80%
Result: Top-1: 65.41%, Top-5: 88.80%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.38%
[Alpha=0.10] Top-5 Accuracy: 88.68%
Result: Top-1: 65.38%, Top-5: 88.68%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 65.37%
[Alpha=0.10] Top-5 Accuracy: 88.55%
Result: Top-1: 65.37%, Top-5: 88.55%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.83%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.83%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.98%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.98%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.95%
[Alpha=0.20] Top-5 Accuracy: 88.90%
Result: Top-1: 65.95%, Top-5: 88.90%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.96%
[Alpha=0.20] Top-5 Accuracy: 88.81%
Result: Top-1: 65.96%, Top-5: 88.81%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.85%
[Alpha=0.20] Top-5 Accuracy: 88.88%
Result: Top-1: 65.85%, Top-5: 88.88%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.93%
[Alpha=0.20] Top-5 Accuracy: 88.86%
Result: Top-1: 65.93%, Top-5: 88.86%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.89%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.89%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.96%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.96%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.90%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.90%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.93%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.93%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.85%
[Alpha=0.20] Top-5 Accuracy: 88.93%
Result: Top-1: 65.85%, Top-5: 88.93%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.85%
[Alpha=0.20] Top-5 Accuracy: 88.83%
Result: Top-1: 65.85%, Top-5: 88.83%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.78%
[Alpha=0.20] Top-5 Accuracy: 88.87%
Result: Top-1: 65.78%, Top-5: 88.87%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.83%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.83%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.85%
[Alpha=0.20] Top-5 Accuracy: 88.86%
Result: Top-1: 65.85%, Top-5: 88.86%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.92%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.92%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.90%
[Alpha=0.20] Top-5 Accuracy: 88.81%
Result: Top-1: 65.90%, Top-5: 88.81%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 66.04%
[Alpha=0.20] Top-5 Accuracy: 88.88%
Result: Top-1: 66.04%, Top-5: 88.88%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.80%
[Alpha=0.20] Top-5 Accuracy: 88.80%
Result: Top-1: 65.80%, Top-5: 88.80%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.88%
[Alpha=0.20] Top-5 Accuracy: 88.88%
Result: Top-1: 65.88%, Top-5: 88.88%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.58%
[Alpha=0.20] Top-5 Accuracy: 88.82%
Result: Top-1: 65.58%, Top-5: 88.82%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.75%
[Alpha=0.20] Top-5 Accuracy: 88.82%
Result: Top-1: 65.75%, Top-5: 88.82%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.83%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.83%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.82%
[Alpha=0.20] Top-5 Accuracy: 88.86%
Result: Top-1: 65.82%, Top-5: 88.86%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.82%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.82%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.61%
[Alpha=0.20] Top-5 Accuracy: 88.88%
Result: Top-1: 65.61%, Top-5: 88.88%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.83%
[Alpha=0.20] Top-5 Accuracy: 88.87%
Result: Top-1: 65.83%, Top-5: 88.87%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.79%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.79%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.86%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.86%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.78%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.78%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.52%
[Alpha=0.20] Top-5 Accuracy: 88.78%
Result: Top-1: 65.52%, Top-5: 88.78%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.80%
[Alpha=0.20] Top-5 Accuracy: 88.83%
Result: Top-1: 65.80%, Top-5: 88.83%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.65%
[Alpha=0.20] Top-5 Accuracy: 88.79%
Result: Top-1: 65.65%, Top-5: 88.79%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.63%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.63%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.64%
[Alpha=0.20] Top-5 Accuracy: 88.85%
Result: Top-1: 65.64%, Top-5: 88.85%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.75%
[Alpha=0.20] Top-5 Accuracy: 88.84%
Result: Top-1: 65.75%, Top-5: 88.84%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.59%
[Alpha=0.20] Top-5 Accuracy: 88.76%
Result: Top-1: 65.59%, Top-5: 88.76%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.74%
[Alpha=0.20] Top-5 Accuracy: 88.82%
Result: Top-1: 65.74%, Top-5: 88.82%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.79%
[Alpha=0.20] Top-5 Accuracy: 88.79%
Result: Top-1: 65.79%, Top-5: 88.79%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.39%
[Alpha=0.20] Top-5 Accuracy: 88.71%
Result: Top-1: 65.39%, Top-5: 88.71%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.91%
[Alpha=0.20] Top-5 Accuracy: 88.60%
Result: Top-1: 64.91%, Top-5: 88.60%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.32%
[Alpha=0.20] Top-5 Accuracy: 88.78%
Result: Top-1: 65.32%, Top-5: 88.78%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.10%
[Alpha=0.20] Top-5 Accuracy: 88.66%
Result: Top-1: 65.10%, Top-5: 88.66%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.94%
[Alpha=0.20] Top-5 Accuracy: 88.48%
Result: Top-1: 64.94%, Top-5: 88.48%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.97%
[Alpha=0.20] Top-5 Accuracy: 88.14%
Result: Top-1: 64.97%, Top-5: 88.14%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.33%
[Alpha=0.20] Top-5 Accuracy: 88.61%
Result: Top-1: 65.33%, Top-5: 88.61%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.34%
[Alpha=0.20] Top-5 Accuracy: 88.77%
Result: Top-1: 65.34%, Top-5: 88.77%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.30%
[Alpha=0.20] Top-5 Accuracy: 88.73%
Result: Top-1: 65.30%, Top-5: 88.73%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.30%
[Alpha=0.20] Top-5 Accuracy: 88.64%
Result: Top-1: 65.30%, Top-5: 88.64%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 65.08%
[Alpha=0.20] Top-5 Accuracy: 88.53%
Result: Top-1: 65.08%, Top-5: 88.53%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 62.69%
[Alpha=0.20] Top-5 Accuracy: 87.52%
Result: Top-1: 62.69%, Top-5: 87.52%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.01%
[Alpha=0.20] Top-5 Accuracy: 88.13%
Result: Top-1: 64.01%, Top-5: 88.13%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 62.76%
[Alpha=0.20] Top-5 Accuracy: 87.30%
Result: Top-1: 62.76%, Top-5: 87.30%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 63.32%
[Alpha=0.20] Top-5 Accuracy: 88.01%
Result: Top-1: 63.32%, Top-5: 88.01%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 63.95%
[Alpha=0.20] Top-5 Accuracy: 88.19%
Result: Top-1: 63.95%, Top-5: 88.19%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 63.93%
[Alpha=0.20] Top-5 Accuracy: 88.01%
Result: Top-1: 63.93%, Top-5: 88.01%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.05%
[Alpha=0.20] Top-5 Accuracy: 87.98%
Result: Top-1: 64.05%, Top-5: 87.98%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.44%
[Alpha=0.20] Top-5 Accuracy: 88.46%
Result: Top-1: 64.44%, Top-5: 88.46%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.32%
[Alpha=0.20] Top-5 Accuracy: 88.32%
Result: Top-1: 64.32%, Top-5: 88.32%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 64.27%
[Alpha=0.20] Top-5 Accuracy: 87.93%
Result: Top-1: 64.27%, Top-5: 87.93%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.71%
[Alpha=0.30] Top-5 Accuracy: 88.80%
Result: Top-1: 65.71%, Top-5: 88.80%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.73%
[Alpha=0.30] Top-5 Accuracy: 88.74%
Result: Top-1: 65.73%, Top-5: 88.74%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.84%
[Alpha=0.30] Top-5 Accuracy: 88.81%
Result: Top-1: 65.84%, Top-5: 88.81%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.78%
[Alpha=0.30] Top-5 Accuracy: 88.78%
Result: Top-1: 65.78%, Top-5: 88.78%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.71%
[Alpha=0.30] Top-5 Accuracy: 88.80%
Result: Top-1: 65.71%, Top-5: 88.80%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.65%
[Alpha=0.30] Top-5 Accuracy: 88.76%
Result: Top-1: 65.65%, Top-5: 88.76%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.71%
[Alpha=0.30] Top-5 Accuracy: 88.76%
Result: Top-1: 65.71%, Top-5: 88.76%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.72%
[Alpha=0.30] Top-5 Accuracy: 88.79%
Result: Top-1: 65.72%, Top-5: 88.79%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.66%
[Alpha=0.30] Top-5 Accuracy: 88.77%
Result: Top-1: 65.66%, Top-5: 88.77%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.70%
[Alpha=0.30] Top-5 Accuracy: 88.74%
Result: Top-1: 65.70%, Top-5: 88.74%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.52%
[Alpha=0.30] Top-5 Accuracy: 88.84%
Result: Top-1: 65.52%, Top-5: 88.84%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.64%
[Alpha=0.30] Top-5 Accuracy: 88.76%
Result: Top-1: 65.64%, Top-5: 88.76%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.59%
[Alpha=0.30] Top-5 Accuracy: 88.79%
Result: Top-1: 65.59%, Top-5: 88.79%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.62%
[Alpha=0.30] Top-5 Accuracy: 88.81%
Result: Top-1: 65.62%, Top-5: 88.81%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.63%
[Alpha=0.30] Top-5 Accuracy: 88.82%
Result: Top-1: 65.63%, Top-5: 88.82%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.67%
[Alpha=0.30] Top-5 Accuracy: 88.73%
Result: Top-1: 65.67%, Top-5: 88.73%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.70%
[Alpha=0.30] Top-5 Accuracy: 88.70%
Result: Top-1: 65.70%, Top-5: 88.70%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.74%
[Alpha=0.30] Top-5 Accuracy: 88.82%
Result: Top-1: 65.74%, Top-5: 88.82%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.55%
[Alpha=0.30] Top-5 Accuracy: 88.68%
Result: Top-1: 65.55%, Top-5: 88.68%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.57%
[Alpha=0.30] Top-5 Accuracy: 88.74%
Result: Top-1: 65.57%, Top-5: 88.74%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.10%
[Alpha=0.30] Top-5 Accuracy: 88.71%
Result: Top-1: 65.10%, Top-5: 88.71%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.45%
[Alpha=0.30] Top-5 Accuracy: 88.70%
Result: Top-1: 65.45%, Top-5: 88.70%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.62%
[Alpha=0.30] Top-5 Accuracy: 88.75%
Result: Top-1: 65.62%, Top-5: 88.75%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.51%
[Alpha=0.30] Top-5 Accuracy: 88.76%
Result: Top-1: 65.51%, Top-5: 88.76%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.47%
[Alpha=0.30] Top-5 Accuracy: 88.71%
Result: Top-1: 65.47%, Top-5: 88.71%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.31%
[Alpha=0.30] Top-5 Accuracy: 88.71%
Result: Top-1: 65.31%, Top-5: 88.71%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.39%
[Alpha=0.30] Top-5 Accuracy: 88.78%
Result: Top-1: 65.39%, Top-5: 88.78%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.40%
[Alpha=0.30] Top-5 Accuracy: 88.76%
Result: Top-1: 65.40%, Top-5: 88.76%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.39%
[Alpha=0.30] Top-5 Accuracy: 88.78%
Result: Top-1: 65.39%, Top-5: 88.78%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.35%
[Alpha=0.30] Top-5 Accuracy: 88.72%
Result: Top-1: 65.35%, Top-5: 88.72%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.79%
[Alpha=0.30] Top-5 Accuracy: 88.57%
Result: Top-1: 64.79%, Top-5: 88.57%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.24%
[Alpha=0.30] Top-5 Accuracy: 88.69%
Result: Top-1: 65.24%, Top-5: 88.69%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.99%
[Alpha=0.30] Top-5 Accuracy: 88.60%
Result: Top-1: 64.99%, Top-5: 88.60%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.09%
[Alpha=0.30] Top-5 Accuracy: 88.75%
Result: Top-1: 65.09%, Top-5: 88.75%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.10%
[Alpha=0.30] Top-5 Accuracy: 88.72%
Result: Top-1: 65.10%, Top-5: 88.72%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.12%
[Alpha=0.30] Top-5 Accuracy: 88.70%
Result: Top-1: 65.12%, Top-5: 88.70%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.06%
[Alpha=0.30] Top-5 Accuracy: 88.58%
Result: Top-1: 65.06%, Top-5: 88.58%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.21%
[Alpha=0.30] Top-5 Accuracy: 88.73%
Result: Top-1: 65.21%, Top-5: 88.73%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 65.28%
[Alpha=0.30] Top-5 Accuracy: 88.69%
Result: Top-1: 65.28%, Top-5: 88.69%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.39%
[Alpha=0.30] Top-5 Accuracy: 88.38%
Result: Top-1: 64.39%, Top-5: 88.38%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 63.63%
[Alpha=0.30] Top-5 Accuracy: 88.25%
Result: Top-1: 63.63%, Top-5: 88.25%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.49%
[Alpha=0.30] Top-5 Accuracy: 88.51%
Result: Top-1: 64.49%, Top-5: 88.51%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 63.89%
[Alpha=0.30] Top-5 Accuracy: 88.28%
Result: Top-1: 63.89%, Top-5: 88.28%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 63.61%
[Alpha=0.30] Top-5 Accuracy: 87.97%
Result: Top-1: 63.61%, Top-5: 87.97%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.00%
[Alpha=0.30] Top-5 Accuracy: 87.83%
Result: Top-1: 64.00%, Top-5: 87.83%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.14%
[Alpha=0.30] Top-5 Accuracy: 88.31%
Result: Top-1: 64.14%, Top-5: 88.31%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.28%
[Alpha=0.30] Top-5 Accuracy: 88.44%
Result: Top-1: 64.28%, Top-5: 88.44%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.13%
[Alpha=0.30] Top-5 Accuracy: 88.41%
Result: Top-1: 64.13%, Top-5: 88.41%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 64.06%
[Alpha=0.30] Top-5 Accuracy: 88.38%
Result: Top-1: 64.06%, Top-5: 88.38%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 63.94%
[Alpha=0.30] Top-5 Accuracy: 88.06%
Result: Top-1: 63.94%, Top-5: 88.06%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 59.99%
[Alpha=0.30] Top-5 Accuracy: 86.26%
Result: Top-1: 59.99%, Top-5: 86.26%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 61.87%
[Alpha=0.30] Top-5 Accuracy: 87.32%
Result: Top-1: 61.87%, Top-5: 87.32%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 60.37%
[Alpha=0.30] Top-5 Accuracy: 85.94%
Result: Top-1: 60.37%, Top-5: 85.94%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 60.88%
[Alpha=0.30] Top-5 Accuracy: 86.98%
Result: Top-1: 60.88%, Top-5: 86.98%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 61.72%
[Alpha=0.30] Top-5 Accuracy: 87.33%
Result: Top-1: 61.72%, Top-5: 87.33%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 62.04%
[Alpha=0.30] Top-5 Accuracy: 87.06%
Result: Top-1: 62.04%, Top-5: 87.06%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 62.33%
[Alpha=0.30] Top-5 Accuracy: 87.20%
Result: Top-1: 62.33%, Top-5: 87.20%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 62.56%
[Alpha=0.30] Top-5 Accuracy: 87.79%
Result: Top-1: 62.56%, Top-5: 87.79%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 62.39%
[Alpha=0.30] Top-5 Accuracy: 87.51%
Result: Top-1: 62.39%, Top-5: 87.51%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 62.48%
[Alpha=0.30] Top-5 Accuracy: 87.04%
Result: Top-1: 62.48%, Top-5: 87.04%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.30%
[Alpha=0.40] Top-5 Accuracy: 88.65%
Result: Top-1: 65.30%, Top-5: 88.65%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.29%
[Alpha=0.40] Top-5 Accuracy: 88.66%
Result: Top-1: 65.29%, Top-5: 88.66%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.41%
[Alpha=0.40] Top-5 Accuracy: 88.65%
Result: Top-1: 65.41%, Top-5: 88.65%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.35%
[Alpha=0.40] Top-5 Accuracy: 88.64%
Result: Top-1: 65.35%, Top-5: 88.64%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.27%
[Alpha=0.40] Top-5 Accuracy: 88.67%
Result: Top-1: 65.27%, Top-5: 88.67%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.27%
[Alpha=0.40] Top-5 Accuracy: 88.64%
Result: Top-1: 65.27%, Top-5: 88.64%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.21%
[Alpha=0.40] Top-5 Accuracy: 88.61%
Result: Top-1: 65.21%, Top-5: 88.61%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.33%
[Alpha=0.40] Top-5 Accuracy: 88.71%
Result: Top-1: 65.33%, Top-5: 88.71%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.22%
[Alpha=0.40] Top-5 Accuracy: 88.57%
Result: Top-1: 65.22%, Top-5: 88.57%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.34%
[Alpha=0.40] Top-5 Accuracy: 88.58%
Result: Top-1: 65.34%, Top-5: 88.58%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.05%
[Alpha=0.40] Top-5 Accuracy: 88.62%
Result: Top-1: 65.05%, Top-5: 88.62%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.04%
[Alpha=0.40] Top-5 Accuracy: 88.58%
Result: Top-1: 65.04%, Top-5: 88.58%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.04%
[Alpha=0.40] Top-5 Accuracy: 88.56%
Result: Top-1: 65.04%, Top-5: 88.56%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.97%
[Alpha=0.40] Top-5 Accuracy: 88.56%
Result: Top-1: 64.97%, Top-5: 88.56%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.10%
[Alpha=0.40] Top-5 Accuracy: 88.65%
Result: Top-1: 65.10%, Top-5: 88.65%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.05%
[Alpha=0.40] Top-5 Accuracy: 88.52%
Result: Top-1: 65.05%, Top-5: 88.52%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.15%
[Alpha=0.40] Top-5 Accuracy: 88.51%
Result: Top-1: 65.15%, Top-5: 88.51%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.22%
[Alpha=0.40] Top-5 Accuracy: 88.66%
Result: Top-1: 65.22%, Top-5: 88.66%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.87%
[Alpha=0.40] Top-5 Accuracy: 88.46%
Result: Top-1: 64.87%, Top-5: 88.46%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 65.06%
[Alpha=0.40] Top-5 Accuracy: 88.56%
Result: Top-1: 65.06%, Top-5: 88.56%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.39%
[Alpha=0.40] Top-5 Accuracy: 88.43%
Result: Top-1: 64.39%, Top-5: 88.43%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.76%
[Alpha=0.40] Top-5 Accuracy: 88.46%
Result: Top-1: 64.76%, Top-5: 88.46%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.99%
[Alpha=0.40] Top-5 Accuracy: 88.57%
Result: Top-1: 64.99%, Top-5: 88.57%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.69%
[Alpha=0.40] Top-5 Accuracy: 88.50%
Result: Top-1: 64.69%, Top-5: 88.50%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.89%
[Alpha=0.40] Top-5 Accuracy: 88.55%
Result: Top-1: 64.89%, Top-5: 88.55%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.50%
[Alpha=0.40] Top-5 Accuracy: 88.46%
Result: Top-1: 64.50%, Top-5: 88.46%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.57%
[Alpha=0.40] Top-5 Accuracy: 88.59%
Result: Top-1: 64.57%, Top-5: 88.59%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.59%
[Alpha=0.40] Top-5 Accuracy: 88.52%
Result: Top-1: 64.59%, Top-5: 88.52%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.61%
[Alpha=0.40] Top-5 Accuracy: 88.54%
Result: Top-1: 64.61%, Top-5: 88.54%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.65%
[Alpha=0.40] Top-5 Accuracy: 88.43%
Result: Top-1: 64.65%, Top-5: 88.43%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 63.52%
[Alpha=0.40] Top-5 Accuracy: 88.19%
Result: Top-1: 63.52%, Top-5: 88.19%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.13%
[Alpha=0.40] Top-5 Accuracy: 88.32%
Result: Top-1: 64.13%, Top-5: 88.32%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.01%
[Alpha=0.40] Top-5 Accuracy: 88.20%
Result: Top-1: 64.01%, Top-5: 88.20%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.23%
[Alpha=0.40] Top-5 Accuracy: 88.45%
Result: Top-1: 64.23%, Top-5: 88.45%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.15%
[Alpha=0.40] Top-5 Accuracy: 88.31%
Result: Top-1: 64.15%, Top-5: 88.31%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.11%
[Alpha=0.40] Top-5 Accuracy: 88.35%
Result: Top-1: 64.11%, Top-5: 88.35%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 63.99%
[Alpha=0.40] Top-5 Accuracy: 88.23%
Result: Top-1: 63.99%, Top-5: 88.23%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.33%
[Alpha=0.40] Top-5 Accuracy: 88.44%
Result: Top-1: 64.33%, Top-5: 88.44%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 64.36%
[Alpha=0.40] Top-5 Accuracy: 88.35%
Result: Top-1: 64.36%, Top-5: 88.35%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.96%
[Alpha=0.40] Top-5 Accuracy: 87.87%
Result: Top-1: 62.96%, Top-5: 87.87%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 61.47%
[Alpha=0.40] Top-5 Accuracy: 87.47%
Result: Top-1: 61.47%, Top-5: 87.47%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.65%
[Alpha=0.40] Top-5 Accuracy: 87.87%
Result: Top-1: 62.65%, Top-5: 87.87%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 61.88%
[Alpha=0.40] Top-5 Accuracy: 87.52%
Result: Top-1: 61.88%, Top-5: 87.52%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 61.85%
[Alpha=0.40] Top-5 Accuracy: 87.18%
Result: Top-1: 61.85%, Top-5: 87.18%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.45%
[Alpha=0.40] Top-5 Accuracy: 87.18%
Result: Top-1: 62.45%, Top-5: 87.18%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.30%
[Alpha=0.40] Top-5 Accuracy: 87.45%
Result: Top-1: 62.30%, Top-5: 87.45%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.56%
[Alpha=0.40] Top-5 Accuracy: 87.88%
Result: Top-1: 62.56%, Top-5: 87.88%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.26%
[Alpha=0.40] Top-5 Accuracy: 87.69%
Result: Top-1: 62.26%, Top-5: 87.69%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.24%
[Alpha=0.40] Top-5 Accuracy: 87.69%
Result: Top-1: 62.24%, Top-5: 87.69%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 62.02%
[Alpha=0.40] Top-5 Accuracy: 87.31%
Result: Top-1: 62.02%, Top-5: 87.31%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 56.46%
[Alpha=0.40] Top-5 Accuracy: 84.26%
Result: Top-1: 56.46%, Top-5: 84.26%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 58.85%
[Alpha=0.40] Top-5 Accuracy: 85.90%
Result: Top-1: 58.85%, Top-5: 85.90%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 57.27%
[Alpha=0.40] Top-5 Accuracy: 84.20%
Result: Top-1: 57.27%, Top-5: 84.20%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 57.84%
[Alpha=0.40] Top-5 Accuracy: 85.39%
Result: Top-1: 57.84%, Top-5: 85.39%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 58.80%
[Alpha=0.40] Top-5 Accuracy: 85.91%
Result: Top-1: 58.80%, Top-5: 85.91%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 59.09%
[Alpha=0.40] Top-5 Accuracy: 85.67%
Result: Top-1: 59.09%, Top-5: 85.67%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 59.66%
[Alpha=0.40] Top-5 Accuracy: 85.96%
Result: Top-1: 59.66%, Top-5: 85.96%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 60.01%
[Alpha=0.40] Top-5 Accuracy: 86.63%
Result: Top-1: 60.01%, Top-5: 86.63%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 59.62%
[Alpha=0.40] Top-5 Accuracy: 86.25%
Result: Top-1: 59.62%, Top-5: 86.25%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 60.13%
[Alpha=0.40] Top-5 Accuracy: 85.70%
Result: Top-1: 60.13%, Top-5: 85.70%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.62%
[Alpha=0.50] Top-5 Accuracy: 88.39%
Result: Top-1: 64.62%, Top-5: 88.39%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.51%
[Alpha=0.50] Top-5 Accuracy: 88.43%
Result: Top-1: 64.51%, Top-5: 88.43%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.54%
[Alpha=0.50] Top-5 Accuracy: 88.41%
Result: Top-1: 64.54%, Top-5: 88.41%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.38%
[Alpha=0.50] Top-5 Accuracy: 88.24%
Result: Top-1: 64.38%, Top-5: 88.24%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.45%
[Alpha=0.50] Top-5 Accuracy: 88.30%
Result: Top-1: 64.45%, Top-5: 88.30%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.39%
[Alpha=0.50] Top-5 Accuracy: 88.39%
Result: Top-1: 64.39%, Top-5: 88.39%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.47%
[Alpha=0.50] Top-5 Accuracy: 88.30%
Result: Top-1: 64.47%, Top-5: 88.30%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.44%
[Alpha=0.50] Top-5 Accuracy: 88.45%
Result: Top-1: 64.44%, Top-5: 88.45%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.44%
[Alpha=0.50] Top-5 Accuracy: 88.27%
Result: Top-1: 64.44%, Top-5: 88.27%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.46%
[Alpha=0.50] Top-5 Accuracy: 88.32%
Result: Top-1: 64.46%, Top-5: 88.32%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.07%
[Alpha=0.50] Top-5 Accuracy: 88.32%
Result: Top-1: 64.07%, Top-5: 88.32%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.81%
[Alpha=0.50] Top-5 Accuracy: 88.21%
Result: Top-1: 63.81%, Top-5: 88.21%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.79%
[Alpha=0.50] Top-5 Accuracy: 88.22%
Result: Top-1: 63.79%, Top-5: 88.22%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.77%
[Alpha=0.50] Top-5 Accuracy: 88.21%
Result: Top-1: 63.77%, Top-5: 88.21%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.87%
[Alpha=0.50] Top-5 Accuracy: 88.36%
Result: Top-1: 63.87%, Top-5: 88.36%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.66%
[Alpha=0.50] Top-5 Accuracy: 88.07%
Result: Top-1: 63.66%, Top-5: 88.07%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.94%
[Alpha=0.50] Top-5 Accuracy: 88.12%
Result: Top-1: 63.94%, Top-5: 88.12%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.26%
[Alpha=0.50] Top-5 Accuracy: 88.38%
Result: Top-1: 64.26%, Top-5: 88.38%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.84%
[Alpha=0.50] Top-5 Accuracy: 88.07%
Result: Top-1: 63.84%, Top-5: 88.07%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 64.09%
[Alpha=0.50] Top-5 Accuracy: 88.27%
Result: Top-1: 64.09%, Top-5: 88.27%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.05%
[Alpha=0.50] Top-5 Accuracy: 87.90%
Result: Top-1: 63.05%, Top-5: 87.90%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.39%
[Alpha=0.50] Top-5 Accuracy: 88.08%
Result: Top-1: 63.39%, Top-5: 88.08%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.88%
[Alpha=0.50] Top-5 Accuracy: 88.16%
Result: Top-1: 63.88%, Top-5: 88.16%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.01%
[Alpha=0.50] Top-5 Accuracy: 88.12%
Result: Top-1: 63.01%, Top-5: 88.12%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.58%
[Alpha=0.50] Top-5 Accuracy: 88.13%
Result: Top-1: 63.58%, Top-5: 88.13%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.11%
[Alpha=0.50] Top-5 Accuracy: 88.02%
Result: Top-1: 63.11%, Top-5: 88.02%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.37%
[Alpha=0.50] Top-5 Accuracy: 88.21%
Result: Top-1: 63.37%, Top-5: 88.21%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.29%
[Alpha=0.50] Top-5 Accuracy: 88.03%
Result: Top-1: 63.29%, Top-5: 88.03%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 63.35%
[Alpha=0.50] Top-5 Accuracy: 88.14%
Result: Top-1: 63.35%, Top-5: 88.14%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.95%
[Alpha=0.50] Top-5 Accuracy: 87.87%
Result: Top-1: 62.95%, Top-5: 87.87%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 61.65%
[Alpha=0.50] Top-5 Accuracy: 87.30%
Result: Top-1: 61.65%, Top-5: 87.30%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.15%
[Alpha=0.50] Top-5 Accuracy: 87.66%
Result: Top-1: 62.15%, Top-5: 87.66%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.14%
[Alpha=0.50] Top-5 Accuracy: 87.58%
Result: Top-1: 62.14%, Top-5: 87.58%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.63%
[Alpha=0.50] Top-5 Accuracy: 87.86%
Result: Top-1: 62.63%, Top-5: 87.86%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.63%
[Alpha=0.50] Top-5 Accuracy: 87.69%
Result: Top-1: 62.63%, Top-5: 87.69%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.20%
[Alpha=0.50] Top-5 Accuracy: 87.63%
Result: Top-1: 62.20%, Top-5: 87.63%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.49%
[Alpha=0.50] Top-5 Accuracy: 87.62%
Result: Top-1: 62.49%, Top-5: 87.62%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.84%
[Alpha=0.50] Top-5 Accuracy: 87.91%
Result: Top-1: 62.84%, Top-5: 87.91%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 62.57%
[Alpha=0.50] Top-5 Accuracy: 87.77%
Result: Top-1: 62.57%, Top-5: 87.77%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 60.73%
[Alpha=0.50] Top-5 Accuracy: 86.88%
Result: Top-1: 60.73%, Top-5: 86.88%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 58.46%
[Alpha=0.50] Top-5 Accuracy: 85.96%
Result: Top-1: 58.46%, Top-5: 85.96%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.84%
[Alpha=0.50] Top-5 Accuracy: 86.87%
Result: Top-1: 59.84%, Top-5: 86.87%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.07%
[Alpha=0.50] Top-5 Accuracy: 86.43%
Result: Top-1: 59.07%, Top-5: 86.43%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.06%
[Alpha=0.50] Top-5 Accuracy: 86.00%
Result: Top-1: 59.06%, Top-5: 86.00%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.83%
[Alpha=0.50] Top-5 Accuracy: 86.21%
Result: Top-1: 59.83%, Top-5: 86.21%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.32%
[Alpha=0.50] Top-5 Accuracy: 86.23%
Result: Top-1: 59.32%, Top-5: 86.23%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 60.20%
[Alpha=0.50] Top-5 Accuracy: 86.79%
Result: Top-1: 60.20%, Top-5: 86.79%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.50%
[Alpha=0.50] Top-5 Accuracy: 86.48%
Result: Top-1: 59.50%, Top-5: 86.48%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 59.50%
[Alpha=0.50] Top-5 Accuracy: 86.47%
Result: Top-1: 59.50%, Top-5: 86.47%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 58.99%
[Alpha=0.50] Top-5 Accuracy: 86.15%
Result: Top-1: 58.99%, Top-5: 86.15%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 52.38%
[Alpha=0.50] Top-5 Accuracy: 81.44%
Result: Top-1: 52.38%, Top-5: 81.44%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 55.00%
[Alpha=0.50] Top-5 Accuracy: 83.77%
Result: Top-1: 55.00%, Top-5: 83.77%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 53.27%
[Alpha=0.50] Top-5 Accuracy: 81.94%
Result: Top-1: 53.27%, Top-5: 81.94%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 54.02%
[Alpha=0.50] Top-5 Accuracy: 83.13%
Result: Top-1: 54.02%, Top-5: 83.13%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 55.09%
[Alpha=0.50] Top-5 Accuracy: 83.63%
Result: Top-1: 55.09%, Top-5: 83.63%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 54.98%
[Alpha=0.50] Top-5 Accuracy: 83.39%
Result: Top-1: 54.98%, Top-5: 83.39%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 56.03%
[Alpha=0.50] Top-5 Accuracy: 84.31%
Result: Top-1: 56.03%, Top-5: 84.31%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 56.71%
[Alpha=0.50] Top-5 Accuracy: 84.99%
Result: Top-1: 56.71%, Top-5: 84.99%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 56.16%
[Alpha=0.50] Top-5 Accuracy: 84.36%
Result: Top-1: 56.16%, Top-5: 84.36%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 56.50%
[Alpha=0.50] Top-5 Accuracy: 83.94%
Result: Top-1: 56.50%, Top-5: 83.94%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 63.49%
[Alpha=0.60] Top-5 Accuracy: 87.96%
Result: Top-1: 63.49%, Top-5: 87.96%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.93%
[Alpha=0.60] Top-5 Accuracy: 88.01%
Result: Top-1: 62.93%, Top-5: 88.01%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 63.29%
[Alpha=0.60] Top-5 Accuracy: 87.95%
Result: Top-1: 63.29%, Top-5: 87.95%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.76%
[Alpha=0.60] Top-5 Accuracy: 87.77%
Result: Top-1: 61.76%, Top-5: 87.77%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.46%
[Alpha=0.60] Top-5 Accuracy: 87.62%
Result: Top-1: 62.46%, Top-5: 87.62%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.70%
[Alpha=0.60] Top-5 Accuracy: 87.87%
Result: Top-1: 62.70%, Top-5: 87.87%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 63.19%
[Alpha=0.60] Top-5 Accuracy: 87.87%
Result: Top-1: 63.19%, Top-5: 87.87%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.65%
[Alpha=0.60] Top-5 Accuracy: 88.02%
Result: Top-1: 62.65%, Top-5: 88.02%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 63.07%
[Alpha=0.60] Top-5 Accuracy: 87.86%
Result: Top-1: 63.07%, Top-5: 87.86%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 63.15%
[Alpha=0.60] Top-5 Accuracy: 87.84%
Result: Top-1: 63.15%, Top-5: 87.84%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.58%
[Alpha=0.60] Top-5 Accuracy: 87.72%
Result: Top-1: 62.58%, Top-5: 87.72%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.70%
[Alpha=0.60] Top-5 Accuracy: 87.65%
Result: Top-1: 60.70%, Top-5: 87.65%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.93%
[Alpha=0.60] Top-5 Accuracy: 87.69%
Result: Top-1: 60.93%, Top-5: 87.69%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.39%
[Alpha=0.60] Top-5 Accuracy: 87.59%
Result: Top-1: 61.39%, Top-5: 87.59%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.63%
[Alpha=0.60] Top-5 Accuracy: 87.86%
Result: Top-1: 61.63%, Top-5: 87.86%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.22%
[Alpha=0.60] Top-5 Accuracy: 87.22%
Result: Top-1: 60.22%, Top-5: 87.22%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.74%
[Alpha=0.60] Top-5 Accuracy: 87.44%
Result: Top-1: 60.74%, Top-5: 87.44%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.81%
[Alpha=0.60] Top-5 Accuracy: 87.87%
Result: Top-1: 61.81%, Top-5: 87.87%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.24%
[Alpha=0.60] Top-5 Accuracy: 87.40%
Result: Top-1: 61.24%, Top-5: 87.40%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.27%
[Alpha=0.60] Top-5 Accuracy: 87.64%
Result: Top-1: 62.27%, Top-5: 87.64%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.14%
[Alpha=0.60] Top-5 Accuracy: 87.07%
Result: Top-1: 61.14%, Top-5: 87.07%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.88%
[Alpha=0.60] Top-5 Accuracy: 87.17%
Result: Top-1: 60.88%, Top-5: 87.17%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 62.03%
[Alpha=0.60] Top-5 Accuracy: 87.51%
Result: Top-1: 62.03%, Top-5: 87.51%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.52%
[Alpha=0.60] Top-5 Accuracy: 87.49%
Result: Top-1: 60.52%, Top-5: 87.49%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.97%
[Alpha=0.60] Top-5 Accuracy: 87.32%
Result: Top-1: 60.97%, Top-5: 87.32%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.85%
[Alpha=0.60] Top-5 Accuracy: 87.24%
Result: Top-1: 60.85%, Top-5: 87.24%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.19%
[Alpha=0.60] Top-5 Accuracy: 87.64%
Result: Top-1: 61.19%, Top-5: 87.64%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.46%
[Alpha=0.60] Top-5 Accuracy: 87.29%
Result: Top-1: 60.46%, Top-5: 87.29%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 61.35%
[Alpha=0.60] Top-5 Accuracy: 87.40%
Result: Top-1: 61.35%, Top-5: 87.40%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 59.65%
[Alpha=0.60] Top-5 Accuracy: 86.96%
Result: Top-1: 59.65%, Top-5: 86.96%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 58.98%
[Alpha=0.60] Top-5 Accuracy: 85.99%
Result: Top-1: 58.98%, Top-5: 85.99%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 59.00%
[Alpha=0.60] Top-5 Accuracy: 86.75%
Result: Top-1: 59.00%, Top-5: 86.75%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 58.83%
[Alpha=0.60] Top-5 Accuracy: 86.51%
Result: Top-1: 58.83%, Top-5: 86.51%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.23%
[Alpha=0.60] Top-5 Accuracy: 86.88%
Result: Top-1: 60.23%, Top-5: 86.88%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.27%
[Alpha=0.60] Top-5 Accuracy: 86.73%
Result: Top-1: 60.27%, Top-5: 86.73%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 59.20%
[Alpha=0.60] Top-5 Accuracy: 86.49%
Result: Top-1: 59.20%, Top-5: 86.49%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 59.98%
[Alpha=0.60] Top-5 Accuracy: 86.68%
Result: Top-1: 59.98%, Top-5: 86.68%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 60.10%
[Alpha=0.60] Top-5 Accuracy: 87.10%
Result: Top-1: 60.10%, Top-5: 87.10%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 59.34%
[Alpha=0.60] Top-5 Accuracy: 86.86%
Result: Top-1: 59.34%, Top-5: 86.86%

============================================================
Testing: alpha=0.6, clusters=64, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 57.56%
[Alpha=0.60] Top-5 Accuracy: 85.59%
Result: Top-1: 57.56%, Top-5: 85.59%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 54.63%
[Alpha=0.60] Top-5 Accuracy: 83.61%
Result: Top-1: 54.63%, Top-5: 83.61%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 56.02%
[Alpha=0.60] Top-5 Accuracy: 85.25%
Result: Top-1: 56.02%, Top-5: 85.25%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 55.43%
[Alpha=0.60] Top-5 Accuracy: 84.80%
Result: Top-1: 55.43%, Top-5: 84.80%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 54.99%
[Alpha=0.60] Top-5 Accuracy: 84.35%
Result: Top-1: 54.99%, Top-5: 84.35%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 55.91%
[Alpha=0.60] Top-5 Accuracy: 84.94%
Result: Top-1: 55.91%, Top-5: 84.94%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 55.07%
[Alpha=0.60] Top-5 Accuracy: 84.42%
Result: Top-1: 55.07%, Top-5: 84.42%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 56.88%
[Alpha=0.60] Top-5 Accuracy: 85.19%
Result: Top-1: 56.88%, Top-5: 85.19%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 55.27%
[Alpha=0.60] Top-5 Accuracy: 84.78%
Result: Top-1: 55.27%, Top-5: 84.78%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 55.36%
[Alpha=0.60] Top-5 Accuracy: 84.76%
Result: Top-1: 55.36%, Top-5: 84.76%

============================================================
Testing: alpha=0.6, clusters=128, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 55.30%
[Alpha=0.60] Top-5 Accuracy: 84.36%
Result: Top-1: 55.30%, Top-5: 84.36%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 47.60%
[Alpha=0.60] Top-5 Accuracy: 77.31%
Result: Top-1: 47.60%, Top-5: 77.31%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 50.40%
[Alpha=0.60] Top-5 Accuracy: 80.69%
Result: Top-1: 50.40%, Top-5: 80.69%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 48.63%
[Alpha=0.60] Top-5 Accuracy: 78.69%
Result: Top-1: 48.63%, Top-5: 78.69%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 49.42%
[Alpha=0.60] Top-5 Accuracy: 80.27%
Result: Top-1: 49.42%, Top-5: 80.27%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 50.73%
[Alpha=0.60] Top-5 Accuracy: 80.85%
Result: Top-1: 50.73%, Top-5: 80.85%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 49.74%
[Alpha=0.60] Top-5 Accuracy: 80.62%
Result: Top-1: 49.74%, Top-5: 80.62%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 51.58%
[Alpha=0.60] Top-5 Accuracy: 82.02%
Result: Top-1: 51.58%, Top-5: 82.02%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 52.40%
[Alpha=0.60] Top-5 Accuracy: 82.41%
Result: Top-1: 52.40%, Top-5: 82.41%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 51.96%
[Alpha=0.60] Top-5 Accuracy: 81.71%
Result: Top-1: 51.96%, Top-5: 81.71%

============================================================
Testing: alpha=0.6, clusters=256, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 51.50%
[Alpha=0.60] Top-5 Accuracy: 81.48%
Result: Top-1: 51.50%, Top-5: 81.48%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 61.70%
[Alpha=0.70] Top-5 Accuracy: 87.11%
Result: Top-1: 61.70%, Top-5: 87.11%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 60.33%
[Alpha=0.70] Top-5 Accuracy: 87.19%
Result: Top-1: 60.33%, Top-5: 87.19%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 60.96%
[Alpha=0.70] Top-5 Accuracy: 87.10%
Result: Top-1: 60.96%, Top-5: 87.10%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.57%
[Alpha=0.70] Top-5 Accuracy: 86.97%
Result: Top-1: 55.57%, Top-5: 86.97%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.65%
[Alpha=0.70] Top-5 Accuracy: 86.53%
Result: Top-1: 57.65%, Top-5: 86.53%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 59.69%
[Alpha=0.70] Top-5 Accuracy: 87.08%
Result: Top-1: 59.69%, Top-5: 87.08%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 60.61%
[Alpha=0.70] Top-5 Accuracy: 87.00%
Result: Top-1: 60.61%, Top-5: 87.00%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 59.78%
[Alpha=0.70] Top-5 Accuracy: 87.34%
Result: Top-1: 59.78%, Top-5: 87.34%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 60.36%
[Alpha=0.70] Top-5 Accuracy: 86.91%
Result: Top-1: 60.36%, Top-5: 86.91%

============================================================
Testing: alpha=0.7, clusters=8, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 60.29%
[Alpha=0.70] Top-5 Accuracy: 86.90%
Result: Top-1: 60.29%, Top-5: 86.90%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 60.57%
[Alpha=0.70] Top-5 Accuracy: 86.69%
Result: Top-1: 60.57%, Top-5: 86.69%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 54.19%
[Alpha=0.70] Top-5 Accuracy: 86.80%
Result: Top-1: 54.19%, Top-5: 86.80%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.41%
[Alpha=0.70] Top-5 Accuracy: 86.73%
Result: Top-1: 55.41%, Top-5: 86.73%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.73%
[Alpha=0.70] Top-5 Accuracy: 86.66%
Result: Top-1: 57.73%, Top-5: 86.66%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.88%
[Alpha=0.70] Top-5 Accuracy: 87.03%
Result: Top-1: 57.88%, Top-5: 87.03%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 51.21%
[Alpha=0.70] Top-5 Accuracy: 86.18%
Result: Top-1: 51.21%, Top-5: 86.18%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 53.14%
[Alpha=0.70] Top-5 Accuracy: 86.34%
Result: Top-1: 53.14%, Top-5: 86.34%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.61%
[Alpha=0.70] Top-5 Accuracy: 86.95%
Result: Top-1: 57.61%, Top-5: 86.95%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.07%
[Alpha=0.70] Top-5 Accuracy: 86.27%
Result: Top-1: 55.07%, Top-5: 86.27%

============================================================
Testing: alpha=0.7, clusters=16, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 59.20%
[Alpha=0.70] Top-5 Accuracy: 86.78%
Result: Top-1: 59.20%, Top-5: 86.78%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 58.36%
[Alpha=0.70] Top-5 Accuracy: 85.79%
Result: Top-1: 58.36%, Top-5: 85.79%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 56.53%
[Alpha=0.70] Top-5 Accuracy: 86.12%
Result: Top-1: 56.53%, Top-5: 86.12%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 59.05%
[Alpha=0.70] Top-5 Accuracy: 86.39%
Result: Top-1: 59.05%, Top-5: 86.39%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.75%
[Alpha=0.70] Top-5 Accuracy: 86.51%
Result: Top-1: 57.75%, Top-5: 86.51%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 54.79%
[Alpha=0.70] Top-5 Accuracy: 86.11%
Result: Top-1: 54.79%, Top-5: 86.11%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.48%
[Alpha=0.70] Top-5 Accuracy: 86.05%
Result: Top-1: 57.48%, Top-5: 86.05%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 58.35%
[Alpha=0.70] Top-5 Accuracy: 86.64%
Result: Top-1: 58.35%, Top-5: 86.64%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 54.89%
[Alpha=0.70] Top-5 Accuracy: 86.14%
Result: Top-1: 54.89%, Top-5: 86.14%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 57.97%
[Alpha=0.70] Top-5 Accuracy: 86.14%
Result: Top-1: 57.97%, Top-5: 86.14%

============================================================
Testing: alpha=0.7, clusters=32, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 52.52%
[Alpha=0.70] Top-5 Accuracy: 85.49%
Result: Top-1: 52.52%, Top-5: 85.49%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.38%
[Alpha=0.70] Top-5 Accuracy: 84.12%
Result: Top-1: 55.38%, Top-5: 84.12%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 54.62%
[Alpha=0.70] Top-5 Accuracy: 85.26%
Result: Top-1: 54.62%, Top-5: 85.26%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 53.36%
[Alpha=0.70] Top-5 Accuracy: 84.78%
Result: Top-1: 53.36%, Top-5: 84.78%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.82%
[Alpha=0.70] Top-5 Accuracy: 85.44%
Result: Top-1: 55.82%, Top-5: 85.44%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 56.23%
[Alpha=0.70] Top-5 Accuracy: 85.32%
Result: Top-1: 56.23%, Top-5: 85.32%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.12%
[Alpha=0.70] Top-5 Accuracy: 84.78%
Result: Top-1: 55.12%, Top-5: 84.78%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 56.53%
[Alpha=0.70] Top-5 Accuracy: 85.18%
Result: Top-1: 56.53%, Top-5: 85.18%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 55.59%
[Alpha=0.70] Top-5 Accuracy: 85.85%
Result: Top-1: 55.59%, Top-5: 85.85%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 53.87%
[Alpha=0.70] Top-5 Accuracy: 85.51%
Result: Top-1: 53.87%, Top-5: 85.51%

============================================================
Testing: alpha=0.7, clusters=64, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 52.95%
[Alpha=0.70] Top-5 Accuracy: 83.49%
Result: Top-1: 52.95%, Top-5: 83.49%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 49.89%
[Alpha=0.70] Top-5 Accuracy: 79.75%
Result: Top-1: 49.89%, Top-5: 79.75%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 50.70%
[Alpha=0.70] Top-5 Accuracy: 82.99%
Result: Top-1: 50.70%, Top-5: 82.99%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 51.00%
[Alpha=0.70] Top-5 Accuracy: 82.28%
Result: Top-1: 51.00%, Top-5: 82.28%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 49.48%
[Alpha=0.70] Top-5 Accuracy: 82.11%
Result: Top-1: 49.48%, Top-5: 82.11%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 51.23%
[Alpha=0.70] Top-5 Accuracy: 83.08%
Result: Top-1: 51.23%, Top-5: 83.08%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 50.11%
[Alpha=0.70] Top-5 Accuracy: 82.11%
Result: Top-1: 50.11%, Top-5: 82.11%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 52.36%
[Alpha=0.70] Top-5 Accuracy: 82.93%
Result: Top-1: 52.36%, Top-5: 82.93%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 49.52%
[Alpha=0.70] Top-5 Accuracy: 82.30%
Result: Top-1: 49.52%, Top-5: 82.30%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 49.62%
[Alpha=0.70] Top-5 Accuracy: 82.32%
Result: Top-1: 49.62%, Top-5: 82.32%

============================================================
Testing: alpha=0.7, clusters=128, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 51.18%
[Alpha=0.70] Top-5 Accuracy: 81.83%
Result: Top-1: 51.18%, Top-5: 81.83%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=1
============================================================
[Alpha=0.70] Top-1 Accuracy: 42.29%
[Alpha=0.70] Top-5 Accuracy: 71.86%
Result: Top-1: 42.29%, Top-5: 71.86%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=25
============================================================
[Alpha=0.70] Top-1 Accuracy: 45.23%
[Alpha=0.70] Top-5 Accuracy: 76.92%
Result: Top-1: 45.23%, Top-5: 76.92%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=50
============================================================
[Alpha=0.70] Top-1 Accuracy: 43.87%
[Alpha=0.70] Top-5 Accuracy: 74.80%
Result: Top-1: 43.87%, Top-5: 74.80%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=75
============================================================
[Alpha=0.70] Top-1 Accuracy: 44.80%
[Alpha=0.70] Top-5 Accuracy: 76.78%
Result: Top-1: 44.80%, Top-5: 76.78%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=100
============================================================
[Alpha=0.70] Top-1 Accuracy: 45.94%
[Alpha=0.70] Top-5 Accuracy: 77.52%
Result: Top-1: 45.94%, Top-5: 77.52%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=125
============================================================
[Alpha=0.70] Top-1 Accuracy: 44.05%
[Alpha=0.70] Top-5 Accuracy: 77.40%
Result: Top-1: 44.05%, Top-5: 77.40%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=150
============================================================
[Alpha=0.70] Top-1 Accuracy: 46.59%
[Alpha=0.70] Top-5 Accuracy: 79.21%
Result: Top-1: 46.59%, Top-5: 79.21%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=175
============================================================
[Alpha=0.70] Top-1 Accuracy: 47.28%
[Alpha=0.70] Top-5 Accuracy: 79.05%
Result: Top-1: 47.28%, Top-5: 79.05%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=200
============================================================
[Alpha=0.70] Top-1 Accuracy: 47.29%
[Alpha=0.70] Top-5 Accuracy: 78.22%
Result: Top-1: 47.29%, Top-5: 78.22%

============================================================
Testing: alpha=0.7, clusters=256, pca_dim=220
============================================================
[Alpha=0.70] Top-1 Accuracy: 45.25%
[Alpha=0.70] Top-5 Accuracy: 78.34%
Result: Top-1: 45.25%, Top-5: 78.34%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 58.83%
[Alpha=0.80] Top-5 Accuracy: 85.67%
Result: Top-1: 58.83%, Top-5: 85.67%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 55.94%
[Alpha=0.80] Top-5 Accuracy: 86.00%
Result: Top-1: 55.94%, Top-5: 86.00%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 55.66%
[Alpha=0.80] Top-5 Accuracy: 85.67%
Result: Top-1: 55.66%, Top-5: 85.67%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 48.03%
[Alpha=0.80] Top-5 Accuracy: 85.69%
Result: Top-1: 48.03%, Top-5: 85.69%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 47.75%
[Alpha=0.80] Top-5 Accuracy: 85.34%
Result: Top-1: 47.75%, Top-5: 85.34%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 54.45%
[Alpha=0.80] Top-5 Accuracy: 85.76%
Result: Top-1: 54.45%, Top-5: 85.76%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 55.41%
[Alpha=0.80] Top-5 Accuracy: 85.48%
Result: Top-1: 55.41%, Top-5: 85.48%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 56.03%
[Alpha=0.80] Top-5 Accuracy: 86.32%
Result: Top-1: 56.03%, Top-5: 86.32%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 54.31%
[Alpha=0.80] Top-5 Accuracy: 85.43%
Result: Top-1: 54.31%, Top-5: 85.43%

============================================================
Testing: alpha=0.8, clusters=8, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 53.47%
[Alpha=0.80] Top-5 Accuracy: 85.39%
Result: Top-1: 53.47%, Top-5: 85.39%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 57.30%
[Alpha=0.80] Top-5 Accuracy: 84.95%
Result: Top-1: 57.30%, Top-5: 84.95%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.75%
[Alpha=0.80] Top-5 Accuracy: 85.48%
Result: Top-1: 46.75%, Top-5: 85.48%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 47.49%
[Alpha=0.80] Top-5 Accuracy: 85.31%
Result: Top-1: 47.49%, Top-5: 85.31%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 52.80%
[Alpha=0.80] Top-5 Accuracy: 85.24%
Result: Top-1: 52.80%, Top-5: 85.24%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 53.55%
[Alpha=0.80] Top-5 Accuracy: 85.69%
Result: Top-1: 53.55%, Top-5: 85.69%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 39.79%
[Alpha=0.80] Top-5 Accuracy: 84.42%
Result: Top-1: 39.79%, Top-5: 84.42%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 45.21%
[Alpha=0.80] Top-5 Accuracy: 84.65%
Result: Top-1: 45.21%, Top-5: 84.65%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 53.45%
[Alpha=0.80] Top-5 Accuracy: 85.41%
Result: Top-1: 53.45%, Top-5: 85.41%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.25%
[Alpha=0.80] Top-5 Accuracy: 84.61%
Result: Top-1: 46.25%, Top-5: 84.61%

============================================================
Testing: alpha=0.8, clusters=16, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 55.00%
[Alpha=0.80] Top-5 Accuracy: 85.33%
Result: Top-1: 55.00%, Top-5: 85.33%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 54.28%
[Alpha=0.80] Top-5 Accuracy: 83.40%
Result: Top-1: 54.28%, Top-5: 83.40%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 51.21%
[Alpha=0.80] Top-5 Accuracy: 84.41%
Result: Top-1: 51.21%, Top-5: 84.41%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 53.87%
[Alpha=0.80] Top-5 Accuracy: 84.79%
Result: Top-1: 53.87%, Top-5: 84.79%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 54.24%
[Alpha=0.80] Top-5 Accuracy: 84.92%
Result: Top-1: 54.24%, Top-5: 84.92%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.35%
[Alpha=0.80] Top-5 Accuracy: 84.30%
Result: Top-1: 46.35%, Top-5: 84.30%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 53.32%
[Alpha=0.80] Top-5 Accuracy: 84.21%
Result: Top-1: 53.32%, Top-5: 84.21%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 55.18%
[Alpha=0.80] Top-5 Accuracy: 85.17%
Result: Top-1: 55.18%, Top-5: 85.17%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.81%
[Alpha=0.80] Top-5 Accuracy: 84.36%
Result: Top-1: 46.81%, Top-5: 84.36%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 53.11%
[Alpha=0.80] Top-5 Accuracy: 84.00%
Result: Top-1: 53.11%, Top-5: 84.00%

============================================================
Testing: alpha=0.8, clusters=32, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 41.58%
[Alpha=0.80] Top-5 Accuracy: 83.13%
Result: Top-1: 41.58%, Top-5: 83.13%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 50.38%
[Alpha=0.80] Top-5 Accuracy: 80.85%
Result: Top-1: 50.38%, Top-5: 80.85%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 49.54%
[Alpha=0.80] Top-5 Accuracy: 82.96%
Result: Top-1: 49.54%, Top-5: 82.96%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 47.54%
[Alpha=0.80] Top-5 Accuracy: 82.20%
Result: Top-1: 47.54%, Top-5: 82.20%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 49.74%
[Alpha=0.80] Top-5 Accuracy: 83.20%
Result: Top-1: 49.74%, Top-5: 83.20%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 50.71%
[Alpha=0.80] Top-5 Accuracy: 83.24%
Result: Top-1: 50.71%, Top-5: 83.24%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 49.81%
[Alpha=0.80] Top-5 Accuracy: 82.52%
Result: Top-1: 49.81%, Top-5: 82.52%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 51.71%
[Alpha=0.80] Top-5 Accuracy: 83.09%
Result: Top-1: 51.71%, Top-5: 83.09%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 50.33%
[Alpha=0.80] Top-5 Accuracy: 83.79%
Result: Top-1: 50.33%, Top-5: 83.79%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 47.20%
[Alpha=0.80] Top-5 Accuracy: 83.62%
Result: Top-1: 47.20%, Top-5: 83.62%

============================================================
Testing: alpha=0.8, clusters=64, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.36%
[Alpha=0.80] Top-5 Accuracy: 80.41%
Result: Top-1: 46.36%, Top-5: 80.41%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 44.02%
[Alpha=0.80] Top-5 Accuracy: 74.37%
Result: Top-1: 44.02%, Top-5: 74.37%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 44.63%
[Alpha=0.80] Top-5 Accuracy: 79.48%
Result: Top-1: 44.63%, Top-5: 79.48%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.22%
[Alpha=0.80] Top-5 Accuracy: 78.82%
Result: Top-1: 46.22%, Top-5: 78.82%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 43.90%
[Alpha=0.80] Top-5 Accuracy: 78.58%
Result: Top-1: 43.90%, Top-5: 78.58%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.00%
[Alpha=0.80] Top-5 Accuracy: 80.28%
Result: Top-1: 46.00%, Top-5: 80.28%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 45.09%
[Alpha=0.80] Top-5 Accuracy: 78.69%
Result: Top-1: 45.09%, Top-5: 78.69%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 47.09%
[Alpha=0.80] Top-5 Accuracy: 79.79%
Result: Top-1: 47.09%, Top-5: 79.79%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 43.30%
[Alpha=0.80] Top-5 Accuracy: 79.10%
Result: Top-1: 43.30%, Top-5: 79.10%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 44.45%
[Alpha=0.80] Top-5 Accuracy: 79.11%
Result: Top-1: 44.45%, Top-5: 79.11%

============================================================
Testing: alpha=0.8, clusters=128, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 46.83%
[Alpha=0.80] Top-5 Accuracy: 78.43%
Result: Top-1: 46.83%, Top-5: 78.43%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=1
============================================================
[Alpha=0.80] Top-1 Accuracy: 36.20%
[Alpha=0.80] Top-5 Accuracy: 65.61%
Result: Top-1: 36.20%, Top-5: 65.61%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=25
============================================================
[Alpha=0.80] Top-1 Accuracy: 39.97%
[Alpha=0.80] Top-5 Accuracy: 72.66%
Result: Top-1: 39.97%, Top-5: 72.66%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=50
============================================================
[Alpha=0.80] Top-1 Accuracy: 39.10%
[Alpha=0.80] Top-5 Accuracy: 70.17%
Result: Top-1: 39.10%, Top-5: 70.17%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=75
============================================================
[Alpha=0.80] Top-1 Accuracy: 40.87%
[Alpha=0.80] Top-5 Accuracy: 72.75%
Result: Top-1: 40.87%, Top-5: 72.75%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=100
============================================================
[Alpha=0.80] Top-1 Accuracy: 41.38%
[Alpha=0.80] Top-5 Accuracy: 73.38%
Result: Top-1: 41.38%, Top-5: 73.38%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=125
============================================================
[Alpha=0.80] Top-1 Accuracy: 39.17%
[Alpha=0.80] Top-5 Accuracy: 73.26%
Result: Top-1: 39.17%, Top-5: 73.26%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=150
============================================================
[Alpha=0.80] Top-1 Accuracy: 42.05%
[Alpha=0.80] Top-5 Accuracy: 75.49%
Result: Top-1: 42.05%, Top-5: 75.49%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=175
============================================================
[Alpha=0.80] Top-1 Accuracy: 41.77%
[Alpha=0.80] Top-5 Accuracy: 74.87%
Result: Top-1: 41.77%, Top-5: 74.87%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=200
============================================================
[Alpha=0.80] Top-1 Accuracy: 42.41%
[Alpha=0.80] Top-5 Accuracy: 74.06%
Result: Top-1: 42.41%, Top-5: 74.06%

============================================================
Testing: alpha=0.8, clusters=256, pca_dim=220
============================================================
[Alpha=0.80] Top-1 Accuracy: 38.59%
[Alpha=0.80] Top-5 Accuracy: 74.28%
Result: Top-1: 38.59%, Top-5: 74.28%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 53.52%
[Alpha=0.90] Top-5 Accuracy: 83.06%
Result: Top-1: 53.52%, Top-5: 83.06%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 49.38%
[Alpha=0.90] Top-5 Accuracy: 84.10%
Result: Top-1: 49.38%, Top-5: 84.10%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 45.51%
[Alpha=0.90] Top-5 Accuracy: 83.56%
Result: Top-1: 45.51%, Top-5: 83.56%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 41.81%
[Alpha=0.90] Top-5 Accuracy: 83.54%
Result: Top-1: 41.81%, Top-5: 83.54%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 36.85%
[Alpha=0.90] Top-5 Accuracy: 83.31%
Result: Top-1: 36.85%, Top-5: 83.31%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 46.23%
[Alpha=0.90] Top-5 Accuracy: 83.69%
Result: Top-1: 46.23%, Top-5: 83.69%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 45.03%
[Alpha=0.90] Top-5 Accuracy: 83.17%
Result: Top-1: 45.03%, Top-5: 83.17%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 51.14%
[Alpha=0.90] Top-5 Accuracy: 84.52%
Result: Top-1: 51.14%, Top-5: 84.52%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 42.79%
[Alpha=0.90] Top-5 Accuracy: 83.28%
Result: Top-1: 42.79%, Top-5: 83.28%

============================================================
Testing: alpha=0.9, clusters=8, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 41.18%
[Alpha=0.90] Top-5 Accuracy: 83.31%
Result: Top-1: 41.18%, Top-5: 83.31%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 51.62%
[Alpha=0.90] Top-5 Accuracy: 82.13%
Result: Top-1: 51.62%, Top-5: 82.13%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 40.88%
[Alpha=0.90] Top-5 Accuracy: 83.47%
Result: Top-1: 40.88%, Top-5: 83.47%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 39.48%
[Alpha=0.90] Top-5 Accuracy: 82.89%
Result: Top-1: 39.48%, Top-5: 82.89%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 46.65%
[Alpha=0.90] Top-5 Accuracy: 82.73%
Result: Top-1: 46.65%, Top-5: 82.73%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 48.82%
[Alpha=0.90] Top-5 Accuracy: 83.64%
Result: Top-1: 48.82%, Top-5: 83.64%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 31.95%
[Alpha=0.90] Top-5 Accuracy: 81.59%
Result: Top-1: 31.95%, Top-5: 81.59%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 38.23%
[Alpha=0.90] Top-5 Accuracy: 81.92%
Result: Top-1: 38.23%, Top-5: 81.92%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 48.11%
[Alpha=0.90] Top-5 Accuracy: 83.04%
Result: Top-1: 48.11%, Top-5: 83.04%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 37.56%
[Alpha=0.90] Top-5 Accuracy: 81.94%
Result: Top-1: 37.56%, Top-5: 81.94%

============================================================
Testing: alpha=0.9, clusters=16, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 49.56%
[Alpha=0.90] Top-5 Accuracy: 83.00%
Result: Top-1: 49.56%, Top-5: 83.00%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 48.03%
[Alpha=0.90] Top-5 Accuracy: 79.62%
Result: Top-1: 48.03%, Top-5: 79.62%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 46.29%
[Alpha=0.90] Top-5 Accuracy: 81.99%
Result: Top-1: 46.29%, Top-5: 81.99%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 47.67%
[Alpha=0.90] Top-5 Accuracy: 82.34%
Result: Top-1: 47.67%, Top-5: 82.34%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 49.78%
[Alpha=0.90] Top-5 Accuracy: 82.44%
Result: Top-1: 49.78%, Top-5: 82.44%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 39.49%
[Alpha=0.90] Top-5 Accuracy: 81.53%
Result: Top-1: 39.49%, Top-5: 81.53%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 47.88%
[Alpha=0.90] Top-5 Accuracy: 81.69%
Result: Top-1: 47.88%, Top-5: 81.69%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 51.52%
[Alpha=0.90] Top-5 Accuracy: 82.98%
Result: Top-1: 51.52%, Top-5: 82.98%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 39.22%
[Alpha=0.90] Top-5 Accuracy: 81.47%
Result: Top-1: 39.22%, Top-5: 81.47%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 45.85%
[Alpha=0.90] Top-5 Accuracy: 80.53%
Result: Top-1: 45.85%, Top-5: 80.53%

============================================================
Testing: alpha=0.9, clusters=32, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 30.31%
[Alpha=0.90] Top-5 Accuracy: 79.15%
Result: Top-1: 30.31%, Top-5: 79.15%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 43.34%
[Alpha=0.90] Top-5 Accuracy: 75.44%
Result: Top-1: 43.34%, Top-5: 75.44%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 44.35%
[Alpha=0.90] Top-5 Accuracy: 79.67%
Result: Top-1: 44.35%, Top-5: 79.67%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 42.70%
[Alpha=0.90] Top-5 Accuracy: 78.47%
Result: Top-1: 42.70%, Top-5: 78.47%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 42.98%
[Alpha=0.90] Top-5 Accuracy: 79.98%
Result: Top-1: 42.98%, Top-5: 79.98%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 44.82%
[Alpha=0.90] Top-5 Accuracy: 80.24%
Result: Top-1: 44.82%, Top-5: 80.24%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 43.46%
[Alpha=0.90] Top-5 Accuracy: 79.30%
Result: Top-1: 43.46%, Top-5: 79.30%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 46.35%
[Alpha=0.90] Top-5 Accuracy: 79.95%
Result: Top-1: 46.35%, Top-5: 79.95%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 45.00%
[Alpha=0.90] Top-5 Accuracy: 80.95%
Result: Top-1: 45.00%, Top-5: 80.95%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 42.07%
[Alpha=0.90] Top-5 Accuracy: 80.67%
Result: Top-1: 42.07%, Top-5: 80.67%

============================================================
Testing: alpha=0.9, clusters=64, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 38.95%
[Alpha=0.90] Top-5 Accuracy: 76.02%
Result: Top-1: 38.95%, Top-5: 76.02%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 37.17%
[Alpha=0.90] Top-5 Accuracy: 67.85%
Result: Top-1: 37.17%, Top-5: 67.85%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 38.69%
[Alpha=0.90] Top-5 Accuracy: 74.88%
Result: Top-1: 38.69%, Top-5: 74.88%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 41.38%
[Alpha=0.90] Top-5 Accuracy: 74.53%
Result: Top-1: 41.38%, Top-5: 74.53%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 38.49%
[Alpha=0.90] Top-5 Accuracy: 74.08%
Result: Top-1: 38.49%, Top-5: 74.08%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 40.91%
[Alpha=0.90] Top-5 Accuracy: 76.58%
Result: Top-1: 40.91%, Top-5: 76.58%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 40.13%
[Alpha=0.90] Top-5 Accuracy: 74.24%
Result: Top-1: 40.13%, Top-5: 74.24%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 41.75%
[Alpha=0.90] Top-5 Accuracy: 75.80%
Result: Top-1: 41.75%, Top-5: 75.80%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 38.13%
[Alpha=0.90] Top-5 Accuracy: 74.91%
Result: Top-1: 38.13%, Top-5: 74.91%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 39.97%
[Alpha=0.90] Top-5 Accuracy: 75.05%
Result: Top-1: 39.97%, Top-5: 75.05%

============================================================
Testing: alpha=0.9, clusters=128, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 42.30%
[Alpha=0.90] Top-5 Accuracy: 74.35%
Result: Top-1: 42.30%, Top-5: 74.35%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=1
============================================================
[Alpha=0.90] Top-1 Accuracy: 30.29%
[Alpha=0.90] Top-5 Accuracy: 58.76%
Result: Top-1: 30.29%, Top-5: 58.76%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=25
============================================================
[Alpha=0.90] Top-1 Accuracy: 35.30%
[Alpha=0.90] Top-5 Accuracy: 67.85%
Result: Top-1: 35.30%, Top-5: 67.85%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=50
============================================================
[Alpha=0.90] Top-1 Accuracy: 34.73%
[Alpha=0.90] Top-5 Accuracy: 65.49%
Result: Top-1: 34.73%, Top-5: 65.49%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=75
============================================================
[Alpha=0.90] Top-1 Accuracy: 37.09%
[Alpha=0.90] Top-5 Accuracy: 68.26%
Result: Top-1: 37.09%, Top-5: 68.26%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=100
============================================================
[Alpha=0.90] Top-1 Accuracy: 37.04%
[Alpha=0.90] Top-5 Accuracy: 68.68%
Result: Top-1: 37.04%, Top-5: 68.68%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=125
============================================================
[Alpha=0.90] Top-1 Accuracy: 35.24%
[Alpha=0.90] Top-5 Accuracy: 68.48%
Result: Top-1: 35.24%, Top-5: 68.48%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=150
============================================================
[Alpha=0.90] Top-1 Accuracy: 37.93%
[Alpha=0.90] Top-5 Accuracy: 71.22%
Result: Top-1: 37.93%, Top-5: 71.22%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=175
============================================================
[Alpha=0.90] Top-1 Accuracy: 36.51%
[Alpha=0.90] Top-5 Accuracy: 70.33%
Result: Top-1: 36.51%, Top-5: 70.33%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=200
============================================================
[Alpha=0.90] Top-1 Accuracy: 37.78%
[Alpha=0.90] Top-5 Accuracy: 69.45%
Result: Top-1: 37.78%, Top-5: 69.45%

============================================================
Testing: alpha=0.9, clusters=256, pca_dim=220
============================================================
[Alpha=0.90] Top-1 Accuracy: 32.67%
[Alpha=0.90] Top-5 Accuracy: 69.52%
Result: Top-1: 32.67%, Top-5: 69.52%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 44.45%
[Alpha=1.00] Top-5 Accuracy: 78.78%
Result: Top-1: 44.45%, Top-5: 78.78%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 40.01%
[Alpha=1.00] Top-5 Accuracy: 80.79%
Result: Top-1: 40.01%, Top-5: 80.79%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 34.12%
[Alpha=1.00] Top-5 Accuracy: 80.03%
Result: Top-1: 34.12%, Top-5: 80.03%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 35.56%
[Alpha=1.00] Top-5 Accuracy: 79.91%
Result: Top-1: 35.56%, Top-5: 79.91%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 29.56%
[Alpha=1.00] Top-5 Accuracy: 79.72%
Result: Top-1: 29.56%, Top-5: 79.72%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 34.75%
[Alpha=1.00] Top-5 Accuracy: 79.86%
Result: Top-1: 34.75%, Top-5: 79.86%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 31.58%
[Alpha=1.00] Top-5 Accuracy: 79.74%
Result: Top-1: 31.58%, Top-5: 79.74%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 44.01%
[Alpha=1.00] Top-5 Accuracy: 81.33%
Result: Top-1: 44.01%, Top-5: 81.33%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 28.92%
[Alpha=1.00] Top-5 Accuracy: 79.73%
Result: Top-1: 28.92%, Top-5: 79.73%

============================================================
Testing: alpha=1.0, clusters=8, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 28.08%
[Alpha=1.00] Top-5 Accuracy: 79.62%
Result: Top-1: 28.08%, Top-5: 79.62%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 42.42%
[Alpha=1.00] Top-5 Accuracy: 77.36%
Result: Top-1: 42.42%, Top-5: 77.36%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 34.97%
[Alpha=1.00] Top-5 Accuracy: 79.68%
Result: Top-1: 34.97%, Top-5: 79.68%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 32.20%
[Alpha=1.00] Top-5 Accuracy: 78.80%
Result: Top-1: 32.20%, Top-5: 78.80%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 39.08%
[Alpha=1.00] Top-5 Accuracy: 78.67%
Result: Top-1: 39.08%, Top-5: 78.67%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 43.78%
[Alpha=1.00] Top-5 Accuracy: 80.14%
Result: Top-1: 43.78%, Top-5: 80.14%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 25.36%
[Alpha=1.00] Top-5 Accuracy: 77.01%
Result: Top-1: 25.36%, Top-5: 77.01%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 30.38%
[Alpha=1.00] Top-5 Accuracy: 77.56%
Result: Top-1: 30.38%, Top-5: 77.56%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 41.01%
[Alpha=1.00] Top-5 Accuracy: 79.36%
Result: Top-1: 41.01%, Top-5: 79.36%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 29.58%
[Alpha=1.00] Top-5 Accuracy: 77.47%
Result: Top-1: 29.58%, Top-5: 77.47%

============================================================
Testing: alpha=1.0, clusters=16, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 43.32%
[Alpha=1.00] Top-5 Accuracy: 78.95%
Result: Top-1: 43.32%, Top-5: 78.95%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 39.30%
[Alpha=1.00] Top-5 Accuracy: 73.70%
Result: Top-1: 39.30%, Top-5: 73.70%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 41.54%
[Alpha=1.00] Top-5 Accuracy: 78.25%
Result: Top-1: 41.54%, Top-5: 78.25%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 41.10%
[Alpha=1.00] Top-5 Accuracy: 78.34%
Result: Top-1: 41.10%, Top-5: 78.34%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 44.20%
[Alpha=1.00] Top-5 Accuracy: 78.61%
Result: Top-1: 44.20%, Top-5: 78.61%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 34.29%
[Alpha=1.00] Top-5 Accuracy: 77.33%
Result: Top-1: 34.29%, Top-5: 77.33%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 41.17%
[Alpha=1.00] Top-5 Accuracy: 77.76%
Result: Top-1: 41.17%, Top-5: 77.76%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 47.02%
[Alpha=1.00] Top-5 Accuracy: 79.83%
Result: Top-1: 47.02%, Top-5: 79.83%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 32.74%
[Alpha=1.00] Top-5 Accuracy: 76.94%
Result: Top-1: 32.74%, Top-5: 76.94%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 36.86%
[Alpha=1.00] Top-5 Accuracy: 75.48%
Result: Top-1: 36.86%, Top-5: 75.48%

============================================================
Testing: alpha=1.0, clusters=32, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 21.99%
[Alpha=1.00] Top-5 Accuracy: 72.99%
Result: Top-1: 21.99%, Top-5: 72.99%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 35.26%
[Alpha=1.00] Top-5 Accuracy: 68.40%
Result: Top-1: 35.26%, Top-5: 68.40%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 39.43%
[Alpha=1.00] Top-5 Accuracy: 75.58%
Result: Top-1: 39.43%, Top-5: 75.58%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 38.11%
[Alpha=1.00] Top-5 Accuracy: 73.80%
Result: Top-1: 38.11%, Top-5: 73.80%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 36.40%
[Alpha=1.00] Top-5 Accuracy: 75.92%
Result: Top-1: 36.40%, Top-5: 75.92%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 39.02%
[Alpha=1.00] Top-5 Accuracy: 76.11%
Result: Top-1: 39.02%, Top-5: 76.11%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 37.01%
[Alpha=1.00] Top-5 Accuracy: 75.21%
Result: Top-1: 37.01%, Top-5: 75.21%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 41.06%
[Alpha=1.00] Top-5 Accuracy: 75.84%
Result: Top-1: 41.06%, Top-5: 75.84%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 39.79%
[Alpha=1.00] Top-5 Accuracy: 77.06%
Result: Top-1: 39.79%, Top-5: 77.06%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 38.45%
[Alpha=1.00] Top-5 Accuracy: 76.64%
Result: Top-1: 38.45%, Top-5: 76.64%

============================================================
Testing: alpha=1.0, clusters=64, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 31.97%
[Alpha=1.00] Top-5 Accuracy: 70.28%
Result: Top-1: 31.97%, Top-5: 70.28%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 30.39%
[Alpha=1.00] Top-5 Accuracy: 60.17%
Result: Top-1: 30.39%, Top-5: 60.17%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 34.01%
[Alpha=1.00] Top-5 Accuracy: 69.64%
Result: Top-1: 34.01%, Top-5: 69.64%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 36.65%
[Alpha=1.00] Top-5 Accuracy: 69.77%
Result: Top-1: 36.65%, Top-5: 69.77%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 33.38%
[Alpha=1.00] Top-5 Accuracy: 68.46%
Result: Top-1: 33.38%, Top-5: 68.46%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 35.92%
[Alpha=1.00] Top-5 Accuracy: 71.81%
Result: Top-1: 35.92%, Top-5: 71.81%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 35.08%
[Alpha=1.00] Top-5 Accuracy: 68.69%
Result: Top-1: 35.08%, Top-5: 68.69%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 36.81%
[Alpha=1.00] Top-5 Accuracy: 71.25%
Result: Top-1: 36.81%, Top-5: 71.25%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 33.70%
[Alpha=1.00] Top-5 Accuracy: 70.04%
Result: Top-1: 33.70%, Top-5: 70.04%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 35.72%
[Alpha=1.00] Top-5 Accuracy: 70.24%
Result: Top-1: 35.72%, Top-5: 70.24%

============================================================
Testing: alpha=1.0, clusters=128, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 37.96%
[Alpha=1.00] Top-5 Accuracy: 69.68%
Result: Top-1: 37.96%, Top-5: 69.68%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=1
============================================================
[Alpha=1.00] Top-1 Accuracy: 25.16%
[Alpha=1.00] Top-5 Accuracy: 51.51%
Result: Top-1: 25.16%, Top-5: 51.51%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=25
============================================================
[Alpha=1.00] Top-1 Accuracy: 31.35%
[Alpha=1.00] Top-5 Accuracy: 63.02%
Result: Top-1: 31.35%, Top-5: 63.02%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=50
============================================================
[Alpha=1.00] Top-1 Accuracy: 30.76%
[Alpha=1.00] Top-5 Accuracy: 60.68%
Result: Top-1: 30.76%, Top-5: 60.68%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=75
============================================================
[Alpha=1.00] Top-1 Accuracy: 33.88%
[Alpha=1.00] Top-5 Accuracy: 63.60%
Result: Top-1: 33.88%, Top-5: 63.60%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=100
============================================================
[Alpha=1.00] Top-1 Accuracy: 32.80%
[Alpha=1.00] Top-5 Accuracy: 64.10%
Result: Top-1: 32.80%, Top-5: 64.10%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=125
============================================================
[Alpha=1.00] Top-1 Accuracy: 31.76%
[Alpha=1.00] Top-5 Accuracy: 63.41%
Result: Top-1: 31.76%, Top-5: 63.41%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=150
============================================================
[Alpha=1.00] Top-1 Accuracy: 34.23%
[Alpha=1.00] Top-5 Accuracy: 66.70%
Result: Top-1: 34.23%, Top-5: 66.70%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=175
============================================================
[Alpha=1.00] Top-1 Accuracy: 31.93%
[Alpha=1.00] Top-5 Accuracy: 65.27%
Result: Top-1: 31.93%, Top-5: 65.27%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=200
============================================================
[Alpha=1.00] Top-1 Accuracy: 33.21%
[Alpha=1.00] Top-5 Accuracy: 64.21%
Result: Top-1: 33.21%, Top-5: 64.21%

============================================================
Testing: alpha=1.0, clusters=256, pca_dim=220
============================================================
[Alpha=1.00] Top-1 Accuracy: 27.73%
[Alpha=1.00] Top-5 Accuracy: 64.24%
Result: Top-1: 27.73%, Top-5: 64.24%

================================================================================
SUMMARY OF ALL RESULTS
================================================================================
Alpha    Clusters   PCA_dim    Top-1      Top-5     
--------------------------------------------------
0.10     8          1          65.89      88.84     
0.10     8          25         65.91      88.84     
0.10     8          50         65.91      88.86     
0.10     8          75         65.92      88.83     
0.10     8          100        65.84      88.84     
0.10     8          125        65.88      88.85     
0.10     8          150        65.89      88.87     
0.10     8          175        65.98      88.85     
0.10     8          200        65.89      88.86     
0.10     8          220        65.87      88.85     
0.10     16         1          65.94      88.87     
0.10     16         25         65.86      88.84     
0.10     16         50         65.78      88.89     
0.10     16         75         65.85      88.83     
0.10     16         100        65.89      88.84     
0.10     16         125        65.88      88.87     
0.10     16         150        65.90      88.84     
0.10     16         175        65.98      88.86     
0.10     16         200        65.82      88.80     
0.10     16         220        65.93      88.82     
0.10     32         1          65.83      88.84     
0.10     32         25         65.87      88.82     
0.10     32         50         65.89      88.86     
0.10     32         75         65.82      88.86     
0.10     32         100        65.88      88.87     
0.10     32         125        65.86      88.86     
0.10     32         150        65.90      88.87     
0.10     32         175        65.81      88.85     
0.10     32         200        65.86      88.84     
0.10     32         220        65.86      88.82     
0.10     64         1          65.83      88.85     
0.10     64         25         65.91      88.81     
0.10     64         50         65.80      88.80     
0.10     64         75         65.83      88.85     
0.10     64         100        65.85      88.86     
0.10     64         125        65.90      88.85     
0.10     64         150        65.85      88.82     
0.10     64         175        65.89      88.89     
0.10     64         200        65.95      88.81     
0.10     64         220        65.76      88.79     
0.10     128        1          65.67      88.81     
0.10     128        25         65.73      88.81     
0.10     128        50         65.71      88.77     
0.10     128        75         65.67      88.71     
0.10     128        100        65.39      88.50     
0.10     128        125        65.79      88.81     
0.10     128        150        65.76      88.80     
0.10     128        175        65.79      88.83     
0.10     128        200        65.74      88.83     
0.10     128        220        65.73      88.74     
0.10     256        1          64.47      88.32     
0.10     256        25         65.23      88.58     
0.10     256        50         64.50      88.37     
0.10     256        75         65.03      88.63     
0.10     256        100        65.37      88.69     
0.10     256        125        65.36      88.61     
0.10     256        150        65.17      88.61     
0.10     256        175        65.41      88.80     
0.10     256        200        65.38      88.68     
0.10     256        220        65.37      88.55     
0.20     8          1          65.83      88.85     
0.20     8          25         65.98      88.85     
0.20     8          50         65.95      88.90     
0.20     8          75         65.96      88.81     
0.20     8          100        65.85      88.88     
0.20     8          125        65.93      88.86     
0.20     8          150        65.89      88.85     
0.20     8          175        65.96      88.84     
0.20     8          200        65.90      88.85     
0.20     8          220        65.93      88.84     
0.20     16         1          65.85      88.93     
0.20     16         25         65.85      88.83     
0.20     16         50         65.78      88.87     
0.20     16         75         65.83      88.84     
0.20     16         100        65.85      88.86     
0.20     16         125        65.92      88.84     
0.20     16         150        65.90      88.81     
0.20     16         175        66.04      88.88     
0.20     16         200        65.80      88.80     
0.20     16         220        65.88      88.88     
0.20     32         1          65.58      88.82     
0.20     32         25         65.75      88.82     
0.20     32         50         65.83      88.85     
0.20     32         75         65.82      88.86     
0.20     32         100        65.82      88.85     
0.20     32         125        65.61      88.88     
0.20     32         150        65.83      88.87     
0.20     32         175        65.79      88.84     
0.20     32         200        65.86      88.84     
0.20     32         220        65.78      88.85     
0.20     64         1          65.52      88.78     
0.20     64         25         65.80      88.83     
0.20     64         50         65.65      88.79     
0.20     64         75         65.63      88.84     
0.20     64         100        65.64      88.85     
0.20     64         125        65.75      88.84     
0.20     64         150        65.59      88.76     
0.20     64         175        65.74      88.82     
0.20     64         200        65.79      88.79     
0.20     64         220        65.39      88.71     
0.20     128        1          64.91      88.60     
0.20     128        25         65.32      88.78     
0.20     128        50         65.10      88.66     
0.20     128        75         64.94      88.48     
0.20     128        100        64.97      88.14     
0.20     128        125        65.33      88.61     
0.20     128        150        65.34      88.77     
0.20     128        175        65.30      88.73     
0.20     128        200        65.30      88.64     
0.20     128        220        65.08      88.53     
0.20     256        1          62.69      87.52     
0.20     256        25         64.01      88.13     
0.20     256        50         62.76      87.30     
0.20     256        75         63.32      88.01     
0.20     256        100        63.95      88.19     
0.20     256        125        63.93      88.01     
0.20     256        150        64.05      87.98     
0.20     256        175        64.44      88.46     
0.20     256        200        64.32      88.32     
0.20     256        220        64.27      87.93     
0.30     8          1          65.71      88.80     
0.30     8          25         65.73      88.74     
0.30     8          50         65.84      88.81     
0.30     8          75         65.78      88.78     
0.30     8          100        65.71      88.80     
0.30     8          125        65.65      88.76     
0.30     8          150        65.71      88.76     
0.30     8          175        65.72      88.79     
0.30     8          200        65.66      88.77     
0.30     8          220        65.70      88.74     
0.30     16         1          65.52      88.84     
0.30     16         25         65.64      88.76     
0.30     16         50         65.59      88.79     
0.30     16         75         65.62      88.81     
0.30     16         100        65.63      88.82     
0.30     16         125        65.67      88.73     
0.30     16         150        65.70      88.70     
0.30     16         175        65.74      88.82     
0.30     16         200        65.55      88.68     
0.30     16         220        65.57      88.74     
0.30     32         1          65.10      88.71     
0.30     32         25         65.45      88.70     
0.30     32         50         65.62      88.75     
0.30     32         75         65.51      88.76     
0.30     32         100        65.47      88.71     
0.30     32         125        65.31      88.71     
0.30     32         150        65.39      88.78     
0.30     32         175        65.40      88.76     
0.30     32         200        65.39      88.78     
0.30     32         220        65.35      88.72     
0.30     64         1          64.79      88.57     
0.30     64         25         65.24      88.69     
0.30     64         50         64.99      88.60     
0.30     64         75         65.09      88.75     
0.30     64         100        65.10      88.72     
0.30     64         125        65.12      88.70     
0.30     64         150        65.06      88.58     
0.30     64         175        65.21      88.73     
0.30     64         200        65.28      88.69     
0.30     64         220        64.39      88.38     
0.30     128        1          63.63      88.25     
0.30     128        25         64.49      88.51     
0.30     128        50         63.89      88.28     
0.30     128        75         63.61      87.97     
0.30     128        100        64.00      87.83     
0.30     128        125        64.14      88.31     
0.30     128        150        64.28      88.44     
0.30     128        175        64.13      88.41     
0.30     128        200        64.06      88.38     
0.30     128        220        63.94      88.06     
0.30     256        1          59.99      86.26     
0.30     256        25         61.87      87.32     
0.30     256        50         60.37      85.94     
0.30     256        75         60.88      86.98     
0.30     256        100        61.72      87.33     
0.30     256        125        62.04      87.06     
0.30     256        150        62.33      87.20     
0.30     256        175        62.56      87.79     
0.30     256        200        62.39      87.51     
0.30     256        220        62.48      87.04     
0.40     8          1          65.30      88.65     
0.40     8          25         65.29      88.66     
0.40     8          50         65.41      88.65     
0.40     8          75         65.35      88.64     
0.40     8          100        65.27      88.67     
0.40     8          125        65.27      88.64     
0.40     8          150        65.21      88.61     
0.40     8          175        65.33      88.71     
0.40     8          200        65.22      88.57     
0.40     8          220        65.34      88.58     
0.40     16         1          65.05      88.62     
0.40     16         25         65.04      88.58     
0.40     16         50         65.04      88.56     
0.40     16         75         64.97      88.56     
0.40     16         100        65.10      88.65     
0.40     16         125        65.05      88.52     
0.40     16         150        65.15      88.51     
0.40     16         175        65.22      88.66     
0.40     16         200        64.87      88.46     
0.40     16         220        65.06      88.56     
0.40     32         1          64.39      88.43     
0.40     32         25         64.76      88.46     
0.40     32         50         64.99      88.57     
0.40     32         75         64.69      88.50     
0.40     32         100        64.89      88.55     
0.40     32         125        64.50      88.46     
0.40     32         150        64.57      88.59     
0.40     32         175        64.59      88.52     
0.40     32         200        64.61      88.54     
0.40     32         220        64.65      88.43     
0.40     64         1          63.52      88.19     
0.40     64         25         64.13      88.32     
0.40     64         50         64.01      88.20     
0.40     64         75         64.23      88.45     
0.40     64         100        64.15      88.31     
0.40     64         125        64.11      88.35     
0.40     64         150        63.99      88.23     
0.40     64         175        64.33      88.44     
0.40     64         200        64.36      88.35     
0.40     64         220        62.96      87.87     
0.40     128        1          61.47      87.47     
0.40     128        25         62.65      87.87     
0.40     128        50         61.88      87.52     
0.40     128        75         61.85      87.18     
0.40     128        100        62.45      87.18     
0.40     128        125        62.30      87.45     
0.40     128        150        62.56      87.88     
0.40     128        175        62.26      87.69     
0.40     128        200        62.24      87.69     
0.40     128        220        62.02      87.31     
0.40     256        1          56.46      84.26     
0.40     256        25         58.85      85.90     
0.40     256        50         57.27      84.20     
0.40     256        75         57.84      85.39     
0.40     256        100        58.80      85.91     
0.40     256        125        59.09      85.67     
0.40     256        150        59.66      85.96     
0.40     256        175        60.01      86.63     
0.40     256        200        59.62      86.25     
0.40     256        220        60.13      85.70     
0.50     8          1          64.62      88.39     
0.50     8          25         64.51      88.43     
0.50     8          50         64.54      88.41     
0.50     8          75         64.38      88.24     
0.50     8          100        64.45      88.30     
0.50     8          125        64.39      88.39     
0.50     8          150        64.47      88.30     
0.50     8          175        64.44      88.45     
0.50     8          200        64.44      88.27     
0.50     8          220        64.46      88.32     
0.50     16         1          64.07      88.32     
0.50     16         25         63.81      88.21     
0.50     16         50         63.79      88.22     
0.50     16         75         63.77      88.21     
0.50     16         100        63.87      88.36     
0.50     16         125        63.66      88.07     
0.50     16         150        63.94      88.12     
0.50     16         175        64.26      88.38     
0.50     16         200        63.84      88.07     
0.50     16         220        64.09      88.27     
0.50     32         1          63.05      87.90     
0.50     32         25         63.39      88.08     
0.50     32         50         63.88      88.16     
0.50     32         75         63.01      88.12     
0.50     32         100        63.58      88.13     
0.50     32         125        63.11      88.02     
0.50     32         150        63.37      88.21     
0.50     32         175        63.29      88.03     
0.50     32         200        63.35      88.14     
0.50     32         220        62.95      87.87     
0.50     64         1          61.65      87.30     
0.50     64         25         62.15      87.66     
0.50     64         50         62.14      87.58     
0.50     64         75         62.63      87.86     
0.50     64         100        62.63      87.69     
0.50     64         125        62.20      87.63     
0.50     64         150        62.49      87.62     
0.50     64         175        62.84      87.91     
0.50     64         200        62.57      87.77     
0.50     64         220        60.73      86.88     
0.50     128        1          58.46      85.96     
0.50     128        25         59.84      86.87     
0.50     128        50         59.07      86.43     
0.50     128        75         59.06      86.00     
0.50     128        100        59.83      86.21     
0.50     128        125        59.32      86.23     
0.50     128        150        60.20      86.79     
0.50     128        175        59.50      86.48     
0.50     128        200        59.50      86.47     
0.50     128        220        58.99      86.15     
0.50     256        1          52.38      81.44     
0.50     256        25         55.00      83.77     
0.50     256        50         53.27      81.94     
0.50     256        75         54.02      83.13     
0.50     256        100        55.09      83.63     
0.50     256        125        54.98      83.39     
0.50     256        150        56.03      84.31     
0.50     256        175        56.71      84.99     
0.50     256        200        56.16      84.36     
0.50     256        220        56.50      83.94     
0.60     8          1          63.49      87.96     
0.60     8          25         62.93      88.01     
0.60     8          50         63.29      87.95     
0.60     8          75         61.76      87.77     
0.60     8          100        62.46      87.62     
0.60     8          125        62.70      87.87     
0.60     8          150        63.19      87.87     
0.60     8          175        62.65      88.02     
0.60     8          200        63.07      87.86     
0.60     8          220        63.15      87.84     
0.60     16         1          62.58      87.72     
0.60     16         25         60.70      87.65     
0.60     16         50         60.93      87.69     
0.60     16         75         61.39      87.59     
0.60     16         100        61.63      87.86     
0.60     16         125        60.22      87.22     
0.60     16         150        60.74      87.44     
0.60     16         175        61.81      87.87     
0.60     16         200        61.24      87.40     
0.60     16         220        62.27      87.64     
0.60     32         1          61.14      87.07     
0.60     32         25         60.88      87.17     
0.60     32         50         62.03      87.51     
0.60     32         75         60.52      87.49     
0.60     32         100        60.97      87.32     
0.60     32         125        60.85      87.24     
0.60     32         150        61.19      87.64     
0.60     32         175        60.46      87.29     
0.60     32         200        61.35      87.40     
0.60     32         220        59.65      86.96     
0.60     64         1          58.98      85.99     
0.60     64         25         59.00      86.75     
0.60     64         50         58.83      86.51     
0.60     64         75         60.23      86.88     
0.60     64         100        60.27      86.73     
0.60     64         125        59.20      86.49     
0.60     64         150        59.98      86.68     
0.60     64         175        60.10      87.10     
0.60     64         200        59.34      86.86     
0.60     64         220        57.56      85.59     
0.60     128        1          54.63      83.61     
0.60     128        25         56.02      85.25     
0.60     128        50         55.43      84.80     
0.60     128        75         54.99      84.35     
0.60     128        100        55.91      84.94     
0.60     128        125        55.07      84.42     
0.60     128        150        56.88      85.19     
0.60     128        175        55.27      84.78     
0.60     128        200        55.36      84.76     
0.60     128        220        55.30      84.36     
0.60     256        1          47.60      77.31     
0.60     256        25         50.40      80.69     
0.60     256        50         48.63      78.69     
0.60     256        75         49.42      80.27     
0.60     256        100        50.73      80.85     
0.60     256        125        49.74      80.62     
0.60     256        150        51.58      82.02     
0.60     256        175        52.40      82.41     
0.60     256        200        51.96      81.71     
0.60     256        220        51.50      81.48     
0.70     8          1          61.70      87.11     
0.70     8          25         60.33      87.19     
0.70     8          50         60.96      87.10     
0.70     8          75         55.57      86.97     
0.70     8          100        57.65      86.53     
0.70     8          125        59.69      87.08     
0.70     8          150        60.61      87.00     
0.70     8          175        59.78      87.34     
0.70     8          200        60.36      86.91     
0.70     8          220        60.29      86.90     
0.70     16         1          60.57      86.69     
0.70     16         25         54.19      86.80     
0.70     16         50         55.41      86.73     
0.70     16         75         57.73      86.66     
0.70     16         100        57.88      87.03     
0.70     16         125        51.21      86.18     
0.70     16         150        53.14      86.34     
0.70     16         175        57.61      86.95     
0.70     16         200        55.07      86.27     
0.70     16         220        59.20      86.78     
0.70     32         1          58.36      85.79     
0.70     32         25         56.53      86.12     
0.70     32         50         59.05      86.39     
0.70     32         75         57.75      86.51     
0.70     32         100        54.79      86.11     
0.70     32         125        57.48      86.05     
0.70     32         150        58.35      86.64     
0.70     32         175        54.89      86.14     
0.70     32         200        57.97      86.14     
0.70     32         220        52.52      85.49     
0.70     64         1          55.38      84.12     
0.70     64         25         54.62      85.26     
0.70     64         50         53.36      84.78     
0.70     64         75         55.82      85.44     
0.70     64         100        56.23      85.32     
0.70     64         125        55.12      84.78     
0.70     64         150        56.53      85.18     
0.70     64         175        55.59      85.85     
0.70     64         200        53.87      85.51     
0.70     64         220        52.95      83.49     
0.70     128        1          49.89      79.75     
0.70     128        25         50.70      82.99     
0.70     128        50         51.00      82.28     
0.70     128        75         49.48      82.11     
0.70     128        100        51.23      83.08     
0.70     128        125        50.11      82.11     
0.70     128        150        52.36      82.93     
0.70     128        175        49.52      82.30     
0.70     128        200        49.62      82.32     
0.70     128        220        51.18      81.83     
0.70     256        1          42.29      71.86     
0.70     256        25         45.23      76.92     
0.70     256        50         43.87      74.80     
0.70     256        75         44.80      76.78     
0.70     256        100        45.94      77.52     
0.70     256        125        44.05      77.40     
0.70     256        150        46.59      79.21     
0.70     256        175        47.28      79.05     
0.70     256        200        47.29      78.22     
0.70     256        220        45.25      78.34     
0.80     8          1          58.83      85.67     
0.80     8          25         55.94      86.00     
0.80     8          50         55.66      85.67     
0.80     8          75         48.03      85.69     
0.80     8          100        47.75      85.34     
0.80     8          125        54.45      85.76     
0.80     8          150        55.41      85.48     
0.80     8          175        56.03      86.32     
0.80     8          200        54.31      85.43     
0.80     8          220        53.47      85.39     
0.80     16         1          57.30      84.95     
0.80     16         25         46.75      85.48     
0.80     16         50         47.49      85.31     
0.80     16         75         52.80      85.24     
0.80     16         100        53.55      85.69     
0.80     16         125        39.79      84.42     
0.80     16         150        45.21      84.65     
0.80     16         175        53.45      85.41     
0.80     16         200        46.25      84.61     
0.80     16         220        55.00      85.33     
0.80     32         1          54.28      83.40     
0.80     32         25         51.21      84.41     
0.80     32         50         53.87      84.79     
0.80     32         75         54.24      84.92     
0.80     32         100        46.35      84.30     
0.80     32         125        53.32      84.21     
0.80     32         150        55.18      85.17     
0.80     32         175        46.81      84.36     
0.80     32         200        53.11      84.00     
0.80     32         220        41.58      83.13     
0.80     64         1          50.38      80.85     
0.80     64         25         49.54      82.96     
0.80     64         50         47.54      82.20     
0.80     64         75         49.74      83.20     
0.80     64         100        50.71      83.24     
0.80     64         125        49.81      82.52     
0.80     64         150        51.71      83.09     
0.80     64         175        50.33      83.79     
0.80     64         200        47.20      83.62     
0.80     64         220        46.36      80.41     
0.80     128        1          44.02      74.37     
0.80     128        25         44.63      79.48     
0.80     128        50         46.22      78.82     
0.80     128        75         43.90      78.58     
0.80     128        100        46.00      80.28     
0.80     128        125        45.09      78.69     
0.80     128        150        47.09      79.79     
0.80     128        175        43.30      79.10     
0.80     128        200        44.45      79.11     
0.80     128        220        46.83      78.43     
0.80     256        1          36.20      65.61     
0.80     256        25         39.97      72.66     
0.80     256        50         39.10      70.17     
0.80     256        75         40.87      72.75     
0.80     256        100        41.38      73.38     
0.80     256        125        39.17      73.26     
0.80     256        150        42.05      75.49     
0.80     256        175        41.77      74.87     
0.80     256        200        42.41      74.06     
0.80     256        220        38.59      74.28     
0.90     8          1          53.52      83.06     
0.90     8          25         49.38      84.10     
0.90     8          50         45.51      83.56     
0.90     8          75         41.81      83.54     
0.90     8          100        36.85      83.31     
0.90     8          125        46.23      83.69     
0.90     8          150        45.03      83.17     
0.90     8          175        51.14      84.52     
0.90     8          200        42.79      83.28     
0.90     8          220        41.18      83.31     
0.90     16         1          51.62      82.13     
0.90     16         25         40.88      83.47     
0.90     16         50         39.48      82.89     
0.90     16         75         46.65      82.73     
0.90     16         100        48.82      83.64     
0.90     16         125        31.95      81.59     
0.90     16         150        38.23      81.92     
0.90     16         175        48.11      83.04     
0.90     16         200        37.56      81.94     
0.90     16         220        49.56      83.00     
0.90     32         1          48.03      79.62     
0.90     32         25         46.29      81.99     
0.90     32         50         47.67      82.34     
0.90     32         75         49.78      82.44     
0.90     32         100        39.49      81.53     
0.90     32         125        47.88      81.69     
0.90     32         150        51.52      82.98     
0.90     32         175        39.22      81.47     
0.90     32         200        45.85      80.53     
0.90     32         220        30.31      79.15     
0.90     64         1          43.34      75.44     
0.90     64         25         44.35      79.67     
0.90     64         50         42.70      78.47     
0.90     64         75         42.98      79.98     
0.90     64         100        44.82      80.24     
0.90     64         125        43.46      79.30     
0.90     64         150        46.35      79.95     
0.90     64         175        45.00      80.95     
0.90     64         200        42.07      80.67     
0.90     64         220        38.95      76.02     
0.90     128        1          37.17      67.85     
0.90     128        25         38.69      74.88     
0.90     128        50         41.38      74.53     
0.90     128        75         38.49      74.08     
0.90     128        100        40.91      76.58     
0.90     128        125        40.13      74.24     
0.90     128        150        41.75      75.80     
0.90     128        175        38.13      74.91     
0.90     128        200        39.97      75.05     
0.90     128        220        42.30      74.35     
0.90     256        1          30.29      58.76     
0.90     256        25         35.30      67.85     
0.90     256        50         34.73      65.49     
0.90     256        75         37.09      68.26     
0.90     256        100        37.04      68.68     
0.90     256        125        35.24      68.48     
0.90     256        150        37.93      71.22     
0.90     256        175        36.51      70.33     
0.90     256        200        37.78      69.45     
0.90     256        220        32.67      69.52     
1.00     8          1          44.45      78.78     
1.00     8          25         40.01      80.79     
1.00     8          50         34.12      80.03     
1.00     8          75         35.56      79.91     
1.00     8          100        29.56      79.72     
1.00     8          125        34.75      79.86     
1.00     8          150        31.58      79.74     
1.00     8          175        44.01      81.33     
1.00     8          200        28.92      79.73     
1.00     8          220        28.08      79.62     
1.00     16         1          42.42      77.36     
1.00     16         25         34.97      79.68     
1.00     16         50         32.20      78.80     
1.00     16         75         39.08      78.67     
1.00     16         100        43.78      80.14     
1.00     16         125        25.36      77.01     
1.00     16         150        30.38      77.56     
1.00     16         175        41.01      79.36     
1.00     16         200        29.58      77.47     
1.00     16         220        43.32      78.95     
1.00     32         1          39.30      73.70     
1.00     32         25         41.54      78.25     
1.00     32         50         41.10      78.34     
1.00     32         75         44.20      78.61     
1.00     32         100        34.29      77.33     
1.00     32         125        41.17      77.76     
1.00     32         150        47.02      79.83     
1.00     32         175        32.74      76.94     
1.00     32         200        36.86      75.48     
1.00     32         220        21.99      72.99     
1.00     64         1          35.26      68.40     
1.00     64         25         39.43      75.58     
1.00     64         50         38.11      73.80     
1.00     64         75         36.40      75.92     
1.00     64         100        39.02      76.11     
1.00     64         125        37.01      75.21     
1.00     64         150        41.06      75.84     
1.00     64         175        39.79      77.06     
1.00     64         200        38.45      76.64     
1.00     64         220        31.97      70.28     
1.00     128        1          30.39      60.17     
1.00     128        25         34.01      69.64     
1.00     128        50         36.65      69.77     
1.00     128        75         33.38      68.46     
1.00     128        100        35.92      71.81     
1.00     128        125        35.08      68.69     
1.00     128        150        36.81      71.25     
1.00     128        175        33.70      70.04     
1.00     128        200        35.72      70.24     
1.00     128        220        37.96      69.68     
1.00     256        1          25.16      51.51     
1.00     256        25         31.35      63.02     
1.00     256        50         30.76      60.68     
1.00     256        75         33.88      63.60     
1.00     256        100        32.80      64.10     
1.00     256        125        31.76      63.41     
1.00     256        150        34.23      66.70     
1.00     256        175        31.93      65.27     
1.00     256        200        33.21      64.21     
1.00     256        220        27.73      64.24     

BEST RESULT:
  Alpha: 0.2
  Clusters: 16
  PCA_dim: 175
  Top-1 Accuracy: 66.04%
  Top-5 Accuracy: 88.88%
2025-09-15 11:40:45,683 - INFO - Experiment for seed 1001 completed in 76374.78 seconds
2025-09-15 11:40:45,690 - INFO - SUCCESS: Experiment for seed 1001 completed successfully
2025-09-15 11:40:45,696 - INFO - Looking for results in: ./checkpoint/quant_result/20250915_1128
2025-09-15 11:40:45,698 - INFO - Parsed 0 reconstructed results from log file for seed 1001
2025-09-15 11:40:45,698 - INFO - Parsed 0 baseline results from log file for seed 1001
2025-09-15 11:40:45,698 - INFO - Seed 1001 completed successfully
2025-09-15 11:40:45,698 - INFO - Sleeping for 0.5 seconds before next seed...
2025-09-15 11:40:46,198 - INFO - 
============================================================
2025-09-15 11:40:46,199 - INFO - Running experiment 2/3 for seed 1002
2025-09-15 11:40:46,199 - INFO - ============================================================
2025-09-15 11:40:46,200 - INFO - Running experiment for seed 1002
2025-09-15 11:40:46,200 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model deit_small --w_bit 2 --a_bit 6 --seed 1002 --config ../configs/4bit/qdrop_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-15 11:40:46,200 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/qdrop
2025-09-15 11:41:06 - start the process.
Namespace(model='deit_small', config='../configs/4bit/qdrop_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1002, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=2, a_bit=6, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 2
a_bit: 6
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: qdrop
drop_prob: 0.5
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/deit_small_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/deit_small_patch16_224.fb_in1k)
[timm/deit_small_patch16_224.fb_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 26.697 (26.697)	Loss 0.5675 (0.5675)	Prec@1 87.800 (87.800)	Prec@5 98.200 (98.200)
Test: [10/100]	Time 0.310 (4.264)	Loss 0.6371 (0.6845)	Prec@1 88.400 (85.000)	Prec@5 96.400 (96.909)
Test: [20/100]	Time 0.301 (2.687)	Loss 0.7345 (0.6957)	Prec@1 81.200 (84.838)	Prec@5 97.400 (96.914)
Test: [30/100]	Time 0.308 (2.175)	Loss 0.6521 (0.7044)	Prec@1 84.400 (84.368)	Prec@5 98.200 (97.000)
Test: [40/100]	Time 0.316 (1.931)	Loss 0.8969 (0.7041)	Prec@1 77.000 (84.463)	Prec@5 95.600 (96.995)
Test: [50/100]	Time 0.312 (1.628)	Loss 1.2925 (0.7827)	Prec@1 69.800 (82.345)	Prec@5 90.600 (96.122)
Test: [60/100]	Time 0.315 (1.412)	Loss 0.9169 (0.8059)	Prec@1 80.200 (81.770)	Prec@5 92.800 (95.780)
Test: [70/100]	Time 0.304 (1.269)	Loss 0.9785 (0.8407)	Prec@1 78.000 (80.800)	Prec@5 95.200 (95.434)
Test: [80/100]	Time 0.315 (1.151)	Loss 0.7631 (0.8600)	Prec@1 83.400 (80.464)	Prec@5 96.000 (95.160)
Test: [90/100]	Time 0.314 (1.059)	Loss 1.2795 (0.8835)	Prec@1 68.400 (79.752)	Prec@5 91.000 (94.985)
 * Prec@1 79.848 Prec@5 95.054 Loss 0.878 Time 99.357
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-15 11:43:27 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:06<07:24,  6.09s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:06<07:24,  6.09s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [00:27<18:19, 15.27s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [00:27<18:19, 15.27s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [00:37<14:49, 12.53s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [00:37<14:49, 12.53s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [01:12<25:23, 21.76s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [01:12<25:23, 21.76s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [01:41<27:56, 24.30s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [01:41<27:56, 24.30s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [02:11<29:48, 26.30s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [02:11<29:48, 26.30s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [02:41<30:36, 27.41s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [02:41<30:36, 27.41s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [03:03<28:15, 25.69s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [03:03<28:15, 25.69s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [03:13<22:19, 20.61s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [03:13<22:19, 20.61s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [03:48<26:58, 25.29s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [03:48<26:58, 25.29s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [04:17<27:46, 26.46s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [04:17<27:46, 26.46s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [04:48<28:35, 27.66s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [04:48<28:35, 27.66s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [05:18<28:50, 28.36s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [05:18<28:50, 28.36s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [05:40<26:29, 26.49s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [05:40<26:29, 26.49s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [05:50<21:00, 21.36s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [05:50<21:00, 21.36s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [06:25<24:51, 25.72s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [06:25<24:51, 25.72s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [06:54<25:16, 26.61s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [06:54<25:16, 26.61s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [07:24<25:44, 27.59s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [07:24<25:44, 27.59s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [07:54<25:50, 28.20s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [07:54<25:50, 28.20s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [08:16<23:43, 26.36s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [08:16<23:43, 26.36s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [08:25<18:47, 21.27s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [08:25<18:47, 21.27s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [09:01<22:16, 25.70s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [09:01<22:16, 25.70s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [09:30<22:38, 26.63s/it]calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [09:30<22:38, 26.63s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [10:00<23:10, 27.81s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [10:00<23:10, 27.81s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [10:30<23:14, 28.46s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [10:30<23:14, 28.46s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [10:52<21:15, 26.56s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [10:52<21:15, 26.56s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [11:02<16:46, 21.42s/it]calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [11:02<16:46, 21.42s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [11:38<19:46, 25.78s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [11:38<19:46, 25.78s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [12:06<19:58, 26.62s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [12:06<19:58, 26.62s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [12:37<20:20, 27.74s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [12:37<20:20, 27.74s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [13:07<20:19, 28.36s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [13:07<20:19, 28.36s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [13:29<18:31, 26.47s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [13:29<18:31, 26.47s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [13:38<14:35, 21.36s/it]calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [13:38<14:35, 21.36s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [14:14<17:07, 25.70s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [14:14<17:07, 25.70s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [14:43<17:21, 26.70s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [14:43<17:21, 26.70s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [15:14<17:39, 27.89s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [15:14<17:39, 27.89s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [15:44<17:42, 28.73s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [15:44<17:42, 28.73s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [16:07<16:12, 27.01s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [16:07<16:12, 27.01s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [16:17<12:46, 21.89s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [16:17<12:46, 21.89s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [16:53<14:47, 26.11s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [16:53<14:47, 26.11s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [17:22<14:49, 26.96s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [17:22<14:49, 26.96s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [17:53<14:56, 28.02s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [17:53<14:56, 28.02s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [18:23<14:51, 28.77s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [18:23<14:51, 28.77s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [18:46<13:30, 27.01s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [18:46<13:30, 27.01s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [18:56<10:33, 21.86s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [18:56<10:33, 21.86s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [19:33<12:15, 26.28s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [19:33<12:15, 26.28s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [20:02<12:11, 27.10s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [20:02<12:11, 27.10s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [20:32<12:12, 28.16s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [20:32<12:12, 28.16s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [21:03<12:01, 28.87s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [21:03<12:01, 28.87s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [21:26<10:49, 27.06s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [21:26<10:49, 27.06s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [21:35<08:22, 21.84s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [21:35<08:22, 21.84s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [22:11<09:32, 26.04s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [22:11<09:32, 26.04s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [22:40<09:25, 26.95s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [22:40<09:25, 26.95s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [23:10<09:18, 27.93s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [23:10<09:18, 27.93s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [23:40<09:01, 28.50s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [23:40<09:01, 28.50s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [24:02<07:58, 26.57s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [24:02<07:58, 26.57s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [24:12<06:04, 21.42s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [24:12<06:04, 21.42s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [24:48<06:52, 25.77s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [24:48<06:52, 25.77s/it]slurmstepd-jnfat04: error: *** JOB 1675179 ON jnfat04 CANCELLED AT 2025-09-15T12:09:03 ***
