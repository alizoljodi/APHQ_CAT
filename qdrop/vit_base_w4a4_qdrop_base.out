Starting ViT-Base W4A4 QDROP experiment at Thu Sep 11 10:45:37 AM CEST 2025
2025-09-11 10:45:38,189 - INFO - Starting multi-seed experiment
2025-09-11 10:45:38,189 - INFO - Architecture: vit_base
2025-09-11 10:45:38,189 - INFO - Weight bits: 4
2025-09-11 10:45:38,189 - INFO - Activation bits: 4
2025-09-11 10:45:38,189 - INFO - Seeds: [1001, 1002, 1003]
2025-09-11 10:45:38,189 - INFO - Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
2025-09-11 10:45:38,189 - INFO - Cluster numbers: [8, 16, 32, 64, 128, 256]
2025-09-11 10:45:38,189 - INFO - PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]
2025-09-11 10:45:38,189 - INFO - Output directory: ./experiment_results/vit_base_w4_a4_20250911_104538
2025-09-11 10:45:38,189 - INFO - Checking basic requirements...
2025-09-11 10:45:38,189 - INFO - Basic checks passed
2025-09-11 10:45:38,189 - INFO - 
Starting experiments for 3 seeds...
2025-09-11 10:45:38,189 - INFO - Total parameter combinations: 600
2025-09-11 10:45:38,189 - INFO - Total experiments: 1800
2025-09-11 10:45:38,189 - INFO - 
============================================================
2025-09-11 10:45:38,189 - INFO - Running experiment 1/3 for seed 1001
2025-09-11 10:45:38,189 - INFO - ============================================================
2025-09-11 10:45:38,189 - INFO - Running experiment for seed 1001
2025-09-11 10:45:38,189 - INFO - Command: /home/alz07xz/project/PD-Quant/pd_quant/bin/python ../test_quant.py --model vit_base --w_bit 4 --a_bit 4 --seed 1001 --config ../configs/4bit/qdrop_baseline.py --dataset /home/alz07xz/imagenet --calib-size 1000 --calib-batch-size 32 --val-batch-size 500 --num-workers 8 --device cuda --alpha-list 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 --num-clusters-list 8 16 32 64 128 256 --pca-dim-list 1 25 50 75 100 125 150 175 200 220 --calibrate --optimize
2025-09-11 10:45:38,189 - INFO - Working directory: /home/alz07xz/project/APHQ_CAT/qdrop
2025-09-11 10:57:07 - start the process.
Namespace(model='vit_base', config='../configs/4bit/qdrop_baseline.py', dataset='/home/alz07xz/imagenet', val_batch_size=500, num_workers=8, device='cuda', reconstruct_mlp=False, load_reconstruct_checkpoint=False, test_reconstruct_checkpoint=False, calibrate=True, load_calibrate_checkpoint=None, test_calibrate_checkpoint=False, optimize=True, load_optimize_checkpoint='', test_optimize_checkpoint=False, print_freq=10, seed=1001, alpha_list=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], num_clusters_list=[8, 16, 32, 64, 128, 256], pca_dim_list=[1, 25, 50, 75, 100, 125, 150, 175, 200, 220], w_bit=4, a_bit=4, calib_size=1000, calib_batch_size=32)
deefe /home/alz07xz/project/APHQ_CAT/configs/4bit
Successfully imported Config class!
optim_size: 1024
calib_size: 1000
optim_batch_size: 32
calib_batch_size: 32
w_bit: 4
a_bit: 4
qconv_a_bit: 8
qhead_a_bit: 4
calib_metric: mse
matmul_head_channel_wise: True
token_channel_wise: False
eq_n: 128
search_round: 3
keep_gpu: True
optim_metric: mse
use_mean_hessian: False
temp: 20
recon_metric: hessian_perturb
pct: 0.99
optim_mode: qdrop
drop_prob: 0.5
reconstruct_mlp: False
Building model ...
No checkpoint found at './checkpoint/vit_raw/vit_base_patch16_224.bin'
Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
[timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Building validation dataloader ...
Validating on test set on fp ...
Test: [0/100]	Time 16.989 (16.989)	Loss 0.4459 (0.4459)	Prec@1 91.400 (91.400)	Prec@5 98.600 (98.600)
Test: [10/100]	Time 0.766 (2.548)	Loss 0.4659 (0.5379)	Prec@1 90.800 (88.455)	Prec@5 98.600 (98.345)
Test: [20/100]	Time 0.770 (1.700)	Loss 0.6057 (0.5588)	Prec@1 85.800 (88.124)	Prec@5 98.600 (98.095)
Test: [30/100]	Time 0.776 (1.401)	Loss 0.5066 (0.5820)	Prec@1 89.800 (87.471)	Prec@5 99.600 (98.045)
Test: [40/100]	Time 0.779 (1.251)	Loss 0.7571 (0.5772)	Prec@1 81.400 (87.532)	Prec@5 97.000 (98.088)
Test: [50/100]	Time 0.799 (1.160)	Loss 1.0069 (0.6165)	Prec@1 77.000 (86.384)	Prec@5 95.200 (97.827)
Test: [60/100]	Time 0.781 (1.099)	Loss 0.5700 (0.6205)	Prec@1 89.200 (86.285)	Prec@5 97.200 (97.751)
Test: [70/100]	Time 0.791 (1.056)	Loss 0.7296 (0.6361)	Prec@1 83.800 (85.673)	Prec@5 97.400 (97.654)
Test: [80/100]	Time 0.799 (1.023)	Loss 0.5101 (0.6392)	Prec@1 88.400 (85.605)	Prec@5 98.000 (97.580)
Test: [90/100]	Time 0.789 (0.998)	Loss 0.9420 (0.6541)	Prec@1 75.000 (85.062)	Prec@5 95.800 (97.495)
 * Prec@1 85.102 Prec@5 97.526 Loss 0.652 Time 98.274
Wraping quantiztion modules (reparam: False, recon: False) ...
2025-09-11 10:59:31 - start mse guided calibration
  0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   0%|          | 0/74 [00:00<?, ?it/s]calibrating patch_embed.proj:   1%|▏         | 1/74 [00:11<14:26, 11.87s/it]calibrating blocks.0.attn.qkv:   1%|▏         | 1/74 [00:11<14:26, 11.87s/it]calibrating blocks.0.attn.qkv:   3%|▎         | 2/74 [01:26<58:37, 48.86s/it]calibrating blocks.0.attn.proj:   3%|▎         | 2/74 [01:26<58:37, 48.86s/it]calibrating blocks.0.attn.proj:   4%|▍         | 3/74 [01:51<45:03, 38.07s/it]calibrating blocks.0.attn.matmul1:   4%|▍         | 3/74 [01:51<45:03, 38.07s/it]calibrating blocks.0.attn.matmul1:   5%|▌         | 4/74 [03:03<59:46, 51.23s/it]calibrating blocks.0.attn.matmul2:   5%|▌         | 4/74 [03:03<59:46, 51.23s/it]calibrating blocks.0.attn.matmul2:   7%|▋         | 5/74 [04:03<1:02:50, 54.64s/it]calibrating blocks.0.mlp.fc1:   7%|▋         | 5/74 [04:03<1:02:50, 54.64s/it]     calibrating blocks.0.mlp.fc1:   8%|▊         | 6/74 [05:57<1:24:41, 74.73s/it]calibrating blocks.0.mlp.fc2:   8%|▊         | 6/74 [05:57<1:24:41, 74.73s/it]calibrating blocks.0.mlp.fc2:   9%|▉         | 7/74 [07:55<1:39:06, 88.76s/it]calibrating blocks.1.attn.qkv:   9%|▉         | 7/74 [07:55<1:39:06, 88.76s/it]calibrating blocks.1.attn.qkv:  11%|█         | 8/74 [09:11<1:33:12, 84.74s/it]calibrating blocks.1.attn.proj:  11%|█         | 8/74 [09:11<1:33:12, 84.74s/it]calibrating blocks.1.attn.proj:  12%|█▏        | 9/74 [09:37<1:12:00, 66.47s/it]calibrating blocks.1.attn.matmul1:  12%|█▏        | 9/74 [09:37<1:12:00, 66.47s/it]calibrating blocks.1.attn.matmul1:  14%|█▎        | 10/74 [10:49<1:12:40, 68.13s/it]calibrating blocks.1.attn.matmul2:  14%|█▎        | 10/74 [10:49<1:12:40, 68.13s/it]calibrating blocks.1.attn.matmul2:  15%|█▍        | 11/74 [11:50<1:09:08, 65.85s/it]calibrating blocks.1.mlp.fc1:  15%|█▍        | 11/74 [11:50<1:09:08, 65.85s/it]     calibrating blocks.1.mlp.fc1:  16%|█▌        | 12/74 [13:44<1:23:20, 80.66s/it]calibrating blocks.1.mlp.fc2:  16%|█▌        | 12/74 [13:44<1:23:20, 80.66s/it]calibrating blocks.1.mlp.fc2:  18%|█▊        | 13/74 [15:43<1:33:35, 92.06s/it]calibrating blocks.2.attn.qkv:  18%|█▊        | 13/74 [15:43<1:33:35, 92.06s/it]calibrating blocks.2.attn.qkv:  19%|█▉        | 14/74 [17:00<1:27:40, 87.67s/it]calibrating blocks.2.attn.proj:  19%|█▉        | 14/74 [17:00<1:27:40, 87.67s/it]calibrating blocks.2.attn.proj:  20%|██        | 15/74 [17:26<1:07:55, 69.07s/it]calibrating blocks.2.attn.matmul1:  20%|██        | 15/74 [17:26<1:07:55, 69.07s/it]calibrating blocks.2.attn.matmul1:  22%|██▏       | 16/74 [18:38<1:07:31, 69.85s/it]calibrating blocks.2.attn.matmul2:  22%|██▏       | 16/74 [18:38<1:07:31, 69.85s/it]calibrating blocks.2.attn.matmul2:  23%|██▎       | 17/74 [19:38<1:03:45, 67.11s/it]calibrating blocks.2.mlp.fc1:  23%|██▎       | 17/74 [19:38<1:03:45, 67.11s/it]     calibrating blocks.2.mlp.fc1:  24%|██▍       | 18/74 [21:34<1:16:10, 81.61s/it]calibrating blocks.2.mlp.fc2:  24%|██▍       | 18/74 [21:34<1:16:10, 81.61s/it]calibrating blocks.2.mlp.fc2:  26%|██▌       | 19/74 [23:33<1:25:02, 92.77s/it]calibrating blocks.3.attn.qkv:  26%|██▌       | 19/74 [23:33<1:25:02, 92.77s/it]calibrating blocks.3.attn.qkv:  27%|██▋       | 20/74 [24:50<1:19:23, 88.22s/it]calibrating blocks.3.attn.proj:  27%|██▋       | 20/74 [24:50<1:19:23, 88.22s/it]calibrating blocks.3.attn.proj:  28%|██▊       | 21/74 [25:16<1:01:24, 69.52s/it]calibrating blocks.3.attn.matmul1:  28%|██▊       | 21/74 [25:16<1:01:24, 69.52s/it]calibrating blocks.3.attn.matmul1:  30%|██▉       | 22/74 [26:28<1:00:46, 70.13s/it]calibrating blocks.3.attn.matmul2:  30%|██▉       | 22/74 [26:28<1:00:46, 70.13s/it]calibrating blocks.3.attn.matmul2:  31%|███       | 23/74 [27:28<57:12, 67.30s/it]  calibrating blocks.3.mlp.fc1:  31%|███       | 23/74 [27:28<57:12, 67.30s/it]     calibrating blocks.3.mlp.fc1:  32%|███▏      | 24/74 [29:23<1:08:00, 81.60s/it]calibrating blocks.3.mlp.fc2:  32%|███▏      | 24/74 [29:23<1:08:00, 81.60s/it]calibrating blocks.3.mlp.fc2:  34%|███▍      | 25/74 [31:22<1:15:38, 92.62s/it]calibrating blocks.4.attn.qkv:  34%|███▍      | 25/74 [31:22<1:15:38, 92.62s/it]calibrating blocks.4.attn.qkv:  35%|███▌      | 26/74 [32:39<1:10:22, 87.97s/it]calibrating blocks.4.attn.proj:  35%|███▌      | 26/74 [32:39<1:10:22, 87.97s/it]calibrating blocks.4.attn.proj:  36%|███▋      | 27/74 [33:05<54:26, 69.50s/it]  calibrating blocks.4.attn.matmul1:  36%|███▋      | 27/74 [33:05<54:26, 69.50s/it]calibrating blocks.4.attn.matmul1:  38%|███▊      | 28/74 [34:18<53:55, 70.34s/it]calibrating blocks.4.attn.matmul2:  38%|███▊      | 28/74 [34:18<53:55, 70.34s/it]calibrating blocks.4.attn.matmul2:  39%|███▉      | 29/74 [35:19<50:40, 67.56s/it]calibrating blocks.4.mlp.fc1:  39%|███▉      | 29/74 [35:19<50:40, 67.56s/it]     calibrating blocks.4.mlp.fc1:  41%|████      | 30/74 [37:13<59:53, 81.68s/it]calibrating blocks.4.mlp.fc2:  41%|████      | 30/74 [37:13<59:53, 81.68s/it]calibrating blocks.4.mlp.fc2:  42%|████▏     | 31/74 [39:12<1:06:25, 92.68s/it]calibrating blocks.5.attn.qkv:  42%|████▏     | 31/74 [39:12<1:06:25, 92.68s/it]calibrating blocks.5.attn.qkv:  43%|████▎     | 32/74 [40:28<1:01:32, 87.91s/it]calibrating blocks.5.attn.proj:  43%|████▎     | 32/74 [40:28<1:01:32, 87.91s/it]calibrating blocks.5.attn.proj:  45%|████▍     | 33/74 [40:55<47:26, 69.43s/it]  calibrating blocks.5.attn.matmul1:  45%|████▍     | 33/74 [40:55<47:26, 69.43s/it]calibrating blocks.5.attn.matmul1:  46%|████▌     | 34/74 [42:07<46:50, 70.27s/it]calibrating blocks.5.attn.matmul2:  46%|████▌     | 34/74 [42:07<46:50, 70.27s/it]calibrating blocks.5.attn.matmul2:  47%|████▋     | 35/74 [43:08<43:51, 67.47s/it]calibrating blocks.5.mlp.fc1:  47%|████▋     | 35/74 [43:08<43:51, 67.47s/it]     calibrating blocks.5.mlp.fc1:  49%|████▊     | 36/74 [45:03<51:51, 81.87s/it]calibrating blocks.5.mlp.fc2:  49%|████▊     | 36/74 [45:03<51:51, 81.87s/it]calibrating blocks.5.mlp.fc2:  50%|█████     | 37/74 [47:02<57:13, 92.79s/it]calibrating blocks.6.attn.qkv:  50%|█████     | 37/74 [47:02<57:13, 92.79s/it]calibrating blocks.6.attn.qkv:  51%|█████▏    | 38/74 [48:18<52:48, 88.02s/it]calibrating blocks.6.attn.proj:  51%|█████▏    | 38/74 [48:18<52:48, 88.02s/it]calibrating blocks.6.attn.proj:  53%|█████▎    | 39/74 [48:45<40:33, 69.53s/it]calibrating blocks.6.attn.matmul1:  53%|█████▎    | 39/74 [48:45<40:33, 69.53s/it]calibrating blocks.6.attn.matmul1:  54%|█████▍    | 40/74 [49:57<39:51, 70.33s/it]calibrating blocks.6.attn.matmul2:  54%|█████▍    | 40/74 [49:57<39:51, 70.33s/it]calibrating blocks.6.attn.matmul2:  55%|█████▌    | 41/74 [50:58<37:07, 67.49s/it]calibrating blocks.6.mlp.fc1:  55%|█████▌    | 41/74 [50:58<37:07, 67.49s/it]     calibrating blocks.6.mlp.fc1:  57%|█████▋    | 42/74 [52:52<43:30, 81.57s/it]calibrating blocks.6.mlp.fc2:  57%|█████▋    | 42/74 [52:52<43:30, 81.57s/it]calibrating blocks.6.mlp.fc2:  58%|█████▊    | 43/74 [54:50<47:40, 92.26s/it]calibrating blocks.7.attn.qkv:  58%|█████▊    | 43/74 [54:50<47:40, 92.26s/it]calibrating blocks.7.attn.qkv:  59%|█████▉    | 44/74 [56:05<43:39, 87.31s/it]calibrating blocks.7.attn.proj:  59%|█████▉    | 44/74 [56:05<43:39, 87.31s/it]calibrating blocks.7.attn.proj:  61%|██████    | 45/74 [56:31<33:15, 68.82s/it]calibrating blocks.7.attn.matmul1:  61%|██████    | 45/74 [56:31<33:15, 68.82s/it]calibrating blocks.7.attn.matmul1:  62%|██████▏   | 46/74 [57:43<32:29, 69.64s/it]calibrating blocks.7.attn.matmul2:  62%|██████▏   | 46/74 [57:43<32:29, 69.64s/it]calibrating blocks.7.attn.matmul2:  64%|██████▎   | 47/74 [58:43<30:07, 66.94s/it]calibrating blocks.7.mlp.fc1:  64%|██████▎   | 47/74 [58:43<30:07, 66.94s/it]     calibrating blocks.7.mlp.fc1:  65%|██████▍   | 48/74 [1:00:38<35:16, 81.42s/it]calibrating blocks.7.mlp.fc2:  65%|██████▍   | 48/74 [1:00:38<35:16, 81.42s/it]calibrating blocks.7.mlp.fc2:  66%|██████▌   | 49/74 [1:02:36<38:30, 92.41s/it]calibrating blocks.8.attn.qkv:  66%|██████▌   | 49/74 [1:02:36<38:30, 92.41s/it]calibrating blocks.8.attn.qkv:  68%|██████▊   | 50/74 [1:03:53<35:07, 87.79s/it]calibrating blocks.8.attn.proj:  68%|██████▊   | 50/74 [1:03:53<35:07, 87.79s/it]calibrating blocks.8.attn.proj:  69%|██████▉   | 51/74 [1:04:20<26:36, 69.39s/it]calibrating blocks.8.attn.matmul1:  69%|██████▉   | 51/74 [1:04:20<26:36, 69.39s/it]calibrating blocks.8.attn.matmul1:  70%|███████   | 52/74 [1:05:31<25:40, 70.02s/it]calibrating blocks.8.attn.matmul2:  70%|███████   | 52/74 [1:05:31<25:40, 70.02s/it]calibrating blocks.8.attn.matmul2:  72%|███████▏  | 53/74 [1:06:32<23:29, 67.12s/it]calibrating blocks.8.mlp.fc1:  72%|███████▏  | 53/74 [1:06:32<23:29, 67.12s/it]     calibrating blocks.8.mlp.fc1:  73%|███████▎  | 54/74 [1:08:27<27:11, 81.58s/it]calibrating blocks.8.mlp.fc2:  73%|███████▎  | 54/74 [1:08:27<27:11, 81.58s/it]calibrating blocks.8.mlp.fc2:  74%|███████▍  | 55/74 [1:10:25<29:16, 92.45s/it]calibrating blocks.9.attn.qkv:  74%|███████▍  | 55/74 [1:10:25<29:16, 92.45s/it]calibrating blocks.9.attn.qkv:  76%|███████▌  | 56/74 [1:11:42<26:23, 87.96s/it]calibrating blocks.9.attn.proj:  76%|███████▌  | 56/74 [1:11:42<26:23, 87.96s/it]calibrating blocks.9.attn.proj:  77%|███████▋  | 57/74 [1:12:09<19:42, 69.53s/it]calibrating blocks.9.attn.matmul1:  77%|███████▋  | 57/74 [1:12:09<19:42, 69.53s/it]calibrating blocks.9.attn.matmul1:  78%|███████▊  | 58/74 [1:13:20<18:41, 70.11s/it]calibrating blocks.9.attn.matmul2:  78%|███████▊  | 58/74 [1:13:20<18:41, 70.11s/it]calibrating blocks.9.attn.matmul2:  80%|███████▉  | 59/74 [1:14:21<16:47, 67.17s/it]calibrating blocks.9.mlp.fc1:  80%|███████▉  | 59/74 [1:14:21<16:47, 67.17s/it]     calibrating blocks.9.mlp.fc1:  81%|████████  | 60/74 [1:16:16<19:01, 81.52s/it]calibrating blocks.9.mlp.fc2:  81%|████████  | 60/74 [1:16:16<19:01, 81.52s/it]calibrating blocks.9.mlp.fc2:  82%|████████▏ | 61/74 [1:18:13<19:59, 92.24s/it]calibrating blocks.10.attn.qkv:  82%|████████▏ | 61/74 [1:18:13<19:59, 92.24s/it]calibrating blocks.10.attn.qkv:  84%|████████▍ | 62/74 [1:19:30<17:32, 87.74s/it]calibrating blocks.10.attn.proj:  84%|████████▍ | 62/74 [1:19:30<17:32, 87.74s/it]calibrating blocks.10.attn.proj:  85%|████████▌ | 63/74 [1:19:57<12:43, 69.43s/it]calibrating blocks.10.attn.matmul1:  85%|████████▌ | 63/74 [1:19:57<12:43, 69.43s/it]calibrating blocks.10.attn.matmul1:  86%|████████▋ | 64/74 [1:21:09<11:42, 70.21s/it]calibrating blocks.10.attn.matmul2:  86%|████████▋ | 64/74 [1:21:09<11:42, 70.21s/it]calibrating blocks.10.attn.matmul2:  88%|████████▊ | 65/74 [1:22:09<10:05, 67.32s/it]calibrating blocks.10.mlp.fc1:  88%|████████▊ | 65/74 [1:22:09<10:05, 67.32s/it]     calibrating blocks.10.mlp.fc1:  89%|████████▉ | 66/74 [1:24:04<10:51, 81.42s/it]calibrating blocks.10.mlp.fc2:  89%|████████▉ | 66/74 [1:24:04<10:51, 81.42s/it]calibrating blocks.10.mlp.fc2:  91%|█████████ | 67/74 [1:26:00<10:43, 91.97s/it]calibrating blocks.11.attn.qkv:  91%|█████████ | 67/74 [1:26:00<10:43, 91.97s/it]calibrating blocks.11.attn.qkv:  92%|█████████▏| 68/74 [1:27:17<08:43, 87.32s/it]calibrating blocks.11.attn.proj:  92%|█████████▏| 68/74 [1:27:17<08:43, 87.32s/it]calibrating blocks.11.attn.proj:  93%|█████████▎| 69/74 [1:27:43<05:45, 69.03s/it]calibrating blocks.11.attn.matmul1:  93%|█████████▎| 69/74 [1:27:43<05:45, 69.03s/it]calibrating blocks.11.attn.matmul1:  95%|█████████▍| 70/74 [1:28:55<04:38, 69.75s/it]calibrating blocks.11.attn.matmul2:  95%|█████████▍| 70/74 [1:28:55<04:38, 69.75s/it]calibrating blocks.11.attn.matmul2:  96%|█████████▌| 71/74 [1:29:55<03:21, 67.05s/it]calibrating blocks.11.mlp.fc1:  96%|█████████▌| 71/74 [1:29:55<03:21, 67.05s/it]     calibrating blocks.11.mlp.fc1:  97%|█████████▋| 72/74 [1:31:51<02:42, 81.49s/it]calibrating blocks.11.mlp.fc2:  97%|█████████▋| 72/74 [1:31:51<02:42, 81.49s/it]calibrating blocks.11.mlp.fc2:  99%|█████████▊| 73/74 [1:33:49<01:32, 92.65s/it]calibrating head:  99%|█████████▊| 73/74 [1:33:49<01:32, 92.65s/it]             calibrating head: 100%|██████████| 74/74 [1:33:53<00:00, 65.93s/it]calibrating head: 100%|██████████| 74/74 [1:33:53<00:00, 76.13s/it]
2025-09-11 12:33:30 - mse guided calibration finished.
Saving checkpoint to ./checkpoint/quant_result/20250911_1057/vit_base_w4_a4_calibsize_1000_mse.pth
Validating after calibration ...
Test: [0/100]	Time 13.466 (13.466)	Loss 0.7140 (0.7140)	Prec@1 83.400 (83.400)	Prec@5 96.000 (96.000)
Test: [10/100]	Time 1.676 (2.752)	Loss 0.8288 (0.8872)	Prec@1 82.600 (79.800)	Prec@5 93.800 (94.055)
Test: [20/100]	Time 1.678 (2.242)	Loss 0.8655 (0.9028)	Prec@1 74.800 (78.210)	Prec@5 97.000 (94.210)
Test: [30/100]	Time 1.678 (2.060)	Loss 0.8368 (0.9103)	Prec@1 81.000 (77.832)	Prec@5 95.600 (94.200)
Test: [40/100]	Time 1.674 (1.967)	Loss 1.1988 (0.9052)	Prec@1 72.000 (78.361)	Prec@5 92.600 (94.376)
Test: [50/100]	Time 1.678 (1.910)	Loss 1.5167 (0.9864)	Prec@1 67.200 (76.871)	Prec@5 88.200 (93.475)
Test: [60/100]	Time 1.676 (1.872)	Loss 1.1942 (1.0185)	Prec@1 76.200 (76.357)	Prec@5 88.200 (93.085)
Test: [70/100]	Time 1.679 (1.844)	Loss 1.2131 (1.0627)	Prec@1 71.600 (75.389)	Prec@5 91.600 (92.628)
Test: [80/100]	Time 1.679 (1.823)	Loss 0.9745 (1.0886)	Prec@1 78.200 (75.035)	Prec@5 94.200 (92.247)
Test: [90/100]	Time 1.675 (1.807)	Loss 1.5955 (1.1229)	Prec@1 64.800 (74.277)	Prec@5 88.200 (91.914)
 * Prec@1 74.554 Prec@5 92.140 Loss 1.109 Time 179.733
Building calibrator ...
2025-09-11 12:36:48 - start mse guided block reconstruction
reconstructing patch_embed ...
initializing raw input and raw output ...
adaround training for patch_embed ...
wraping quantizers in patch_embed ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.215 (rec:0.215, round:0.000)	b=0.00	count=500
Total loss:	0.100 (rec:0.100, round:0.000)	b=0.00	count=1000
Total loss:	0.107 (rec:0.107, round:0.000)	b=0.00	count=1500
Total loss:	0.091 (rec:0.091, round:0.000)	b=0.00	count=2000
Total loss:	0.063 (rec:0.063, round:0.000)	b=0.00	count=2500
Total loss:	0.097 (rec:0.097, round:0.000)	b=0.00	count=3000
Total loss:	0.048 (rec:0.048, round:0.000)	b=0.00	count=3500
Total loss:	5577.302 (rec:0.045, round:5577.256)	b=20.00	count=4000
Total loss:	2958.314 (rec:0.104, round:2958.210)	b=19.44	count=4500
Total loss:	2715.962 (rec:0.087, round:2715.875)	b=18.88	count=5000
Total loss:	2555.628 (rec:0.062, round:2555.566)	b=18.31	count=5500
Total loss:	2419.553 (rec:0.095, round:2419.458)	b=17.75	count=6000
Total loss:	2294.442 (rec:0.084, round:2294.358)	b=17.19	count=6500
Total loss:	2173.142 (rec:0.086, round:2173.056)	b=16.62	count=7000
Total loss:	2055.708 (rec:0.088, round:2055.620)	b=16.06	count=7500
Total loss:	1938.457 (rec:0.038, round:1938.419)	b=15.50	count=8000
Total loss:	1822.170 (rec:0.075, round:1822.095)	b=14.94	count=8500
Total loss:	1705.629 (rec:0.064, round:1705.565)	b=14.38	count=9000
Total loss:	1588.274 (rec:0.071, round:1588.203)	b=13.81	count=9500
Total loss:	1468.490 (rec:0.081, round:1468.409)	b=13.25	count=10000
Total loss:	1345.328 (rec:0.118, round:1345.210)	b=12.69	count=10500
Total loss:	1220.893 (rec:0.088, round:1220.805)	b=12.12	count=11000
Total loss:	1094.316 (rec:0.096, round:1094.220)	b=11.56	count=11500
Total loss:	965.139 (rec:0.133, round:965.006)	b=11.00	count=12000
Total loss:	833.597 (rec:0.103, round:833.494)	b=10.44	count=12500
Total loss:	702.384 (rec:0.141, round:702.243)	b=9.88	count=13000
Total loss:	573.282 (rec:0.178, round:573.104)	b=9.31	count=13500
Total loss:	448.706 (rec:0.110, round:448.596)	b=8.75	count=14000
Total loss:	333.692 (rec:0.222, round:333.470)	b=8.19	count=14500
Total loss:	234.571 (rec:0.187, round:234.385)	b=7.62	count=15000
Total loss:	150.416 (rec:0.156, round:150.260)	b=7.06	count=15500
Total loss:	87.303 (rec:0.286, round:87.017)	b=6.50	count=16000
Total loss:	44.345 (rec:0.296, round:44.048)	b=5.94	count=16500
Total loss:	17.706 (rec:0.276, round:17.431)	b=5.38	count=17000
Total loss:	5.797 (rec:0.298, round:5.500)	b=4.81	count=17500
Total loss:	1.733 (rec:0.324, round:1.409)	b=4.25	count=18000
Total loss:	0.710 (rec:0.386, round:0.324)	b=3.69	count=18500
Total loss:	0.308 (rec:0.238, round:0.069)	b=3.12	count=19000
Total loss:	0.278 (rec:0.263, round:0.015)	b=2.56	count=19500
Total loss:	0.400 (rec:0.396, round:0.004)	b=2.00	count=20000
finished reconstructing patch_embed.
reconstructing blocks.0 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.0 ...
wraping quantizers in blocks.0 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	0.859 (rec:0.859, round:0.000)	b=0.00	count=500
Total loss:	0.746 (rec:0.746, round:0.000)	b=0.00	count=1000
Total loss:	0.682 (rec:0.682, round:0.000)	b=0.00	count=1500
Total loss:	0.640 (rec:0.640, round:0.000)	b=0.00	count=2000
Total loss:	0.585 (rec:0.585, round:0.000)	b=0.00	count=2500
Total loss:	0.582 (rec:0.582, round:0.000)	b=0.00	count=3000
Total loss:	0.573 (rec:0.573, round:0.000)	b=0.00	count=3500
Total loss:	63648.414 (rec:0.547, round:63647.867)	b=20.00	count=4000
Total loss:	27283.787 (rec:0.531, round:27283.256)	b=19.44	count=4500
Total loss:	24833.654 (rec:0.518, round:24833.137)	b=18.88	count=5000
Total loss:	23111.221 (rec:0.541, round:23110.680)	b=18.31	count=5500
Total loss:	21587.979 (rec:0.527, round:21587.451)	b=17.75	count=6000
Total loss:	20154.270 (rec:0.543, round:20153.727)	b=17.19	count=6500
Total loss:	18788.246 (rec:0.527, round:18787.719)	b=16.62	count=7000
Total loss:	17472.916 (rec:0.571, round:17472.346)	b=16.06	count=7500
Total loss:	16212.122 (rec:0.528, round:16211.595)	b=15.50	count=8000
Total loss:	15006.985 (rec:0.495, round:15006.490)	b=14.94	count=8500
Total loss:	13850.944 (rec:0.508, round:13850.437)	b=14.38	count=9000
Total loss:	12736.032 (rec:0.488, round:12735.545)	b=13.81	count=9500
Total loss:	11666.872 (rec:0.495, round:11666.377)	b=13.25	count=10000
Total loss:	10645.548 (rec:0.544, round:10645.004)	b=12.69	count=10500
Total loss:	9657.863 (rec:0.496, round:9657.367)	b=12.12	count=11000
Total loss:	8705.487 (rec:0.556, round:8704.931)	b=11.56	count=11500
Total loss:	7784.325 (rec:0.498, round:7783.827)	b=11.00	count=12000
Total loss:	6891.545 (rec:0.498, round:6891.048)	b=10.44	count=12500
Total loss:	6024.700 (rec:0.517, round:6024.184)	b=9.88	count=13000
Total loss:	5190.917 (rec:0.494, round:5190.423)	b=9.31	count=13500
Total loss:	4389.207 (rec:0.524, round:4388.683)	b=8.75	count=14000
Total loss:	3620.363 (rec:0.508, round:3619.855)	b=8.19	count=14500
Total loss:	2894.108 (rec:0.503, round:2893.605)	b=7.62	count=15000
Total loss:	2213.432 (rec:0.516, round:2212.916)	b=7.06	count=15500
Total loss:	1588.669 (rec:0.503, round:1588.166)	b=6.50	count=16000
Total loss:	1045.069 (rec:0.522, round:1044.547)	b=5.94	count=16500
Total loss:	613.734 (rec:0.489, round:613.246)	b=5.38	count=17000
Total loss:	304.986 (rec:0.550, round:304.436)	b=4.81	count=17500
Total loss:	119.940 (rec:0.526, round:119.414)	b=4.25	count=18000
Total loss:	31.235 (rec:0.502, round:30.733)	b=3.69	count=18500
Total loss:	4.539 (rec:0.533, round:4.006)	b=3.12	count=19000
Total loss:	0.729 (rec:0.538, round:0.191)	b=2.56	count=19500
Total loss:	0.555 (rec:0.552, round:0.004)	b=2.00	count=20000
finished reconstructing blocks.0.
reconstructing blocks.1 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.1 ...
wraping quantizers in blocks.1 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.202 (rec:1.202, round:0.000)	b=0.00	count=500
Total loss:	1.135 (rec:1.135, round:0.000)	b=0.00	count=1000
Total loss:	1.020 (rec:1.020, round:0.000)	b=0.00	count=1500
Total loss:	1.030 (rec:1.030, round:0.000)	b=0.00	count=2000
Total loss:	1.047 (rec:1.047, round:0.000)	b=0.00	count=2500
Total loss:	0.900 (rec:0.900, round:0.000)	b=0.00	count=3000
Total loss:	0.922 (rec:0.922, round:0.000)	b=0.00	count=3500
Total loss:	63102.445 (rec:0.942, round:63101.504)	b=20.00	count=4000
Total loss:	27884.889 (rec:0.912, round:27883.977)	b=19.44	count=4500
Total loss:	25418.547 (rec:0.875, round:25417.672)	b=18.88	count=5000
Total loss:	23657.590 (rec:0.871, round:23656.719)	b=18.31	count=5500
Total loss:	22063.617 (rec:0.843, round:22062.773)	b=17.75	count=6000
Total loss:	20560.244 (rec:0.817, round:20559.428)	b=17.19	count=6500
Total loss:	19124.293 (rec:0.838, round:19123.455)	b=16.62	count=7000
Total loss:	17740.295 (rec:0.853, round:17739.441)	b=16.06	count=7500
Total loss:	16409.869 (rec:0.835, round:16409.033)	b=15.50	count=8000
Total loss:	15132.556 (rec:0.883, round:15131.672)	b=14.94	count=8500
Total loss:	13906.632 (rec:0.831, round:13905.801)	b=14.38	count=9000
Total loss:	12727.471 (rec:0.845, round:12726.625)	b=13.81	count=9500
Total loss:	11597.546 (rec:0.825, round:11596.721)	b=13.25	count=10000
Total loss:	10521.310 (rec:0.865, round:10520.445)	b=12.69	count=10500
Total loss:	9492.926 (rec:0.826, round:9492.100)	b=12.12	count=11000
Total loss:	8514.688 (rec:0.835, round:8513.853)	b=11.56	count=11500
Total loss:	7584.737 (rec:0.817, round:7583.920)	b=11.00	count=12000
Total loss:	6692.412 (rec:0.822, round:6691.589)	b=10.44	count=12500
Total loss:	5837.215 (rec:0.870, round:5836.346)	b=9.88	count=13000
Total loss:	5018.519 (rec:0.840, round:5017.678)	b=9.31	count=13500
Total loss:	4240.951 (rec:0.810, round:4240.141)	b=8.75	count=14000
Total loss:	3508.712 (rec:0.822, round:3507.890)	b=8.19	count=14500
Total loss:	2808.275 (rec:0.789, round:2807.486)	b=7.62	count=15000
Total loss:	2148.204 (rec:0.822, round:2147.382)	b=7.06	count=15500
Total loss:	1528.317 (rec:0.869, round:1527.447)	b=6.50	count=16000
Total loss:	946.599 (rec:0.884, round:945.715)	b=5.94	count=16500
Total loss:	462.030 (rec:0.882, round:461.148)	b=5.38	count=17000
Total loss:	182.698 (rec:0.848, round:181.850)	b=4.81	count=17500
Total loss:	60.599 (rec:0.855, round:59.744)	b=4.25	count=18000
Total loss:	15.137 (rec:0.857, round:14.281)	b=3.69	count=18500
Total loss:	2.907 (rec:0.839, round:2.068)	b=3.12	count=19000
Total loss:	0.950 (rec:0.824, round:0.126)	b=2.56	count=19500
Total loss:	0.856 (rec:0.855, round:0.001)	b=2.00	count=20000
finished reconstructing blocks.1.
reconstructing blocks.2 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.2 ...
wraping quantizers in blocks.2 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.609 (rec:1.609, round:0.000)	b=0.00	count=500
Total loss:	1.562 (rec:1.562, round:0.000)	b=0.00	count=1000
Total loss:	1.492 (rec:1.492, round:0.000)	b=0.00	count=1500
Total loss:	1.461 (rec:1.461, round:0.000)	b=0.00	count=2000
Total loss:	1.499 (rec:1.499, round:0.000)	b=0.00	count=2500
Total loss:	1.422 (rec:1.422, round:0.000)	b=0.00	count=3000
Total loss:	1.423 (rec:1.423, round:0.000)	b=0.00	count=3500
Total loss:	63534.551 (rec:1.399, round:63533.152)	b=20.00	count=4000
Total loss:	29339.518 (rec:1.338, round:29338.180)	b=19.44	count=4500
Total loss:	26874.424 (rec:1.397, round:26873.027)	b=18.88	count=5000
Total loss:	25140.760 (rec:1.377, round:25139.383)	b=18.31	count=5500
Total loss:	23598.008 (rec:1.372, round:23596.637)	b=17.75	count=6000
Total loss:	22150.092 (rec:1.408, round:22148.684)	b=17.19	count=6500
Total loss:	20755.590 (rec:1.395, round:20754.195)	b=16.62	count=7000
Total loss:	19412.104 (rec:1.351, round:19410.754)	b=16.06	count=7500
Total loss:	18100.373 (rec:1.358, round:18099.016)	b=15.50	count=8000
Total loss:	16822.312 (rec:1.328, round:16820.984)	b=14.94	count=8500
Total loss:	15589.094 (rec:1.328, round:15587.766)	b=14.38	count=9000
Total loss:	14393.050 (rec:1.364, round:14391.686)	b=13.81	count=9500
Total loss:	13219.938 (rec:1.350, round:13218.589)	b=13.25	count=10000
Total loss:	12094.926 (rec:1.351, round:12093.574)	b=12.69	count=10500
Total loss:	11002.508 (rec:1.340, round:11001.168)	b=12.12	count=11000
Total loss:	9942.334 (rec:1.324, round:9941.010)	b=11.56	count=11500
Total loss:	8917.087 (rec:1.296, round:8915.791)	b=11.00	count=12000
Total loss:	7928.176 (rec:1.301, round:7926.875)	b=10.44	count=12500
Total loss:	6973.442 (rec:1.296, round:6972.146)	b=9.88	count=13000
Total loss:	6052.701 (rec:1.373, round:6051.328)	b=9.31	count=13500
Total loss:	5159.846 (rec:1.366, round:5158.480)	b=8.75	count=14000
Total loss:	4310.081 (rec:1.359, round:4308.721)	b=8.19	count=14500
Total loss:	3494.553 (rec:1.368, round:3493.185)	b=7.62	count=15000
Total loss:	2719.694 (rec:1.319, round:2718.375)	b=7.06	count=15500
Total loss:	1981.532 (rec:1.337, round:1980.195)	b=6.50	count=16000
Total loss:	1271.496 (rec:1.412, round:1270.083)	b=5.94	count=16500
Total loss:	631.208 (rec:1.322, round:629.886)	b=5.38	count=17000
Total loss:	237.210 (rec:1.296, round:235.914)	b=4.81	count=17500
Total loss:	68.683 (rec:1.318, round:67.364)	b=4.25	count=18000
Total loss:	14.417 (rec:1.324, round:13.093)	b=3.69	count=18500
Total loss:	2.773 (rec:1.367, round:1.406)	b=3.12	count=19000
Total loss:	1.401 (rec:1.344, round:0.057)	b=2.56	count=19500
Total loss:	1.339 (rec:1.339, round:0.000)	b=2.00	count=20000
finished reconstructing blocks.2.
reconstructing blocks.3 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.3 ...
wraping quantizers in blocks.3 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.518 (rec:1.518, round:0.000)	b=0.00	count=500
Total loss:	1.467 (rec:1.467, round:0.000)	b=0.00	count=1000
Total loss:	1.398 (rec:1.398, round:0.000)	b=0.00	count=1500
Total loss:	1.411 (rec:1.411, round:0.000)	b=0.00	count=2000
Total loss:	1.363 (rec:1.363, round:0.000)	b=0.00	count=2500
Total loss:	1.363 (rec:1.363, round:0.000)	b=0.00	count=3000
Total loss:	1.340 (rec:1.340, round:0.000)	b=0.00	count=3500
Total loss:	64140.234 (rec:1.303, round:64138.930)	b=20.00	count=4000
Total loss:	30093.836 (rec:1.323, round:30092.512)	b=19.44	count=4500
Total loss:	27650.012 (rec:1.313, round:27648.699)	b=18.88	count=5000
Total loss:	25966.230 (rec:1.297, round:25964.934)	b=18.31	count=5500
Total loss:	24475.359 (rec:1.260, round:24474.100)	b=17.75	count=6000
Total loss:	23063.430 (rec:1.254, round:23062.176)	b=17.19	count=6500
Total loss:	21702.883 (rec:1.265, round:21701.617)	b=16.62	count=7000
Total loss:	20378.535 (rec:1.289, round:20377.246)	b=16.06	count=7500
Total loss:	19086.619 (rec:1.272, round:19085.348)	b=15.50	count=8000
Total loss:	17816.037 (rec:1.278, round:17814.758)	b=14.94	count=8500
Total loss:	16568.469 (rec:1.299, round:16567.170)	b=14.38	count=9000
Total loss:	15349.463 (rec:1.287, round:15348.176)	b=13.81	count=9500
Total loss:	14158.529 (rec:1.306, round:14157.224)	b=13.25	count=10000
Total loss:	13000.966 (rec:1.288, round:12999.678)	b=12.69	count=10500
Total loss:	11866.446 (rec:1.227, round:11865.219)	b=12.12	count=11000
Total loss:	10763.484 (rec:1.247, round:10762.237)	b=11.56	count=11500
Total loss:	9689.014 (rec:1.262, round:9687.752)	b=11.00	count=12000
Total loss:	8644.189 (rec:1.303, round:8642.887)	b=10.44	count=12500
Total loss:	7628.444 (rec:1.250, round:7627.194)	b=9.88	count=13000
Total loss:	6649.975 (rec:1.278, round:6648.697)	b=9.31	count=13500
Total loss:	5705.667 (rec:1.218, round:5704.450)	b=8.75	count=14000
Total loss:	4791.528 (rec:1.269, round:4790.259)	b=8.19	count=14500
Total loss:	3911.510 (rec:1.277, round:3910.233)	b=7.62	count=15000
Total loss:	3069.854 (rec:1.214, round:3068.640)	b=7.06	count=15500
Total loss:	2264.977 (rec:1.263, round:2263.714)	b=6.50	count=16000
Total loss:	1495.835 (rec:1.259, round:1494.575)	b=5.94	count=16500
Total loss:	814.250 (rec:1.258, round:812.993)	b=5.38	count=17000
Total loss:	354.740 (rec:1.254, round:353.486)	b=4.81	count=17500
Total loss:	121.234 (rec:1.239, round:119.995)	b=4.25	count=18000
Total loss:	22.753 (rec:1.272, round:21.481)	b=3.69	count=18500
Total loss:	2.704 (rec:1.272, round:1.432)	b=3.12	count=19000
Total loss:	1.339 (rec:1.266, round:0.073)	b=2.56	count=19500
Total loss:	1.258 (rec:1.255, round:0.002)	b=2.00	count=20000
finished reconstructing blocks.3.
reconstructing blocks.4 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.4 ...
wraping quantizers in blocks.4 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.569 (rec:1.569, round:0.000)	b=0.00	count=500
Total loss:	1.376 (rec:1.376, round:0.000)	b=0.00	count=1000
Total loss:	1.427 (rec:1.427, round:0.000)	b=0.00	count=1500
Total loss:	1.319 (rec:1.319, round:0.000)	b=0.00	count=2000
Total loss:	1.315 (rec:1.315, round:0.000)	b=0.00	count=2500
Total loss:	1.279 (rec:1.279, round:0.000)	b=0.00	count=3000
Total loss:	1.264 (rec:1.264, round:0.000)	b=0.00	count=3500
Total loss:	63715.770 (rec:1.230, round:63714.539)	b=20.00	count=4000
Total loss:	29417.484 (rec:1.266, round:29416.219)	b=19.44	count=4500
Total loss:	26996.562 (rec:1.210, round:26995.354)	b=18.88	count=5000
Total loss:	25309.650 (rec:1.240, round:25308.410)	b=18.31	count=5500
Total loss:	23803.971 (rec:1.268, round:23802.703)	b=17.75	count=6000
Total loss:	22389.893 (rec:1.166, round:22388.727)	b=17.19	count=6500
Total loss:	21023.879 (rec:1.258, round:21022.621)	b=16.62	count=7000
Total loss:	19692.332 (rec:1.200, round:19691.131)	b=16.06	count=7500
Total loss:	18391.895 (rec:1.237, round:18390.656)	b=15.50	count=8000
Total loss:	17120.543 (rec:1.182, round:17119.361)	b=14.94	count=8500
Total loss:	15885.372 (rec:1.230, round:15884.143)	b=14.38	count=9000
Total loss:	14681.676 (rec:1.173, round:14680.502)	b=13.81	count=9500
Total loss:	13508.340 (rec:1.215, round:13507.125)	b=13.25	count=10000
Total loss:	12363.836 (rec:1.170, round:12362.666)	b=12.69	count=10500
Total loss:	11257.204 (rec:1.184, round:11256.020)	b=12.12	count=11000
Total loss:	10188.827 (rec:1.212, round:10187.615)	b=11.56	count=11500
Total loss:	9146.496 (rec:1.198, round:9145.298)	b=11.00	count=12000
Total loss:	8143.649 (rec:1.160, round:8142.489)	b=10.44	count=12500
Total loss:	7176.261 (rec:1.178, round:7175.083)	b=9.88	count=13000
Total loss:	6243.449 (rec:1.188, round:6242.261)	b=9.31	count=13500
Total loss:	5342.503 (rec:1.204, round:5341.300)	b=8.75	count=14000
Total loss:	4474.615 (rec:1.159, round:4473.456)	b=8.19	count=14500
Total loss:	3641.807 (rec:1.182, round:3640.625)	b=7.62	count=15000
Total loss:	2844.897 (rec:1.169, round:2843.728)	b=7.06	count=15500
Total loss:	2092.627 (rec:1.176, round:2091.450)	b=6.50	count=16000
Total loss:	1383.474 (rec:1.223, round:1382.251)	b=5.94	count=16500
Total loss:	779.244 (rec:1.184, round:778.060)	b=5.38	count=17000
Total loss:	368.119 (rec:1.195, round:366.924)	b=4.81	count=17500
Total loss:	142.517 (rec:1.248, round:141.270)	b=4.25	count=18000
Total loss:	38.098 (rec:1.251, round:36.847)	b=3.69	count=18500
Total loss:	5.968 (rec:1.255, round:4.713)	b=3.12	count=19000
Total loss:	1.420 (rec:1.195, round:0.224)	b=2.56	count=19500
Total loss:	1.162 (rec:1.156, round:0.006)	b=2.00	count=20000
finished reconstructing blocks.4.
reconstructing blocks.5 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.5 ...
wraping quantizers in blocks.5 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.530 (rec:1.530, round:0.000)	b=0.00	count=500
Total loss:	1.472 (rec:1.472, round:0.000)	b=0.00	count=1000
Total loss:	1.399 (rec:1.399, round:0.000)	b=0.00	count=1500
Total loss:	1.332 (rec:1.332, round:0.000)	b=0.00	count=2000
Total loss:	1.258 (rec:1.258, round:0.000)	b=0.00	count=2500
Total loss:	1.342 (rec:1.342, round:0.000)	b=0.00	count=3000
Total loss:	1.267 (rec:1.267, round:0.000)	b=0.00	count=3500
Total loss:	63458.984 (rec:1.291, round:63457.695)	b=20.00	count=4000
Total loss:	28761.074 (rec:1.276, round:28759.797)	b=19.44	count=4500
Total loss:	26320.344 (rec:1.201, round:26319.143)	b=18.88	count=5000
Total loss:	24584.168 (rec:1.188, round:24582.980)	b=18.31	count=5500
Total loss:	23027.752 (rec:1.159, round:23026.594)	b=17.75	count=6000
Total loss:	21549.270 (rec:1.238, round:21548.031)	b=17.19	count=6500
Total loss:	20125.012 (rec:1.181, round:20123.830)	b=16.62	count=7000
Total loss:	18741.670 (rec:1.127, round:18740.543)	b=16.06	count=7500
Total loss:	17391.496 (rec:1.223, round:17390.273)	b=15.50	count=8000
Total loss:	16090.532 (rec:1.118, round:16089.414)	b=14.94	count=8500
Total loss:	14831.845 (rec:1.206, round:14830.639)	b=14.38	count=9000
Total loss:	13616.613 (rec:1.211, round:13615.402)	b=13.81	count=9500
Total loss:	12448.359 (rec:1.245, round:12447.114)	b=13.25	count=10000
Total loss:	11319.721 (rec:1.189, round:11318.532)	b=12.69	count=10500
Total loss:	10237.072 (rec:1.057, round:10236.016)	b=12.12	count=11000
Total loss:	9203.776 (rec:1.128, round:9202.648)	b=11.56	count=11500
Total loss:	8213.869 (rec:1.326, round:8212.544)	b=11.00	count=12000
Total loss:	7273.341 (rec:1.198, round:7272.144)	b=10.44	count=12500
Total loss:	6373.177 (rec:1.166, round:6372.011)	b=9.88	count=13000
Total loss:	5506.000 (rec:1.121, round:5504.878)	b=9.31	count=13500
Total loss:	4684.371 (rec:1.144, round:4683.227)	b=8.75	count=14000
Total loss:	3906.085 (rec:1.179, round:3904.906)	b=8.19	count=14500
Total loss:	3165.149 (rec:1.189, round:3163.959)	b=7.62	count=15000
Total loss:	2464.171 (rec:1.116, round:2463.056)	b=7.06	count=15500
Total loss:	1806.884 (rec:1.136, round:1805.748)	b=6.50	count=16000
Total loss:	1201.726 (rec:1.210, round:1200.516)	b=5.94	count=16500
Total loss:	692.513 (rec:1.095, round:691.418)	b=5.38	count=17000
Total loss:	337.546 (rec:1.150, round:336.396)	b=4.81	count=17500
Total loss:	131.918 (rec:1.088, round:130.830)	b=4.25	count=18000
Total loss:	35.261 (rec:1.155, round:34.106)	b=3.69	count=18500
Total loss:	5.620 (rec:1.130, round:4.489)	b=3.12	count=19000
Total loss:	1.289 (rec:1.087, round:0.202)	b=2.56	count=19500
Total loss:	1.145 (rec:1.133, round:0.012)	b=2.00	count=20000
finished reconstructing blocks.5.
reconstructing blocks.6 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.6 ...
wraping quantizers in blocks.6 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.958 (rec:1.958, round:0.000)	b=0.00	count=500
Total loss:	1.919 (rec:1.919, round:0.000)	b=0.00	count=1000
Total loss:	1.879 (rec:1.879, round:0.000)	b=0.00	count=1500
Total loss:	1.795 (rec:1.795, round:0.000)	b=0.00	count=2000
Total loss:	1.676 (rec:1.676, round:0.000)	b=0.00	count=2500
Total loss:	1.847 (rec:1.847, round:0.000)	b=0.00	count=3000
Total loss:	1.707 (rec:1.707, round:0.000)	b=0.00	count=3500
Total loss:	62398.957 (rec:1.759, round:62397.199)	b=20.00	count=4000
Total loss:	27443.244 (rec:1.521, round:27441.723)	b=19.44	count=4500
Total loss:	24903.176 (rec:1.506, round:24901.670)	b=18.88	count=5000
Total loss:	23025.639 (rec:1.631, round:23024.008)	b=18.31	count=5500
Total loss:	21331.035 (rec:1.360, round:21329.676)	b=17.75	count=6000
Total loss:	19735.021 (rec:1.382, round:19733.641)	b=17.19	count=6500
Total loss:	18202.016 (rec:1.536, round:18200.480)	b=16.62	count=7000
Total loss:	16732.225 (rec:1.360, round:16730.865)	b=16.06	count=7500
Total loss:	15329.278 (rec:1.549, round:15327.729)	b=15.50	count=8000
Total loss:	13993.365 (rec:1.614, round:13991.751)	b=14.94	count=8500
Total loss:	12731.455 (rec:1.643, round:12729.812)	b=14.38	count=9000
Total loss:	11543.131 (rec:1.641, round:11541.490)	b=13.81	count=9500
Total loss:	10426.994 (rec:1.499, round:10425.495)	b=13.25	count=10000
Total loss:	9386.234 (rec:1.496, round:9384.738)	b=12.69	count=10500
Total loss:	8401.689 (rec:1.541, round:8400.148)	b=12.12	count=11000
Total loss:	7480.314 (rec:1.538, round:7478.776)	b=11.56	count=11500
Total loss:	6614.306 (rec:1.502, round:6612.804)	b=11.00	count=12000
Total loss:	5806.294 (rec:1.452, round:5804.843)	b=10.44	count=12500
Total loss:	5044.390 (rec:1.610, round:5042.780)	b=9.88	count=13000
Total loss:	4324.756 (rec:1.535, round:4323.222)	b=9.31	count=13500
Total loss:	3650.781 (rec:1.466, round:3649.315)	b=8.75	count=14000
Total loss:	3020.892 (rec:1.525, round:3019.366)	b=8.19	count=14500
Total loss:	2433.505 (rec:1.582, round:2431.923)	b=7.62	count=15000
Total loss:	1882.792 (rec:1.335, round:1881.456)	b=7.06	count=15500
Total loss:	1375.281 (rec:1.492, round:1373.788)	b=6.50	count=16000
Total loss:	920.258 (rec:1.606, round:918.653)	b=5.94	count=16500
Total loss:	534.942 (rec:1.492, round:533.449)	b=5.38	count=17000
Total loss:	253.979 (rec:1.544, round:252.436)	b=4.81	count=17500
Total loss:	92.940 (rec:1.651, round:91.289)	b=4.25	count=18000
Total loss:	22.348 (rec:1.361, round:20.987)	b=3.69	count=18500
Total loss:	3.936 (rec:1.463, round:2.473)	b=3.12	count=19000
Total loss:	1.778 (rec:1.608, round:0.170)	b=2.56	count=19500
Total loss:	1.735 (rec:1.714, round:0.020)	b=2.00	count=20000
finished reconstructing blocks.6.
reconstructing blocks.7 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.7 ...
wraping quantizers in blocks.7 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.793 (rec:1.793, round:0.000)	b=0.00	count=500
Total loss:	1.815 (rec:1.815, round:0.000)	b=0.00	count=1000
Total loss:	1.612 (rec:1.612, round:0.000)	b=0.00	count=1500
Total loss:	1.509 (rec:1.509, round:0.000)	b=0.00	count=2000
Total loss:	1.630 (rec:1.630, round:0.000)	b=0.00	count=2500
Total loss:	1.600 (rec:1.600, round:0.000)	b=0.00	count=3000
Total loss:	1.627 (rec:1.627, round:0.000)	b=0.00	count=3500
Total loss:	64220.965 (rec:1.778, round:64219.188)	b=20.00	count=4000
Total loss:	28685.902 (rec:1.750, round:28684.152)	b=19.44	count=4500
Total loss:	26270.293 (rec:1.522, round:26268.771)	b=18.88	count=5000
Total loss:	24561.836 (rec:1.580, round:24560.256)	b=18.31	count=5500
Total loss:	23031.129 (rec:1.632, round:23029.496)	b=17.75	count=6000
Total loss:	21581.090 (rec:1.665, round:21579.424)	b=17.19	count=6500
Total loss:	20177.719 (rec:1.512, round:20176.207)	b=16.62	count=7000
Total loss:	18806.012 (rec:1.511, round:18804.500)	b=16.06	count=7500
Total loss:	17468.311 (rec:1.673, round:17466.637)	b=15.50	count=8000
Total loss:	16161.508 (rec:1.557, round:16159.951)	b=14.94	count=8500
Total loss:	14895.699 (rec:1.492, round:14894.207)	b=14.38	count=9000
Total loss:	13661.839 (rec:1.558, round:13660.281)	b=13.81	count=9500
Total loss:	12473.272 (rec:1.515, round:12471.758)	b=13.25	count=10000
Total loss:	11321.714 (rec:1.605, round:11320.109)	b=12.69	count=10500
Total loss:	10214.890 (rec:1.497, round:10213.393)	b=12.12	count=11000
Total loss:	9162.138 (rec:1.599, round:9160.539)	b=11.56	count=11500
Total loss:	8151.759 (rec:1.555, round:8150.204)	b=11.00	count=12000
Total loss:	7191.848 (rec:1.655, round:7190.193)	b=10.44	count=12500
Total loss:	6279.693 (rec:1.655, round:6278.039)	b=9.88	count=13000
Total loss:	5408.831 (rec:1.543, round:5407.289)	b=9.31	count=13500
Total loss:	4577.393 (rec:1.616, round:4575.777)	b=8.75	count=14000
Total loss:	3793.903 (rec:1.552, round:3792.351)	b=8.19	count=14500
Total loss:	3058.906 (rec:1.826, round:3057.080)	b=7.62	count=15000
Total loss:	2371.609 (rec:1.408, round:2370.200)	b=7.06	count=15500
Total loss:	1742.094 (rec:1.468, round:1740.625)	b=6.50	count=16000
Total loss:	1170.709 (rec:1.415, round:1169.294)	b=5.94	count=16500
Total loss:	691.332 (rec:1.483, round:689.849)	b=5.38	count=17000
Total loss:	327.532 (rec:1.452, round:326.080)	b=4.81	count=17500
Total loss:	109.521 (rec:1.459, round:108.062)	b=4.25	count=18000
Total loss:	19.973 (rec:1.440, round:18.533)	b=3.69	count=18500
Total loss:	2.921 (rec:1.517, round:1.404)	b=3.12	count=19000
Total loss:	1.664 (rec:1.595, round:0.069)	b=2.56	count=19500
Total loss:	1.718 (rec:1.716, round:0.002)	b=2.00	count=20000
finished reconstructing blocks.7.
reconstructing blocks.8 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.8 ...
wraping quantizers in blocks.8 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	2.121 (rec:2.121, round:0.000)	b=0.00	count=500
Total loss:	2.023 (rec:2.023, round:0.000)	b=0.00	count=1000
Total loss:	2.040 (rec:2.040, round:0.000)	b=0.00	count=1500
Total loss:	1.958 (rec:1.958, round:0.000)	b=0.00	count=2000
Total loss:	2.008 (rec:2.008, round:0.000)	b=0.00	count=2500
Total loss:	2.014 (rec:2.014, round:0.000)	b=0.00	count=3000
Total loss:	1.994 (rec:1.994, round:0.000)	b=0.00	count=3500
Total loss:	65022.996 (rec:1.987, round:65021.008)	b=20.00	count=4000
Total loss:	30223.074 (rec:1.946, round:30221.129)	b=19.44	count=4500
Total loss:	27817.305 (rec:1.907, round:27815.398)	b=18.88	count=5000
Total loss:	26157.451 (rec:1.841, round:26155.609)	b=18.31	count=5500
Total loss:	24669.709 (rec:1.882, round:24667.826)	b=17.75	count=6000
Total loss:	23262.111 (rec:1.893, round:23260.219)	b=17.19	count=6500
Total loss:	21898.898 (rec:1.899, round:21897.000)	b=16.62	count=7000
Total loss:	20559.133 (rec:1.919, round:20557.215)	b=16.06	count=7500
Total loss:	19248.420 (rec:1.820, round:19246.600)	b=15.50	count=8000
Total loss:	17947.801 (rec:1.955, round:17945.846)	b=14.94	count=8500
Total loss:	16673.764 (rec:1.845, round:16671.918)	b=14.38	count=9000
Total loss:	15416.759 (rec:2.109, round:15414.650)	b=13.81	count=9500
Total loss:	14188.664 (rec:1.777, round:14186.887)	b=13.25	count=10000
Total loss:	12992.625 (rec:1.924, round:12990.701)	b=12.69	count=10500
Total loss:	11818.972 (rec:1.798, round:11817.174)	b=12.12	count=11000
Total loss:	10672.585 (rec:1.905, round:10670.680)	b=11.56	count=11500
Total loss:	9565.024 (rec:1.866, round:9563.158)	b=11.00	count=12000
Total loss:	8507.743 (rec:1.884, round:8505.859)	b=10.44	count=12500
Total loss:	7485.740 (rec:1.865, round:7483.875)	b=9.88	count=13000
Total loss:	6498.365 (rec:1.653, round:6496.711)	b=9.31	count=13500
Total loss:	5546.239 (rec:1.992, round:5544.247)	b=8.75	count=14000
Total loss:	4641.240 (rec:1.899, round:4639.341)	b=8.19	count=14500
Total loss:	3784.299 (rec:1.987, round:3782.312)	b=7.62	count=15000
Total loss:	2974.389 (rec:2.009, round:2972.380)	b=7.06	count=15500
Total loss:	2236.047 (rec:1.984, round:2234.063)	b=6.50	count=16000
Total loss:	1558.611 (rec:1.952, round:1556.659)	b=5.94	count=16500
Total loss:	974.563 (rec:2.000, round:972.564)	b=5.38	count=17000
Total loss:	509.711 (rec:2.018, round:507.693)	b=4.81	count=17500
Total loss:	192.383 (rec:1.787, round:190.596)	b=4.25	count=18000
Total loss:	39.947 (rec:1.796, round:38.151)	b=3.69	count=18500
Total loss:	4.319 (rec:1.775, round:2.545)	b=3.12	count=19000
Total loss:	2.049 (rec:1.989, round:0.059)	b=2.56	count=19500
Total loss:	1.870 (rec:1.869, round:0.000)	b=2.00	count=20000
finished reconstructing blocks.8.
reconstructing blocks.9 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.9 ...
wraping quantizers in blocks.9 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.749 (rec:1.749, round:0.000)	b=0.00	count=500
Total loss:	1.863 (rec:1.863, round:0.000)	b=0.00	count=1000
Total loss:	1.755 (rec:1.755, round:0.000)	b=0.00	count=1500
Total loss:	1.782 (rec:1.782, round:0.000)	b=0.00	count=2000
Total loss:	1.680 (rec:1.680, round:0.000)	b=0.00	count=2500
Total loss:	1.865 (rec:1.865, round:0.000)	b=0.00	count=3000
Total loss:	1.804 (rec:1.804, round:0.000)	b=0.00	count=3500
Total loss:	65574.789 (rec:1.848, round:65572.938)	b=20.00	count=4000
Total loss:	30781.941 (rec:1.802, round:30780.139)	b=19.44	count=4500
Total loss:	28412.010 (rec:1.838, round:28410.172)	b=18.88	count=5000
Total loss:	26822.834 (rec:1.765, round:26821.068)	b=18.31	count=5500
Total loss:	25425.023 (rec:1.637, round:25423.387)	b=17.75	count=6000
Total loss:	24095.330 (rec:1.705, round:24093.625)	b=17.19	count=6500
Total loss:	22803.533 (rec:1.713, round:22801.820)	b=16.62	count=7000
Total loss:	21529.180 (rec:1.805, round:21527.375)	b=16.06	count=7500
Total loss:	20262.469 (rec:1.734, round:20260.734)	b=15.50	count=8000
Total loss:	19009.494 (rec:1.827, round:19007.668)	b=14.94	count=8500
Total loss:	17766.873 (rec:1.811, round:17765.062)	b=14.38	count=9000
Total loss:	16529.107 (rec:1.736, round:16527.371)	b=13.81	count=9500
Total loss:	15301.771 (rec:1.615, round:15300.156)	b=13.25	count=10000
Total loss:	14098.819 (rec:1.857, round:14096.962)	b=12.69	count=10500
Total loss:	12900.380 (rec:1.815, round:12898.564)	b=12.12	count=11000
Total loss:	11723.305 (rec:1.793, round:11721.512)	b=11.56	count=11500
Total loss:	10570.465 (rec:1.648, round:10568.816)	b=11.00	count=12000
Total loss:	9442.054 (rec:1.760, round:9440.294)	b=10.44	count=12500
Total loss:	8349.025 (rec:1.693, round:8347.332)	b=9.88	count=13000
Total loss:	7283.256 (rec:1.700, round:7281.556)	b=9.31	count=13500
Total loss:	6255.795 (rec:1.770, round:6254.025)	b=8.75	count=14000
Total loss:	5265.187 (rec:1.752, round:5263.435)	b=8.19	count=14500
Total loss:	4313.707 (rec:1.703, round:4312.003)	b=7.62	count=15000
Total loss:	3419.086 (rec:1.670, round:3417.416)	b=7.06	count=15500
Total loss:	2585.101 (rec:1.697, round:2583.404)	b=6.50	count=16000
Total loss:	1828.969 (rec:1.689, round:1827.279)	b=5.94	count=16500
Total loss:	1166.578 (rec:1.762, round:1164.816)	b=5.38	count=17000
Total loss:	625.770 (rec:1.861, round:623.909)	b=4.81	count=17500
Total loss:	246.249 (rec:1.771, round:244.477)	b=4.25	count=18000
Total loss:	54.336 (rec:1.710, round:52.626)	b=3.69	count=18500
Total loss:	5.820 (rec:1.787, round:4.033)	b=3.12	count=19000
Total loss:	1.802 (rec:1.699, round:0.102)	b=2.56	count=19500
Total loss:	1.637 (rec:1.635, round:0.003)	b=2.00	count=20000
finished reconstructing blocks.9.
reconstructing blocks.10 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.10 ...
wraping quantizers in blocks.10 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.784 (rec:1.784, round:0.000)	b=0.00	count=500
Total loss:	1.772 (rec:1.772, round:0.000)	b=0.00	count=1000
Total loss:	1.670 (rec:1.670, round:0.000)	b=0.00	count=1500
Total loss:	1.595 (rec:1.595, round:0.000)	b=0.00	count=2000
Total loss:	1.635 (rec:1.635, round:0.000)	b=0.00	count=2500
Total loss:	1.546 (rec:1.546, round:0.000)	b=0.00	count=3000
Total loss:	1.793 (rec:1.793, round:0.000)	b=0.00	count=3500
Total loss:	65870.875 (rec:1.720, round:65869.156)	b=20.00	count=4000
Total loss:	31596.268 (rec:1.660, round:31594.607)	b=19.44	count=4500
Total loss:	29242.844 (rec:1.649, round:29241.195)	b=18.88	count=5000
Total loss:	27698.219 (rec:1.552, round:27696.666)	b=18.31	count=5500
Total loss:	26360.447 (rec:1.479, round:26358.969)	b=17.75	count=6000
Total loss:	25100.084 (rec:1.572, round:25098.512)	b=17.19	count=6500
Total loss:	23871.023 (rec:1.586, round:23869.438)	b=16.62	count=7000
Total loss:	22666.258 (rec:1.547, round:22664.711)	b=16.06	count=7500
Total loss:	21466.873 (rec:1.611, round:21465.262)	b=15.50	count=8000
Total loss:	20266.389 (rec:1.543, round:20264.846)	b=14.94	count=8500
Total loss:	19063.338 (rec:1.546, round:19061.793)	b=14.38	count=9000
Total loss:	17857.344 (rec:1.485, round:17855.859)	b=13.81	count=9500
Total loss:	16659.389 (rec:1.654, round:16657.734)	b=13.25	count=10000
Total loss:	15458.966 (rec:1.530, round:15457.436)	b=12.69	count=10500
Total loss:	14261.227 (rec:1.711, round:14259.516)	b=12.12	count=11000
Total loss:	13063.411 (rec:1.366, round:13062.045)	b=11.56	count=11500
Total loss:	11879.233 (rec:1.482, round:11877.752)	b=11.00	count=12000
Total loss:	10707.117 (rec:1.561, round:10705.557)	b=10.44	count=12500
Total loss:	9547.983 (rec:1.522, round:9546.461)	b=9.88	count=13000
Total loss:	8402.243 (rec:1.490, round:8400.753)	b=9.31	count=13500
Total loss:	7287.864 (rec:1.593, round:7286.271)	b=8.75	count=14000
Total loss:	6201.448 (rec:1.570, round:6199.878)	b=8.19	count=14500
Total loss:	5149.525 (rec:1.493, round:5148.033)	b=7.62	count=15000
Total loss:	4142.183 (rec:1.517, round:4140.666)	b=7.06	count=15500
Total loss:	3192.168 (rec:1.484, round:3190.684)	b=6.50	count=16000
Total loss:	2314.048 (rec:1.443, round:2312.605)	b=5.94	count=16500
Total loss:	1529.262 (rec:1.637, round:1527.625)	b=5.38	count=17000
Total loss:	865.552 (rec:1.498, round:864.055)	b=4.81	count=17500
Total loss:	370.383 (rec:1.513, round:368.870)	b=4.25	count=18000
Total loss:	95.233 (rec:1.571, round:93.662)	b=3.69	count=18500
Total loss:	10.401 (rec:1.568, round:8.833)	b=3.12	count=19000
Total loss:	1.768 (rec:1.529, round:0.239)	b=2.56	count=19500
Total loss:	1.625 (rec:1.624, round:0.001)	b=2.00	count=20000
finished reconstructing blocks.10.
reconstructing blocks.11 ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for blocks.11 ...
wraping quantizers in blocks.11 ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	1.639 (rec:1.639, round:0.000)	b=0.00	count=500
Total loss:	1.532 (rec:1.532, round:0.000)	b=0.00	count=1000
Total loss:	1.747 (rec:1.747, round:0.000)	b=0.00	count=1500
Total loss:	1.567 (rec:1.567, round:0.000)	b=0.00	count=2000
Total loss:	1.441 (rec:1.441, round:0.000)	b=0.00	count=2500
Total loss:	1.456 (rec:1.456, round:0.000)	b=0.00	count=3000
Total loss:	1.601 (rec:1.601, round:0.000)	b=0.00	count=3500
Total loss:	65164.520 (rec:1.514, round:65163.008)	b=20.00	count=4000
Total loss:	30352.527 (rec:1.528, round:30351.000)	b=19.44	count=4500
Total loss:	27924.600 (rec:1.513, round:27923.086)	b=18.88	count=5000
Total loss:	26241.570 (rec:1.488, round:26240.082)	b=18.31	count=5500
Total loss:	24750.328 (rec:1.494, round:24748.834)	b=17.75	count=6000
Total loss:	23337.143 (rec:1.607, round:23335.535)	b=17.19	count=6500
Total loss:	21960.119 (rec:1.479, round:21958.641)	b=16.62	count=7000
Total loss:	20613.846 (rec:1.383, round:20612.463)	b=16.06	count=7500
Total loss:	19291.217 (rec:1.486, round:19289.730)	b=15.50	count=8000
Total loss:	17993.762 (rec:1.490, round:17992.271)	b=14.94	count=8500
Total loss:	16719.660 (rec:1.507, round:16718.152)	b=14.38	count=9000
Total loss:	15469.399 (rec:1.448, round:15467.951)	b=13.81	count=9500
Total loss:	14236.118 (rec:1.483, round:14234.636)	b=13.25	count=10000
Total loss:	13029.248 (rec:1.489, round:13027.759)	b=12.69	count=10500
Total loss:	11861.723 (rec:1.386, round:11860.337)	b=12.12	count=11000
Total loss:	10729.724 (rec:1.427, round:10728.297)	b=11.56	count=11500
Total loss:	9633.269 (rec:1.592, round:9631.677)	b=11.00	count=12000
Total loss:	8568.062 (rec:1.398, round:8566.664)	b=10.44	count=12500
Total loss:	7537.814 (rec:1.451, round:7536.363)	b=9.88	count=13000
Total loss:	6549.863 (rec:1.452, round:6548.411)	b=9.31	count=13500
Total loss:	5603.090 (rec:1.433, round:5601.657)	b=8.75	count=14000
Total loss:	4690.425 (rec:1.579, round:4688.846)	b=8.19	count=14500
Total loss:	3825.555 (rec:1.647, round:3823.908)	b=7.62	count=15000
Total loss:	3014.799 (rec:1.456, round:3013.343)	b=7.06	count=15500
Total loss:	2258.219 (rec:1.454, round:2256.765)	b=6.50	count=16000
Total loss:	1561.286 (rec:1.504, round:1559.781)	b=5.94	count=16500
Total loss:	939.569 (rec:1.487, round:938.081)	b=5.38	count=17000
Total loss:	445.911 (rec:1.417, round:444.494)	b=4.81	count=17500
Total loss:	148.217 (rec:1.663, round:146.554)	b=4.25	count=18000
Total loss:	28.742 (rec:1.545, round:27.197)	b=3.69	count=18500
Total loss:	3.174 (rec:1.464, round:1.710)	b=3.12	count=19000
Total loss:	1.561 (rec:1.506, round:0.054)	b=2.56	count=19500
Total loss:	1.497 (rec:1.496, round:0.001)	b=2.00	count=20000
finished reconstructing blocks.11.
reconstructing head ...
initializing raw input and raw output ...
initializing quanted input ...
adaround training for head ...
wraping quantizers in head ...
Total loss:	2.000 (rec:2.000, round:0.000)	b=0.00	count=1
Total loss:	2.045 (rec:2.045, round:0.000)	b=0.00	count=500
Total loss:	2.382 (rec:2.382, round:0.000)	b=0.00	count=1000
Total loss:	1.446 (rec:1.446, round:0.000)	b=0.00	count=1500
Total loss:	1.487 (rec:1.487, round:0.000)	b=0.00	count=2000
Total loss:	0.873 (rec:0.873, round:0.000)	b=0.00	count=2500
Total loss:	1.503 (rec:1.503, round:0.000)	b=0.00	count=3000
Total loss:	1.479 (rec:1.479, round:0.000)	b=0.00	count=3500
Total loss:	7123.810 (rec:1.200, round:7122.610)	b=20.00	count=4000
Total loss:	4334.377 (rec:0.759, round:4333.618)	b=19.44	count=4500
Total loss:	4056.274 (rec:1.105, round:4055.169)	b=18.88	count=5000
Total loss:	3882.523 (rec:1.095, round:3881.429)	b=18.31	count=5500
Total loss:	3740.945 (rec:1.210, round:3739.736)	b=17.75	count=6000
Total loss:	3615.291 (rec:1.203, round:3614.088)	b=17.19	count=6500
Total loss:	3497.238 (rec:0.925, round:3496.313)	b=16.62	count=7000
Total loss:	3381.692 (rec:0.998, round:3380.694)	b=16.06	count=7500
Total loss:	3269.534 (rec:1.134, round:3268.401)	b=15.50	count=8000
Total loss:	3157.011 (rec:0.878, round:3156.132)	b=14.94	count=8500
Total loss:	3043.546 (rec:1.492, round:3042.054)	b=14.38	count=9000
Total loss:	2927.895 (rec:0.726, round:2927.169)	b=13.81	count=9500
Total loss:	2814.229 (rec:0.922, round:2813.307)	b=13.25	count=10000
Total loss:	2697.062 (rec:1.433, round:2695.629)	b=12.69	count=10500
Total loss:	2577.349 (rec:1.345, round:2576.004)	b=12.12	count=11000
Total loss:	2455.800 (rec:0.974, round:2454.826)	b=11.56	count=11500
Total loss:	2330.879 (rec:1.117, round:2329.762)	b=11.00	count=12000
Total loss:	2201.665 (rec:0.959, round:2200.707)	b=10.44	count=12500
Total loss:	2069.679 (rec:0.976, round:2068.703)	b=9.88	count=13000
Total loss:	1930.598 (rec:1.135, round:1929.462)	b=9.31	count=13500
Total loss:	1787.518 (rec:1.021, round:1786.497)	b=8.75	count=14000
Total loss:	1640.242 (rec:0.787, round:1639.455)	b=8.19	count=14500
Total loss:	1485.919 (rec:0.885, round:1485.033)	b=7.62	count=15000
Total loss:	1324.729 (rec:0.790, round:1323.939)	b=7.06	count=15500
Total loss:	1159.188 (rec:1.253, round:1157.935)	b=6.50	count=16000
Total loss:	987.365 (rec:0.734, round:986.631)	b=5.94	count=16500
Total loss:	813.220 (rec:1.080, round:812.140)	b=5.38	count=17000
Total loss:	635.990 (rec:0.774, round:635.216)	b=4.81	count=17500
Total loss:	460.737 (rec:0.980, round:459.757)	b=4.25	count=18000
Total loss:	292.886 (rec:0.984, round:291.902)	b=3.69	count=18500
Total loss:	146.755 (rec:1.046, round:145.709)	b=3.12	count=19000
Total loss:	44.707 (rec:0.919, round:43.788)	b=2.56	count=19500
Total loss:	6.649 (rec:0.984, round:5.666)	b=2.00	count=20000
finished reconstructing head.
2025-09-11 14:31:48 - mse guided block reconstruction finished.
Saving checkpoint to ./checkpoint/quant_result/20250911_1057/vit_base_w4_a4_optimsize_1024_mse_qdrop.pth
Validating on calibration set after block reconstruction ...
Test: [0/32]	Time 0.445 (0.445)	Loss 0.6000 (0.6000)	Prec@1 87.500 (87.500)	Prec@5 96.875 (96.875)
Test: [10/32]	Time 0.077 (0.110)	Loss 1.0432 (0.8170)	Prec@1 78.125 (82.102)	Prec@5 90.625 (95.455)
Test: [20/32]	Time 0.077 (0.140)	Loss 0.5219 (0.7533)	Prec@1 87.500 (83.929)	Prec@5 100.000 (95.982)
Test: [30/32]	Time 0.077 (0.120)	Loss 0.9275 (0.7305)	Prec@1 75.000 (84.879)	Prec@5 90.625 (95.968)
 * Prec@1 85.059 Prec@5 95.801 Loss 0.728 Time 3.894
Validating on test set after block reconstruction ...
Test: [0/100]	Time 15.862 (15.862)	Loss 0.5188 (0.5188)	Prec@1 89.800 (89.800)	Prec@5 98.000 (98.000)
Test: [10/100]	Time 1.680 (3.019)	Loss 0.6184 (0.6612)	Prec@1 88.000 (86.164)	Prec@5 97.400 (97.582)
Test: [20/100]	Time 1.676 (2.380)	Loss 0.8190 (0.7023)	Prec@1 81.400 (85.057)	Prec@5 98.000 (97.324)
Test: [30/100]	Time 1.678 (2.154)	Loss 0.6014 (0.7197)	Prec@1 86.800 (84.303)	Prec@5 99.000 (97.323)
Test: [40/100]	Time 1.682 (2.038)	Loss 0.9286 (0.7172)	Prec@1 78.200 (84.590)	Prec@5 95.200 (97.327)
Test: [50/100]	Time 1.684 (1.968)	Loss 1.2172 (0.7654)	Prec@1 74.800 (83.420)	Prec@5 90.800 (96.788)
Test: [60/100]	Time 1.683 (1.921)	Loss 0.7762 (0.7717)	Prec@1 84.600 (83.259)	Prec@5 95.200 (96.666)
Test: [70/100]	Time 1.681 (1.887)	Loss 0.8455 (0.7953)	Prec@1 82.000 (82.558)	Prec@5 96.800 (96.476)
Test: [80/100]	Time 1.678 (1.862)	Loss 0.7108 (0.8052)	Prec@1 85.400 (82.442)	Prec@5 96.000 (96.296)
Test: [90/100]	Time 1.676 (1.841)	Loss 1.2392 (0.8241)	Prec@1 71.600 (81.813)	Prec@5 92.200 (96.171)
 * Prec@1 81.966 Prec@5 96.234 Loss 0.819 Time 182.873
2025-09-11 14:34:55 - finished the process.
Extracting logits from quantized and full-precision models...
Testing combinations:
  Alpha values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  Cluster numbers: [8, 16, 32, 64, 128, 256]
  PCA dimensions: [1, 25, 50, 75, 100, 125, 150, 175, 200, 220]

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.98%
[Alpha=0.10] Top-5 Accuracy: 96.20%
Result: Top-1: 81.98%, Top-5: 96.20%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.99%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.99%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.96%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.96%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.99%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.99%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 82.00%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 82.00%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.97%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.97%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.98%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.98%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 82.00%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 82.00%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.96%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.96%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=8, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.98%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.98%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.93%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.93%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.95%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.95%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.94%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.94%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.93%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.93%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.96%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.96%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.98%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.98%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.95%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.95%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.97%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.97%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.94%
[Alpha=0.10] Top-5 Accuracy: 96.26%
Result: Top-1: 81.94%, Top-5: 96.26%

============================================================
Testing: alpha=0.1, clusters=16, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.96%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.96%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.91%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.91%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.96%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.96%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.88%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.88%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.92%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.92%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.93%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.93%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.96%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.96%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.95%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.95%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.91%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.91%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.93%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.93%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=32, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.92%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.92%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.77%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.77%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.95%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.95%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.92%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.92%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.90%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.90%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.92%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.92%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.94%
[Alpha=0.10] Top-5 Accuracy: 96.25%
Result: Top-1: 81.94%, Top-5: 96.25%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.85%
[Alpha=0.10] Top-5 Accuracy: 96.22%
Result: Top-1: 81.85%, Top-5: 96.22%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.93%
[Alpha=0.10] Top-5 Accuracy: 96.21%
Result: Top-1: 81.93%, Top-5: 96.21%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.95%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.95%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=64, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.90%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.90%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.66%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.66%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.73%
[Alpha=0.10] Top-5 Accuracy: 96.18%
Result: Top-1: 81.73%, Top-5: 96.18%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.70%
[Alpha=0.10] Top-5 Accuracy: 96.21%
Result: Top-1: 81.70%, Top-5: 96.21%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.86%
[Alpha=0.10] Top-5 Accuracy: 96.23%
Result: Top-1: 81.86%, Top-5: 96.23%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.77%
[Alpha=0.10] Top-5 Accuracy: 96.19%
Result: Top-1: 81.77%, Top-5: 96.19%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.55%
[Alpha=0.10] Top-5 Accuracy: 95.96%
Result: Top-1: 81.55%, Top-5: 95.96%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.83%
[Alpha=0.10] Top-5 Accuracy: 96.20%
Result: Top-1: 81.83%, Top-5: 96.20%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.87%
[Alpha=0.10] Top-5 Accuracy: 96.22%
Result: Top-1: 81.87%, Top-5: 96.22%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.86%
[Alpha=0.10] Top-5 Accuracy: 96.24%
Result: Top-1: 81.86%, Top-5: 96.24%

============================================================
Testing: alpha=0.1, clusters=128, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.85%
[Alpha=0.10] Top-5 Accuracy: 96.21%
Result: Top-1: 81.85%, Top-5: 96.21%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=1
============================================================
[Alpha=0.10] Top-1 Accuracy: 69.78%
[Alpha=0.10] Top-5 Accuracy: 93.32%
Result: Top-1: 69.78%, Top-5: 93.32%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=25
============================================================
[Alpha=0.10] Top-1 Accuracy: 80.59%
[Alpha=0.10] Top-5 Accuracy: 95.39%
Result: Top-1: 80.59%, Top-5: 95.39%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=50
============================================================
[Alpha=0.10] Top-1 Accuracy: 58.31%
[Alpha=0.10] Top-5 Accuracy: 93.63%
Result: Top-1: 58.31%, Top-5: 93.63%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=75
============================================================
[Alpha=0.10] Top-1 Accuracy: 78.94%
[Alpha=0.10] Top-5 Accuracy: 95.38%
Result: Top-1: 78.94%, Top-5: 95.38%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=100
============================================================
[Alpha=0.10] Top-1 Accuracy: 80.16%
[Alpha=0.10] Top-5 Accuracy: 95.44%
Result: Top-1: 80.16%, Top-5: 95.44%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=125
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.37%
[Alpha=0.10] Top-5 Accuracy: 95.99%
Result: Top-1: 81.37%, Top-5: 95.99%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=150
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.58%
[Alpha=0.10] Top-5 Accuracy: 96.12%
Result: Top-1: 81.58%, Top-5: 96.12%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=175
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.64%
[Alpha=0.10] Top-5 Accuracy: 96.13%
Result: Top-1: 81.64%, Top-5: 96.13%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=200
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.65%
[Alpha=0.10] Top-5 Accuracy: 96.13%
Result: Top-1: 81.65%, Top-5: 96.13%

============================================================
Testing: alpha=0.1, clusters=256, pca_dim=220
============================================================
[Alpha=0.10] Top-1 Accuracy: 81.58%
[Alpha=0.10] Top-5 Accuracy: 96.10%
Result: Top-1: 81.58%, Top-5: 96.10%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.90%
[Alpha=0.20] Top-5 Accuracy: 96.21%
Result: Top-1: 81.90%, Top-5: 96.21%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.87%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.87%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.85%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.85%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.91%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.91%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.92%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.92%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.88%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.88%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.91%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.91%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.90%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.90%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.89%
[Alpha=0.20] Top-5 Accuracy: 96.23%
Result: Top-1: 81.89%, Top-5: 96.23%

============================================================
Testing: alpha=0.2, clusters=8, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.90%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.90%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.78%
[Alpha=0.20] Top-5 Accuracy: 96.21%
Result: Top-1: 81.78%, Top-5: 96.21%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.87%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.87%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.87%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.87%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.86%
[Alpha=0.20] Top-5 Accuracy: 96.26%
Result: Top-1: 81.86%, Top-5: 96.26%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.92%
[Alpha=0.20] Top-5 Accuracy: 96.23%
Result: Top-1: 81.92%, Top-5: 96.23%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.92%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.92%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.91%
[Alpha=0.20] Top-5 Accuracy: 96.23%
Result: Top-1: 81.91%, Top-5: 96.23%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.88%
[Alpha=0.20] Top-5 Accuracy: 96.26%
Result: Top-1: 81.88%, Top-5: 96.26%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.89%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.89%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=16, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.89%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.89%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.71%
[Alpha=0.20] Top-5 Accuracy: 96.18%
Result: Top-1: 81.71%, Top-5: 96.18%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.84%
[Alpha=0.20] Top-5 Accuracy: 96.22%
Result: Top-1: 81.84%, Top-5: 96.22%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.84%
[Alpha=0.20] Top-5 Accuracy: 96.22%
Result: Top-1: 81.84%, Top-5: 96.22%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.83%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.83%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.84%
[Alpha=0.20] Top-5 Accuracy: 96.23%
Result: Top-1: 81.84%, Top-5: 96.23%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.93%
[Alpha=0.20] Top-5 Accuracy: 96.25%
Result: Top-1: 81.93%, Top-5: 96.25%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.86%
[Alpha=0.20] Top-5 Accuracy: 96.22%
Result: Top-1: 81.86%, Top-5: 96.22%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.83%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.83%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.82%
[Alpha=0.20] Top-5 Accuracy: 96.23%
Result: Top-1: 81.82%, Top-5: 96.23%

============================================================
Testing: alpha=0.2, clusters=32, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.84%
[Alpha=0.20] Top-5 Accuracy: 96.22%
Result: Top-1: 81.84%, Top-5: 96.22%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.35%
[Alpha=0.20] Top-5 Accuracy: 96.16%
Result: Top-1: 81.35%, Top-5: 96.16%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.72%
[Alpha=0.20] Top-5 Accuracy: 96.22%
Result: Top-1: 81.72%, Top-5: 96.22%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.81%
[Alpha=0.20] Top-5 Accuracy: 96.23%
Result: Top-1: 81.81%, Top-5: 96.23%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.81%
[Alpha=0.20] Top-5 Accuracy: 96.21%
Result: Top-1: 81.81%, Top-5: 96.21%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.79%
[Alpha=0.20] Top-5 Accuracy: 96.20%
Result: Top-1: 81.79%, Top-5: 96.20%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.71%
[Alpha=0.20] Top-5 Accuracy: 96.21%
Result: Top-1: 81.71%, Top-5: 96.21%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.71%
[Alpha=0.20] Top-5 Accuracy: 96.21%
Result: Top-1: 81.71%, Top-5: 96.21%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.79%
[Alpha=0.20] Top-5 Accuracy: 96.20%
Result: Top-1: 81.79%, Top-5: 96.20%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.81%
[Alpha=0.20] Top-5 Accuracy: 96.24%
Result: Top-1: 81.81%, Top-5: 96.24%

============================================================
Testing: alpha=0.2, clusters=64, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.71%
[Alpha=0.20] Top-5 Accuracy: 96.18%
Result: Top-1: 81.71%, Top-5: 96.18%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 80.69%
[Alpha=0.20] Top-5 Accuracy: 96.09%
Result: Top-1: 80.69%, Top-5: 96.09%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.32%
[Alpha=0.20] Top-5 Accuracy: 96.01%
Result: Top-1: 81.32%, Top-5: 96.01%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.36%
[Alpha=0.20] Top-5 Accuracy: 96.18%
Result: Top-1: 81.36%, Top-5: 96.18%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.61%
[Alpha=0.20] Top-5 Accuracy: 96.11%
Result: Top-1: 81.61%, Top-5: 96.11%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.53%
[Alpha=0.20] Top-5 Accuracy: 96.15%
Result: Top-1: 81.53%, Top-5: 96.15%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.37%
[Alpha=0.20] Top-5 Accuracy: 95.82%
Result: Top-1: 81.37%, Top-5: 95.82%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.59%
[Alpha=0.20] Top-5 Accuracy: 96.13%
Result: Top-1: 81.59%, Top-5: 96.13%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.58%
[Alpha=0.20] Top-5 Accuracy: 96.19%
Result: Top-1: 81.58%, Top-5: 96.19%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.70%
[Alpha=0.20] Top-5 Accuracy: 96.19%
Result: Top-1: 81.70%, Top-5: 96.19%

============================================================
Testing: alpha=0.2, clusters=128, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.67%
[Alpha=0.20] Top-5 Accuracy: 96.15%
Result: Top-1: 81.67%, Top-5: 96.15%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=1
============================================================
[Alpha=0.20] Top-1 Accuracy: 66.85%
[Alpha=0.20] Top-5 Accuracy: 86.80%
Result: Top-1: 66.85%, Top-5: 86.80%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=25
============================================================
[Alpha=0.20] Top-1 Accuracy: 79.42%
[Alpha=0.20] Top-5 Accuracy: 94.68%
Result: Top-1: 79.42%, Top-5: 94.68%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=50
============================================================
[Alpha=0.20] Top-1 Accuracy: 54.86%
[Alpha=0.20] Top-5 Accuracy: 88.42%
Result: Top-1: 54.86%, Top-5: 88.42%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=75
============================================================
[Alpha=0.20] Top-1 Accuracy: 75.78%
[Alpha=0.20] Top-5 Accuracy: 93.46%
Result: Top-1: 75.78%, Top-5: 93.46%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=100
============================================================
[Alpha=0.20] Top-1 Accuracy: 79.79%
[Alpha=0.20] Top-5 Accuracy: 94.21%
Result: Top-1: 79.79%, Top-5: 94.21%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=125
============================================================
[Alpha=0.20] Top-1 Accuracy: 80.77%
[Alpha=0.20] Top-5 Accuracy: 95.64%
Result: Top-1: 80.77%, Top-5: 95.64%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=150
============================================================
[Alpha=0.20] Top-1 Accuracy: 80.84%
[Alpha=0.20] Top-5 Accuracy: 95.83%
Result: Top-1: 80.84%, Top-5: 95.83%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=175
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.13%
[Alpha=0.20] Top-5 Accuracy: 95.92%
Result: Top-1: 81.13%, Top-5: 95.92%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=200
============================================================
[Alpha=0.20] Top-1 Accuracy: 81.13%
[Alpha=0.20] Top-5 Accuracy: 95.98%
Result: Top-1: 81.13%, Top-5: 95.98%

============================================================
Testing: alpha=0.2, clusters=256, pca_dim=220
============================================================
[Alpha=0.20] Top-1 Accuracy: 80.69%
[Alpha=0.20] Top-5 Accuracy: 95.79%
Result: Top-1: 80.69%, Top-5: 95.79%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.77%
[Alpha=0.30] Top-5 Accuracy: 96.19%
Result: Top-1: 81.77%, Top-5: 96.19%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.83%
[Alpha=0.30] Top-5 Accuracy: 96.20%
Result: Top-1: 81.83%, Top-5: 96.20%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.79%
[Alpha=0.30] Top-5 Accuracy: 96.22%
Result: Top-1: 81.79%, Top-5: 96.22%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.86%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.86%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.85%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.85%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.81%
[Alpha=0.30] Top-5 Accuracy: 96.22%
Result: Top-1: 81.81%, Top-5: 96.22%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.82%
[Alpha=0.30] Top-5 Accuracy: 96.18%
Result: Top-1: 81.82%, Top-5: 96.18%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.86%
[Alpha=0.30] Top-5 Accuracy: 96.22%
Result: Top-1: 81.86%, Top-5: 96.22%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.85%
[Alpha=0.30] Top-5 Accuracy: 96.20%
Result: Top-1: 81.85%, Top-5: 96.20%

============================================================
Testing: alpha=0.3, clusters=8, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.86%
[Alpha=0.30] Top-5 Accuracy: 96.20%
Result: Top-1: 81.86%, Top-5: 96.20%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.52%
[Alpha=0.30] Top-5 Accuracy: 96.19%
Result: Top-1: 81.52%, Top-5: 96.19%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.76%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.76%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.82%
[Alpha=0.30] Top-5 Accuracy: 96.22%
Result: Top-1: 81.82%, Top-5: 96.22%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.76%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.76%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.83%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.83%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.80%
[Alpha=0.30] Top-5 Accuracy: 96.18%
Result: Top-1: 81.80%, Top-5: 96.18%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.83%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.83%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.79%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.79%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.76%
[Alpha=0.30] Top-5 Accuracy: 96.22%
Result: Top-1: 81.76%, Top-5: 96.22%

============================================================
Testing: alpha=0.3, clusters=16, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.81%
[Alpha=0.30] Top-5 Accuracy: 96.19%
Result: Top-1: 81.81%, Top-5: 96.19%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.40%
[Alpha=0.30] Top-5 Accuracy: 96.13%
Result: Top-1: 81.40%, Top-5: 96.13%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.71%
[Alpha=0.30] Top-5 Accuracy: 96.18%
Result: Top-1: 81.71%, Top-5: 96.18%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.74%
[Alpha=0.30] Top-5 Accuracy: 96.18%
Result: Top-1: 81.74%, Top-5: 96.18%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.73%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.73%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.73%
[Alpha=0.30] Top-5 Accuracy: 96.18%
Result: Top-1: 81.73%, Top-5: 96.18%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.81%
[Alpha=0.30] Top-5 Accuracy: 96.19%
Result: Top-1: 81.81%, Top-5: 96.19%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.80%
[Alpha=0.30] Top-5 Accuracy: 96.17%
Result: Top-1: 81.80%, Top-5: 96.17%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.69%
[Alpha=0.30] Top-5 Accuracy: 96.19%
Result: Top-1: 81.69%, Top-5: 96.19%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.70%
[Alpha=0.30] Top-5 Accuracy: 96.18%
Result: Top-1: 81.70%, Top-5: 96.18%

============================================================
Testing: alpha=0.3, clusters=32, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.72%
[Alpha=0.30] Top-5 Accuracy: 96.16%
Result: Top-1: 81.72%, Top-5: 96.16%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 80.49%
[Alpha=0.30] Top-5 Accuracy: 96.01%
Result: Top-1: 80.49%, Top-5: 96.01%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.35%
[Alpha=0.30] Top-5 Accuracy: 96.12%
Result: Top-1: 81.35%, Top-5: 96.12%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.59%
[Alpha=0.30] Top-5 Accuracy: 96.17%
Result: Top-1: 81.59%, Top-5: 96.17%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.58%
[Alpha=0.30] Top-5 Accuracy: 96.14%
Result: Top-1: 81.58%, Top-5: 96.14%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.53%
[Alpha=0.30] Top-5 Accuracy: 96.15%
Result: Top-1: 81.53%, Top-5: 96.15%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.41%
[Alpha=0.30] Top-5 Accuracy: 96.14%
Result: Top-1: 81.41%, Top-5: 96.14%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.43%
[Alpha=0.30] Top-5 Accuracy: 96.15%
Result: Top-1: 81.43%, Top-5: 96.15%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.54%
[Alpha=0.30] Top-5 Accuracy: 96.12%
Result: Top-1: 81.54%, Top-5: 96.12%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.58%
[Alpha=0.30] Top-5 Accuracy: 96.21%
Result: Top-1: 81.58%, Top-5: 96.21%

============================================================
Testing: alpha=0.3, clusters=64, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.49%
[Alpha=0.30] Top-5 Accuracy: 96.13%
Result: Top-1: 81.49%, Top-5: 96.13%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 78.96%
[Alpha=0.30] Top-5 Accuracy: 95.63%
Result: Top-1: 78.96%, Top-5: 95.63%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 80.56%
[Alpha=0.30] Top-5 Accuracy: 95.83%
Result: Top-1: 80.56%, Top-5: 95.83%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 80.78%
[Alpha=0.30] Top-5 Accuracy: 96.02%
Result: Top-1: 80.78%, Top-5: 96.02%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.09%
[Alpha=0.30] Top-5 Accuracy: 95.97%
Result: Top-1: 81.09%, Top-5: 95.97%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.09%
[Alpha=0.30] Top-5 Accuracy: 96.02%
Result: Top-1: 81.09%, Top-5: 96.02%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.12%
[Alpha=0.30] Top-5 Accuracy: 95.68%
Result: Top-1: 81.12%, Top-5: 95.68%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.16%
[Alpha=0.30] Top-5 Accuracy: 96.05%
Result: Top-1: 81.16%, Top-5: 96.05%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.16%
[Alpha=0.30] Top-5 Accuracy: 96.06%
Result: Top-1: 81.16%, Top-5: 96.06%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.34%
[Alpha=0.30] Top-5 Accuracy: 96.12%
Result: Top-1: 81.34%, Top-5: 96.12%

============================================================
Testing: alpha=0.3, clusters=128, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 81.12%
[Alpha=0.30] Top-5 Accuracy: 95.99%
Result: Top-1: 81.12%, Top-5: 95.99%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=1
============================================================
[Alpha=0.30] Top-1 Accuracy: 63.75%
[Alpha=0.30] Top-5 Accuracy: 82.72%
Result: Top-1: 63.75%, Top-5: 82.72%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=25
============================================================
[Alpha=0.30] Top-1 Accuracy: 77.81%
[Alpha=0.30] Top-5 Accuracy: 94.10%
Result: Top-1: 77.81%, Top-5: 94.10%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=50
============================================================
[Alpha=0.30] Top-1 Accuracy: 52.81%
[Alpha=0.30] Top-5 Accuracy: 82.05%
Result: Top-1: 52.81%, Top-5: 82.05%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=75
============================================================
[Alpha=0.30] Top-1 Accuracy: 73.47%
[Alpha=0.30] Top-5 Accuracy: 90.88%
Result: Top-1: 73.47%, Top-5: 90.88%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=100
============================================================
[Alpha=0.30] Top-1 Accuracy: 78.92%
[Alpha=0.30] Top-5 Accuracy: 93.75%
Result: Top-1: 78.92%, Top-5: 93.75%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=125
============================================================
[Alpha=0.30] Top-1 Accuracy: 79.90%
[Alpha=0.30] Top-5 Accuracy: 95.26%
Result: Top-1: 79.90%, Top-5: 95.26%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=150
============================================================
[Alpha=0.30] Top-1 Accuracy: 79.57%
[Alpha=0.30] Top-5 Accuracy: 95.38%
Result: Top-1: 79.57%, Top-5: 95.38%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=175
============================================================
[Alpha=0.30] Top-1 Accuracy: 80.39%
[Alpha=0.30] Top-5 Accuracy: 95.56%
Result: Top-1: 80.39%, Top-5: 95.56%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=200
============================================================
[Alpha=0.30] Top-1 Accuracy: 80.32%
[Alpha=0.30] Top-5 Accuracy: 95.68%
Result: Top-1: 80.32%, Top-5: 95.68%

============================================================
Testing: alpha=0.3, clusters=256, pca_dim=220
============================================================
[Alpha=0.30] Top-1 Accuracy: 79.59%
[Alpha=0.30] Top-5 Accuracy: 95.45%
Result: Top-1: 79.59%, Top-5: 95.45%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.55%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.55%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.72%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.72%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.68%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.68%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.70%
[Alpha=0.40] Top-5 Accuracy: 96.16%
Result: Top-1: 81.70%, Top-5: 96.16%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.73%
[Alpha=0.40] Top-5 Accuracy: 96.15%
Result: Top-1: 81.73%, Top-5: 96.15%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.66%
[Alpha=0.40] Top-5 Accuracy: 96.15%
Result: Top-1: 81.66%, Top-5: 96.15%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.70%
[Alpha=0.40] Top-5 Accuracy: 96.13%
Result: Top-1: 81.70%, Top-5: 96.13%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.77%
[Alpha=0.40] Top-5 Accuracy: 96.16%
Result: Top-1: 81.77%, Top-5: 96.16%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.69%
[Alpha=0.40] Top-5 Accuracy: 96.13%
Result: Top-1: 81.69%, Top-5: 96.13%

============================================================
Testing: alpha=0.4, clusters=8, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.68%
[Alpha=0.40] Top-5 Accuracy: 96.15%
Result: Top-1: 81.68%, Top-5: 96.15%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.07%
[Alpha=0.40] Top-5 Accuracy: 96.11%
Result: Top-1: 81.07%, Top-5: 96.11%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.57%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.57%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.60%
[Alpha=0.40] Top-5 Accuracy: 96.19%
Result: Top-1: 81.60%, Top-5: 96.19%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.60%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.60%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.68%
[Alpha=0.40] Top-5 Accuracy: 96.17%
Result: Top-1: 81.68%, Top-5: 96.17%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.72%
[Alpha=0.40] Top-5 Accuracy: 96.12%
Result: Top-1: 81.72%, Top-5: 96.12%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.68%
[Alpha=0.40] Top-5 Accuracy: 96.17%
Result: Top-1: 81.68%, Top-5: 96.17%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.62%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.62%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.59%
[Alpha=0.40] Top-5 Accuracy: 96.19%
Result: Top-1: 81.59%, Top-5: 96.19%

============================================================
Testing: alpha=0.4, clusters=16, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.63%
[Alpha=0.40] Top-5 Accuracy: 96.15%
Result: Top-1: 81.63%, Top-5: 96.15%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.85%
[Alpha=0.40] Top-5 Accuracy: 96.03%
Result: Top-1: 80.85%, Top-5: 96.03%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.33%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.33%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.53%
[Alpha=0.40] Top-5 Accuracy: 96.11%
Result: Top-1: 81.53%, Top-5: 96.11%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.51%
[Alpha=0.40] Top-5 Accuracy: 96.14%
Result: Top-1: 81.51%, Top-5: 96.14%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.61%
[Alpha=0.40] Top-5 Accuracy: 96.09%
Result: Top-1: 81.61%, Top-5: 96.09%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.64%
[Alpha=0.40] Top-5 Accuracy: 96.09%
Result: Top-1: 81.64%, Top-5: 96.09%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.61%
[Alpha=0.40] Top-5 Accuracy: 96.10%
Result: Top-1: 81.61%, Top-5: 96.10%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.48%
[Alpha=0.40] Top-5 Accuracy: 96.09%
Result: Top-1: 81.48%, Top-5: 96.09%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.49%
[Alpha=0.40] Top-5 Accuracy: 96.07%
Result: Top-1: 81.49%, Top-5: 96.07%

============================================================
Testing: alpha=0.4, clusters=32, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.62%
[Alpha=0.40] Top-5 Accuracy: 96.03%
Result: Top-1: 81.62%, Top-5: 96.03%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 79.11%
[Alpha=0.40] Top-5 Accuracy: 95.71%
Result: Top-1: 79.11%, Top-5: 95.71%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.75%
[Alpha=0.40] Top-5 Accuracy: 95.99%
Result: Top-1: 80.75%, Top-5: 95.99%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.27%
[Alpha=0.40] Top-5 Accuracy: 96.08%
Result: Top-1: 81.27%, Top-5: 96.08%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.10%
[Alpha=0.40] Top-5 Accuracy: 95.99%
Result: Top-1: 81.10%, Top-5: 95.99%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.05%
[Alpha=0.40] Top-5 Accuracy: 96.02%
Result: Top-1: 81.05%, Top-5: 96.02%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.04%
[Alpha=0.40] Top-5 Accuracy: 96.04%
Result: Top-1: 81.04%, Top-5: 96.04%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.01%
[Alpha=0.40] Top-5 Accuracy: 96.05%
Result: Top-1: 81.01%, Top-5: 96.05%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.22%
[Alpha=0.40] Top-5 Accuracy: 96.00%
Result: Top-1: 81.22%, Top-5: 96.00%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 81.16%
[Alpha=0.40] Top-5 Accuracy: 96.06%
Result: Top-1: 81.16%, Top-5: 96.06%

============================================================
Testing: alpha=0.4, clusters=64, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.97%
[Alpha=0.40] Top-5 Accuracy: 96.02%
Result: Top-1: 80.97%, Top-5: 96.02%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 76.66%
[Alpha=0.40] Top-5 Accuracy: 94.79%
Result: Top-1: 76.66%, Top-5: 94.79%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 79.70%
[Alpha=0.40] Top-5 Accuracy: 95.59%
Result: Top-1: 79.70%, Top-5: 95.59%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 79.72%
[Alpha=0.40] Top-5 Accuracy: 95.73%
Result: Top-1: 79.72%, Top-5: 95.73%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.38%
[Alpha=0.40] Top-5 Accuracy: 95.76%
Result: Top-1: 80.38%, Top-5: 95.76%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.30%
[Alpha=0.40] Top-5 Accuracy: 95.77%
Result: Top-1: 80.30%, Top-5: 95.77%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.49%
[Alpha=0.40] Top-5 Accuracy: 95.50%
Result: Top-1: 80.49%, Top-5: 95.50%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.65%
[Alpha=0.40] Top-5 Accuracy: 95.85%
Result: Top-1: 80.65%, Top-5: 95.85%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.45%
[Alpha=0.40] Top-5 Accuracy: 95.78%
Result: Top-1: 80.45%, Top-5: 95.78%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.84%
[Alpha=0.40] Top-5 Accuracy: 95.94%
Result: Top-1: 80.84%, Top-5: 95.94%

============================================================
Testing: alpha=0.4, clusters=128, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 80.37%
[Alpha=0.40] Top-5 Accuracy: 95.80%
Result: Top-1: 80.37%, Top-5: 95.80%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=1
============================================================
[Alpha=0.40] Top-1 Accuracy: 59.95%
[Alpha=0.40] Top-5 Accuracy: 79.97%
Result: Top-1: 59.95%, Top-5: 79.97%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=25
============================================================
[Alpha=0.40] Top-1 Accuracy: 75.19%
[Alpha=0.40] Top-5 Accuracy: 93.22%
Result: Top-1: 75.19%, Top-5: 93.22%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=50
============================================================
[Alpha=0.40] Top-1 Accuracy: 51.03%
[Alpha=0.40] Top-5 Accuracy: 75.82%
Result: Top-1: 51.03%, Top-5: 75.82%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=75
============================================================
[Alpha=0.40] Top-1 Accuracy: 71.58%
[Alpha=0.40] Top-5 Accuracy: 88.85%
Result: Top-1: 71.58%, Top-5: 88.85%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=100
============================================================
[Alpha=0.40] Top-1 Accuracy: 77.80%
[Alpha=0.40] Top-5 Accuracy: 93.26%
Result: Top-1: 77.80%, Top-5: 93.26%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=125
============================================================
[Alpha=0.40] Top-1 Accuracy: 78.54%
[Alpha=0.40] Top-5 Accuracy: 94.66%
Result: Top-1: 78.54%, Top-5: 94.66%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=150
============================================================
[Alpha=0.40] Top-1 Accuracy: 77.69%
[Alpha=0.40] Top-5 Accuracy: 94.68%
Result: Top-1: 77.69%, Top-5: 94.68%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=175
============================================================
[Alpha=0.40] Top-1 Accuracy: 79.23%
[Alpha=0.40] Top-5 Accuracy: 95.02%
Result: Top-1: 79.23%, Top-5: 95.02%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=200
============================================================
[Alpha=0.40] Top-1 Accuracy: 78.95%
[Alpha=0.40] Top-5 Accuracy: 95.29%
Result: Top-1: 78.95%, Top-5: 95.29%

============================================================
Testing: alpha=0.4, clusters=256, pca_dim=220
============================================================
[Alpha=0.40] Top-1 Accuracy: 78.34%
[Alpha=0.40] Top-5 Accuracy: 94.93%
Result: Top-1: 78.34%, Top-5: 94.93%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.28%
[Alpha=0.50] Top-5 Accuracy: 96.12%
Result: Top-1: 81.28%, Top-5: 96.12%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.45%
[Alpha=0.50] Top-5 Accuracy: 96.08%
Result: Top-1: 81.45%, Top-5: 96.08%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.40%
[Alpha=0.50] Top-5 Accuracy: 96.06%
Result: Top-1: 81.40%, Top-5: 96.06%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.43%
[Alpha=0.50] Top-5 Accuracy: 96.08%
Result: Top-1: 81.43%, Top-5: 96.08%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.44%
[Alpha=0.50] Top-5 Accuracy: 96.05%
Result: Top-1: 81.44%, Top-5: 96.05%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.39%
[Alpha=0.50] Top-5 Accuracy: 96.07%
Result: Top-1: 81.39%, Top-5: 96.07%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.36%
[Alpha=0.50] Top-5 Accuracy: 96.04%
Result: Top-1: 81.36%, Top-5: 96.04%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.47%
[Alpha=0.50] Top-5 Accuracy: 96.09%
Result: Top-1: 81.47%, Top-5: 96.09%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.46%
[Alpha=0.50] Top-5 Accuracy: 96.04%
Result: Top-1: 81.46%, Top-5: 96.04%

============================================================
Testing: alpha=0.5, clusters=8, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.36%
[Alpha=0.50] Top-5 Accuracy: 96.05%
Result: Top-1: 81.36%, Top-5: 96.05%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.60%
[Alpha=0.50] Top-5 Accuracy: 95.99%
Result: Top-1: 80.60%, Top-5: 95.99%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.34%
[Alpha=0.50] Top-5 Accuracy: 96.02%
Result: Top-1: 81.34%, Top-5: 96.02%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.37%
[Alpha=0.50] Top-5 Accuracy: 96.09%
Result: Top-1: 81.37%, Top-5: 96.09%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.40%
[Alpha=0.50] Top-5 Accuracy: 96.04%
Result: Top-1: 81.40%, Top-5: 96.04%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.40%
[Alpha=0.50] Top-5 Accuracy: 96.05%
Result: Top-1: 81.40%, Top-5: 96.05%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.45%
[Alpha=0.50] Top-5 Accuracy: 96.00%
Result: Top-1: 81.45%, Top-5: 96.00%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.39%
[Alpha=0.50] Top-5 Accuracy: 96.06%
Result: Top-1: 81.39%, Top-5: 96.06%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.35%
[Alpha=0.50] Top-5 Accuracy: 96.00%
Result: Top-1: 81.35%, Top-5: 96.00%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.32%
[Alpha=0.50] Top-5 Accuracy: 96.06%
Result: Top-1: 81.32%, Top-5: 96.06%

============================================================
Testing: alpha=0.5, clusters=16, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.38%
[Alpha=0.50] Top-5 Accuracy: 96.03%
Result: Top-1: 81.38%, Top-5: 96.03%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.04%
[Alpha=0.50] Top-5 Accuracy: 95.87%
Result: Top-1: 80.04%, Top-5: 95.87%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.80%
[Alpha=0.50] Top-5 Accuracy: 96.01%
Result: Top-1: 80.80%, Top-5: 96.01%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.10%
[Alpha=0.50] Top-5 Accuracy: 95.94%
Result: Top-1: 81.10%, Top-5: 95.94%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.06%
[Alpha=0.50] Top-5 Accuracy: 95.98%
Result: Top-1: 81.06%, Top-5: 95.98%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.20%
[Alpha=0.50] Top-5 Accuracy: 95.97%
Result: Top-1: 81.20%, Top-5: 95.97%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.23%
[Alpha=0.50] Top-5 Accuracy: 95.92%
Result: Top-1: 81.23%, Top-5: 95.92%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.11%
[Alpha=0.50] Top-5 Accuracy: 95.97%
Result: Top-1: 81.11%, Top-5: 95.97%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.13%
[Alpha=0.50] Top-5 Accuracy: 95.91%
Result: Top-1: 81.13%, Top-5: 95.91%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.15%
[Alpha=0.50] Top-5 Accuracy: 95.90%
Result: Top-1: 81.15%, Top-5: 95.90%

============================================================
Testing: alpha=0.5, clusters=32, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 81.16%
[Alpha=0.50] Top-5 Accuracy: 95.90%
Result: Top-1: 81.16%, Top-5: 95.90%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 77.26%
[Alpha=0.50] Top-5 Accuracy: 95.24%
Result: Top-1: 77.26%, Top-5: 95.24%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.81%
[Alpha=0.50] Top-5 Accuracy: 95.73%
Result: Top-1: 79.81%, Top-5: 95.73%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.66%
[Alpha=0.50] Top-5 Accuracy: 95.86%
Result: Top-1: 80.66%, Top-5: 95.86%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.49%
[Alpha=0.50] Top-5 Accuracy: 95.74%
Result: Top-1: 80.49%, Top-5: 95.74%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.34%
[Alpha=0.50] Top-5 Accuracy: 95.85%
Result: Top-1: 80.34%, Top-5: 95.85%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.37%
[Alpha=0.50] Top-5 Accuracy: 95.75%
Result: Top-1: 80.37%, Top-5: 95.75%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.27%
[Alpha=0.50] Top-5 Accuracy: 95.81%
Result: Top-1: 80.27%, Top-5: 95.81%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.66%
[Alpha=0.50] Top-5 Accuracy: 95.83%
Result: Top-1: 80.66%, Top-5: 95.83%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.46%
[Alpha=0.50] Top-5 Accuracy: 95.82%
Result: Top-1: 80.46%, Top-5: 95.82%

============================================================
Testing: alpha=0.5, clusters=64, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.11%
[Alpha=0.50] Top-5 Accuracy: 95.77%
Result: Top-1: 80.11%, Top-5: 95.77%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 73.59%
[Alpha=0.50] Top-5 Accuracy: 93.35%
Result: Top-1: 73.59%, Top-5: 93.35%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 78.49%
[Alpha=0.50] Top-5 Accuracy: 95.19%
Result: Top-1: 78.49%, Top-5: 95.19%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 78.14%
[Alpha=0.50] Top-5 Accuracy: 95.23%
Result: Top-1: 78.14%, Top-5: 95.23%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.30%
[Alpha=0.50] Top-5 Accuracy: 95.43%
Result: Top-1: 79.30%, Top-5: 95.43%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.27%
[Alpha=0.50] Top-5 Accuracy: 95.40%
Result: Top-1: 79.27%, Top-5: 95.40%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.67%
[Alpha=0.50] Top-5 Accuracy: 95.18%
Result: Top-1: 79.67%, Top-5: 95.18%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.80%
[Alpha=0.50] Top-5 Accuracy: 95.48%
Result: Top-1: 79.80%, Top-5: 95.48%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.30%
[Alpha=0.50] Top-5 Accuracy: 95.29%
Result: Top-1: 79.30%, Top-5: 95.29%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 80.01%
[Alpha=0.50] Top-5 Accuracy: 95.67%
Result: Top-1: 80.01%, Top-5: 95.67%

============================================================
Testing: alpha=0.5, clusters=128, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 79.31%
[Alpha=0.50] Top-5 Accuracy: 95.51%
Result: Top-1: 79.31%, Top-5: 95.51%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=1
============================================================
[Alpha=0.50] Top-1 Accuracy: 53.64%
[Alpha=0.50] Top-5 Accuracy: 76.58%
Result: Top-1: 53.64%, Top-5: 76.58%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=25
============================================================
[Alpha=0.50] Top-1 Accuracy: 71.87%
[Alpha=0.50] Top-5 Accuracy: 91.62%
Result: Top-1: 71.87%, Top-5: 91.62%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=50
============================================================
[Alpha=0.50] Top-1 Accuracy: 48.68%
[Alpha=0.50] Top-5 Accuracy: 71.39%
Result: Top-1: 48.68%, Top-5: 71.39%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=75
============================================================
[Alpha=0.50] Top-1 Accuracy: 66.94%
[Alpha=0.50] Top-5 Accuracy: 87.00%
Result: Top-1: 66.94%, Top-5: 87.00%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=100
============================================================
[Alpha=0.50] Top-1 Accuracy: 75.90%
[Alpha=0.50] Top-5 Accuracy: 92.46%
Result: Top-1: 75.90%, Top-5: 92.46%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=125
============================================================
[Alpha=0.50] Top-1 Accuracy: 76.39%
[Alpha=0.50] Top-5 Accuracy: 93.72%
Result: Top-1: 76.39%, Top-5: 93.72%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=150
============================================================
[Alpha=0.50] Top-1 Accuracy: 74.85%
[Alpha=0.50] Top-5 Accuracy: 93.40%
Result: Top-1: 74.85%, Top-5: 93.40%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=175
============================================================
[Alpha=0.50] Top-1 Accuracy: 77.42%
[Alpha=0.50] Top-5 Accuracy: 94.27%
Result: Top-1: 77.42%, Top-5: 94.27%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=200
============================================================
[Alpha=0.50] Top-1 Accuracy: 76.90%
[Alpha=0.50] Top-5 Accuracy: 94.50%
Result: Top-1: 76.90%, Top-5: 94.50%

============================================================
Testing: alpha=0.5, clusters=256, pca_dim=220
============================================================
[Alpha=0.50] Top-1 Accuracy: 76.42%
[Alpha=0.50] Top-5 Accuracy: 94.11%
Result: Top-1: 76.42%, Top-5: 94.11%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.96%
[Alpha=0.60] Top-5 Accuracy: 96.02%
Result: Top-1: 80.96%, Top-5: 96.02%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.79%
[Alpha=0.60] Top-5 Accuracy: 95.95%
Result: Top-1: 80.79%, Top-5: 95.95%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.71%
[Alpha=0.60] Top-5 Accuracy: 95.94%
Result: Top-1: 80.71%, Top-5: 95.94%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.76%
[Alpha=0.60] Top-5 Accuracy: 95.92%
Result: Top-1: 80.76%, Top-5: 95.92%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.75%
[Alpha=0.60] Top-5 Accuracy: 95.91%
Result: Top-1: 80.75%, Top-5: 95.91%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.70%
[Alpha=0.60] Top-5 Accuracy: 95.92%
Result: Top-1: 80.70%, Top-5: 95.92%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.74%
[Alpha=0.60] Top-5 Accuracy: 95.92%
Result: Top-1: 80.74%, Top-5: 95.92%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.75%
[Alpha=0.60] Top-5 Accuracy: 95.95%
Result: Top-1: 80.75%, Top-5: 95.95%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.78%
[Alpha=0.60] Top-5 Accuracy: 95.89%
Result: Top-1: 80.78%, Top-5: 95.89%

============================================================
Testing: alpha=0.6, clusters=8, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.68%
[Alpha=0.60] Top-5 Accuracy: 95.91%
Result: Top-1: 80.68%, Top-5: 95.91%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 79.88%
[Alpha=0.60] Top-5 Accuracy: 95.83%
Result: Top-1: 79.88%, Top-5: 95.83%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.89%
[Alpha=0.60] Top-5 Accuracy: 95.82%
Result: Top-1: 80.89%, Top-5: 95.82%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.83%
[Alpha=0.60] Top-5 Accuracy: 95.92%
Result: Top-1: 80.83%, Top-5: 95.92%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.76%
[Alpha=0.60] Top-5 Accuracy: 95.85%
Result: Top-1: 80.76%, Top-5: 95.85%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.83%
[Alpha=0.60] Top-5 Accuracy: 95.94%
Result: Top-1: 80.83%, Top-5: 95.94%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.89%
[Alpha=0.60] Top-5 Accuracy: 95.81%
Result: Top-1: 80.89%, Top-5: 95.81%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.94%
[Alpha=0.60] Top-5 Accuracy: 95.91%
Result: Top-1: 80.94%, Top-5: 95.91%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.12%
[Alpha=0.60] Top-5 Accuracy: 95.84%
Result: Top-1: 80.12%, Top-5: 95.84%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.79%
[Alpha=0.60] Top-5 Accuracy: 95.89%
Result: Top-1: 80.79%, Top-5: 95.89%

============================================================
Testing: alpha=0.6, clusters=16, pca_dim=220
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.96%
[Alpha=0.60] Top-5 Accuracy: 95.89%
Result: Top-1: 80.96%, Top-5: 95.89%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=1
============================================================
[Alpha=0.60] Top-1 Accuracy: 78.89%
[Alpha=0.60] Top-5 Accuracy: 95.59%
Result: Top-1: 78.89%, Top-5: 95.59%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=25
============================================================
[Alpha=0.60] Top-1 Accuracy: 79.93%
[Alpha=0.60] Top-5 Accuracy: 95.81%
Result: Top-1: 79.93%, Top-5: 95.81%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=50
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.03%
[Alpha=0.60] Top-5 Accuracy: 95.77%
Result: Top-1: 80.03%, Top-5: 95.77%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=75
============================================================
[Alpha=0.60] Top-1 Accuracy: 80.09%
[Alpha=0.60] Top-5 Accuracy: 95.79%
Result: Top-1: 80.09%, Top-5: 95.79%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=100
============================================================
[Alpha=0.60] Top-1 Accuracy: 79.97%
[Alpha=0.60] Top-5 Accuracy: 95.73%
Result: Top-1: 79.97%, Top-5: 95.73%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=125
============================================================
[Alpha=0.60] Top-1 Accuracy: 78.79%
[Alpha=0.60] Top-5 Accuracy: 95.71%
Result: Top-1: 78.79%, Top-5: 95.71%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=150
============================================================
[Alpha=0.60] Top-1 Accuracy: 79.89%
[Alpha=0.60] Top-5 Accuracy: 95.75%
Result: Top-1: 79.89%, Top-5: 95.75%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=175
============================================================
[Alpha=0.60] Top-1 Accuracy: 79.84%
[Alpha=0.60] Top-5 Accuracy: 95.69%
Result: Top-1: 79.84%, Top-5: 95.69%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=200
============================================================
[Alpha=0.60] Top-1 Accuracy: 79.02%
[Alpha=0.60] Top-5 Accuracy: 95.73%
Result: Top-1: 79.02%, Top-5: 95.73%

============================================================
Testing: alpha=0.6, clusters=32, pca_dim=220
============================================================
slurmstepd-jnfat06: error: *** JOB 1659767 ON jnfat06 CANCELLED AT 2025-09-12T13:43:28 ***
